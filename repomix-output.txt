This file is a merged representation of the entire codebase, combined into a single document by Repomix.

================================================================
File Summary
================================================================

Purpose:
--------
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.

File Format:
------------
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Multiple file entries, each consisting of:
  a. A separator line (================)
  b. The file path (File: path/to/file)
  c. Another separator line
  d. The full contents of the file
  e. A blank line

Usage Guidelines:
-----------------
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.

Notes:
------
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded

Additional Info:
----------------

================================================================
Directory Structure
================================================================
__init__.py
examples/generate_uml_diagram.py
examples/README.md
examples/uml_structure.puml
pipeline/analyzer/__init__.py
pipeline/analyzer/pdf.py
pipeline/cleaner/__init__.py
pipeline/cleaner/pdf.py
pipeline/config/__init__.py
pipeline/config/config.py
pipeline/config/example_config.yaml
pipeline/config/hvac_config.json
pipeline/config/hvac_config.yaml
pipeline/core/file_processor.py
pipeline/data/output/pdf/json/MF-SPECS_232500 FL - HVAC WATER TREATMENT.json
pipeline/data/tests/excel/sample.csv
pipeline/data/tests/text/sample.txt
pipeline/docs/class_diagram.puml
pipeline/docs/CLASSIFICATION_FIX.md
pipeline/docs/document_classification.md
pipeline/docs/er_diagram.puml
pipeline/docs/pdf-extraction-implementation-plan.md
pipeline/docs/pipeline_c4_diagram.puml
pipeline/docs/pipeline_diagram.puml
pipeline/docs/pipeline-plan.md
pipeline/docs/schema_analysis.md
pipeline/ENHANCEMENT_CHECKLIST.md
pipeline/ENHANCEMENT_SUMMARY.md
pipeline/ENHANCEMENTS_README.md
pipeline/examples/batch_processing_example.py
pipeline/examples/config.yaml
pipeline/examples/document_classification_example.py
pipeline/examples/pdf_extraction_example.py
pipeline/examples/schema_analysis_example.py
pipeline/IMPLEMENTATION_PLAN.md
pipeline/ISSUE_FIXES.md
pipeline/models/models.py
pipeline/PIPELINE_USAGE.md
pipeline/pipeline.py
pipeline/processors/classifiers/__init__.py
pipeline/processors/classifiers/pattern_matcher.py
pipeline/processors/classifiers/rule_based.py
pipeline/processors/document_classifier.py
pipeline/processors/formatters/factory.py
pipeline/processors/formatters/json_formatter.py
pipeline/processors/formatters/markdown_formatter.py
pipeline/processors/pdf_extractor.py
pipeline/processors/pdf_formatter.py
pipeline/processors/pdf_validator.py
pipeline/pyproject.toml
pipeline/pytest.ini
pipeline/README.md
pipeline/rename_input_files.py
pipeline/requirements-dev.txt
pipeline/run_pipeline.py
pipeline/run_tests.py
pipeline/SCHEMA_VISUALIZATION.md
pipeline/schema/__init__.py
pipeline/schema/analyzer.py
pipeline/schema/data/schemas/form_20250314231329.json
pipeline/schema/data/schemas/form_20250314231331.json
pipeline/schema/data/schemas/form_20250314231332.json
pipeline/schema/data/schemas/form_20250314231335.json
pipeline/schema/data/schemas/form_20250314231336.json
pipeline/schema/data/schemas/form_20250314231339.json
pipeline/schema/data/schemas/form_20250314231340.json
pipeline/schema/data/schemas/form_20250314231341.json
pipeline/schema/data/schemas/form_20250314231343.json
pipeline/schema/data/schemas/form_20250314231344.json
pipeline/schema/data/schemas/generic_document_20250314230806.json
pipeline/schema/data/schemas/generic_document_20250314230807.json
pipeline/schema/data/schemas/generic_document_20250314230809.json
pipeline/schema/data/schemas/generic_document_20250314231152.json
pipeline/schema/data/schemas/generic_document_20250314231153.json
pipeline/schema/data/schemas/generic_document_20250314231154.json
pipeline/schema/data/schemas/generic_document_20250314231156.json
pipeline/schema/data/schemas/generic_document_20250314231157.json
pipeline/schema/data/schemas/generic_document_20250314231158.json
pipeline/schema/data/schemas/generic_document_20250314231159.json
pipeline/schema/data/schemas/generic_document_20250314231200.json
pipeline/schema/data/schemas/generic_document_20250314231201.json
pipeline/schema/data/schemas/generic_document_20250314231202.json
pipeline/schema/data/schemas/generic_document_20250314231203.json
pipeline/schema/data/schemas/generic_document_20250314231204.json
pipeline/schema/data/schemas/generic_document_20250314231205.json
pipeline/schema/data/schemas/generic_document_20250314231206.json
pipeline/schema/data/schemas/generic_document_20250314231208.json
pipeline/schema/data/schemas/generic_document_20250314231209.json
pipeline/schema/data/schemas/generic_document_20250314231210.json
pipeline/schema/data/schemas/generic_document_20250314231212.json
pipeline/schema/data/schemas/generic_document_20250314231213.json
pipeline/schema/data/schemas/generic_document_20250314231214.json
pipeline/schema/data/schemas/generic_document_20250314231215.json
pipeline/schema/data/schemas/generic_document_20250314231216.json
pipeline/schema/data/schemas/generic_document_20250314231217.json
pipeline/schema/data/schemas/generic_document_20250314231218.json
pipeline/schema/data/schemas/generic_document_20250314231219.json
pipeline/schema/data/schemas/generic_document_20250314231220.json
pipeline/schema/data/schemas/generic_document_20250314231221.json
pipeline/schema/data/schemas/generic_document_20250314231222.json
pipeline/schema/data/schemas/generic_document_20250314231223.json
pipeline/schema/data/schemas/generic_document_20250314231224.json
pipeline/schema/data/schemas/generic_document_20250314231225.json
pipeline/schema/data/schemas/generic_document_20250314231227.json
pipeline/schema/data/schemas/generic_document_20250314231229.json
pipeline/schema/data/schemas/generic_document_20250314231230.json
pipeline/schema/data/schemas/generic_document_20250314231231.json
pipeline/schema/data/schemas/generic_document_20250314231232.json
pipeline/schema/data/schemas/generic_document_20250314231233.json
pipeline/schema/data/schemas/generic_document_20250314231234.json
pipeline/schema/data/schemas/generic_document_20250314231235.json
pipeline/schema/data/schemas/generic_document_20250314231237.json
pipeline/schema/data/schemas/generic_document_20250314231238.json
pipeline/schema/data/schemas/generic_document_20250314231239.json
pipeline/schema/data/schemas/generic_document_20250314231240.json
pipeline/schema/data/schemas/generic_document_20250314231241.json
pipeline/schema/data/schemas/generic_document_20250314231242.json
pipeline/schema/data/schemas/generic_document_20250314231243.json
pipeline/schema/data/schemas/generic_document_20250314231244.json
pipeline/schema/data/schemas/generic_document_20250314231245.json
pipeline/schema/data/schemas/generic_document_20250314231246.json
pipeline/schema/data/schemas/generic_document_20250314231247.json
pipeline/schema/data/schemas/generic_document_20250314231248.json
pipeline/schema/data/schemas/generic_document_20250314231249.json
pipeline/schema/data/schemas/generic_document_20250314231250.json
pipeline/schema/data/schemas/generic_document_20250314231251.json
pipeline/schema/data/schemas/generic_document_20250314231253.json
pipeline/schema/data/schemas/generic_document_20250314231255.json
pipeline/schema/data/schemas/generic_document_20250314231256.json
pipeline/schema/data/schemas/generic_document_20250314231258.json
pipeline/schema/data/schemas/generic_document_20250314231300.json
pipeline/schema/data/schemas/generic_document_20250314231302.json
pipeline/schema/data/schemas/generic_document_20250314231305.json
pipeline/schema/data/schemas/generic_document_20250314231306.json
pipeline/schema/data/schemas/generic_document_20250314231308.json
pipeline/schema/data/schemas/generic_document_20250314231309.json
pipeline/schema/data/schemas/generic_document_20250314231310.json
pipeline/schema/data/schemas/generic_document_20250314231311.json
pipeline/schema/data/schemas/generic_document_20250314231312.json
pipeline/schema/data/schemas/generic_document_20250314231316.json
pipeline/schema/data/schemas/generic_document_20250314231320.json
pipeline/schema/data/schemas/generic_document_20250314231321.json
pipeline/schema/data/schemas/generic_document_20250314231322.json
pipeline/schema/data/schemas/generic_document_20250314231323.json
pipeline/schema/data/schemas/generic_document_20250314231324.json
pipeline/schema/data/schemas/generic_document_20250314231325.json
pipeline/schema/data/schemas/generic_document_20250314231326.json
pipeline/schema/data/schemas/generic_document_20250314231327.json
pipeline/schema/data/schemas/generic_document_20250314231328.json
pipeline/schema/data/schemas/generic_document_20250314231333.json
pipeline/schema/data/schemas/generic_document_20250314231334.json
pipeline/schema/data/schemas/generic_document_20250314231341.json
pipeline/schema/data/schemas/generic_document_20250314231342.json
pipeline/schema/data/schemas/generic_document_20250314231345.json
pipeline/schema/data/schemas/generic_document_20250314231346.json
pipeline/schema/extended_registry.py
pipeline/schema/matchers.py
pipeline/schema/registry.py
pipeline/schema/templates/__init__.py
pipeline/schema/vectorizer.py
pipeline/schema/visualizer.py
pipeline/setup_pytest_env.py
pipeline/strategies/__init__.py
pipeline/strategies/base.py
pipeline/strategies/formatter.py
pipeline/SYSTEM_DIAGRAMS.md
pipeline/tests/__init__.py
pipeline/tests/analyzer/test_pdf_analyzer.py
pipeline/tests/cleaner/test_pdf_cleaner.py
pipeline/tests/conftest.py
pipeline/tests/processors/test_pdf_extractor.py
pipeline/tests/test_classification_fix.py
pipeline/tests/test_config.py
pipeline/tests/test_logging.py
pipeline/tests/test_models.py
pipeline/tests/test_pipeline_logging.py
pipeline/tests/test_pipeline.py
pipeline/utils/logging.py
pipeline/utils/progress.py
pipeline/uv.lock
pipeline/VERIFICATION_PLAN.md
pipeline/verify/base.py
pipeline/verify/factory.py
pipeline/verify/json_tree.py
pipeline/verify/markdown.py
pipeline/visualize_schema.py
pyproject.toml
README.md
run_uml.py
uml/__init__.py
uml/cli/__init__.py
uml/cli/extract_activity.py
uml/cli/extract_app_sequences.py
uml/cli/extract_class.py
uml/cli/extract_sequence.py
uml/cli/extract_state.py
uml/cli/run_uml_generator.py
uml/cli/uml_cli.py
uml/config/__init__.py
uml/core/__init__.py
uml/core/exceptions.py
uml/core/filesystem.py
uml/core/interfaces.py
uml/core/service.py
uml/diagrams/__init__.py
uml/diagrams/activity_diagram/__init__.py
uml/diagrams/activity_diagram/analyzer.py
uml/diagrams/activity_diagram/generator.py
uml/diagrams/activity_diagram/models.py
uml/diagrams/base.py
uml/diagrams/class_diagram/__init__.py
uml/diagrams/class_diagram/analyzer.py
uml/diagrams/class_diagram/generator.py
uml/diagrams/class_diagram/models.py
uml/diagrams/sequence_diagram/__init__.py
uml/diagrams/sequence_diagram/analyzer.py
uml/diagrams/sequence_diagram/generator.py
uml/diagrams/sequence_diagram/models.py
uml/diagrams/state_diagram/__init__.py
uml/diagrams/state_diagram/analyzer.py
uml/diagrams/state_diagram/generator.py
uml/diagrams/state_diagram/models.py
uml/factories.py
uml/pyproject.toml
uml/README.md
uml/REVIEW.md
uml/run.py
uml/scripts/cleanup_old_code.py
uml/scripts/install_dev.py
uml/scripts/setup_venv.py
uml/utils/__init__.py
uml/utils/paths.py

================================================================
Files
================================================================

================
File: __init__.py
================
"""Utility scripts for sequence diagram generation and UML tools.

This package contains tools for:
- Extracting sequence diagrams from Python code
- Generating UML diagrams
- Running UML generators
"""

__version__ = "0.1.0"

================
File: examples/generate_uml_diagram.py
================
#!/usr/bin/env python
"""
Example script to generate a UML diagram of the UML generator itself.

This script demonstrates how to use the UML generator to analyze
the UML generator code structure and generate a class diagram.
"""

import os
import subprocess
import sys
from pathlib import Path

# Add the project root to the Python path
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

# Get the project root directory
PROJECT_ROOT = Path(__file__).parent.parent.parent
UML_DIR = PROJECT_ROOT / "utils" / "uml"
OUTPUT_DIR = PROJECT_ROOT / "docs" / "source" / "_generated_uml" / "examples"

# Create output directory if it doesn't exist
os.makedirs(OUTPUT_DIR, exist_ok=True)

print("Generating UML diagram of the UML generator itself...")
print(f"Source directory: {UML_DIR}")
print(f"Output directory: {OUTPUT_DIR}")

# Method 1: Using the extract_class.py script
print("\nMethod 1: Using extract_class.py")
try:
    subprocess.run(
        [
            sys.executable,
            str(PROJECT_ROOT / "utils" / "extract_class.py"),
            "--source",
            str(UML_DIR),
            "--output",
            str(OUTPUT_DIR),
            "--recursive",
            "--verbose",
        ],
        check=True,
    )
    print(f"Class diagram generated at {OUTPUT_DIR}/uml.puml")
except subprocess.CalledProcessError as e:
    print(f"Error running extract_class.py: {e}")

# Method 2: Using the unified run.py entry point
print("\nMethod 2: Using the unified entry point (run.py)")
try:
    subprocess.run(
        [
            sys.executable,
            str(PROJECT_ROOT / "utils" / "uml" / "run.py"),
            "--type",
            "class",
            "--source",
            str(UML_DIR),
            "--output",
            str(OUTPUT_DIR / "unified"),
            "--recursive",
            "--verbose",
        ],
        check=True,
    )
    print(f"Class diagram generated at {OUTPUT_DIR}/unified/class")
except subprocess.CalledProcessError as e:
    print(f"Error running run.py: {e}")

# Method 3: Using run_uml.py (which uses the virtual environment)
print("\nMethod 3: Using run_uml.py (requires virtual environment setup)")
print("To use this method, first run:")
print("  python utils/install_dev.py")
print("Then run:")
print(
    "  python utils/run_uml.py extract_class.py --source utils/uml --output docs/source/_generated_uml/examples --recursive",
)

print("\nTo view the generated diagrams, you need a PlantUML viewer or renderer.")
print(
    "You can use the PlantUML extension in VSCode or convert them to images using the PlantUML jar.",
)

# Instructions for installing the utils package
print("\nTo install the UML generator as a package:")
print("1. Run the installation script:")
print("   python utils/install_dev.py")
print("2. This will create a virtual environment in utils/.venv")
print("3. You can then use the UML generator scripts with the virtual environment")

================
File: examples/README.md
================
# UML Generator Examples

This directory contains examples demonstrating how to use the UML generator.

## Files

- `uml_structure.puml`: A PlantUML diagram showing the architecture of the UML generator itself
- `generate_uml_diagram.py`: A Python script demonstrating how to generate UML diagrams from code

## Using the UML Generator

The UML generator can be used in several ways:

### 1. Using the individual extraction scripts

```bash
# Generate class diagrams
python utils/extract_class.py --source path/to/source --output path/to/output

# Generate sequence diagrams
python utils/extract_sequence.py --source path/to/source --output path/to/output

# Generate activity diagrams
python utils/extract_activity.py --source path/to/source --output path/to/output

# Generate state diagrams
python utils/extract_state.py --source path/to/source --output path/to/output
```

### 2. Using the unified entry point

```bash
# Generate all diagram types
python utils/uml/run.py --type all --source path/to/source --output path/to/output

# Generate a specific diagram type
python utils/uml/run.py --type class --source path/to/source --output path/to/output
```

### 3. Using the run_uml.py script (with virtual environment)

First, set up the virtual environment:

```bash
python utils/install_dev.py
```

Then run the UML generator using the run_uml.py script:

```bash
python utils/run_uml.py extract_class.py --source path/to/source --output path/to/output
```

### 4. Using the main run_uml_generator.py script

This script generates diagrams for the entire project structure:

```bash
python utils/run_uml_generator.py
```

## Viewing the Generated Diagrams

The generated diagrams are in PlantUML format (.puml files). To view them, you can:

1. Use the PlantUML extension in VSCode
2. Use the PlantUML server at http://www.plantuml.com/plantuml/
3. Convert them to images using the PlantUML jar

## Example: Generate a UML Diagram of the UML Generator

To generate a UML diagram of the UML generator itself, run:

```bash
python utils/examples/generate_uml_diagram.py
```

This will generate class diagrams of the UML generator code in the `docs/source/_generated_uml/examples` directory.

## Example: View the UML Structure Diagram

The `uml_structure.puml` file contains a pre-created diagram showing the architecture of the UML generator. You can view this file using any PlantUML viewer.

================
File: examples/uml_structure.puml
================
@startuml UML Generator Structure

' Style settings
skinparam packageStyle rectangle
skinparam monochrome true
skinparam shadowing false
skinparam defaultFontName Arial
skinparam defaultFontSize 12
skinparam packageFontStyle bold
skinparam classFontStyle bold
skinparam classFontSize 14
skinparam classAttributeFontSize 12
skinparam linetype ortho

' Title
title UML Generator Architecture

' Packages
package "utils.uml" {
  class "run.py" as Run {
    +parse_arguments()
    +create_service()
    +get_source_paths()
    +main()
  }
  
  class "factories.py" as Factories {
    +DefaultDiagramFactory
  }
  
  package "core" {
    class "service.py" as Service {
      +UmlService
      +generate_diagram()
      +generate_diagrams()
      +generate_all_diagrams()
    }
    
    class "interfaces.py" as Interfaces {
      +DiagramAnalyzer
      +DiagramGenerator
      +DiagramFactory
      +DiagramModel
    }
    
    class "filesystem.py" as FileSystem {
      +FileSystem
      +read_file()
      +write_file()
      +ensure_directory()
    }
    
    class "exceptions.py" as Exceptions {
      +DiagramTypeError
      +AnalysisError
      +GenerationError
    }
  }
  
  package "diagrams" {
    package "class_diagram" {
      class "analyzer.py" as ClassAnalyzer {
        +ClassAnalyzer
        +analyze()
      }
      
      class "generator.py" as ClassGenerator {
        +ClassDiagramGenerator
        +generate_diagram()
      }
      
      class "models.py" as ClassModels {
        +ClassModel
        +ClassDiagram
      }
    }
    
    package "sequence_diagram" {
      class "analyzer.py" as SequenceAnalyzer {
        +SequenceAnalyzer
        +analyze()
      }
      
      class "generator.py" as SequenceGenerator {
        +SequenceDiagramGenerator
        +generate_diagram()
      }
      
      class "models.py" as SequenceModels {
        +SequenceModel
        +SequenceDiagram
      }
    }
    
    package "activity_diagram" {
      class "analyzer.py" as ActivityAnalyzer {
        +ActivityAnalyzer
        +analyze()
      }
      
      class "generator.py" as ActivityGenerator {
        +ActivityDiagramGenerator
        +generate_diagram()
      }
      
      class "models.py" as ActivityModels {
        +ActivityModel
        +ActivityDiagram
      }
    }
    
    package "state_diagram" {
      class "analyzer.py" as StateAnalyzer {
        +StateAnalyzer
        +analyze()
      }
      
      class "generator.py" as StateGenerator {
        +StateDiagramGenerator
        +generate_diagram()
      }
      
      class "models.py" as StateModels {
        +StateModel
        +StateDiagram
      }
    }
  }
}

' External scripts
package "utils" {
  class "extract_class.py" as ExtractClass {
    +parse_arguments()
    +main()
  }
  
  class "extract_sequence.py" as ExtractSequence {
    +parse_arguments()
    +main()
  }
  
  class "extract_activity.py" as ExtractActivity {
    +parse_arguments()
    +main()
  }
  
  class "extract_state.py" as ExtractState {
    +parse_arguments()
    +main()
  }
  
  class "run_uml_generator.py" as RunUmlGenerator {
    +get_directories_to_process()
    +generate_class_diagrams()
    +generate_sequence_diagrams()
    +generate_activity_diagrams()
    +generate_state_diagrams()
    +main()
  }
}

' Relationships
Run --> Service : uses
Run --> Factories : creates

Factories --> ClassAnalyzer : creates
Factories --> ClassGenerator : creates
Factories --> SequenceAnalyzer : creates
Factories --> SequenceGenerator : creates
Factories --> ActivityAnalyzer : creates
Factories --> ActivityGenerator : creates
Factories --> StateAnalyzer : creates
Factories --> StateGenerator : creates

Service --> Factories : uses
Service --> Interfaces : implements

ClassAnalyzer --> ClassModels : creates
ClassGenerator --> ClassModels : uses
SequenceAnalyzer --> SequenceModels : creates
SequenceGenerator --> SequenceModels : uses
ActivityAnalyzer --> ActivityModels : creates
ActivityGenerator --> ActivityModels : uses
StateAnalyzer --> StateModels : creates
StateGenerator --> StateModels : uses

ExtractClass --> Service : uses
ExtractSequence --> Service : uses
ExtractActivity --> Service : uses
ExtractState --> Service : uses
RunUmlGenerator --> Service : uses

@enduml

================
File: pipeline/analyzer/__init__.py
================
"""
Analyzer package.

This package provides document analysis functionality.
"""

from .pdf import PDFAnalyzer

__all__ = ["PDFAnalyzer"]

================
File: pipeline/analyzer/pdf.py
================
"""
PDF analyzer implementation.

This module provides functionality for analyzing PDF document structure.
"""

from typing import Any, Dict

import pypdf

from utils.pipeline.strategies.base import AnalyzerStrategy
from utils.pipeline.utils.logging import get_logger


class PDFAnalyzer(AnalyzerStrategy):
    """Analyzes PDF document structure and content."""

    def __init__(self):
        self.logger = get_logger(__name__)

    def analyze(self, input_path: str) -> Dict[str, Any]:
        """
        Analyze PDF document structure.

        Args:
            input_path: Path to PDF file

        Returns:
            Dictionary containing analysis results
        """
        self.logger.info("Analyzing PDF: %s", input_path)

        try:
            with open(input_path, "rb") as f:
                pdf = pypdf.PdfReader(f)

                # Extract basic metadata
                metadata = {}
                if pdf.metadata:
                    metadata = {
                        "title": pdf.metadata.get("/Title", ""),
                        "author": pdf.metadata.get("/Author", ""),
                        "subject": pdf.metadata.get("/Subject", ""),
                        "creator": pdf.metadata.get("/Creator", ""),
                        "producer": pdf.metadata.get("/Producer", ""),
                        "creation_date": pdf.metadata.get("/CreationDate", ""),
                        "modification_date": pdf.metadata.get("/ModDate", ""),
                    }

                # Extract page information
                pages = []
                for i, page in enumerate(pdf.pages):
                    page_info = {
                        "number": i + 1,
                        "size": page.mediabox,
                        "rotation": page.get("/Rotate", 0),
                        "content": page.extract_text(),
                    }
                    pages.append(page_info)

                # Build sections from content
                sections = []
                current_section = None

                for page in pages:
                    content = page["content"]
                    lines = content.split("\n")

                    for line in lines:
                        line = line.strip()
                        if not line:
                            continue

                        # Simple heuristic for section detection
                        if line.isupper() or line.startswith(
                            ("#", "Chapter", "Section")
                        ):
                            # New section
                            if current_section:
                                sections.append(current_section)
                            current_section = {
                                "title": line,
                                "content": "",
                                "level": 0 if line.isupper() else 1,
                            }
                        elif current_section:
                            current_section["content"] += line + "\n"
                        else:
                            # Text before first section
                            current_section = {
                                "title": "Introduction",
                                "content": line + "\n",
                                "level": 0,
                            }

                # Add last section
                if current_section:
                    sections.append(current_section)

                return {
                    "path": input_path,
                    "type": "pdf",
                    "metadata": metadata,
                    "pages": pages,
                    "sections": sections,
                }

        except Exception as e:
            self.logger.error("Failed to analyze PDF: %s", str(e), exc_info=True)
            # Return minimal structure for error case
            return {
                "path": input_path,
                "type": "pdf",
                "metadata": {},
                "sections": [
                    {
                        "title": "Error",
                        "content": f"Failed to analyze PDF: {str(e)}",
                        "level": 0,
                    }
                ],
            }

================
File: pipeline/cleaner/__init__.py
================
"""
Cleaner package.

This package provides document content cleaning and normalization functionality.
"""

from .pdf import PDFCleaner

__all__ = ["PDFCleaner"]

================
File: pipeline/cleaner/pdf.py
================
"""
PDF cleaner implementation.

This module provides functionality for cleaning and normalizing PDF content.
"""

import re
from typing import Any, Dict

from utils.pipeline.strategies.base import CleanerStrategy
from utils.pipeline.utils.logging import get_logger


class PDFCleaner(CleanerStrategy):
    """Cleans and normalizes PDF content."""

    def __init__(self):
        self.logger = get_logger(__name__)

    def clean(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Clean and normalize PDF content.

        Args:
            analysis_result: Analysis results from PDFAnalyzer

        Returns:
            Dictionary containing cleaned data
        """
        self.logger.info("Cleaning PDF content for: %s", analysis_result.get("path"))

        try:
            # Clean sections
            cleaned_sections = []
            for section in analysis_result.get("sections", []):
                cleaned_section = self._clean_section(section)
                if cleaned_section["content"].strip():  # Only keep non-empty sections
                    cleaned_sections.append(cleaned_section)

            # Clean metadata
            cleaned_metadata = self._clean_metadata(analysis_result.get("metadata", {}))

            # Clean page content
            cleaned_pages = []
            for page in analysis_result.get("pages", []):
                cleaned_page = self._clean_page(page)
                cleaned_pages.append(cleaned_page)

            return {
                "path": analysis_result.get("path"),
                "type": analysis_result.get("type"),
                "metadata": cleaned_metadata,
                "pages": cleaned_pages,
                "sections": cleaned_sections,
            }

        except Exception as e:
            self.logger.error("Failed to clean PDF content: %s", str(e), exc_info=True)
            return analysis_result  # Return original data on error

    def _clean_section(self, section: Dict[str, Any]) -> Dict[str, Any]:
        """Clean a single section."""
        content = section.get("content", "")

        # Remove excessive whitespace
        content = re.sub(r"\s+", " ", content)
        content = re.sub(r"\n\s*\n", "\n\n", content)
        content = content.strip()

        # Clean up common OCR artifacts
        content = re.sub(
            r"[^\S\n]+", " ", content
        )  # Replace multiple spaces with single
        content = re.sub(r"(?<=[.!?])\s+", "\n", content)  # Line break after sentences
        content = re.sub(r"[^\x00-\x7F]+", "", content)  # Remove non-ASCII characters

        return {
            "title": section.get("title", "").strip(),
            "content": content,
            "level": section.get("level", 0),
        }

    def _clean_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Clean metadata fields."""
        cleaned = {}
        for key, value in metadata.items():
            if isinstance(value, str):
                # Remove non-printable characters and normalize whitespace
                value = "".join(char for char in value if char.isprintable())
                value = re.sub(r"\s+", " ", value).strip()
            cleaned[key] = value
        return cleaned

    def _clean_page(self, page: Dict[str, Any]) -> Dict[str, Any]:
        """Clean page content."""
        content = page.get("content", "")

        # Basic content cleaning
        content = re.sub(r"\s+", " ", content)  # Normalize whitespace
        content = re.sub(r"[^\x00-\x7F]+", "", content)  # Remove non-ASCII
        content = content.strip()

        return {
            "number": page.get("number"),
            "size": page.get("size"),
            "rotation": page.get("rotation", 0),
            "content": content,
        }

================
File: pipeline/config/__init__.py
================
"""
Configuration module for the pipeline.

This module provides functions for loading and managing configuration settings.
"""

from .config import PipelineConfig, load_config

__all__ = ["load_config", "PipelineConfig"]

================
File: pipeline/config/config.py
================
"""
Configuration module for the pipeline.

This module handles loading, validating, and merging configuration settings using Pydantic.
"""

import os
from enum import Enum
from pathlib import Path
from typing import Dict, List, Optional, Union

import yaml
from pydantic import BaseModel, Field, field_validator, model_validator

# Environment variable prefix
ENV_PREFIX = "PIPELINE_"


class LogLevel(str, Enum):
    """Valid log levels."""

    DEBUG = "DEBUG"
    INFO = "INFO"
    WARNING = "WARNING"
    ERROR = "ERROR"
    CRITICAL = "CRITICAL"


class ValidationLevel(str, Enum):
    """Validation levels for document processing."""

    BASIC = "basic"
    STRICT = "strict"
    CUSTOM = "custom"


class ComponentConfig(BaseModel):
    """Configuration for individual document processing components."""

    analyzer: str
    cleaner: str
    extractor: str
    validator: str
    formatter: str


class StrategyConfig(BaseModel):
    """Configuration for document processing strategies."""

    pdf: Union[str, ComponentConfig] = "strategies.pdf"
    excel: Union[str, ComponentConfig] = "strategies.excel"
    word: Union[str, ComponentConfig] = "strategies.word"
    text: Union[str, ComponentConfig] = "strategies.text"


class DocumentTypeRule(BaseModel):
    """Configuration for a single document type rule."""

    # Keywords to look for in section titles
    title_keywords: List[str] = Field(default_factory=list)

    # Keywords to look for in document content
    content_keywords: List[str] = Field(default_factory=list)

    # Patterns to match (e.g., invoice numbers, measurements)
    patterns: List[str] = Field(default_factory=list)

    # Confidence weights for different features
    weights: Dict[str, float] = Field(
        default_factory=lambda: {
            "title_match": 0.4,
            "content_match": 0.3,
            "pattern_match": 0.3,
        }
    )

    # Minimum confidence threshold to classify as this type
    threshold: float = 0.5

    # Schema pattern to use for this document type
    schema_pattern: str = "standard"


class ClassificationConfig(BaseModel):
    """Configuration for document classification."""

    # Enable/disable classification
    enabled: bool = True

    # Default confidence threshold
    default_threshold: float = 0.3

    # Classification method (rule_based, pattern_matcher, etc.)
    method: str = "rule_based"

    # Document type rules
    rules: Dict[str, DocumentTypeRule] = Field(
        default_factory=lambda: {
            "SPECIFICATION": DocumentTypeRule(
                title_keywords=["specification", "spec", "technical", "requirements"],
                content_keywords=[
                    "dimensions",
                    "capacity",
                    "performance",
                    "material",
                    "compliance",
                    "standard",
                ],
                patterns=[
                    "mm",
                    "cm",
                    "m",
                    "kg",
                    "lb",
                    "°c",
                    "°f",
                    "hz",
                    "mhz",
                    "ghz",
                    "kw",
                    "hp",
                ],
                threshold=0.4,
                schema_pattern="detailed_specification",
            ),
            "INVOICE": DocumentTypeRule(
                title_keywords=["invoice", "bill", "receipt"],
                content_keywords=["invoice #", "invoice no", "payment", "due date"],
                patterns=["\\$\\d+\\.\\d{2}", "total", "subtotal"],
                threshold=0.5,
                schema_pattern="detailed_invoice",
            ),
            "PROPOSAL": DocumentTypeRule(
                title_keywords=["proposal", "offer", "quote"],
                content_keywords=["proposed", "offer", "scope of work", "timeline"],
                patterns=["proposed by", "submitted to", "valid for"],
                threshold=0.5,
                schema_pattern="detailed_proposal",
            ),
            "TERMS_AND_CONDITIONS": DocumentTypeRule(
                title_keywords=["terms", "conditions", "agreement", "contract"],
                content_keywords=[
                    "shall",
                    "herein",
                    "pursuant",
                    "liability",
                    "warranty",
                    "indemnify",
                ],
                patterns=["party", "parties", "agree", "clause", "section"],
                threshold=0.5,
                schema_pattern="formal_terms",
            ),
        }
    )

    # Filename pattern matching (optional)
    filename_patterns: Dict[str, str] = Field(
        default_factory=lambda: {
            "SPECIFICATION": r"(?i)spec|specification",
            "INVOICE": r"(?i)invoice|bill",
            "PROPOSAL": r"(?i)proposal|offer",
            "TERMS_AND_CONDITIONS": r"(?i)terms|conditions|agreement",
        }
    )


class PipelineConfig(BaseModel):
    """Pipeline configuration model with validation."""

    input_dir: str = Field(
        default="data/input", description="Directory for input documents"
    )
    output_dir: str = Field(
        default="data/output", description="Directory for processed output"
    )
    output_format: str = Field(default="yaml", description="Output format (yaml/json)")
    log_level: LogLevel = Field(default=LogLevel.INFO, description="Logging level")
    validation_level: ValidationLevel = Field(
        default=ValidationLevel.BASIC, description="Validation strictness"
    )
    strategies: StrategyConfig = Field(
        default_factory=StrategyConfig, description="Document processing strategies"
    )
    classification: ClassificationConfig = Field(
        default_factory=ClassificationConfig,
        description="Document classification settings",
    )

    def __getitem__(self, key: str):
        """Enable dictionary-like access to configuration values."""
        return getattr(self, key)

    def __eq__(self, other):
        """Enable equality comparison with dictionaries."""
        if isinstance(other, dict):
            return self.model_dump() == other
        return super().__eq__(other)

    @classmethod
    def get_default(cls) -> "PipelineConfig":
        """Get a new instance with default values."""
        return cls()

    @field_validator("input_dir")
    def validate_input_dir(cls, v: str) -> str:
        """Validate input directory exists if absolute path."""
        path = Path(v)
        if path.is_absolute() and not path.exists():
            # Create the directory if it doesn't exist
            path.mkdir(parents=True, exist_ok=True)
        # Always return forward slashes for cross-platform compatibility
        return str(path).replace("\\", "/")

    @field_validator("output_dir")
    def validate_output_dir(cls, v: str) -> str:
        """Validate output directory exists."""
        if not v.strip():
            raise ValueError("Output directory cannot be empty")
        path = Path(v)
        # Create the directory if it doesn't exist
        path.mkdir(parents=True, exist_ok=True)
        # Always return forward slashes for cross-platform compatibility
        return str(path).replace("\\", "/")

    @model_validator(mode="after")
    def validate_strategy_paths(self) -> "PipelineConfig":
        """Validate strategy paths are not empty."""
        for strategy_type, strategy in self.strategies.model_dump().items():
            if isinstance(strategy, str):
                if not strategy.strip():
                    raise ValueError(
                        f"Invalid strategy path for {strategy_type}: {strategy}"
                    )
            elif isinstance(strategy, dict):
                for component, path in strategy.items():
                    if not isinstance(path, str) or not path.strip():
                        raise ValueError(
                            f"Invalid {component} path for {strategy_type}: {path}"
                        )
        return self


def load_config(
    config_path: Optional[str] = None,
    config_dict: Optional[dict] = None,
    override_dict: Optional[dict] = None,
    use_env: bool = False,
) -> PipelineConfig:
    """
    Load configuration from various sources and merge them.

    The configuration is loaded in the following order (later sources override earlier ones):
    1. Default configuration (from PipelineConfig defaults)
    2. Configuration file (if provided)
    3. Configuration dictionary (if provided)
    4. Override dictionary (if provided)
    5. Environment variables (if use_env is True)

    Args:
        config_path: Path to a YAML configuration file
        config_dict: Configuration dictionary to use instead of loading from file
        override_dict: Dictionary with values that override the loaded configuration
        use_env: Whether to use environment variables to override configuration

    Returns:
        A validated PipelineConfig instance

    Raises:
        FileNotFoundError: If the configuration file does not exist
        yaml.YAMLError: If the configuration file contains invalid YAML
        ValidationError: If the configuration is invalid
    """
    # Start with empty config to be filled
    config_data = {}

    # Load from file if provided
    if config_path:
        config_data = _load_from_file(config_path)
    else:
        # Use config_dict if provided
        if config_dict:
            config_data = config_dict.copy()

        # Apply overrides if provided
        if override_dict:
            config_data = _merge_configs(config_data, override_dict)

    # Apply environment variables if requested
    if use_env:
        env_config = _load_from_env()
        config_data = _merge_configs(config_data, env_config)

    # Create and validate the configuration
    return PipelineConfig(**config_data)


def _load_from_file(config_path: str) -> dict:
    """Load configuration from a YAML file."""
    if not os.path.exists(config_path):
        raise FileNotFoundError(f"Configuration file not found: {config_path}")

    with open(config_path, "r") as f:
        return yaml.safe_load(f) or {}


def _load_from_env() -> dict:
    """Load configuration from environment variables."""
    config = {}

    for key, value in os.environ.items():
        if key.startswith(ENV_PREFIX):
            # Convert PIPELINE_INPUT_DIR to input_dir
            config_key = key[len(ENV_PREFIX) :].lower()

            # Handle nested keys (e.g., PIPELINE_STRATEGIES_PDF)
            if config_key.startswith("strategies_"):
                strategy_type = config_key[len("strategies_") :]
                if "strategies" not in config:
                    config["strategies"] = {}
                config["strategies"][strategy_type] = value
            else:
                # For any other keys, use as-is
                config[config_key] = value

    # Print environment variables for debugging
    print(f"Environment variables: {config}")

    return config


def _merge_configs(base: dict, override: dict) -> dict:
    """
    Merge two configuration dictionaries.

    The override dictionary takes precedence over the base dictionary.
    For nested dictionaries, the merge is recursive.
    """
    result = base.copy()

    for key, value in override.items():
        if key in result and isinstance(result[key], dict) and isinstance(value, dict):
            # Recursively merge nested dictionaries
            result[key] = _merge_configs(result[key], value)
        else:
            # Override or add the value
            result[key] = value

    return result

================
File: pipeline/config/example_config.yaml
================
# Example Pipeline Configuration
# This file demonstrates the available configuration options for the pipeline

# Basic settings
input_dir: "data/input"
output_dir: "data/output"
output_format: "json"  # Options: json, yaml, markdown
log_level: "INFO"  # Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
validation_level: "basic"  # Options: basic, strict, custom

# Document processing strategies
strategies:
  pdf:
    analyzer: "utils.pipeline.analyzer.pdf.PDFAnalyzer"
    cleaner: "utils.pipeline.cleaner.pdf.PDFCleaner"
    extractor: "utils.pipeline.processors.pdf_extractor.PDFExtractor"
    validator: "utils.pipeline.processors.pdf_validator.PDFValidator"
  excel:
    analyzer: "utils.pipeline.analyzer.excel.ExcelAnalyzer"
    cleaner: "utils.pipeline.cleaner.excel.ExcelCleaner"
    extractor: "utils.pipeline.processors.excel_extractor.ExcelExtractor"
    validator: "utils.pipeline.processors.excel_validator.ExcelValidator"
  word:
    analyzer: "utils.pipeline.analyzer.word.WordAnalyzer"
    cleaner: "utils.pipeline.cleaner.word.WordCleaner"
    extractor: "utils.pipeline.processors.word_extractor.WordExtractor"
    validator: "utils.pipeline.processors.word_validator.WordValidator"
  text:
    analyzer: "utils.pipeline.analyzer.text.TextAnalyzer"
    cleaner: "utils.pipeline.cleaner.text.TextCleaner"
    extractor: "utils.pipeline.processors.text_extractor.TextExtractor"
    validator: "utils.pipeline.processors.text_validator.TextValidator"

# Document classification configuration
classification:
  # Enable/disable classification
  enabled: true
  
  # Default confidence threshold
  default_threshold: 0.3
  
  # Classification method (rule_based, pattern_matcher, etc.)
  method: "rule_based"
  
  # Document type rules
  rules:
    # Specification document type
    SPECIFICATION:
      # Keywords to look for in section titles
      title_keywords: 
        - "specification"
        - "spec"
        - "technical"
        - "requirements"
        - "section"
      
      # Keywords to look for in document content
      content_keywords: 
        - "dimensions"
        - "capacity"
        - "performance"
        - "material"
        - "compliance"
        - "standard"
        - "installation"
        - "quality"
      
      # Patterns to match (e.g., measurements)
      patterns: 
        - "mm"
        - "cm"
        - "m"
        - "kg"
        - "lb"
        - "°c"
        - "°f"
        - "hz"
        - "mhz"
        - "ghz"
        - "kw"
        - "hp"
      
      # Confidence weights for different features
      weights:
        title_match: 0.4
        content_match: 0.3
        pattern_match: 0.3
      
      # Minimum confidence threshold to classify as this type
      threshold: 0.4
      
      # Schema pattern to use for this document type
      schema_pattern: "detailed_specification"
    
    # HVAC Specification document type
    HVAC_SPECIFICATION:
      title_keywords: 
        - "hvac"
        - "heating"
        - "ventilation"
        - "air conditioning"
        - "mechanical"
      content_keywords: 
        - "temperature"
        - "humidity"
        - "airflow"
        - "ductwork"
        - "refrigerant"
        - "cooling"
        - "heating"
      patterns: 
        - "°f"
        - "°c"
        - "cfm"
        - "btu"
      threshold: 0.4
      schema_pattern: "hvac_specification"
    
    # Invoice document type
    INVOICE:
      title_keywords: 
        - "invoice"
        - "bill"
        - "receipt"
      content_keywords: 
        - "invoice #"
        - "invoice no"
        - "payment"
        - "due date"
        - "amount due"
        - "bill to"
      patterns: 
        - "\\$\\d+\\.\\d{2}"
        - "total"
        - "subtotal"
        - "tax"
      weights:
        title_match: 0.4
        content_match: 0.4
        pattern_match: 0.2
      threshold: 0.5
      schema_pattern: "detailed_invoice"
    
    # Proposal document type
    PROPOSAL:
      title_keywords: 
        - "proposal"
        - "offer"
        - "quote"
      content_keywords: 
        - "proposed"
        - "offer"
        - "scope of work"
        - "timeline"
        - "project"
      patterns: 
        - "proposed by"
        - "submitted to"
        - "valid for"
        - "\\$\\d+\\.\\d{2}"
      threshold: 0.5
      schema_pattern: "detailed_proposal"
    
    # Terms and Conditions document type
    TERMS_AND_CONDITIONS:
      title_keywords: 
        - "terms"
        - "conditions"
        - "agreement"
        - "contract"
      content_keywords: 
        - "shall"
        - "herein"
        - "pursuant"
        - "liability"
        - "warranty"
        - "indemnify"
        - "jurisdiction"
      patterns: 
        - "party"
        - "parties"
        - "agree"
        - "clause"
        - "section"
      threshold: 0.5
      schema_pattern: "formal_terms"
  
  # Filename pattern matching (optional)
  filename_patterns:
    SPECIFICATION: "(?i)spec|specification"
    HVAC_SPECIFICATION: "(?i)hvac|heating|ventilation"
    INVOICE: "(?i)invoice|bill|receipt"
    PROPOSAL: "(?i)proposal|offer|quote"
    TERMS_AND_CONDITIONS: "(?i)terms|conditions|agreement|contract"

# File processing configuration
file_processing:
  # Input configuration
  input:
    patterns: ["*.pdf", "*.docx", "*.xlsx", "*.txt"]
    recursive: false
    exclude_patterns: ["*_temp*", "*_backup*"]
    max_files: 0  # 0 means no limit
  
  # Output configuration
  output:
    formats: ["json", "markdown"]
    structure: "flat"  # Options: flat, hierarchical, mirror
    naming:
      template: "{original_name}_{format}"
      preserve_extension: false
      timestamp: false
    overwrite: true
  
  # Processing configuration
  processing:
    batch_size: 10
    parallel: false
    continue_on_error: true
    error_handling:
      log_level: "error"
      retry_count: 0
      retry_delay: 1
  
  # Reporting configuration
  reporting:
    summary: true
    detailed: true
    format: "json"
    save_path: "processing_report.json"

================
File: pipeline/config/hvac_config.json
================
{
  "input_dir": "data/input",
  "output_dir": "data/output",
  "output_format": "json",
  "log_level": "INFO",
  "validation_level": "basic",

  "strategies": {
    "pdf": {
      "analyzer": "utils.pipeline.analyzer.pdf.PDFAnalyzer",
      "cleaner": "utils.pipeline.cleaner.pdf.PDFCleaner",
      "extractor": "utils.pipeline.processors.pdf_extractor.PDFExtractor",
      "validator": "utils.pipeline.processors.pdf_validator.PDFValidator"
    }
  },

  "classification": {
    "enabled": true,
    "default_threshold": 0.3,
    "method": "rule_based",

    "rules": {
      "HVAC_SPECIFICATION": {
        "title_keywords": [
          "hvac",
          "heating",
          "ventilation",
          "air conditioning",
          "mechanical",
          "air handling",
          "ductwork",
          "refrigeration",
          "cooling",
          "thermal"
        ],
        "content_keywords": [
          "temperature",
          "humidity",
          "airflow",
          "ductwork",
          "refrigerant",
          "cooling",
          "heating",
          "ventilation",
          "air handling unit",
          "ahu",
          "vav",
          "chiller",
          "boiler",
          "condenser",
          "evaporator",
          "thermostat",
          "diffuser",
          "damper",
          "plenum",
          "insulation",
          "filter",
          "air quality",
          "ashrae"
        ],
        "patterns": [
          "°f",
          "°c",
          "cfm",
          "btu",
          "btuh",
          "ton",
          "kw",
          "hp",
          "psi",
          "inWC",
          "inH2O",
          "fpm",
          "rpm",
          "db",
          "wb",
          "rh%",
          "merv"
        ],
        "weights": {
          "title_match": 0.4,
          "content_match": 0.4,
          "pattern_match": 0.2
        },
        "threshold": 0.3,
        "schema_pattern": "hvac_specification"
      },
      "MECHANICAL_SPECIFICATION": {
        "title_keywords": [
          "mechanical",
          "plumbing",
          "piping",
          "equipment",
          "system"
        ],
        "content_keywords": [
          "mechanical",
          "equipment",
          "system",
          "installation",
          "pipe",
          "duct",
          "valve",
          "pump",
          "fan",
          "motor",
          "control",
          "sensor"
        ],
        "patterns": ["psi", "gpm", "rpm", "hp", "kw", "in\\.", "ft\\."],
        "threshold": 0.4,
        "schema_pattern": "mechanical_specification"
      },
      "ELECTRICAL_SPECIFICATION": {
        "title_keywords": [
          "electrical",
          "power",
          "wiring",
          "circuit",
          "control"
        ],
        "content_keywords": [
          "electrical",
          "power",
          "voltage",
          "current",
          "wire",
          "conduit",
          "circuit",
          "breaker",
          "panel",
          "motor",
          "controller",
          "disconnect",
          "transformer"
        ],
        "patterns": ["v", "kv", "a", "ma", "kva", "kw", "hz", "ohm", "awg"],
        "threshold": 0.4,
        "schema_pattern": "electrical_specification"
      }
    },

    "filename_patterns": {
      "HVAC_SPECIFICATION": "(?i)hvac|heating|ventilation|air.?conditioning|mechanical|ahu|vav|cooling",
      "MECHANICAL_SPECIFICATION": "(?i)mechanical|plumbing|piping|equipment",
      "ELECTRICAL_SPECIFICATION": "(?i)electrical|power|wiring|circuit|control"
    }
  },

  "file_processing": {
    "input": {
      "patterns": ["*.pdf"],
      "recursive": true,
      "exclude_patterns": ["*_temp*", "*_backup*"]
    },
    "output": {
      "formats": ["json", "markdown"],
      "structure": "hierarchical",
      "naming": {
        "template": "{original_name}",
        "preserve_extension": false,
        "timestamp": true
      },
      "overwrite": true
    },
    "reporting": {
      "summary": true,
      "detailed": true,
      "format": "json",
      "save_path": "hvac_processing_report.json"
    }
  }
}

================
File: pipeline/config/hvac_config.yaml
================
# HVAC Specification Pipeline Configuration
# This configuration is optimized for processing HVAC specification documents

# Basic settings
input_dir: "data/input"
output_dir: "data/output"
output_format: "json"
log_level: "INFO"
validation_level: "basic"

# Document processing strategies
strategies:
  pdf:
    analyzer: "utils.pipeline.analyzer.pdf.PDFAnalyzer"
    cleaner: "utils.pipeline.cleaner.pdf.PDFCleaner"
    extractor: "utils.pipeline.processors.pdf_extractor.PDFExtractor"
    validator: "utils.pipeline.processors.pdf_validator.PDFValidator"

# Document classification configuration
classification:
  enabled: true
  default_threshold: 0.3
  method: "rule_based"
  
  # Document type rules
  rules:
    # HVAC Specification document type with enhanced keywords and patterns
    HVAC_SPECIFICATION:
      title_keywords: 
        - "hvac"
        - "heating"
        - "ventilation"
        - "air conditioning"
        - "mechanical"
        - "air handling"
        - "ductwork"
        - "refrigeration"
        - "cooling"
        - "thermal"
      
      content_keywords: 
        - "temperature"
        - "humidity"
        - "airflow"
        - "ductwork"
        - "refrigerant"
        - "cooling"
        - "heating"
        - "ventilation"
        - "air handling unit"
        - "ahu"
        - "vav"
        - "chiller"
        - "boiler"
        - "condenser"
        - "evaporator"
        - "thermostat"
        - "diffuser"
        - "damper"
        - "plenum"
        - "insulation"
        - "filter"
        - "air quality"
        - "ashrae"
      
      patterns: 
        - "°f"
        - "°c"
        - "cfm"
        - "btu"
        - "btuh"
        - "ton"
        - "kw"
        - "hp"
        - "psi"
        - "inWC"
        - "inH2O"
        - "fpm"
        - "rpm"
        - "db"
        - "wb"
        - "rh%"
        - "merv"
      
      weights:
        title_match: 0.4
        content_match: 0.4
        pattern_match: 0.2
      
      threshold: 0.3  # Lower threshold to catch more HVAC documents
      schema_pattern: "hvac_specification"
    
    # Mechanical Specification (broader category that includes HVAC)
    MECHANICAL_SPECIFICATION:
      title_keywords: 
        - "mechanical"
        - "plumbing"
        - "piping"
        - "equipment"
        - "system"
      
      content_keywords: 
        - "mechanical"
        - "equipment"
        - "system"
        - "installation"
        - "pipe"
        - "duct"
        - "valve"
        - "pump"
        - "fan"
        - "motor"
        - "control"
        - "sensor"
      
      patterns: 
        - "psi"
        - "gpm"
        - "rpm"
        - "hp"
        - "kw"
        - "in\\."
        - "ft\\."
      
      threshold: 0.4
      schema_pattern: "mechanical_specification"
    
    # Electrical Specification (often related to HVAC)
    ELECTRICAL_SPECIFICATION:
      title_keywords: 
        - "electrical"
        - "power"
        - "wiring"
        - "circuit"
        - "control"
      
      content_keywords: 
        - "electrical"
        - "power"
        - "voltage"
        - "current"
        - "wire"
        - "conduit"
        - "circuit"
        - "breaker"
        - "panel"
        - "motor"
        - "controller"
        - "disconnect"
        - "transformer"
      
      patterns: 
        - "v"
        - "kv"
        - "a"
        - "ma"
        - "kva"
        - "kw"
        - "hz"
        - "ohm"
        - "awg"
      
      threshold: 0.4
      schema_pattern: "electrical_specification"
  
  # Filename pattern matching
  filename_patterns:
    HVAC_SPECIFICATION: "(?i)hvac|heating|ventilation|air.?conditioning|mechanical|ahu|vav|cooling"
    MECHANICAL_SPECIFICATION: "(?i)mechanical|plumbing|piping|equipment"
    ELECTRICAL_SPECIFICATION: "(?i)electrical|power|wiring|circuit|control"

# File processing configuration
file_processing:
  input:
    patterns: ["*.pdf"]
    recursive: true
    exclude_patterns: ["*_temp*", "*_backup*"]
  
  output:
    formats: ["json", "markdown"]
    structure: "hierarchical"  # Organize by document type
    naming:
      template: "{original_name}"
      preserve_extension: false
      timestamp: true
    overwrite: true
  
  reporting:
    summary: true
    detailed: true
    format: "json"
    save_path: "hvac_processing_report.json"

================
File: pipeline/core/file_processor.py
================
"""
File processor module for handling batch processing of files through the pipeline.

This module provides functionality for discovering input files, processing them
through the pipeline, and generating output files in various formats.
"""

import csv
import json
import os
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple, Union

from utils.pipeline.pipeline import Pipeline
from utils.pipeline.utils.logging import get_logger
from utils.pipeline.utils.progress import PipelineProgress

# Default configuration
DEFAULT_CONFIG = {
    "file_processing": {
        "input": {
            "patterns": ["*.pdf"],
            "recursive": False,
            "exclude_patterns": [],
            "max_files": 0,
        },
        "output": {
            "formats": ["json"],
            "directory": "output",
            "structure": "flat",
            "naming": {
                "template": "{original_name}_{format}",
                "preserve_extension": False,
                "timestamp": False,
            },
            "overwrite": True,
        },
        "processing": {
            "batch_size": 10,
            "parallel": False,
            "continue_on_error": True,
            "error_handling": {
                "log_level": "error",
                "retry_count": 0,
                "retry_delay": 1,
            },
        },
        "reporting": {
            "summary": True,
            "detailed": True,
            "format": "json",
            "save_path": "processing_report.json",
        },
    }
}


class FileProcessor:
    """
    Handles batch processing of files through the pipeline.

    This class provides functionality for:
    1. Discovering input files based on patterns
    2. Processing files through the pipeline
    3. Generating output files in various formats
    4. Tracking progress and reporting results
    """

    def __init__(
        self,
        input_dir: Union[str, Path],
        output_dir: Optional[Union[str, Path]] = None,
        config: Optional[Dict[str, Any]] = None,
    ):
        """
        Initialize the file processor.

        Args:
            input_dir: Directory containing input files
            output_dir: Directory for output files (defaults to input_dir/output)
            config: Configuration dictionary
        """
        # Load and merge configuration
        self.config = self._load_config(config)

        # Set up directories
        self.input_dir = Path(input_dir)
        self.output_dir = Path(output_dir) if output_dir else self._get_output_dir()

        # Initialize pipeline with relevant config subset
        pipeline_config = self._extract_pipeline_config()
        self.pipeline = Pipeline(pipeline_config)

        # Set up logging
        self.logger = get_logger(__name__)

        # Ensure output directory exists
        self.output_dir.mkdir(parents=True, exist_ok=True)

        self.logger.info(
            f"FileProcessor initialized with input_dir={self.input_dir}, "
            f"output_dir={self.output_dir}"
        )

    def _load_config(self, config: Optional[Dict[str, Any]]) -> Dict[str, Any]:
        """Load and validate configuration."""
        # Start with defaults
        merged_config = DEFAULT_CONFIG.copy()

        # Merge with provided config
        if config:
            self._deep_update(merged_config, config)

        # Validate critical settings
        self._validate_config(merged_config)

        return merged_config

    def _deep_update(self, d: Dict[str, Any], u: Dict[str, Any]) -> Dict[str, Any]:
        """Recursively update a dictionary."""
        for k, v in u.items():
            if isinstance(v, dict) and k in d and isinstance(d[k], dict):
                self._deep_update(d[k], v)
            else:
                d[k] = v
        return d

    def _validate_config(self, config: Dict[str, Any]) -> None:
        """Validate configuration settings."""
        # Check for required settings
        if not config.get("file_processing", {}).get("input", {}).get("patterns"):
            config["file_processing"]["input"]["patterns"] = ["*.pdf"]
            self.logger.warning("No input patterns specified, defaulting to '*.pdf'")

        # Validate output formats
        valid_formats = ["json", "markdown"]
        formats = config.get("file_processing", {}).get("output", {}).get("formats", [])

        valid_output_formats = []
        for fmt in formats:
            if fmt.lower() not in valid_formats:
                self.logger.warning(f"Unsupported format '{fmt}', will be ignored")
            else:
                valid_output_formats.append(fmt.lower())

        if not valid_output_formats:
            valid_output_formats = ["json"]
            config["file_processing"]["output"]["formats"] = valid_output_formats
            self.logger.warning(
                "No valid output formats specified, defaulting to 'json'"
            )

    def _extract_pipeline_config(self) -> Dict[str, Any]:
        """Extract pipeline-specific configuration."""
        pipeline_config = {}

        # Copy relevant top-level keys
        for key in ["output_format", "strategies"]:
            if key in self.config:
                pipeline_config[key] = self.config[key]

        return pipeline_config

    def _get_output_dir(self) -> Path:
        """Get output directory from configuration or default."""
        output_config = self.config.get("file_processing", {}).get("output", {})
        output_dir = output_config.get("directory", "output")

        # If relative path, make it relative to input_dir
        if not os.path.isabs(output_dir):
            return self.input_dir / output_dir

        return Path(output_dir)

    def discover_files(self) -> List[Path]:
        """
        Discover input files based on configuration.

        Returns:
            List of file paths matching the configured patterns
        """
        input_config = self.config.get("file_processing", {}).get("input", {})

        # Get patterns and exclusions
        patterns = input_config.get("patterns", ["*.pdf"])
        exclude_patterns = input_config.get("exclude_patterns", [])
        recursive = input_config.get("recursive", False)
        max_files = input_config.get("max_files", 0)

        # Collect all matching files
        all_files = []

        for pattern in patterns:
            # Handle recursive vs non-recursive
            if recursive:
                glob_pattern = f"**/{pattern}"
            else:
                glob_pattern = pattern

            # Find matching files
            matches = list(self.input_dir.glob(glob_pattern))
            all_files.extend(matches)

        # Filter out directories and excluded patterns
        files = []
        for file_path in all_files:
            if not file_path.is_file():
                continue

            # Check exclusions
            excluded = False
            for exclude in exclude_patterns:
                if file_path.match(exclude):
                    excluded = True
                    break

            if not excluded:
                files.append(file_path)

        # Sort files for consistent processing order
        files.sort()

        # Apply max_files limit if specified
        if max_files > 0 and len(files) > max_files:
            self.logger.warning(
                f"Found {len(files)} files, limiting to {max_files} as configured"
            )
            files = files[:max_files]

        self.logger.info(f"Discovered {len(files)} files for processing")
        return files

    def create_output_path(self, input_file: Path, format_name: str) -> Path:
        """
        Create output path based on configuration.

        Args:
            input_file: Input file path
            format_name: Output format name (e.g., 'json', 'markdown')

        Returns:
            Path object for the output file
        """
        output_config = self.config.get("file_processing", {}).get("output", {})

        # Get naming configuration
        naming = output_config.get("naming", {})
        template = naming.get("template", "{original_name}_{format}")
        preserve_ext = naming.get("preserve_extension", False)
        add_timestamp = naming.get("timestamp", False)

        # Get structure type
        structure = output_config.get("structure", "flat")

        # Prepare filename components
        original_name = input_file.stem
        if preserve_ext:
            original_name = input_file.name

        # Add timestamp if configured
        timestamp = ""
        if add_timestamp:
            timestamp = datetime.now().strftime("_%Y%m%d%H%M%S")

        # Format the filename using template
        filename = template.format(
            original_name=original_name,
            format=format_name,
            timestamp=timestamp,
            type=self._detect_document_type(input_file),
        )

        # Add appropriate extension
        if format_name == "json":
            filename = f"{filename}.json"
        elif format_name == "markdown":
            filename = f"{filename}.md"

        # Determine directory based on structure
        if structure == "flat":
            # All files in the output directory
            output_path = self.output_dir / filename

        elif structure == "hierarchical":
            # Organize by document type and format
            doc_type = self._detect_document_type(input_file)
            output_path = self.output_dir / doc_type / format_name / filename

        elif structure == "mirror":
            # Mirror the input directory structure
            try:
                rel_path = input_file.relative_to(self.input_dir)
                output_path = self.output_dir / rel_path.parent / filename
            except ValueError:
                # If input_file is not relative to input_dir, use flat structure
                output_path = self.output_dir / filename

        else:
            # Default to flat structure
            output_path = self.output_dir / filename

        # Create parent directories
        output_path.parent.mkdir(parents=True, exist_ok=True)

        # Handle existing files
        if output_path.exists() and not output_config.get("overwrite", True):
            # Add numeric suffix if overwrite is disabled
            counter = 1
            while output_path.exists():
                stem = output_path.stem
                suffix = output_path.suffix
                output_path = output_path.with_name(f"{stem}_{counter}{suffix}")
                counter += 1

        return output_path

    def _detect_document_type(self, file_path: Path) -> str:
        """
        Detect document type based on file extension.

        Args:
            file_path: Path to the file

        Returns:
            Document type string (e.g., 'pdf', 'excel')
        """
        ext = file_path.suffix.lower()

        if ext == ".pdf":
            return "pdf"
        elif ext in [".xlsx", ".xls"]:
            return "excel"
        elif ext in [".docx", ".doc"]:
            return "word"
        elif ext == ".txt":
            return "text"
        else:
            return "generic"

    def generate_outputs(
        self, input_file: Path, output_data: Dict[str, Any]
    ) -> List[str]:
        """
        Generate output files in all configured formats.

        Args:
            input_file: Input file path
            output_data: Processed data from pipeline

        Returns:
            List of output file paths
        """
        formats = (
            self.config.get("file_processing", {})
            .get("output", {})
            .get("formats", ["json"])
        )
        output_paths = []

        for format_name in formats:
            # Save original output format
            original_format = self.pipeline.config.get("output_format")

            try:
                # Set pipeline output format
                self.pipeline.config["output_format"] = format_name.upper()

                # Create output path
                output_path = self.create_output_path(input_file, format_name)

                # Save output
                self.pipeline.save_output(output_data, str(output_path))
                output_paths.append(str(output_path))

                self.logger.info(f"Generated {format_name} output: {output_path}")

            except Exception as e:
                self.logger.error(f"Failed to generate {format_name} output: {str(e)}")

            finally:
                # Restore original output format
                self.pipeline.config["output_format"] = original_format

        return output_paths

    def process_all_files(self) -> List[Dict[str, Any]]:
        """
        Process all discovered files according to configuration.

        Returns:
            List of result dictionaries with processing status and outputs
        """
        # Get processing configuration
        proc_config = self.config.get("file_processing", {}).get("processing", {})
        continue_on_error = proc_config.get("continue_on_error", True)

        # Discover files
        files = self.discover_files()
        if not files:
            self.logger.warning("No matching files found")
            return []

        # Initialize progress tracking
        progress = PipelineProgress()
        results = []

        with progress:
            # Add overall progress tracking
            overall_task = progress.add_task(
                f"Processing {len(files)} files", total=len(files)
            )

            # Process each file
            for file in files:
                try:
                    progress.display_success(f"Processing {file.name}")

                    # Process the file without progress display
                    output_data = self.pipeline.run(str(file), show_progress=False)

                    # Generate outputs in all configured formats
                    output_paths = self.generate_outputs(file, output_data)

                    # Record result
                    results.append(
                        {
                            "file": str(file),
                            "status": "success",
                            "outputs": output_paths,
                        }
                    )

                    progress.display_success(f"Successfully processed {file.name}")

                except Exception as e:
                    error_msg = f"Error processing {file.name}: {str(e)}"
                    self.logger.error(error_msg, exc_info=True)
                    progress.display_error(error_msg)

                    # Record failure
                    results.append(
                        {"file": str(file), "status": "error", "error": str(e)}
                    )

                    # Stop processing if configured to do so
                    if not continue_on_error:
                        progress.display_error(
                            "Stopping due to error (continue_on_error=False)"
                        )
                        break

                finally:
                    # Update overall progress
                    progress.update(overall_task, advance=1)

        # Generate report if configured
        if (
            self.config.get("file_processing", {})
            .get("reporting", {})
            .get("summary", True)
        ):
            self.generate_report(results)

        return results

    def process_single_file(
        self, input_file: Union[str, Path], output_format: Optional[str] = None
    ) -> Tuple[Dict[str, Any], str]:
        """
        Process a single file (for backward compatibility).

        Args:
            input_file: Path to input file
            output_format: Optional output format override

        Returns:
            Tuple of (output_data, output_path)
        """
        input_path = Path(input_file)

        # Override output format if specified
        original_format = self.pipeline.config.get("output_format")
        if output_format:
            self.pipeline.config["output_format"] = output_format.upper()

        try:
            # Process the file without progress display
            output_data = self.pipeline.run(str(input_path), show_progress=False)

            # Generate output with specified format
            format_name = (
                output_format.lower()
                if output_format
                else (original_format.lower() if original_format else "json")
            )
            output_path = self.create_output_path(input_path, format_name)
            self.pipeline.save_output(output_data, str(output_path))

            return output_data, str(output_path)

        finally:
            # Restore original format
            if output_format:
                self.pipeline.config["output_format"] = original_format

    def generate_report(self, results: List[Dict[str, Any]]) -> str:
        """
        Generate processing report based on configuration.

        Args:
            results: List of processing results

        Returns:
            Path to the generated report
        """
        report_config = self.config.get("file_processing", {}).get("reporting", {})

        # Skip if reporting is disabled
        if not report_config.get("summary", True) and not report_config.get(
            "detailed", False
        ):
            return ""

        # Prepare report data
        report = {
            "timestamp": datetime.now().isoformat(),
            "summary": {
                "total_files": len(results),
                "successful": sum(1 for r in results if r["status"] == "success"),
                "failed": sum(1 for r in results if r["status"] == "error"),
            },
        }

        # Add detailed information if configured
        if report_config.get("detailed", False):
            report["details"] = results

        # Determine report format and path
        format_name = report_config.get("format", "json")
        save_path = report_config.get("save_path", "processing_report.json")

        # Ensure path is absolute
        if not os.path.isabs(save_path):
            save_path = os.path.join(str(self.output_dir), save_path)

        # Create directory if needed
        os.makedirs(os.path.dirname(os.path.abspath(save_path)), exist_ok=True)

        # Save report
        with open(save_path, "w") as f:
            if format_name == "json":
                json.dump(report, f, indent=2)
            elif format_name == "csv" and report_config.get("detailed", False):
                # Simple CSV export for detailed reports
                writer = csv.writer(f)
                writer.writerow(["file", "status", "outputs", "error"])
                for item in results:
                    writer.writerow(
                        [
                            item["file"],
                            item["status"],
                            ",".join(item.get("outputs", [])),
                            item.get("error", ""),
                        ]
                    )
            else:
                # Default to simple text format
                f.write("Processing Report\n")
                f.write(f"Timestamp: {report['timestamp']}\n")
                f.write(f"Total Files: {report['summary']['total_files']}\n")
                f.write(f"Successful: {report['summary']['successful']}\n")
                f.write(f"Failed: {report['summary']['failed']}\n")

        self.logger.info(f"Report saved to {save_path}")
        return save_path

================
File: pipeline/data/output/pdf/json/MF-SPECS_232500 FL - HVAC WATER TREATMENT.json
================
{
  "document": {
    "metadata": {
      "title": "SECTION 232500 - HVAC WATER TREATMENT",
      "author": "ARCOM, Inc.",
      "subject": "HVAC WATER TREATMENT",
      "creator": "Microsoft Office Word",
      "producer": "Aspose.Words for .NET 24.11.1",
      "creation_date": "D:20131216234100Z",
      "modification_date": "D:20250314221816-06'00'"
    },
    "path": "utils\\pipeline\\data\\input\\MF-SPECS_232500 FL - HVAC WATER TREATMENT.pdf",
    "type": ""
  },
  "content": [
    {
      "title": "Introduction",
      "content": "Copyright 2013 AIA\nMasterSpec Premium\n06/13\n",
      "children": [],
      "level": 3
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 1\n",
      "children": [
        {
          "title": "TIPS:",
          "content": "To view non-printing Editor's Notes that provide guidance for editing, click on Masterworks/Single-File\nFormatting/Toggle/Editor's Notes.\nTo read detailed research, technical information about products and materials, and coordination checklists,\nclick on Masterworks/Supporting Information.\n",
          "children": [],
          "level": 3
        }
      ],
      "level": 0
    },
    {
      "title": "PART 1 - GENERAL",
      "content": "1.1\n",
      "children": [
        {
          "title": "A.",
          "content": "Drawings and general provisions of the Contract, including General and Supplementary Conditions and\nDivision 01 Specification Sections, apply to this Section.\n1.2\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Section includes the following HVAC water-treatment systems:\n1.\nManual and automatic chemical-feed equipment and controls.\n2.\nOzone-generator biocide equipment and controls.\n3.\nStainless-steel pipes and fittings.\n4.\nUV-irradiation unit, biocide equipment, and controls.\n5.\nChemical treatment test equipment.\n6.\nChemicals.\n7.\nHVAC makeup-water softeners.\n8.\nRO equipment for HVAC makeup water.\n9.\nWater filtration equipment.\n1.3\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "EEPROM: Electrically erasable, programmable read-only memory.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "RO: Reverse osmosis.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "C.",
          "content": "TSS: Total suspended solids are solid materials, including organic and inorganic, that are suspended in\nthe water. These solids may include silt, plankton, and industrial wastes.\n1.4\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Product Data: Include rated capacities, operating characteristics, and furnished specialties and accessories\n",
          "children": [
            {
              "title": "for the following products:",
              "content": "Copyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 2\n1.\nBypass feeders.\n2.\nWater meters.\n3.\nInhibitor injection timers.\n4.\npH controllers.\n5.\nTSS controllers.\n6.\nBiocide feeder timers.\n7.\nChemical solution tanks.\n8.\nInjection pumps.\n9.\nOzone generators.\n10.\nUV-irradiation units.\n11.\nChemical test equipment.\n12.\nChemical material safety data sheets.\n13.\nWater softeners.\n14.\nRO units.\n15.\nMultimedia filters.\n16.\nSelf-cleaning strainers.\n17.\nReplaceable bag- or cartridge-type filters.\n18.\nCentrifugal separators.\n",
      "children": [
        {
          "title": "B.",
          "content": "Shop Drawings: Pretreatment and chemical[, and ozone-generator biocide][, and UV-irradiation\nbiocide] treatment equipment showing tanks, maintenance space required, and piping connections to\nHVAC systems.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "1. Include plans, elevations, sections, and attachment details.",
          "content": "1.\nInclude diagrams for power and control wiring.\n1.5\n",
          "children": [
            {
              "title": "A.",
              "content": "Seismic Qualification Certificates: For [water softeners] [RO equipment] [water filtration units] and\ncomponents, from manufacturer.\n1.\nBasis for Certification: Indicate whether withstand certification is based on actual test of\nassembled components or on calculation.\n2.\nDimensioned Outline Drawings of Equipment Unit: Identify center of gravity and locate and\ndescribe mounting and anchorage provisions.\n",
              "children": [],
              "level": 2
            },
            {
              "title": "B.",
              "content": "Water Analysis Provider Qualifications: Verification of experience and capability of HVAC water-\ntreatment service provider.\n",
              "children": [],
              "level": 2
            },
            {
              "title": "C.",
              "content": "Field quality-control reports.\n",
              "children": [
                {
                  "title": "Other Informational Submittals:",
                  "content": "1.\nWater-Treatment Program: Written sequence of operation on an annual basis for the application\nequipment required to achieve water quality defined in \"Performance Requirements\" Article.\n2.\nWater Analysis: Illustrate water quality available at Project site.\n3.\nPassivation Confirmation Report: Verify passivation of galvanized-steel surfaces, and confirm this\nobservation in a letter to Architect.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
                  "children": [],
                  "level": 3
                }
              ],
              "level": 2
            }
          ],
          "level": 1
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 3\n1.6\n",
      "children": [
        {
          "title": "A.",
          "content": "Operation and Maintenance Data: For sensors, injection pumps, [water softeners,] [RO equipment,]\n[water filtration units,] and controllers to include in emergency, operation, and maintenance manuals.\n1.7\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "HVAC Water-Treatment Service Provider Qualifications: An experienced HVAC water-treatment service\nprovider capable of analyzing water qualities, installing water-treatment equipment, and applying water\ntreatment as specified in this Section.\n",
          "children": [],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "PART 2 - PRODUCTS",
      "content": "2.1\n",
      "children": [
        {
          "title": "A.",
          "content": "<Double click here to find, evaluate, and insert list of manufacturers and products.>\n2.2\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Water quality for HVAC systems shall minimize corrosion, scale buildup, and biological growth for\noptimum efficiency of HVAC equipment without creating a hazard to operating personnel or to the\nenvironment.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "Base HVAC water treatment on quality of water available at Project site, HVAC system equipment\nmaterial characteristics and functional performance characteristics, operating personnel capabilities, and\nrequirements and guidelines of authorities having jurisdiction.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "C.",
          "content": "Closed hydronic systems, including [hot-water heating] [chilled water] [dual-temperature water]\n[and] [glycol cooling], shall have the following water qualities:\n1.\npH: Maintain a value within [9.0 to 10.5] <Insert range>.\n2.\n\"P\" Alkalinity: Maintain a value within [100 to 500] <Insert range> ppm.\n3.\nBoron: Maintain a value within [100 to 200] <Insert range> ppm.\n4.\nChemical Oxygen Demand: Maintain a maximum value of [100] <Insert number> ppm.\n5.\nSoluble Copper: Maintain a maximum value of [0.20] <Insert number> ppm.\n6.\nTSS: Maintain a maximum value of [10] <Insert number> ppm.\n7.\nAmmonia: Maintain a maximum value of [20] <Insert number> ppm.\n8.\nFree Caustic Alkalinity: Maintain a maximum value of [20] <Insert number> ppm.\n9.\n",
          "children": [
            {
              "title": "Microbiological Limits:",
              "content": "a.\nTotal Aerobic Plate Count: Maintain a maximum value of [1000] <Insert number>\norganisms/mL.\nb.\nTotal Anaerobic Plate Count: Maintain a maximum value of [100] <Insert number>\norganisms/mL.\nc.\nNitrate Reducers: Maintain a maximum value of [100] <Insert number> organisms/mL.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 4\nd.\nSulfate Reducers: Maintain a maximum value of [zero] <Insert number> organisms/mL.\ne.\nIron Bacteria: Maintain a maximum value of [zero] <Insert number> organisms/mL.\n10.\n<Insert other requirements if necessary>.\n",
      "children": [
        {
          "title": "Steam Boiler and Steam Condensate:",
          "content": "1.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Steam Condensate:",
          "content": "a.\npH: Maintain a value within [7.8 to 8.4] <Insert range>.\nb.\nTotal Alkalinity: Maintain a value within [5 to 50] <Insert range> ppm.\nc.\nChemical Oxygen Demand: Maintain a maximum value of [15] <Insert number> ppm.\nd.\nSoluble Copper: Maintain a maximum value of [0.20] <Insert number> ppm.\ne.\nTSS: Maintain a maximum value of [10] <Insert number> ppm.\nf.\nAmmonia: Maintain a maximum value of [20] <Insert number> ppm.\ng.\nTotal Hardness: Maintain a maximum value of [2] <Insert number> ppm.\nh.\n<Insert other requirements if necessary>.\n2.\nSteam boiler operating at 15 psig (104 kPa) and less shall have the following water qualities:\na.\n\"OH\" Alkalinity: Maintain a value within [200 to 400] <Insert range> ppm.\nb.\nTSS: Maintain a value within [600 to 3000] <Insert range> ppm.\nc.\n<Insert other requirements if necessary>.\n3.\nSteam boiler operating at more than 15 psig (104 kPa) shall have the following water qualities:\na.\n\"OH\" Alkalinity: Maintain a value within [200 to 400] <Insert range> ppm.\nb.\nTSS: Maintain a value within [600 to 1200] <Insert range> ppm to maximum 30 times\nRO water TSS.\nc.\n<Insert other requirements if necessary>.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "E.",
          "content": "Open hydronic systems, including [condenser] [fluid-cooler spray] water, shall have the following\n",
          "children": [
            {
              "title": "water qualities:",
              "content": "1.\npH: Maintain a value within [8.0 to 9.1] <Insert range>.\n2.\n\"P\" Alkalinity: Maintain a maximum value of [100] <Insert number> ppm.\n3.\nChemical Oxygen Demand: Maintain a maximum value of [100] <Insert number> ppm.\n4.\nSoluble Copper: Maintain a maximum value of [0.20] <Insert number> ppm.\n5.\nTSS: Maintain a maximum value of [10] <Insert number> ppm.\n6.\nAmmonia: Maintain a maximum value of [20] <Insert number> ppm.\n7.\nFree \"OH\" Alkalinity: Maintain a maximum value of [zero] <Insert number> ppm.\n8.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "Microbiological Limits:",
              "content": "a.\nTotal Aerobic Plate Count: Maintain a maximum value of [10,000] <Insert number>\norganisms/mL.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 5\nb.\nTotal Anaerobic Plate Count: Maintain a maximum value of [1000] <Insert number>\norganisms/mL.\nc.\nNitrate Reducers: Maintain a maximum value of [100] <Insert number> organisms/mL.\nd.\nSulfate Reducers: Maintain a maximum value of [zero] <Insert number> organisms/mL.\ne.\nIron Bacteria: Maintain a maximum value of [zero] <Insert number> organisms/mL.\n9.\nPolymer Testable: Maintain a minimum value within [10 to 40] <Insert range>.\n10.\n<Insert other requirements if necessary>.\n",
      "children": [
        {
          "title": "F.",
          "content": "Passivation for Galvanized Steel: For the first 60 days of operation.\n1.\npH: Maintain a value within [7 to 8] <Insert range>.\n2.\nCalcium Carbonate Hardness: Maintain a value within [100 to 300] <Insert range> ppm.\n3.\nCalcium Carbonate Alkalinity: Maintain a value within [100 to 300] <Insert range> ppm.\n2.3\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Bypass Feeders: Steel, with corrosion-resistant exterior coating, minimum 3-1/2-inch (89-mm) fill\nopening in the top, and NPS 3/4 (DN 20) bottom inlet and top side outlet. Quarter turn or threaded fill cap\nwith gasket seal and diaphragm to lock the top on the feeder when exposed to system pressure in the\nvessel.\n1.\nCapacity: [2 gal. (7.6 L)] [5 gal. (19 L)] <Insert value>.\n2.\nMinimum Working Pressure: [125 psig (860 kPa)] [175 psig (1210 kPa)] <Insert value>.\n2.4\n",
          "children": [
            {
              "title": "Water Meter:",
              "content": "1.\nAWWA C700, oscillating-piston, magnetic-drive, totalization meter.\n2.\nBody: Bronze.\n3.\nMinimum Working-Pressure Rating: 150 psig (1035 kPa).\n4.\nMaximum Pressure Loss at Design Flow: 3 psig (20 kPa).\n5.\nRegistration: Gallons (Liters) or cubic feet (cubic meters).\n6.\nEnd Connections: Threaded.\n7.\nControls: Flow-control switch with normally open contacts; rated for maximum 10 A, 250-V ac,\nand that will close at adjustable increments of total flow.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "Water Meter:",
              "content": "1.\nAWWA C701, turbine-type, totalization meter.\n2.\nBody: Bronze.\n3.\nMinimum Working-Pressure Rating: 100 psig (690 kPa).\n4.\nMaximum Pressure Loss at Design Flow: 3 psig (20 kPa).\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 6\n5.\nRegistration: Gallons (Liters) or cubic feet (cubic meters).\n6.\nEnd Connections: Threaded.\n7.\nControls: Low-voltage signal capable of transmitting 1000 feet (305 m).\n",
      "children": [
        {
          "title": "Water Meter:",
          "content": "1.\nAWWA C701, turbine-type, totalization meter.\n2.\nBody: [Bronze] [Epoxy-coated cast iron].\n3.\nMinimum Working-Pressure Rating: 150 psig (1035 kPa).\n4.\nMaximum Pressure Loss at Design Flow: 3 psig (20 kPa).\n5.\nRegistration: Gallons (Liters) or cubic feet (cubic meters).\n6.\nEnd Connections: Flanged.\n7.\nControls: Flow-control switch with normally open contacts; rated for maximum 10 A, 250-V ac,\nand that will close at adjustable increments of total flow.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Inhibitor Injection Timers:",
          "content": "1.\nMicroprocessor-based controller with digital display in NEMA 250, Type 12 enclosure with\ngasketed and lockable door.[ Interface for start/stop and status indication at central\nworkstation as described in Section 230923 \"Direct Digital Control (DDC) System for\n",
          "children": [],
          "level": 3
        },
        {
          "title": "HVAC.\"]",
          "content": "2.\nProgrammable timers with infinite adjustment over full range, and mounted in cabinet with hand-\noff-auto switches and status lights.\n3.\nTest switch.\n4.\nHand-off-auto switch for chemical pump.\n5.\nIlluminated legend to indicate feed when pump is activated.\n6.\nProgrammable lockout timer with indicator light. Lockout timer to deactivate the pump and\nactivate alarm circuits.\n7.\nDigital display makeup totalizer to measure amount of makeup and bleed-off water from two\nwater meter inputs.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "pH Controller:",
          "content": "1.\nMicroprocessor-based controller, 1 percent accuracy in a range from zero to 14 units. Incorporate\nsolid-state integrated circuits and digital display in NEMA 250, Type 12 enclosure with gasketed\nand lockable door.[ Interface for start/stop and status indication at central workstation as\ndescribed in Section 230923 \"Direct Digital Control (DDC) System for HVAC.\"]\n2.\nDigital display and touch pad for input.\n3.\nSensor probe adaptable to sample stream manifold.\n4.\nHigh, low, and normal pH indication.\n5.\nHigh or low-pH-alarm-light trip points, field adjustable; with silence switch.\n6.\nHand-off-auto switch for acid pump.\n7.\nInternal adjustable hysteresis or deadband.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "TSS Controller:",
          "content": "1.\nMicroprocessor-based controller, 1 percent accuracy in a range from zero to 5000 micromhos.\nIncorporate solid-state integrated circuits and digital display in NEMA 250, Type 12 enclosure\nwith\ngasketed\nand\nlockable\ndoor.[ Interface\nfor\nstart/stop\nand\nstatus\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
          "children": [],
          "level": 3
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 7\nindication at central workstation as described in Section 230923 \"Direct Digital Control\n(DDC) System for HVAC.\"]\n2.\nDigital display and touch pad for input.\n3.\nSensor probe adaptable to sample stream manifold.\n4.\nHigh, low, and normal conductance indication.\n5.\nHigh- or low-conductance-alarm-light trip points, field adjustable; with silence switch.\n6.\nHand-off-auto switch for solenoid bleed-off valve.\n7.\nBleed-off valve activated indication.\n8.\nInternal adjustable hysteresis or deadband.\n9.\n",
      "children": [
        {
          "title": "Bleed Valves:",
          "content": "a.\nCooling Systems: Forged-brass body, globe pattern, general-purpose solenoid with\ncontinuous-duty coil, or motorized valve.\nb.\nSteam Boilers: Motorized ball valve, steel body, and TFE seats and seals.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Biocide Feeder Timer:",
          "content": "1.\nMicroprocessor-based controller with digital display in NEMA 250, Type 12 enclosure with\ngasketed and lockable door.[ Interface for start/stop and status indication at central\nworkstation as described in Section 230923 \"Direct Digital Control (DDC) System for\n",
          "children": [],
          "level": 3
        },
        {
          "title": "HVAC.\"]",
          "content": "2.\n24-hour timer with 14-day skip feature to permit activation any hour of day.\n3.\nPrecision, solid-state, bleed-off lockout timer and clock-controlled biocide pump timer. Prebleed\nand bleed lockout timers.\n4.\nSolid-state alternator to enable use of two formulations.\n5.\n24-hour display of time of day.\n6.\n14-day display of day of week.\n7.\nBattery backup so clock is not disturbed by power outages.\n8.\nHand-off-auto switches for biocide pumps.\n9.\nBiocide A and Biocide B pump running indication.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Chemical Solution Tanks:",
          "content": "1.\nChemical-resistant reservoirs fabricated from high-density opaque polyethylene with minimum\n110 percent containment vessel.\n2.\nMolded cover with recess for mounting pump.\n3.\nCapacity: [30 gal. (114 L)] [50 gal. (189 L)] [120 gal. (454 L)] <Insert value>.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Chemical Solution Injection Pumps:",
          "content": "1.\nSelf-priming, positive displacement; rated for intended chemical with minimum 25 percent safety\nfactor for design pressure and temperature.\n2.\nAdjustable flow rate.\n3.\nMetal and thermoplastic construction.\n4.\nBuilt-in relief valve.\n5.\nFully enclosed, continuous-duty, single-phase motor. Comply with requirements in\nSection 230513 \"Common Motor Requirements for HVAC Equipment.\"\na.\nElectrical Components, Devices, and Accessories: Listed and labeled as defined in\nNFPA 70, by a qualified testing agency, and marked for intended location and application.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
          "children": [],
          "level": 3
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 8\n",
      "children": [
        {
          "title": "J.",
          "content": "Chemical Solution Tubing: Polyethylene tubing with compression fittings and joints except\nASTM A 269, Type 304, stainless steel for steam boiler injection assemblies.\n",
          "children": [
            {
              "title": "Injection Assembly:",
              "content": "1.\nQuill: Minimum NPS 1/2 (DN 15) with insertion length sufficient to discharge into at least 25\npercent of pipe diameter.\n2.\nBall Valve: [Three] [Two]-piece stainless steel, as described in \"Stainless-Steel Pipes and\nFittings\" Article; selected to fit quill.\n3.\nPacking Gland: Mechanical seal on quill of sufficient length to allow quill removal during system\noperation.\n4.\nAssembly Pressure/Temperature Rating: Minimum 600 psig (4137 kPa) at 200 deg F (93 deg C).\n2.5\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Corona discharge generator with stainless-steel generating cells and transformer housed in a NEMA 250,\nType 4 enclosure. Assembly shall be suitable for continuous duty. Provide site glasses to verify proper\noperation of generator.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "Water-cooled generators shall be provided with cooling water at maximum [70 deg F (21 deg C)]\n<Insert value> and [35 psig (241 kPa)] <Insert value>.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "C.",
          "content": "Generator vessels exposed to system pressure shall be constructed according to ASME Boiler and\nPressure Vessel Code and be equipped with pressure relief valve.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "D.",
          "content": "External air compressor or induced airflow through a cleanable prefilter supplies concentrated oxygen\nthrough a molecular sieve with minus 62 deg F (minus 52 deg C) dew point to avoid the formation of\nnitric acid.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "E.",
          "content": "Microprocessor-based control with software in EEPROM, surge protection, high-temperature cutout, and\noperational status lights.[ Interface for start/stop and status indication at central workstation as\ndescribed in Section 230923 \"Direct Digital Control (DDC) System for HVAC.\"]\n",
          "children": [
            {
              "title": "Ozone Contactors:",
              "content": "1.\nBubble diffusers.\n2.\nInduction injection nozzle.\n3.\nInjectors with static mixers.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "Ozone Detector and Alarm Devices:",
              "content": "1.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "Detector:",
              "content": "a.\nSensor: Metal dioxide semiconductor.\nb.\nConcentration Range: [0.01 to 0.14] <Insert range> ppm.\nc.\nAccuracy: Plus or minus 20 percent of range.\nd.\nSensitivity: 0.01 ppm.\ne.\nResponse Time: Maximum 10 seconds.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 9\nf.\nOperating Temperature: 50 to 100 deg F (10 to 38 deg C).\ng.\nRelative Humidity: 20 to 95 percent, noncondensing over the operating temperature range.\n2.\n",
      "children": [
        {
          "title": "Horns:",
          "content": "a.\nElectric-vibrating-polarized type.\nb.\n24-V dc, with provision for housing the operating mechanism behind a grille.\nc.\nHorns shall produce a sound-pressure level of 90 dBA, measured 10 feet (3 m) from the\nhorn.\nd.\nElectrical Components, Devices, and Accessories: Listed and labeled as defined in\nNFPA 70, by a qualified testing agency, and marked for intended location and application.\n3.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Visible Alarm Devices:",
          "content": "a.\nXenon strobe lights listed in UL 1971, with clear or nominal white polycarbonate lens\nmounted on an aluminum faceplate.\nb.\nRated Light Output: [75] [110] <Insert number> candela.\nc.\nStrobe Leads: Factory connected to screw terminals.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "H.",
          "content": "Self-Contained Breathing Apparatus: Open-circuit, pressure-demand compressed air includes completely\nassembled, portable, self-contained devices designed for hazardous breathing environment application.\n1.\nFace Piece: EPDM or silicone rubber construction material, one-size-fits-all with double-sealing\nedge, stainless-steel speaking diaphragm and lens retainer, five adjustable straps to hold face piece\nto head (two straps on each side and one on top), exhalation valve in mask, close-fitting nose piece\nto ensure no CO2 buildup, and perspiration drain to avoid skin irritation and to prevent eyepiece,\nspectacle, and lens fogging.\n2.\nBackplate: Orthopedically designed of [chemical and impact-resistant, glass-fiber composite]\n[aluminum].\n3.\nHarness and Carrier Assembly: Large triangular back pad, backplate, and adjustable waist and\nshoulder straps. Modular in design, detachable components, and easy to clean and maintain.\nShoulder straps padded with flame-resistant material, reinforced with stainless-steel cable, and\nattached with T-nuts, washers, and screws.\n4.\nAir Cylinder: [30] [45] [60]-minute, low-pressure, air-supply-loaded [fiberglass] [aluminum]\n[steel] cylinders fitted with quick-fill assembly for refilling and air transfer.\n5.\nWall-Mounting Cabinet: Leakproof, corrosion-resistant, clear, plastic case.\n6.\nTested and Certified: By the National Institute for Occupational Safety and Health and by the\nMine Safety and Health Administration, according to 42 CFR 84, Subpart H.\n2.6\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Stainless-Steel Tubing: Comply with ASTM A 269, Type 316.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "Stainless-Steel Fittings: Comply with ASTM A 815/A 815M, Type 316, Grade WP-S.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "C.",
          "content": "Two-Piece, Full-Port, Stainless-Steel Ball Valves: ASTM A 351/A 351M, Type 316 stainless-steel body;\n",
          "children": [],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "ASTM A 276,",
      "content": "Type 316\nstainless-steel\nstem\nand\nvented\nball,\ncarbon-filled\n",
      "children": [
        {
          "title": "TFE",
          "content": "Copyright 2013 AIA\nMasterSpec Premium\n06/13\n",
          "children": [],
          "level": 3
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 10\nseats, threaded body design with adjustable stem packing, threaded ends, and 250-psig (1725-kPa) Steam\nWorking Pressure and 600-psig (4140-kPa) Cold Working Pressure ratings.\n",
      "children": [
        {
          "title": "D.",
          "content": "Three-Piece, Full-Port, Stainless-Steel Ball Valves: ASTM A 351/A 351M, Type 316 stainless-steel\nbody; ASTM A 276, Type 316 stainless-steel stem and vented ball, threaded body design with adjustable\nstem packing, threaded ends, and 150-psig (1035-kPa) Steam Working Pressure and 600-psig (4140-kPa)\nCold Working Pressure rating.\n2.7\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Target Irradiation: Minimum 30,000 microwatts x s/sq. cm.\n",
          "children": [
            {
              "title": "Light Source Vessels:",
              "content": "1.\nASTM A 666, Type 304 stainless steel.\n2.\nConstruct for minimum [150 psig (1035 kPa)] <Insert value> at [150 deg F (65 deg C)] <Insert\nvalue> according to ASME Boiler and Pressure Vessel Code, and equipped with pressure relief\nvalve.\n3.\nLight Source Sleeve: Quartz, with EPDM O-ring seals.\n4.\nLight Source: Replaceable UV lamp producing minimum target irradiation of 254-nm wavelength\nlight.\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        },
        {
          "title": "C.",
          "content": "Controls: Interlock with pumps to operate when water is circulating.\n2.8\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Test Kit: Manufacturer-recommended equipment and chemicals in a wall-mounting cabinet for testing\npH, TSS, inhibitor, chloride, alkalinity, and hardness; sulfite and testable polymer tests for high-pressure\nboilers; and oxidizing biocide test for open cooling systems.\n",
          "children": [
            {
              "title": "Sample Cooler:",
              "content": "1.\nTube: Sample.\na.\nSize: NPS 1/4 (DN 8) tubing.\nb.\nMaterial: ASTM A 666, Type 316 stainless steel.\nc.\nPressure Rating: Minimum 2000 psig (13 790 kPa).\nd.\nTemperature Rating: Minimum 850 deg F (454 deg C).\n2.\nShell: Cooling water.\na.\nMaterial: ASTM A 666, Type 304 stainless steel.\nb.\nPressure Rating: Minimum 250 psig (1725 kPa).\nc.\nTemperature Rating: Minimum 450 deg F (232 deg C).\n3.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "Capacities and Characteristics:",
              "content": "a.\nTube: Sample.\n1)\nFlow Rate: [0.25 gpm (0.016 L/s)] <Insert value>.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 11\n2)\nEntering Temperature: [400 deg F (204 deg C)] <Insert value>.\n3)\nLeaving Temperature: [88 deg F (31 deg C)] <Insert value>.\n4)\nPressure Loss: [6.5 psig (44.8 kPa)] <Insert value>.\nb.\nShell: Cooling water.\n1)\nFlow Rate: [3 gpm (0.19 L/s)] <Insert value>.\n2)\nEntering Temperature: [70 deg F (21 deg C)] <Insert value>.\n3)\nPressure Loss: [1.0 psig (6.89 kPa)] <Insert value>.\n",
      "children": [
        {
          "title": "C.",
          "content": "Corrosion Test-Coupon Assembly: Constructed of corrosive-resistant material, complete with piping,\nvalves, and mild steel and copper coupons. Locate copper coupon downstream from mild steel coupon in\nthe test-coupon assembly.\n1.\n[Two] <Insert number>-station rack for closed-loop systems.\n2.\n[Four] <Insert number>-station rack for open-loop systems.\n2.9\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Chemicals shall be as recommended by water-treatment system manufacturer that are compatible with\npiping system components and connected equipment and that can attain water quality specified in\n\"Performance Requirements\" Article.\n",
          "children": [
            {
              "title": "Water Softener Chemicals:",
              "content": "1.\nMineral: High-capacity, sulfonated-polystyrene ion-exchange resin that is stable over entire pH\nrange with good resistance to bead fracture from attrition or shock. Resin exchange capacity\nminimum 30,000 grains/cu. ft. (69 kg/cu. m) of calcium carbonate of resin when regenerated with\n15 lb (6.8 kg) of salt.\n2.\nSalt for Brine Tanks: High-purity sodium chloride, free of dirt and foreign material. Rock and\ngranulated forms are unacceptable.\n2.10\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        },
        {
          "title": "A.",
          "content": "<Double click here to find, evaluate, and insert list of manufacturers and products.>\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "Description: Twin mineral tanks and one brine tank, factory mounted on skid.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "C.",
          "content": "Electrical Components, Devices, and Accessories: Listed and labeled as defined in NFPA 70, by a\nqualified testing agency, and marked for intended location and application.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "D.",
          "content": "Fabricate supports and attachments to tanks with reinforcement strong enough to resist tank movement\nduring seismic event when tank supports are anchored to building structure as recommended in writing\nby manufacturer.\n",
          "children": [
            {
              "title": "Mineral Tanks:",
              "content": "1.\nFabricate and label steel filter tanks to comply with ASME Boiler and Pressure Vessel Code:\nSection VIII, Division 1.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 12\n2.\nFabricate and label Fiber Reinforced Plastic filter tanks to comply with ASME Boiler and Pressure\nVessel Code: Section X, if indicated.\n3.\nPressure Rating: [100 psig (690 kPa)] [125 psig (860 kPa)] [150 psig (1035 kPa)] <Insert\nvalue> minimum.\n4.\nWetted Components: Suitable for water temperatures from [40 to at least 100 deg F (5 to at least\n38 deg C)] <Insert range>.\n5.\nFreeboard: 50 percent, minimum, for backwash expansion above the normal resin bed level.\n6.\nSupport Legs or Skirt: Constructed of structural steel, welded, or bonded to tank before testing and\nlabeling.\n7.\nFinish: Hot-dip galvanized on exterior and interior of tank after fabrication.\n8.\nUpper Distribution System: Single-point type, fabricated from galvanized-steel pipe and fittings.\n9.\nLower Distribution System: Hub and radial-arm or header-lateral type; fabricated from PVC pipe\nand fittings with individual, fine-slotted, nonclogging polyethylene strainers; arranged for even-\nflow distribution through resin bed.\n",
      "children": [
        {
          "title": "F.",
          "content": "Controls: Automatic; factory mounted on mineral tanks and factory wired.\n1.\nAdjustable duration of regeneration steps.\n2.\nPush-button start and complete manual operation override.\n3.\nPointer on pilot-control valve shall indicate cycle of operation.\n4.\nMeans of manual operation of pilot-control valve if power fails.\n5.\nMain Operating Valves: Industrial, automatic, multiport, diaphragm type with the following\n",
          "children": [
            {
              "title": "features:",
              "content": "a.\nSlow opening and closing, nonslam operation.\nb.\nDiaphragm guiding on full perimeter from fully open to fully closed.\nc.\nIsolated dissimilar metals within valve.\nd.\nSelf-adjusting, internal, automatic brine injector that draws brine and rinses at constant rate\nindependent of pressure.\ne.\nFloat-operated brine valve to automatically measure the correct amount of brine to the\nsoftener and refill with fresh water.\nf.\nSampling cocks for soft water.\n6.\nFlow Control: Automatic control of backwash and flush rates over variations in operating\npressures that do not require field adjustments. Equip mineral tanks with automatic-reset-head\nwater meter that electrically activates cycle controller to initiate regeneration at preset total in\ngallons (liters) and that automatically resets after regeneration to preset total in gallons (liters) for\nnext service run. Include alternator to regenerate one mineral tank with the other in service.\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        },
        {
          "title": "G.",
          "content": "Brine Tank: Combination measuring and wet-salt storing system.\n1.\nTank and Cover Material: Fiberglass a minimum of 3/16 inch (4.8 mm) thick; or molded\npolyethylene a minimum of 3/8 inch (9.5 mm) thick.\n2.\nBrine Valve: Float operated and plastic fitted for automatic control of brine withdrawn and\nfreshwater refill.\n3.\nSize: Large enough for at least four regenerations at full salting.\n",
          "children": [
            {
              "title": "Factory-Installed Accessories:",
              "content": "Copyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 13\n1.\nPiping, valves, tubing, and drains.\n2.\nSampling cocks.\n3.\nMain-operating-valve position indicators.\n4.\nWater meters.\n",
      "children": [
        {
          "title": "I.",
          "content": "Water Test Kit: Include in wall-mounting enclosure for water softener.\n",
          "children": [
            {
              "title": "Capacities and Characteristics:",
              "content": "1.\nContinuous Service Flow Rate: <Insert gpm (L/s)> at 15-psig (104-kPa) pressure loss.\n2.\nPeak Service Flow Rate: <Insert gpm (L/s)> at 25-psig (173-kPa) pressure loss.\n3.\nWater Consumption: <Insert gal./day (cu. m/day)>.\n4.\nWater Demand: <Insert number> hours/day.\n5.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "Electrical Characteristics:",
              "content": "a.\nVolts: <Insert value>.\nb.\nPhase: <Insert value>.\nc.\nHertz: <Insert value>.\nd.\nFull-Load Amperes: <Insert value>.\ne.\nMinimum Circuit Ampacity: <Insert value>.\nf.\nMaximum Overcurrent Protection: <Insert amperage>.\ng.\nInterrupting Capacity: <Insert amperage>.\n2.11\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        },
        {
          "title": "A.",
          "content": "<Double click here to find, evaluate, and insert list of manufacturers and products.>\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "Description: Factory fabricated and tested with RO membrane elements in housings, high-pressure pumps\nand motors, controls, valves, and prefilter; mounted on skid.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "C.",
          "content": "Electrical Components, Devices, and Accessories: Listed and labeled as defined in NFPA 70, by a\nqualified testing agency, and marked for intended location and application.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "D.",
          "content": "Fabricate supports and attachments to tanks with reinforcement strong enough to resist tank movement\nduring seismic event when tank supports are anchored to building structure as recommended in writing\nby manufacturer.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "E.",
          "content": "Skid Assembly: Welded-steel frame coated with epoxy protective finish.\n",
          "children": [
            {
              "title": "RO Membrane and Housing:",
              "content": "1.\nElement: Thin-film composite with U-cup brine seal with minimum 98 percent salt rejection based\non 2000-ppm water supplied at 225 psig (1551 kPa) and 77 deg F (25 deg C).\n2.\nHousing: ASTM A 666, Type 304 stainless steel with PVC end caps held in place with stainless-\nsteel straps.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "High-Pressure Pumps and Motors:",
              "content": "1.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "Pump:",
              "content": "Copyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 14\na.\nVertical, multistage centrifugal operating at 3500 rpm with ASTM A 666, Type 304\nstainless-steel casing, shaft, impellers, and inlet and discharge casting.\nb.\nBearings shall be tungsten carbide and ceramic.\nc.\nCast-iron frame and flanged suction and discharge connections.\nd.\nMotor: NEMA-standard, C-faced totally enclosed, fan cooled motor supported on the\npump-bearing frame. General requirements for motors are specified in Section 230513\n\"Common Motor Requirements for HVAC Equipment.\"\n",
      "children": [
        {
          "title": "Controls:",
          "content": "1.\nMicroprocessor-based controller with digital display.\n2.\nInterlock for remote start/stop control.\n3.\nMembrane flush sequence when pumps shut down.\n4.\nRun time indicator.\n5.\nLow-pressure safety cutoff.\n6.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Panel-mounted gages as follows:",
          "content": "a.\nProduct and concentrate.\nb.\nInlet, cartridge filter outlet, RO feed, RO concentrate, and RO product pressures.\nc.\nProduct conductivity monitor.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Valves:",
          "content": "1.\nStainless-steel pump, concentrate, and recycle throttling valves rated for minimum 300 psig (2068\nkPa).\n2.\nAutomatic inlet shutoff valve, diaphragm type; solenoid actuated, normally closed, and\nconstructed of glass-reinforced noryl thermoplastic.\n3.\nPVC valves with EPDM seats and seals for isolation at inlet, and check and sample valves at\nproduct and concentrate. Sample valves at cartridge filter outlet, concentrate, and product outlet.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Prefilter:",
          "content": "1.\nHousing: Polypropylene with built-in relief or vent valve.\n2.\nElement: Spun-wound polypropylene.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "K.",
          "content": "Inlet Water Tempering Valve: Thermostatic water-tempering valve to maintain [77 deg F (25 deg C)]\n<Insert value> inlet water temperature to RO unit.\n",
          "children": [
            {
              "title": "Activated Carbon Filter:",
              "content": "1.\nMedia Tank: Fiberglass-reinforced polyester rated for minimum 150 psig (1035 kPa) with internal\nbackwash distributor and filtered water collector.\n2.\nMedia: 12-by-40-mesh, bituminous coal-based activated carbon.\n3.\nBackwash Valve: Piston-operated control valve with drain-line, flow-control orifice.\n4.\nBackwash Control: Seven-day time clock.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "Atmospheric Storage Tank:",
              "content": "Copyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 15\n1.\nTank: Polyethylene single piece with closed top and flat bottom with manway in top, 0.2-micron\nfilter vent, inlet, discharge, and drain piping connections, and bulkhead fittings for level controls.\n2.\nControl: Level switches start and stop RO unit. Low-level limit shall stop repressurization pumps\nand signal an alarm.\n",
      "children": [
        {
          "title": "Repressurization Pumps:",
          "content": "1.\nPumps: Two close-coupled, single-stage centrifugal pumps with mechanical seals. Wetted\ncomponents ASTM A 666, Type 316 stainless steel.\n2.\nControls: NEMA-4X pump control panel constructed of fiberglass to control pumps, one\noperating and one standby, with automatic alternator and fail-over control.\n3.\nMotor: Open, drip proof motor supported on the pump-bearing frame. General requirements for\nmotors are specified in Section 230513 \"Common Motor Requirements for HVAC Equipment.\"\na.\nElectrical Components, Devices, and Accessories: Listed and labeled as defined in\nNFPA 70, by a qualified testing agency, and marked for intended location and application.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "O.",
          "content": "Water Test Kit: Include in wall-mounting cabinet for RO unit.\n",
          "children": [
            {
              "title": "Capacities and Characteristics:",
              "content": "1.\nRO Product Flow Rate: <Insert gpm (L/s)>.\n2.\nTotal Water Flow Rate: <Insert gpm (L/s)>.\n3.\nDaily Water Consumption: <Insert gal./day (cu. m/day)>.\n4.\nWater Demand: <Insert number> hours/day.\n5.\nStorage Tank Size: <Insert gal. (L)>.\n6.\nRO Inlet Operating Temperature: [77 deg F (25 deg C)] <Insert value>.\n7.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "High-Pressure Pump:",
              "content": "a.\nDischarge Pressure: <Insert psig (kPa)>.\nb.\nFlow Rate: <Insert gpm (L/s)>.\nc.\nHorsepower: <Insert value>.\nd.\nMotor Speed: [3500] <Insert number> rpm.\n8.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "Repressure Pumps:",
              "content": "a.\nDischarge Pressure: <Insert psig (kPa)>.\nb.\nFlow Rate: <Insert gpm (L/s)>.\nc.\nHorsepower: <Insert value>.\nd.\nMotor Speed: [3500] <Insert number> rpm.\n9.\n",
              "children": [],
              "level": 3
            },
            {
              "title": "Prefilter Design (at Total Water Flow Rate):",
              "content": "a.\nFilter Efficiency: [98] <Insert number> percent.\nb.\nParticle Size: [5] <Insert number> microns and larger.\nc.\nClean Pressure Loss: [2 psig (14 kPa)] <Insert value>.\nd.\nReplacement Pressure Loss: [6 psig (41 kPa)] <Insert value>.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 16\n10.\nElectrical Characteristics (Single-Point Connection):\na.\nVolts: <Insert value>.\nb.\nPhase: <Insert value>.\nc.\nHertz: <Insert value>.\nd.\nFull-Load Amperes: <Insert value>.\ne.\nMinimum Circuit Ampacity: <Insert value>.\nf.\nMaximum Overcurrent Protection: <Insert amperage>.\ng.\nInterrupting Capacity: <Insert amperage>.\n2.12\n",
      "children": [
        {
          "title": "Multimedia Filters:",
          "content": "1.\n<Double click here to find, evaluate, and insert list of manufacturers and products.>\n2.\nDescription: Factory-fabricated and -tested, simplex, multimedia filter system of filter tank,\nmedia, strainer, circulating pump, piping, and controls for removing particles from water.\na.\nFilter Tank: Corrosion resistant with distribution system and media.\n3.\nElectrical Components, Devices, and Accessories: Listed and labeled as defined in NFPA 70, by a\nqualified testing agency, and marked for intended location and application.\na.\nFabricate and label steel filter tanks to comply with ASME Boiler and Pressure Vessel\nCode: Section VIII, Division 1.\nb.\nFabricate and label FRP filter tanks to comply with ASME Boiler and Pressure Vessel\nCode: Section X, if indicated.\nc.\nPipe Connections NPS 2 (DN 50) and Smaller: Threaded according to ASME B1.20.1.\nd.\nSteel Tank Pipe Connections NPS 2-1/2 (DN 65) and Larger: Steel, Class 150 flanges\naccording to ASME B16.5 or grooved according to AWWA C606.\ne.\nFRP Tank Pipe Connections NPS 2-1/2 (DN 65) and Larger: Type A, integral;\n[Designation E, 125-psig (0.862-MPa)] [or] [Designation F, 150-psig (1.034-MPa)]\npressure category flanges of grade same as tank material according to ASTM D 5421.\nf.\nMotorized Valves: Flanged or grooved-end, ductile-iron butterfly type with [EPDM]\n<Insert material> valve seat and stem seal; with ASTM B 148 aluminum bronze disc.\ng.\nStrainer: Basket type mounted on pump suction.\nh.\nPiping: ASTM A 53/A 53M, Type S, F, or E; Grade B, Schedule 40 black steel, with\nflanged, grooved, or threaded joints and malleable, steel welding, or ductile-iron fittings.\ni.\nPiping: ASTM B 88, Type L (ASTM B 88M, Type B) copper water tube, copper-alloy\nsolder-joint fittings and brazed, flanged, or grooved joints.\nj.\nSafety Valves: Automatic pressure relief.\nk.\nCirculating Pump: Overhung impeller, close coupled, single stage, end suction, centrifugal.\nComply with UL 778 and with HI 1.1-1.2 and HI 1.3.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
          "children": [],
          "level": 3
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 17\n1)\nCasing: Radially split, cast iron.\n2)\nPressure Rating: [125 psig (860 kPa)] [150 psig (1035 kPa)] minimum.\n3)\nImpeller: ASTM B 584, cast bronze; statically and dynamically balanced, closed,\nand keyed to shaft.\n4)\nShaft and Shaft Sleeve: Steel shaft, with copper-alloy shaft sleeve.\n5)\nSeal: Mechanical.\n6)\nMotor: ODP motor supported on the pump-bearing frame. General requirements for\nmotors are specified in Section 230513 \"Common Motor Requirements for HVAC\nEquipment.\"\nl.\nControls: Automatic control of circulating pump and tank backwash; factory wired for\nsingle electrical connection.\n1)\nPanel: NEMA 250, [Type 4] <Insert type> enclosure with time clock and pressure\ngages.\n2)\nPump: Automatic and manual switching; manual switch position bypasses safeties\nand controls.\n3)\nBackwash: Automatic; with time clock and differential pressure switch.\n4)\nBackwash Valve: Tank mounted with valves interlocked to single actuator.\nm.\nSupport: Skid mounting.[ Fabricate supports and base and attachment to tank with\nreinforcement strong enough to resist filter movement during a seismic event when\nfilter base is anchored to building structure.]\n4.\n",
      "children": [
        {
          "title": "Capacities and Characteristics:",
          "content": "a.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Filter Design:",
          "content": "1)\nWater Flow: <Insert gpm (L/s)>.\n2)\nClean Pressure Loss: [5 psig (34.5 kPa)] <Insert value>.\n3)\nMaximum Media Flow Rate: [15 gpm/sq. ft. (10.2 L/s per sq. m)] <Insert value>.\n4)\nFiltration Efficiency: [98] <Insert number> percent.\n5)\nParticle-Specific Gravity: [1.8] <Insert number>.\n6)\nParticle Size: [5] [10] [20] [45] <Insert number> microns.\nb.\nFilter Tank: With internal distribution piping.\n1)\nPressure Rating: <Insert psig (kPa)>.\n2)\nDiameter: <Insert inches (mm)>.\n3)\nInlet and Outlet Size: <Insert NPS (DN)>.\n4)\nBlowdown Piping Outlet Size: <Insert NPS (DN)>.\nc.\nFilter Media: <Insert material>.\nd.\nStart Backwash Pressure Loss: [13 psig (90 kPa)] <Insert value>.\ne.\nBackwash Period: [10] <Insert number> minutes.\nf.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Circulating Pump:",
          "content": "1)\nCapacity: <Insert gpm (L/s)>.\n2)\nTotal Dynamic Head: <Insert feet (kPa)>.\n3)\nMotor Speed: <Insert number> rpm.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
          "children": [],
          "level": 3
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 18\n4)\nInlet Size: <Insert NPS (DN)>.\n5)\nOutlet Size: <Insert NPS (DN)>.\ng.\n",
      "children": [
        {
          "title": "Pump Motor Size and Electrical Characteristics:",
          "content": "1)\nHorsepower: <Insert value>.\n2)\nVolts: [120] [208] [240] [277] [480] <Insert number> V.\n3)\nPhase: [Single] [Three].\n4)\nHertz: [60] <Insert number> Hz.\nh.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Unit Electrical Characteristics:",
          "content": "1)\nFull-Load Amperes: <Insert value>.\n2)\nMinimum Circuit Ampacity: <Insert value>.\n3)\nMaximum Overcurrent Protection: <Insert amperage>.\n4)\nInterrupting Capacity: <Insert amperage>.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Self-Cleaning Strainers:",
          "content": "1.\n<Double click here to find, evaluate, and insert list of manufacturers and products.>\n2.\nDescription: Factory-fabricated and -tested, ASTM A 126, Class B, cast-iron or steel, self-\ncleaning strainer system of tank, strainer, backwash arm or cleaning spiral, drive and motor,\npiping, and controls for removing particles from water.\na.\nFabricate and label ASTM A 126, Class B, cast-iron or steel strainer tanks to comply with\nASME Boiler and Pressure Vessel Code: Section VIII, Division 1.\nb.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Pipe Connections:",
          "content": "1)\nNPS 2 (DN 50) and Smaller: Threaded according to ASME B1.20.1.\n2)\nNPS 2-1/2 (DN 65) and Larger: Steel, Class 150 flanges according to ASME B16.5\nor grooved according to AWWA C606.\n3.\nMotorized Valves: Flanged or grooved-end, ductile-iron angle type with [EPDM] <Insert\nmaterial> valve seat and stem seal; with ASTM B 148 aluminum bronze disc.\n4.\nStrainer: ASTM A 666, Type 316 stainless steel.\n5.\nPiping: ASTM A 53/A 53M, Type S, F, or E; Grade B, Schedule 40 black steel, with flanged,\ngrooved, or threaded joints and malleable, steel welding, or ductile-iron fittings.\n6.\nSafety Valves: Automatic pressure relief.\n7.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Backwash Arm Drive:",
          "content": "a.\nDrive Casing: Cast iron.\nb.\nWorm Gears: Immersed in oil.\nc.\nMotor: ODP motor supported on the strainer-bearing frame. General requirements for\nmotors are specified in Section 230513 \"Common Motor Requirements for HVAC\nEquipment.\"\n8.\nControls: Automatic control of backwash; factory wired for single electrical connection.\na.\nPanel: NEMA 250, [Type 4] <Insert type> enclosure with time clock and pressure gages.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
          "children": [],
          "level": 3
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 19\nb.\nBackwash Arm Drive: Automatic and manual switching; manual switch position bypasses\nsafeties and controls.\nc.\nBackwash: Automatic; with time clock and differential pressure switch.\nd.\nBackwash Valve: Electric actuator.\n9.\nSupport: Skid mounting.[ Fabricate supports and base and attachment to tank with\nreinforcement strong enough to resist strainer movement during a seismic event when\nstrainer base is anchored to building structure.]\n10.\n",
      "children": [
        {
          "title": "Capacities and Characteristics:",
          "content": "a.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Strainer Design:",
          "content": "1)\nWater Flow: <Insert gpm (L/s)>.\n2)\nClean Pressure Loss: [5 psig (34.5 kPa)] <Insert value>.\n3)\nStrainer Mesh: [40] [60] [80] <Insert number>.\nb.\nStrainer Tank: With internal distribution piping.\n1)\nMaterial: [Cast iron] [Steel] <Insert material>.\n2)\nPressure Rating: [150 psig (1034 kPa)] <Insert value>.\n3)\nInlet and Outlet Size: <Insert NPS (DN)>.\n4)\nBackwash Piping Outlet Size: <Insert NPS (DN)>.\nc.\nStart Backwash: [10 psig (69 kPa)] <Insert value>.\nd.\nBackwash Period: [5] <Insert number> minutes.\ne.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Drive Motor Size and Electrical Characteristics:",
          "content": "1)\nHorsepower: <Insert value>.\n2)\nVolts: [120] [208] [240] [277] [480] <Insert number> V.\n3)\nPhase: [Single] [Three].\n4)\nHertz: [60] <Insert number> Hz.\nf.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Unit Electrical Characteristics:",
          "content": "1)\nFull-Load Amperes: <Insert value>.\n2)\nMinimum Circuit Ampacity: <Insert value>.\n3)\nMaximum Overcurrent Protection: <Insert amperage>.\n4)\nInterrupting Capacity: <Insert amperage>.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "[Bag] [Cartridge]-Type Filters:",
          "content": "1.\n<Double click here to find, evaluate, and insert list of manufacturers and products.>\n2.\nDescription: Floor-mounting housing with filter [bags] [cartridges] for removing particles from\nwater.\na.\nHousing: Corrosion resistant; designed to separate inlet from outlet and to direct inlet\nthrough [bag] [cartridge]-type water filter; with [bag support and ]base, feet, or skirt.\n1)\nPipe Connections NPS 2 (DN 50) and Smaller: Threaded according to\n",
          "children": [],
          "level": 3
        }
      ],
      "level": 0
    },
    {
      "title": "ASME B1.20.1.",
      "content": "Copyright 2013 AIA\nMasterSpec Premium\n06/13\n",
      "children": [],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 20\n2)\nSteel Housing Pipe Connections NPS 2-1/2 (DN 65) and Larger: Steel, Class 150\nflanges according to ASME B16.5 or grooved according to AWWA C606.\n3)\nPlastic Housing Pipe Connections NPS 2-1/2 (DN 65) and Larger: 150-psig (1035-\nkPa) plastic flanges.\nb.\n[Bag] [Cartridge]: Replaceable; of shape to fit housing.\n3.\n",
      "children": [
        {
          "title": "Capacities and Characteristics:",
          "content": "a.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Filter Design:",
          "content": "1)\nWater Flow Rate: <Insert gpm (L/s)>.\n2)\nFiltration Efficiency: [98] <Insert number> percent.\n3)\nParticle Size: [10] [20] <Insert number> microns and larger.\n4)\nClean Pressure Loss: [2 psig (14 kPa)] <Insert value>.\n5)\nPressure Loss at Replacement: [6 psig (41 kPa)] <Insert value>.\nb.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Housing:",
          "content": "1)\nMaterial: [Carbon steel] [Plastic].\n2)\nPressure Rating: <Insert psig (kPa)>.\n3)\nSeal Material: [Nitrile Rubber] <Insert material>.\n4)\nDiameter: <Insert inches (mm)>.\n5)\nHeight or Length: <Insert inches (mm)>.\n6)\nInlet and Outlet Size: <Insert NPS (DN)>.\n7)\nDrain Size: [Not applicable] <Insert NPS (DN)>.\n8)\nBag Support Basket Material: [Stainless steel] <Insert material>.\nc.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "[Bag] [Cartridge]:",
          "content": "1)\nNumber Required: <Insert number>.\n2)\nNominal Diameter: <Insert inches (mm)>.\n3)\nNominal Length: <Insert inches (mm)>.\n4)\nMedia Material: [Cotton] [Polyester] [Polypropylene] <Insert material>.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Centrifugal Separators:",
          "content": "1.\n<Double click here to find, evaluate, and insert list of manufacturers and products.>\n2.\nDescription: Simplex separator housing with baffles and chambers for removing particles from\nwater by centrifugal action and gravity.\n3.\nHousing: With manufacturer's proprietary system of baffles and chambers.\na.\nConstruction: Fabricate and label steel separator housing to comply with ASME Boiler and\nPressure Vessel Code: Section VIII, Division 1.\nb.\nInlet: Designed with tangential entry to produce centrifugal flow of feedwater.\nc.\nVortex Chamber: Designed for downward vortex flow and gravity separation of particles.\nd.\nCollection Chamber: Designed to hold separated particles.\ne.\nOutlet: Near top of unit.\nf.\nPurge: At bottom of collection chamber.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
          "children": [],
          "level": 3
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 21\ng.\nPipe Connections NPS 2 (DN 50) and Smaller: Threaded according to ASME B1.20.1.\nh.\nPipe Connections NPS 2-1/2 (DN 65) and Larger: Steel, Class 150 flanges according to\nASME B16.5 or grooved according to AWWA C606. Provide stainless-steel flanges if tank\nis stainless steel.\n4.\nMotorized Purge Valve: Gate or plug pattern valve.\na.\nMotorized Valves: Butterfly-type, flanged or grooved-end, ductile-iron body, with\n[EPDM] <Insert material> valve seat and stem seal; with ASTM B 148 aluminum bronze\ndisc.\nb.\nElectrical Components, Devices, and Accessories: Listed and labeled as defined in\nNFPA 70, by a qualified testing agency, and marked for intended location and application.\n5.\nStrainer: Stainless-steel basket type mounted on pump suction.\n6.\nPiping: ASTM A 53/A 53M, Type S, F, or E; Grade B, Schedule 40 black steel, with flanged,\ngrooved, or threaded joints and malleable, steel welding, or ductile-iron fittings.\n7.\nPiping: ASTM B 88, Type L (ASTM B 88M, Type B) copper water tube, copper-alloy solder-joint\nfittings, and brazed, flanged, or grooved joints.\n8.\nCirculating Pump: Overhung impeller, close coupled, single stage, end suction, centrifugal.\nComply with UL 778 and with HI 1.1-1.2 and HI 1.3.\na.\nCasing: Radially split, cast iron.\nb.\nPressure Rating: [125 psig (860 kPa)] [150 psig (1035 kPa)] minimum.\nc.\nImpeller: ASTM B 584, cast bronze; statically and dynamically balanced, closed, and\nkeyed to shaft.\nd.\nShaft and Shaft Sleeve: Steel shaft with copper-alloy shaft sleeve.\ne.\nSeal: Mechanical.\nf.\nMotor: ODP motor supported on the pump-bearing frame. General requirements for motors\nare specified in Section 230513 \"Common Motor Requirements for HVAC Equipment.\"\ng.\nElectrical Components, Devices, and Accessories: Listed and labeled as defined in\nNFPA 70, by a qualified testing agency, and marked for intended location and application.\n9.\nControls: Automatic control of circulating pump and separator purge; factory wired for single\nelectrical connection.\na.\nPanel: NEMA 250, [Type 4] <Insert type> enclosure.\nb.\nPump: Automatic and manual switching; manual switch position bypasses safeties and\ncontrols.\nc.\nSeparator Purge: Automatic and manual.\nd.\nTSS Controller Interlock: Open separator purge valve with bleed-off control.\n10.\nSupport: Skid mounting.[ Fabricate supports and base and attachment to separator housing\nwith reinforcement strong enough to resist separator movement during a seismic event when\nseparator base is anchored to building structure.]\n11.\n",
      "children": [
        {
          "title": "Capacities and Characteristics:",
          "content": "a.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Separator Design:",
          "content": "Copyright 2013 AIA\nMasterSpec Premium\n06/13\n",
          "children": [],
          "level": 3
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 22\n1)\nWater Flow Rate: <Insert gpm (L/s)>.\n2)\nPressure Loss: [5 psig (34.5 kPa)] <Insert value>.\n3)\nSeparator Efficiency: [98] <Insert number> percent.\n4)\nParticle-Specific Gravity: [1.8] <Insert number>.\n5)\nParticle Size: [5] [10] [20] [45] <Insert number> microns.\nb.\n",
      "children": [
        {
          "title": "Housing:",
          "content": "1)\nMaterial: [Steel] [Stainless steel] [Plastic] [Fiberglass] <Insert material>.\n2)\nPressure Rating: <Insert psig (kPa)>.\n3)\nDiameter: <Insert inches (mm)>.\n4)\nHeight: <Insert inches (mm)>.\n5)\nInlet and Outlet Size: <Insert NPS (DN)>.\n6)\nPurge Size: <Insert NPS (DN)>.\nc.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Circulating Pump:",
          "content": "1)\nCapacity: <Insert gpm (L/s)>.\n2)\nTotal Dynamic Head: <Insert feet (kPa)>.\n3)\nMotor Speed: <Insert number> rpm.\n4)\nInlet Size: <Insert NPS (DN)>.\n5)\nOutlet Size: <Insert NPS (DN)>.\nd.\n",
          "children": [],
          "level": 3
        },
        {
          "title": "Pump Motor Size and Electrical Characteristics:",
          "content": "1)\nHorsepower: <Insert value>.\n2)\nVolts: [120] [208] [240] [277] [480] <Insert number> V.\n3)\nPhase: [Single] [Three].\n4)\nHertz: [60] <Insert number> Hz.\n5)\nFull-Load Amperes: <Insert value>.\n6)\nMinimum Circuit Ampacity: <Insert value>.\n7)\nMaximum Overcurrent Protection: <Insert amperage>.\n8)\nInterrupting Capacity: <Insert amperage>.\n",
          "children": [],
          "level": 3
        }
      ],
      "level": 0
    },
    {
      "title": "PART 3 - EXECUTION",
      "content": "3.1\n",
      "children": [
        {
          "title": "A.",
          "content": "Perform an analysis of supply water to determine quality of water available at Project site.\n3.2\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Install chemical application equipment on concrete bases level and plumb. Maintain manufacturer's\nrecommended clearances. Arrange units so controls and devices that require servicing are accessible.\nAnchor chemical tanks and floor-mounting accessories to substrate.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
          "children": [],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 23\n",
      "children": [
        {
          "title": "B.",
          "content": "Install seismic restraints for equipment and floor-mounting accessories and anchor to building structure.\nSee Section 230548 \"Vibration and Seismic Controls for HVAC\" for seismic restraints.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "C.",
          "content": "Install water-testing equipment on wall near water-chemical-application equipment.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "D.",
          "content": "Install interconnecting control wiring for chemical treatment controls and sensors.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "E.",
          "content": "Mount sensors and injectors in piping circuits.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "F.",
          "content": "Bypass Feeders: Install in closed hydronic systems, including [hot-water heating] [chilled water] [dual-\ntemperature water] [and] [glycol cooling], and equipped with the following:\n1.\nInstall bypass feeder in a bypass circuit around circulating pumps unless otherwise indicated on\nDrawings.\n2.\nInstall water meter in makeup-water supply.\n3.\nInstall test-coupon assembly in bypass circuit around circulating pumps unless otherwise indicated\non Drawings.\n4.\nInstall a gate or full-port ball isolation valves on inlet, outlet, and drain below feeder inlet.\n5.\nInstall a swing check on inlet after the isolation valve.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "G.",
          "content": "Install automatic chemical-feed equipment for steam boiler and steam condensate systems and include the\n",
          "children": [
            {
              "title": "following:",
              "content": "1.\nInstall makeup-water softener.\n2.\nInstall water meter in makeup-water supply.\n3.\nInstall inhibitor injection pumps and solution tanks with injection timer sensing contacts in water\nmeter.\na.\nPumps shall operate for timed interval when contacts close at water meter in makeup-water\nsupply connection.\n4.\nInstall test equipment and furnish test-kit to Owner.\n5.\nInstall RO unit for makeup water.\n6.\nInstall TSS controller with sensor and bleed valves.\na.\nBleed valves shall cycle to maintain maximum TSS concentration.\n7.\nInstall inhibitor injection timer with injection pumps and solution tanks.\na.\nPumps shall operate for timed interval on contact closure at water meter in makeup-water\nsupply connection. Injection pump shall discharge into main steam supply header.\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        },
        {
          "title": "H.",
          "content": "Install automatic chemical-feed equipment for [condenser] [fluid-cooler spray] water and include the\n",
          "children": [
            {
              "title": "following:",
              "content": "1.\nInstall makeup-water softener.\n2.\nInstall water meter in makeup-water supply.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 24\n3.\nInstall inhibitor injection pumps and solution tanks with injection timer sensing contacts in water\nmeter.\na.\nPumps shall operate for timed interval on contact closure at water meter in makeup-water\nsupply connection. Injection pump shall discharge into boiler feedwater tank or feedwater\nsupply connection at boiler.\n4.\nInstall test equipment and provide test-kit to Owner. Install test-coupon assembly in bypass circuit\naround circulating pumps unless otherwise indicated on Drawings.\n5.\nInstall TSS controller with sensor and bleed valves.\na.\nBleed valves shall cycle to maintain maximum TSS concentration.\n6.\nInstall pH sensor and controller with injection pumps and solution tanks.\na.\nInjector pumps shall operate to maintain required pH.\n7.\nInstall biocide feeder alternating timer with two sets of injection pumps and solution tanks.\na.\nInjection pumps shall operate to feed biocide on an alternating basis.\n8.\nInstall ozone generator with diffusers in condenser-water piping.\na.\nOzone generator shall operate continuously with condenser-water flow.\n9.\nInstall UV-irradiation lamps in condenser-water piping.\na.\nUV lights shall operate continuously with condenser-water flow.\n3.3\n",
      "children": [
        {
          "title": "A.",
          "content": "Install ozone generator and equipment on concrete bases level and plumb. Maintain manufacturer's\nrecommended clearances. Arrange units so controls and devices that require servicing are accessible.\nAnchor mineral and brine tanks and floor-mounting accessories to substrate.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "Install seismic restraints for equipment and floor-mounting accessories and anchor to building structure.\nSee Section 230548 \"Vibration and Seismic Controls for HVAC\" for seismic restraints.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "C.",
          "content": "Pipe ozone from ozone generator to condenser water with stainless-steel pipe and fittings with welded\njoints.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "D.",
          "content": "Install [two] [three]-piece, stainless-steel ball valve in ozone supply to condenser water.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "E.",
          "content": "Pipe cooling water to ozone generator and to air-gap drain fitting with stainless-steel pipe and fittings\nwith welded joints where enclosed in ozone-generator room.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "F.",
          "content": "Install [two] [three]-piece, stainless-steel ball valve in cooling water supply to ozone generator.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
          "children": [],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 25\n",
      "children": [
        {
          "title": "G.",
          "content": "Mounting supports for ozone generator shall be ASTM A 666, Type 316 stainless steel.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "H.",
          "content": "Mount breathing apparatus outside ozone-generator room.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "I.",
          "content": "Mount and install ozone detector, warning lights, and audible alarm inside ozone-generator room. Mount\nanother set of warning lights and audible alarm just outside the main entrance to ozone-generator room.\n3.4\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Install UV-irradiation units on concrete bases level and plumb. Maintain manufacturer's recommended\nclearances. Arrange units so controls and devices that require servicing are accessible. Anchor mineral\nand brine tanks and floor-mounting accessories to substrate.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "Install seismic restraints for UV-irradiation units and floor-mounting accessories and anchor to building\nstructure. See Section 230548 \"Vibration and Seismic Controls for HVAC\" for seismic restraints.\n3.5\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Install water softener equipment on concrete bases level and plumb. Maintain manufacturer's\nrecommended clearances. Arrange units so controls and devices that require servicing are accessible.\nAnchor mineral and brine tanks and floor-mounting accessories to substrate.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "Install seismic restraints for tanks and floor-mounting accessories and anchor to building structure. See\nSection 230548 \"Vibration and Seismic Controls for HVAC\" for seismic restraints.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "C.",
          "content": "Install brine lines and fittings furnished by equipment manufacturer but not factory installed.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "D.",
          "content": "Prepare mineral-tank distribution system and underbed for minerals and place specified mineral into\nmineral tanks.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "E.",
          "content": "Install water-testing sets on wall adjacent to water softeners.\n3.6\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Install RO unit and storage tank on concrete bases level and plumb. Maintain manufacturer's\nrecommended clearances. Arrange units so controls and devices that require servicing are accessible.\nAnchor RO unit and storage tank with pumps to substrate.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "Install seismic restraints for tanks and floor-mounting accessories and anchor to building structure. See\nSection 230548 \"Vibration and Seismic Controls for HVAC\" for seismic restraints.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "C.",
          "content": "Install interconnecting piping and controls furnished by equipment manufacturer but not factory installed.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "D.",
          "content": "Install water-testing sets on wall adjacent to RO unit.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
          "children": [],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 26\n3.7\n",
      "children": [
        {
          "title": "A.",
          "content": "Piping installation requirements are specified in other Sections. Drawings indicate general arrangement of\npiping, fittings, and specialties.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "Where installing piping adjacent to equipment, allow space for service and maintenance.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "C.",
          "content": "Make piping connections between HVAC water-treatment equipment and dissimilar-metal piping with\ndielectric fittings. Dielectric fittings are specified in Section 232113 \"Hydronic Piping.\"\n",
          "children": [],
          "level": 2
        },
        {
          "title": "D.",
          "content": "Install shutoff valves on HVAC water-treatment equipment inlet and outlet. Metal general-duty valves are\nspecified in Section 230523.11 \"Globe Valves for HVAC Piping,\" Section 230523.12 \"Ball Valves for\nHVAC Piping,\" Section 230523.13 \"Butterfly Valves for HVAC Piping,\" and Section 230523.15 \"Gate\nValves for HVAC Piping.\"\n",
          "children": [],
          "level": 2
        },
        {
          "title": "E.",
          "content": "See Section 221119 \"Domestic Water Piping Specialties\" for backflow preventers required in makeup-\nwater connections to potable-water systems.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "F.",
          "content": "Confirm applicable electrical requirements in electrical Sections for connecting electrical equipment.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "G.",
          "content": "Ground equipment according to Section 260526 \"Grounding and Bonding for Electrical Systems.\"\n",
          "children": [],
          "level": 2
        },
        {
          "title": "H.",
          "content": "Connect wiring according to Section 260519 \"Low-Voltage Electrical Power Conductors and Cables.\"\n3.8\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Manufacturer's Field Service: Engage a factory-authorized service representative to test and inspect\ncomponents, assemblies, and equipment installations, including connections.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "B.",
          "content": "Perform the following tests and inspections[ with the assistance of a factory-authorized service\n",
          "children": [
            {
              "title": "representative]:",
              "content": "1.\nInspect field-assembled components and equipment installation, including piping and electrical\nconnections.\n2.\nInspect piping and equipment to determine that systems and equipment have been cleaned,\nflushed, and filled with water, and are fully operational before introducing chemicals for water-\ntreatment system.\n3.\nPlace HVAC water-treatment system into operation and calibrate controls during the preliminary\nphase of HVAC system's startup procedures.\n4.\nDo not enclose, cover, or put piping into operation until it is tested and satisfactory test results are\nachieved.\n5.\nTest for leaks and defects. If testing is performed in segments, submit separate report for each test,\ncomplete with diagram of portion of piping tested.\n6.\nLeave uncovered and unconcealed new, altered, extended, and replaced water piping until it has\nbeen tested and approved. Expose work that has been covered or concealed before it has been\ntested and approved.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 27\n7.\nCap and subject piping to static water pressure of 50 psig (345 kPa) above operating pressure,\nwithout exceeding pressure rating of piping system materials. Isolate test source and allow test\npressure to stand for four hours. Leaks and loss in test pressure constitute defects.\n8.\nRepair leaks and defects with new materials and retest piping until no leaks exist.\n",
      "children": [
        {
          "title": "C.",
          "content": "Equipment will be considered defective if it does not pass tests and inspections.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "D.",
          "content": "Prepare test and inspection reports.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "E.",
          "content": "Sample boiler water at one-week intervals after boiler startup for a period of five weeks, and prepare test\nreport advising Owner of changes necessary to adhere to \"Performance Requirements\" Article for each\nrequired characteristic. Sample boiler water at [four] [six] [eight] <Insert number>-week intervals\nfollowing the testing noted above to show that automatic chemical-feed systems are maintaining water\nquality within performance requirements specified in this Section.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "F.",
          "content": "At [four] [six] [eight] <Insert number>-week intervals following Substantial Completion, perform\nseparate water analyses on hydronic systems to show that automatic chemical-feed systems are\nmaintaining water quality within performance requirements specified in this Section. Submit written\nreports of water analysis advising Owner of changes necessary to adhere to \"Performance Requirements\"\nArticle.\n",
          "children": [],
          "level": 2
        },
        {
          "title": "G.",
          "content": "Comply with ASTM D 3370 and with the following standards:\n1.\nSilica: ASTM D 859.\n2.\nSteam System: ASTM D 1066.\n3.\nAcidity and Alkalinity: ASTM D 1067.\n4.\nIron: ASTM D 1068.\n5.\nWater Hardness: ASTM D 1126.\n3.9\n",
          "children": [],
          "level": 2
        },
        {
          "title": "A.",
          "content": "Scope of Maintenance Service: Provide chemicals and service program to maintain water conditions\nrequired above to inhibit corrosion, scale formation, and biological growth for [cooling, chilled-water\npiping] [heating, hot-water piping] [heating, steam and condensate piping] [steam and condensate\nsystem for humidifier and cooking appliance applications] [condenser-water piping] and equipment.\nServices and chemicals shall be provided for a period of one year from date of Substantial Completion\n",
          "children": [
            {
              "title": "and shall include the following:",
              "content": "1.\nInitial water analysis and HVAC water-treatment recommendations.\n2.\nStartup assistance for Contractor to flush the systems, clean with detergents, and initially fill\nsystems with required chemical treatment prior to operation.\n3.\nPeriodic field service and consultation.\n4.\nCustomer report charts and log sheets.\n5.\nLaboratory technical analysis.\n6.\nAnalyses and reports of all chemical items concerning safety and compliance with government\nregulations.\nCopyright 2013 AIA\nMasterSpec Premium\n06/13\n",
              "children": [],
              "level": 3
            }
          ],
          "level": 2
        }
      ],
      "level": 0
    },
    {
      "title": "HVAC WATER TREATMENT",
      "content": "232500 - 28\n3.10\n",
      "children": [
        {
          "title": "A.",
          "content": "[Engage a factory-authorized service representative to train] [Train] Owner's maintenance personnel\nto adjust, operate, and maintain HVAC water-treatment systems and equipment.\n",
          "children": [],
          "level": 2
        }
      ],
      "level": 0
    }
  ],
  "tables": [
    {
      "page": 1,
      "table_number": 1,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 1,
      "table_number": 2,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Drawings and general provisions of the Contract, including General and Supplementary Conditions and "
        ],
        [
          "Division 01 Specification Sections, apply to this Section."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 1,
      "table_number": 3,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Manual and automatic chemical-feed equipment and controls."
        ],
        [
          "2."
        ],
        [
          "Ozone-generator biocide equipment and controls."
        ],
        [
          "3."
        ],
        [
          "Stainless-steel pipes and fittings."
        ],
        [
          "4."
        ],
        [
          "UV-irradiation unit, biocide equipment, and controls."
        ],
        [
          "5."
        ],
        [
          "Chemical treatment test equipment."
        ],
        [
          "6."
        ],
        [
          "Chemicals."
        ],
        [
          "7."
        ],
        [
          "HVAC makeup-water softeners."
        ],
        [
          "8."
        ],
        [
          "RO equipment for HVAC makeup water."
        ],
        [
          "9."
        ],
        [
          "Water filtration equipment."
        ]
      ],
      "column_count": 1,
      "row_count": 18,
      "detection_method": "layout_analysis"
    },
    {
      "page": 1,
      "table_number": 4,
      "headers": [
        "C."
      ],
      "data": [
        [
          "TSS: Total suspended solids are solid materials, including organic and inorganic, that are suspended in "
        ],
        [
          "the water. These solids may include silt, plankton, and industrial wastes."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 1,
      "table_number": 5,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Product Data: Include rated capacities, operating characteristics, and furnished specialties and accessories "
        ],
        [
          "for the following products:"
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 2,
      "table_number": 6,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 2,
      "table_number": 7,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Bypass feeders."
        ],
        [
          "2."
        ],
        [
          "Water meters."
        ],
        [
          "3."
        ],
        [
          "Inhibitor injection timers."
        ],
        [
          "4."
        ],
        [
          "pH controllers."
        ],
        [
          "5."
        ],
        [
          "TSS controllers."
        ],
        [
          "6."
        ],
        [
          "Biocide feeder timers."
        ],
        [
          "7."
        ],
        [
          "Chemical solution tanks."
        ],
        [
          "8."
        ],
        [
          "Injection pumps."
        ],
        [
          "9."
        ],
        [
          "Ozone generators."
        ],
        [
          "10."
        ],
        [
          "UV-irradiation units."
        ],
        [
          "11."
        ],
        [
          "Chemical test equipment."
        ],
        [
          "12."
        ],
        [
          "Chemical material safety data sheets."
        ],
        [
          "13."
        ],
        [
          "Water softeners."
        ],
        [
          "14."
        ],
        [
          "RO units."
        ],
        [
          "15."
        ],
        [
          "Multimedia filters."
        ],
        [
          "16."
        ],
        [
          "Self-cleaning strainers."
        ],
        [
          "17."
        ],
        [
          "Replaceable bag- or cartridge-type filters."
        ],
        [
          "18."
        ],
        [
          "Centrifugal separators."
        ]
      ],
      "column_count": 1,
      "row_count": 36,
      "detection_method": "layout_analysis"
    },
    {
      "page": 2,
      "table_number": 8,
      "headers": [
        "B."
      ],
      "data": [
        [
          "Shop Drawings: Pretreatment and chemical[",
          ", and ozone-generator biocide",
          "][",
          ", and UV-irradiation "
        ],
        [
          "biocide",
          "] treatment equipment showing tanks, maintenance space required, and piping connections to "
        ],
        [
          "HVAC systems."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 2,
      "table_number": 9,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Seismic Qualification Certificates: For [",
          "water softeners",
          "] [",
          "RO equipment",
          "] [",
          "water filtration units",
          "] and "
        ],
        [
          "components, from manufacturer."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 2,
      "table_number": 10,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Basis for Certification: Indicate whether withstand certification is based on actual test of "
        ],
        [
          "assembled components or on calculation."
        ],
        [
          "2."
        ],
        [
          "Dimensioned Outline Drawings of Equipment Unit: Identify center of gravity and locate and "
        ],
        [
          "describe mounting and anchorage provisions."
        ]
      ],
      "column_count": 1,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 2,
      "table_number": 11,
      "headers": [
        "B."
      ],
      "data": [
        [
          "Water Analysis Provider Qualifications: Verification of experience and capability of HVAC water-"
        ],
        [
          "treatment service provider."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 2,
      "table_number": 12,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Water-Treatment Program: Written sequence of operation on an annual basis for the application "
        ],
        [
          "equipment required to achieve water quality defined in \"Performance Requirements\" Article."
        ],
        [
          "2."
        ],
        [
          "Water Analysis: Illustrate water quality available at Project site."
        ],
        [
          "3."
        ],
        [
          "Passivation Confirmation Report: Verify passivation of galvanized-steel surfaces, and confirm this "
        ],
        [
          "observation in a letter to Architect."
        ]
      ],
      "column_count": 1,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 3,
      "table_number": 13,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 3,
      "table_number": 14,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Operation and Maintenance Data: For sensors, injection pumps, [",
          "water softeners,",
          "] [",
          "RO equipment,",
          "] "
        ],
        [
          "[",
          "water filtration units,",
          "] and controllers to include in emergency, operation, and maintenance manuals."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 3,
      "table_number": 15,
      "headers": [
        "A."
      ],
      "data": [
        [
          "HVAC Water-Treatment Service Provider Qualifications: An experienced HVAC water-treatment service "
        ],
        [
          "provider capable of analyzing water qualities, installing water-treatment equipment, and applying water "
        ],
        [
          "treatment as specified in this Section."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 3,
      "table_number": 16,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Water quality for HVAC systems shall minimize corrosion, scale buildup, and biological growth for "
        ],
        [
          "optimum efficiency of HVAC equipment without creating a hazard to operating personnel or to the "
        ],
        [
          "environment."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 3,
      "table_number": 17,
      "headers": [
        "B."
      ],
      "data": [
        [
          "Base HVAC water treatment on quality of water available at Project site, HVAC system equipment "
        ],
        [
          "material characteristics and functional performance characteristics, operating personnel capabilities, and "
        ],
        [
          "requirements and guidelines of authorities having jurisdiction."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 3,
      "table_number": 18,
      "headers": [
        "C."
      ],
      "data": [
        [
          "Closed hydronic systems, including [",
          "hot-water heating",
          "] [",
          "chilled water",
          "] [",
          "dual-temperature water",
          "] "
        ],
        [
          "[",
          "and",
          "] [",
          "glycol cooling",
          "], shall have the following water qualities:"
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 3,
      "table_number": 19,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "pH: Maintain a value within [",
          "9.0 to 10.5",
          "] <",
          "Insert range",
          ">."
        ],
        [
          "2."
        ],
        [
          "\"P\" Alkalinity: Maintain a value within [",
          "100 to 500",
          "] <",
          "Insert range",
          "> ppm."
        ],
        [
          "3."
        ],
        [
          "Boron: Maintain a value within [",
          "100 to 200",
          "] <",
          "Insert range",
          "> ppm."
        ],
        [
          "4."
        ],
        [
          "Chemical Oxygen Demand: Maintain a maximum value of [",
          "100",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "5."
        ],
        [
          "Soluble Copper: Maintain a maximum value of [",
          "0.20",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "6."
        ],
        [
          "TSS: Maintain a maximum value of [",
          "10",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "7."
        ],
        [
          "Ammonia: Maintain a maximum value of [",
          "20",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "8."
        ],
        [
          "Free Caustic Alkalinity: Maintain a maximum value of [",
          "20",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "9."
        ],
        [
          "Microbiological Limits:"
        ]
      ],
      "column_count": 5,
      "row_count": 18,
      "detection_method": "layout_analysis"
    },
    {
      "page": 3,
      "table_number": 20,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Total Aerobic Plate Count: Maintain a maximum value of [",
          "1000",
          "] <",
          "Insert number",
          "> "
        ],
        [
          "organisms/mL."
        ],
        [
          "b."
        ],
        [
          "Total Anaerobic Plate Count: Maintain a maximum value of [",
          "100",
          "] <",
          "Insert number",
          "> "
        ],
        [
          "organisms/mL."
        ],
        [
          "c."
        ],
        [
          "Nitrate Reducers: Maintain a maximum value of [",
          "100",
          "] <",
          "Insert number",
          "> organisms/mL."
        ]
      ],
      "column_count": 5,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 4,
      "table_number": 21,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 4,
      "table_number": 22,
      "headers": [],
      "data": [
        [
          "d."
        ],
        [
          "Sulfate Reducers: Maintain a maximum value of [",
          "zero",
          "] <",
          "Insert number",
          "> organisms/mL."
        ],
        [
          "e."
        ],
        [
          "Iron Bacteria: Maintain a maximum value of [",
          "zero",
          "] <",
          "Insert number",
          "> organisms/mL."
        ]
      ],
      "column_count": 5,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 4,
      "table_number": 23,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "pH: Maintain a value within [",
          "7.8 to 8.4",
          "] <",
          "Insert range",
          ">."
        ],
        [
          "b."
        ],
        [
          "Total Alkalinity: Maintain a value within [",
          "5 to 50",
          "] <",
          "Insert range",
          "> ppm."
        ],
        [
          "c."
        ],
        [
          "Chemical Oxygen Demand: Maintain a maximum value of [",
          "15",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "d."
        ],
        [
          "Soluble Copper: Maintain a maximum value of [",
          "0.20",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "e."
        ],
        [
          "TSS: Maintain a maximum value of [",
          "10",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "f."
        ],
        [
          "Ammonia: Maintain a maximum value of [",
          "20",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "g."
        ],
        [
          "Total Hardness: Maintain a maximum value of [",
          "2",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "h."
        ],
        [
          "<",
          "Insert other requirements if necessary",
          ">."
        ]
      ],
      "column_count": 5,
      "row_count": 16,
      "detection_method": "layout_analysis"
    },
    {
      "page": 4,
      "table_number": 24,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "\"OH\" Alkalinity: Maintain a value within [",
          "200 to 400",
          "] <",
          "Insert range",
          "> ppm."
        ],
        [
          "b."
        ],
        [
          "TSS: Maintain a value within [",
          "600 to 3000",
          "] <",
          "Insert range",
          "> ppm."
        ],
        [
          "c."
        ],
        [
          "<",
          "Insert other requirements if necessary",
          ">."
        ]
      ],
      "column_count": 5,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 4,
      "table_number": 25,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "\"OH\" Alkalinity: Maintain a value within [",
          "200 to 400",
          "] <",
          "Insert range",
          "> ppm."
        ],
        [
          "b."
        ],
        [
          "TSS: Maintain a value within [",
          "600 to 1200",
          "] <",
          "Insert range",
          "> ppm to maximum 30 times "
        ],
        [
          "RO water TSS."
        ],
        [
          "c."
        ],
        [
          "<",
          "Insert other requirements if necessary",
          ">."
        ]
      ],
      "column_count": 5,
      "row_count": 7,
      "detection_method": "layout_analysis"
    },
    {
      "page": 4,
      "table_number": 26,
      "headers": [
        "E."
      ],
      "data": [
        [
          "Open hydronic systems, including [",
          "condenser",
          "] [",
          "fluid-cooler spray",
          "] water, shall have the following "
        ],
        [
          "water qualities:"
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 4,
      "table_number": 27,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "pH: Maintain a value within [",
          "8.0 to 9.1",
          "] <",
          "Insert range",
          ">."
        ],
        [
          "2."
        ],
        [
          "\"P\" Alkalinity: Maintain a maximum value of [",
          "100",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "3."
        ],
        [
          "Chemical Oxygen Demand: Maintain a maximum value of [",
          "100",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "4."
        ],
        [
          "Soluble Copper: Maintain a maximum value of [",
          "0.20",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "5."
        ],
        [
          "TSS: Maintain a maximum value of [",
          "10",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "6."
        ],
        [
          "Ammonia: Maintain a maximum value of [",
          "20",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "7."
        ],
        [
          "Free \"OH\" Alkalinity: Maintain a maximum value of [",
          "zero",
          "] <",
          "Insert number",
          "> ppm."
        ],
        [
          "8."
        ],
        [
          "Microbiological Limits:"
        ]
      ],
      "column_count": 5,
      "row_count": 16,
      "detection_method": "layout_analysis"
    },
    {
      "page": 4,
      "table_number": 28,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Total Aerobic Plate Count: Maintain a maximum value of [",
          "10,000",
          "] <",
          "Insert number",
          "> "
        ],
        [
          "organisms/mL."
        ]
      ],
      "column_count": 5,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 5,
      "table_number": 29,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 5,
      "table_number": 30,
      "headers": [],
      "data": [
        [
          "b."
        ],
        [
          "Total Anaerobic Plate Count: Maintain a maximum value of [",
          "1000",
          "] <",
          "Insert number",
          "> "
        ],
        [
          "organisms/mL."
        ],
        [
          "c."
        ],
        [
          "Nitrate Reducers: Maintain a maximum value of [",
          "100",
          "] <",
          "Insert number",
          "> organisms/mL."
        ],
        [
          "d."
        ],
        [
          "Sulfate Reducers: Maintain a maximum value of [",
          "zero",
          "] <",
          "Insert number",
          "> organisms/mL."
        ],
        [
          "e."
        ],
        [
          "Iron Bacteria: Maintain a maximum value of [",
          "zero",
          "] <",
          "Insert number",
          "> organisms/mL."
        ]
      ],
      "column_count": 5,
      "row_count": 9,
      "detection_method": "layout_analysis"
    },
    {
      "page": 5,
      "table_number": 31,
      "headers": [],
      "data": [
        [
          "9."
        ],
        [
          "Polymer Testable: Maintain a minimum value within [",
          "10 to 40",
          "] <",
          "Insert range",
          ">."
        ],
        [
          "10."
        ],
        [
          "<",
          "Insert other requirements if necessary",
          ">."
        ]
      ],
      "column_count": 5,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 5,
      "table_number": 32,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "pH: Maintain a value within [",
          "7 to 8",
          "] <",
          "Insert range",
          ">."
        ],
        [
          "2."
        ],
        [
          "Calcium Carbonate Hardness: Maintain a value within [",
          "100 to 300",
          "] <",
          "Insert range",
          "> ppm."
        ],
        [
          "3."
        ],
        [
          "Calcium Carbonate Alkalinity: Maintain a value within [",
          "100 to 300",
          "] <",
          "Insert range",
          "> ppm."
        ]
      ],
      "column_count": 5,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 5,
      "table_number": 33,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Bypass Feeders: Steel, with corrosion-resistant exterior coating, minimum ",
          "3-1/2-inch",
          " (89-mm)",
          " fill "
        ],
        [
          "opening in the top, and ",
          "NPS 3/4",
          " (DN 20)",
          " bottom inlet and top side outlet. Quarter turn or threaded fill cap "
        ],
        [
          "with gasket seal and diaphragm to lock the top on the feeder when exposed to system pressure in the "
        ],
        [
          "vessel."
        ]
      ],
      "column_count": 1,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 5,
      "table_number": 34,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Capacity: [",
          "2 gal.",
          " (7.6 L)",
          "] [",
          "5 gal.",
          " (19 L)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "2."
        ],
        [
          "Minimum Working Pressure: [",
          "125 psig",
          " (860 kPa)",
          "] [",
          "175 psig",
          " (1210 kPa)",
          "] <",
          "Insert value",
          ">."
        ]
      ],
      "column_count": 9,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 5,
      "table_number": 35,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "AWWA C700, oscillating-piston, magnetic-drive, totalization meter."
        ],
        [
          "2."
        ],
        [
          "Body: Bronze."
        ],
        [
          "3."
        ],
        [
          "Minimum Working-Pressure Rating: ",
          "150 psig",
          " (1035 kPa)",
          "."
        ],
        [
          "4."
        ],
        [
          "Maximum Pressure Loss at Design Flow: ",
          "3 psig",
          " (20 kPa)",
          "."
        ],
        [
          "5."
        ],
        [
          "Registration: ",
          "Gallons",
          " (Liters)",
          " or ",
          "cubic feet",
          " (cubic meters)",
          "."
        ],
        [
          "6."
        ],
        [
          "End Connections: Threaded."
        ],
        [
          "7."
        ],
        [
          "Controls: Flow-control switch with normally open contacts; rated for maximum 10 A, 250-V ac, "
        ],
        [
          "and that will close at adjustable increments of total flow."
        ]
      ],
      "column_count": 7,
      "row_count": 15,
      "detection_method": "layout_analysis"
    },
    {
      "page": 5,
      "table_number": 36,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "AWWA C701, turbine-type, totalization meter."
        ],
        [
          "2."
        ],
        [
          "Body: Bronze."
        ],
        [
          "3."
        ],
        [
          "Minimum Working-Pressure Rating: ",
          "100 psig",
          " (690 kPa)",
          "."
        ],
        [
          "4."
        ],
        [
          "Maximum Pressure Loss at Design Flow: ",
          "3 psig",
          " (20 kPa)",
          "."
        ]
      ],
      "column_count": 4,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 6,
      "table_number": 37,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 6,
      "table_number": 38,
      "headers": [],
      "data": [
        [
          "5."
        ],
        [
          "Registration: ",
          "Gallons",
          " (Liters)",
          " or ",
          "cubic feet",
          " (cubic meters)",
          "."
        ],
        [
          "6."
        ],
        [
          "End Connections: Threaded."
        ],
        [
          "7."
        ],
        [
          "Controls: Low-voltage signal capable of transmitting ",
          "1000 feet",
          " (305 m)",
          "."
        ]
      ],
      "column_count": 7,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 6,
      "table_number": 39,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "AWWA C701, turbine-type, totalization meter."
        ],
        [
          "2."
        ],
        [
          "Body: [",
          "Bronze",
          "] [",
          "Epoxy-coated cast iron",
          "]."
        ],
        [
          "3."
        ],
        [
          "Minimum Working-Pressure Rating: ",
          "150 psig",
          " (1035 kPa)",
          "."
        ],
        [
          "4."
        ],
        [
          "Maximum Pressure Loss at Design Flow: ",
          "3 psig",
          " (20 kPa)",
          "."
        ],
        [
          "5."
        ],
        [
          "Registration: ",
          "Gallons",
          " (Liters)",
          " or ",
          "cubic feet",
          " (cubic meters)",
          "."
        ],
        [
          "6."
        ],
        [
          "End Connections: Flanged."
        ],
        [
          "7."
        ],
        [
          "Controls: Flow-control switch with normally open contacts; rated for maximum 10 A, 250-V ac, "
        ],
        [
          "and that will close at adjustable increments of total flow."
        ]
      ],
      "column_count": 7,
      "row_count": 15,
      "detection_method": "layout_analysis"
    },
    {
      "page": 6,
      "table_number": 40,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Microprocessor-based controller with digital display in NEMA 250, Type 12 enclosure with "
        ],
        [
          "gasketed and lockable door.[",
          " Interface for start/stop and status indication at central "
        ],
        [
          "workstation as described in Section 230923 \"Direct Digital Control (DDC) System for "
        ],
        [
          "HVAC.\"",
          "]"
        ],
        [
          "2."
        ],
        [
          "Programmable timers with infinite adjustment over full range, and mounted in cabinet with hand-"
        ],
        [
          "off-auto switches and status lights."
        ],
        [
          "3."
        ],
        [
          "Test switch."
        ],
        [
          "4."
        ],
        [
          "Hand-off-auto switch for chemical pump."
        ],
        [
          "5."
        ],
        [
          "Illuminated legend to indicate feed when pump is activated."
        ],
        [
          "6."
        ],
        [
          "Programmable lockout timer with indicator light. Lockout timer to deactivate the pump and "
        ],
        [
          "activate alarm circuits."
        ],
        [
          "7."
        ],
        [
          "Digital display makeup totalizer to measure amount of makeup and bleed-off water from two "
        ],
        [
          "water meter inputs."
        ]
      ],
      "column_count": 2,
      "row_count": 20,
      "detection_method": "layout_analysis"
    },
    {
      "page": 6,
      "table_number": 41,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Microprocessor-based controller, 1 percent accuracy in a range from zero to 14 units. Incorporate "
        ],
        [
          "solid-state integrated circuits and digital display in NEMA 250, Type 12 enclosure with gasketed "
        ],
        [
          "and lockable door.[",
          " Interface for start/stop and status indication at central workstation as "
        ],
        [
          "described in Section 230923 \"Direct Digital Control (DDC) System for HVAC.\"",
          "]"
        ],
        [
          "2."
        ],
        [
          "Digital display and touch pad for input."
        ],
        [
          "3."
        ],
        [
          "Sensor probe adaptable to sample stream manifold."
        ],
        [
          "4."
        ],
        [
          "High, low, and normal pH indication."
        ],
        [
          "5."
        ],
        [
          "High or low-pH-alarm-light trip points, field adjustable; with silence switch."
        ],
        [
          "6."
        ],
        [
          "Hand-off-auto switch for acid pump."
        ],
        [
          "7."
        ],
        [
          "Internal adjustable hysteresis or deadband."
        ]
      ],
      "column_count": 2,
      "row_count": 17,
      "detection_method": "layout_analysis"
    },
    {
      "page": 6,
      "table_number": 42,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Microprocessor-based controller, 1 percent accuracy in a range from zero to 5000 micromhos. "
        ],
        [
          "Incorporate solid-state integrated circuits and digital display in NEMA 250, Type 12 enclosure "
        ],
        [
          "with "
        ],
        [
          "gasketed "
        ],
        [
          "and "
        ],
        [
          "lockable "
        ],
        [
          "door.[",
          " Interface "
        ],
        [
          "for "
        ],
        [
          "start/stop "
        ],
        [
          "and "
        ],
        [
          "status "
        ]
      ],
      "column_count": 2,
      "row_count": 12,
      "detection_method": "layout_analysis"
    },
    {
      "page": 7,
      "table_number": 43,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 7,
      "table_number": 44,
      "headers": [],
      "data": [
        [
          "indication at central workstation as described in Section 230923 \"Direct Digital Control "
        ],
        [
          "(DDC) System for HVAC.\"",
          "]"
        ],
        [
          "2."
        ],
        [
          "Digital display and touch pad for input."
        ],
        [
          "3."
        ],
        [
          "Sensor probe adaptable to sample stream manifold."
        ],
        [
          "4."
        ],
        [
          "High, low, and normal conductance indication."
        ],
        [
          "5."
        ],
        [
          "High- or low-conductance-alarm-light trip points, field adjustable; with silence switch."
        ],
        [
          "6."
        ],
        [
          "Hand-off-auto switch for solenoid bleed-off valve."
        ],
        [
          "7."
        ],
        [
          "Bleed-off valve activated indication."
        ],
        [
          "8."
        ],
        [
          "Internal adjustable hysteresis or deadband."
        ],
        [
          "9."
        ],
        [
          "Bleed Valves:"
        ]
      ],
      "column_count": 2,
      "row_count": 18,
      "detection_method": "layout_analysis"
    },
    {
      "page": 7,
      "table_number": 45,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Cooling Systems: Forged-brass body, globe pattern, general-purpose solenoid with "
        ],
        [
          "continuous-duty coil, or motorized valve."
        ],
        [
          "b."
        ],
        [
          "Steam Boilers: Motorized ball valve, steel body, and TFE seats and seals."
        ]
      ],
      "column_count": 1,
      "row_count": 5,
      "detection_method": "layout_analysis"
    },
    {
      "page": 7,
      "table_number": 46,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Microprocessor-based controller with digital display in NEMA 250, Type 12 enclosure with "
        ],
        [
          "gasketed and lockable door.[",
          " Interface for start/stop and status indication at central "
        ],
        [
          "workstation as described in Section 230923 \"Direct Digital Control (DDC) System for "
        ],
        [
          "HVAC.\"",
          "]"
        ],
        [
          "2."
        ],
        [
          "24-hour timer with 14-day skip feature to permit activation any hour of day."
        ],
        [
          "3."
        ],
        [
          "Precision, solid-state, bleed-off lockout timer and clock-controlled biocide pump timer. Prebleed "
        ],
        [
          "and bleed lockout timers."
        ],
        [
          "4."
        ],
        [
          "Solid-state alternator to enable use of two formulations."
        ],
        [
          "5."
        ],
        [
          "24-hour display of time of day."
        ],
        [
          "6."
        ],
        [
          "14-day display of day of week."
        ],
        [
          "7."
        ],
        [
          "Battery backup so clock is not disturbed by power outages."
        ],
        [
          "8."
        ],
        [
          "Hand-off-auto switches for biocide pumps."
        ],
        [
          "9."
        ],
        [
          "Biocide A and Biocide B pump running indication."
        ]
      ],
      "column_count": 2,
      "row_count": 22,
      "detection_method": "layout_analysis"
    },
    {
      "page": 7,
      "table_number": 47,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Chemical-resistant reservoirs fabricated from high-density opaque polyethylene with minimum "
        ],
        [
          "110 percent containment vessel."
        ],
        [
          "2."
        ],
        [
          "Molded cover with recess for mounting pump."
        ],
        [
          "3."
        ],
        [
          "Capacity: [",
          "30 gal.",
          " (114 L)",
          "] [",
          "50 gal.",
          " (189 L)",
          "] [",
          "120 gal.",
          " (454 L)",
          "] <",
          "Insert value",
          ">."
        ]
      ],
      "column_count": 12,
      "row_count": 7,
      "detection_method": "layout_analysis"
    },
    {
      "page": 7,
      "table_number": 48,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Self-priming, positive displacement; rated for intended chemical with minimum 25 percent safety "
        ],
        [
          "factor for design pressure and temperature."
        ],
        [
          "2."
        ],
        [
          "Adjustable flow rate."
        ],
        [
          "3."
        ],
        [
          "Metal and thermoplastic construction."
        ],
        [
          "4."
        ],
        [
          "Built-in relief valve."
        ],
        [
          "5."
        ],
        [
          "Fully enclosed, continuous-duty, single-phase motor. Comply with requirements in "
        ],
        [
          "Section 230513 \"Common Motor Requirements for HVAC Equipment.\""
        ]
      ],
      "column_count": 1,
      "row_count": 12,
      "detection_method": "layout_analysis"
    },
    {
      "page": 7,
      "table_number": 49,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Electrical Components, Devices, and Accessories: Listed and labeled as defined in "
        ],
        [
          "NFPA 70, by a qualified testing agency, and marked for intended location and application."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 8,
      "table_number": 50,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 8,
      "table_number": 51,
      "headers": [
        "J."
      ],
      "data": [
        [
          "Chemical Solution Tubing: Polyethylene tubing with compression fittings and joints except "
        ],
        [
          "ASTM A 269, Type 304, stainless steel for steam boiler injection assemblies."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 8,
      "table_number": 52,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Quill: Minimum ",
          "NPS 1/2",
          " (DN 15)",
          " with insertion length sufficient to discharge into at least 25 "
        ],
        [
          "percent of pipe diameter."
        ],
        [
          "2."
        ],
        [
          "Ball Valve: [",
          "Three",
          "] [",
          "Two",
          "]-piece stainless steel, as described in \"Stainless-Steel Pipes and "
        ],
        [
          "Fittings\" Article; selected to fit quill."
        ],
        [
          "3."
        ],
        [
          "Packing Gland: Mechanical seal on quill of sufficient length to allow quill removal during system "
        ],
        [
          "operation."
        ],
        [
          "4."
        ],
        [
          "Assembly Pressure/Temperature Rating: Minimum ",
          "600 psig",
          " (4137 kPa)",
          " at ",
          "200 deg F",
          " (93 deg C)",
          "."
        ]
      ],
      "column_count": 7,
      "row_count": 11,
      "detection_method": "layout_analysis"
    },
    {
      "page": 8,
      "table_number": 53,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Corona discharge generator with stainless-steel generating cells and transformer housed in a NEMA 250, "
        ],
        [
          "Type 4 enclosure. Assembly shall be suitable for continuous duty. Provide site glasses to verify proper "
        ],
        [
          "operation of generator."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 8,
      "table_number": 54,
      "headers": [
        "B."
      ],
      "data": [
        [
          "Water-cooled generators shall be provided with cooling water at maximum [",
          "70 deg F",
          " (21 deg C)",
          "] "
        ],
        [
          "<",
          "Insert value",
          "> and [",
          "35 psig",
          " (241 kPa)",
          "] <",
          "Insert value",
          ">."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 8,
      "table_number": 55,
      "headers": [
        "C."
      ],
      "data": [
        [
          "Generator vessels exposed to system pressure shall be constructed according to ASME Boiler and "
        ],
        [
          "Pressure Vessel Code and be equipped with pressure relief valve."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 8,
      "table_number": 56,
      "headers": [
        "D."
      ],
      "data": [
        [
          "External air compressor or induced airflow through a cleanable prefilter supplies concentrated oxygen "
        ],
        [
          "through a molecular sieve with ",
          "minus 62 deg F",
          " (minus 52 deg C)",
          " dew point to avoid the formation of "
        ],
        [
          "nitric acid."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 8,
      "table_number": 57,
      "headers": [
        "E."
      ],
      "data": [
        [
          "Microprocessor-based control with software in EEPROM, surge protection, high-temperature cutout, and "
        ],
        [
          "operational status lights.[",
          " Interface for start/stop and status indication at central workstation as "
        ],
        [
          "described in Section 230923 \"Direct Digital Control (DDC) System for HVAC.\"",
          "]"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 8,
      "table_number": 58,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Bubble diffusers."
        ],
        [
          "2."
        ],
        [
          "Induction injection nozzle."
        ],
        [
          "3."
        ],
        [
          "Injectors with static mixers."
        ]
      ],
      "column_count": 1,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 8,
      "table_number": 59,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Sensor: Metal dioxide semiconductor."
        ],
        [
          "b."
        ],
        [
          "Concentration Range: [",
          "0.01 to 0.14",
          "] <",
          "Insert range",
          "> ppm."
        ],
        [
          "c."
        ],
        [
          "Accuracy: Plus or minus 20 percent of range."
        ],
        [
          "d."
        ],
        [
          "Sensitivity: 0.01 ppm."
        ],
        [
          "e."
        ],
        [
          "Response Time: Maximum 10 seconds."
        ]
      ],
      "column_count": 5,
      "row_count": 10,
      "detection_method": "layout_analysis"
    },
    {
      "page": 9,
      "table_number": 60,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 9,
      "table_number": 61,
      "headers": [],
      "data": [
        [
          "f."
        ],
        [
          "Operating Temperature: ",
          "50 to 100 deg F",
          " (10 to 38 deg C)",
          "."
        ],
        [
          "g."
        ],
        [
          "Relative Humidity: 20 to 95 percent, noncondensing over the operating temperature range."
        ]
      ],
      "column_count": 4,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 9,
      "table_number": 62,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Electric-vibrating-polarized type."
        ],
        [
          "b."
        ],
        [
          "24-V dc, with provision for housing the operating mechanism behind a grille."
        ],
        [
          "c."
        ],
        [
          "Horns shall produce a sound-pressure level of 90 dBA, measured ",
          "10 feet",
          " (3 m)",
          " from the "
        ],
        [
          "horn."
        ],
        [
          "d."
        ],
        [
          "Electrical Components, Devices, and Accessories: Listed and labeled as defined in "
        ],
        [
          "NFPA 70, by a qualified testing agency, and marked for intended location and application."
        ]
      ],
      "column_count": 4,
      "row_count": 10,
      "detection_method": "layout_analysis"
    },
    {
      "page": 9,
      "table_number": 63,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Xenon strobe lights listed in UL 1971, with clear or nominal white polycarbonate lens "
        ],
        [
          "mounted on an aluminum faceplate."
        ],
        [
          "b."
        ],
        [
          "Rated Light Output: [",
          "75",
          "] [",
          "110",
          "] <",
          "Insert number",
          "> candela."
        ],
        [
          "c."
        ],
        [
          "Strobe Leads: Factory connected to screw terminals."
        ]
      ],
      "column_count": 7,
      "row_count": 7,
      "detection_method": "layout_analysis"
    },
    {
      "page": 9,
      "table_number": 64,
      "headers": [
        "H."
      ],
      "data": [
        [
          "Self-Contained Breathing Apparatus: Open-circuit, pressure-demand compressed air includes completely "
        ],
        [
          "assembled, portable, self-contained devices designed for hazardous breathing environment application."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 9,
      "table_number": 65,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Face Piece: EPDM or silicone rubber construction material, one-size-fits-all with double-sealing "
        ],
        [
          "edge, stainless-steel speaking diaphragm and lens retainer, five adjustable straps to hold face piece "
        ],
        [
          "to head (two straps on each side and one on top), exhalation valve in mask, close-fitting nose piece "
        ],
        [
          "to ensure no CO",
          "2",
          " buildup, and perspiration drain to avoid skin irritation and to prevent eyepiece, "
        ],
        [
          "spectacle, and lens fogging."
        ],
        [
          "2."
        ],
        [
          "Backplate: Orthopedically designed of [",
          "chemical and impact-resistant, glass-fiber composite",
          "] "
        ],
        [
          "[",
          "aluminum",
          "]."
        ],
        [
          "3."
        ],
        [
          "Harness and Carrier Assembly: Large triangular back pad, backplate, and adjustable waist and "
        ],
        [
          "shoulder straps. Modular in design, detachable components, and easy to clean and maintain. "
        ],
        [
          "Shoulder straps padded with flame-resistant material, reinforced with stainless-steel cable, and "
        ],
        [
          "attached with T-nuts, washers, and screws."
        ],
        [
          "4."
        ],
        [
          "Air Cylinder: [",
          "30",
          "] [",
          "45",
          "] [",
          "60",
          "]-minute, low-pressure, air-supply-loaded [",
          "fiberglass",
          "] [",
          "aluminum",
          "] "
        ],
        [
          "[",
          "steel",
          "] cylinders fitted with quick-fill assembly for refilling and air transfer."
        ],
        [
          "5."
        ],
        [
          "Wall-Mounting Cabinet: Leakproof, corrosion-resistant, clear, plastic case."
        ],
        [
          "6."
        ],
        [
          "Tested and Certified: By the National Institute for Occupational Safety and Health and by the "
        ],
        [
          "Mine Safety and Health Administration, according to 42 CFR 84, Subpart H."
        ]
      ],
      "column_count": 11,
      "row_count": 22,
      "detection_method": "layout_analysis"
    },
    {
      "page": 9,
      "table_number": 66,
      "headers": [
        "C."
      ],
      "data": [
        [
          "Two-Piece, Full-Port, Stainless-Steel Ball Valves: ASTM A 351/A 351M, Type 316 stainless-steel body; "
        ],
        [
          "ASTM A 276, "
        ],
        [
          "Type 316 "
        ],
        [
          "stainless-steel "
        ],
        [
          "stem "
        ],
        [
          "and "
        ],
        [
          "vented "
        ],
        [
          "ball, "
        ],
        [
          "carbon-filled "
        ],
        [
          "TFE "
        ]
      ],
      "column_count": 1,
      "row_count": 10,
      "detection_method": "layout_analysis"
    },
    {
      "page": 10,
      "table_number": 67,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 10,
      "table_number": 68,
      "headers": [
        "D."
      ],
      "data": [
        [
          "Three-Piece, Full-Port, Stainless-Steel Ball Valves: ASTM A 351/A 351M, Type 316 stainless-steel "
        ],
        [
          "body; ASTM A 276, Type 316 stainless-steel stem and vented ball, threaded body design with adjustable "
        ],
        [
          "stem packing, threaded ends, and ",
          "150-psig",
          " (1035-kPa)",
          " Steam Working Pressure and ",
          "600-psig",
          " (4140-kPa)",
          " "
        ],
        [
          "Cold Working Pressure rating."
        ]
      ],
      "column_count": 1,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 10,
      "table_number": 69,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "ASTM A 666, Type 304 stainless steel."
        ],
        [
          "2."
        ],
        [
          "Construct for minimum [",
          "150 psig",
          " (1035 kPa)",
          "] <",
          "Insert value",
          "> at [",
          "150 deg F",
          " (65 deg C)",
          "] <",
          "Insert "
        ],
        [
          "value",
          "> according to ASME Boiler and Pressure Vessel Code, and equipped with pressure relief "
        ],
        [
          "valve."
        ],
        [
          "3."
        ],
        [
          "Light Source Sleeve: Quartz, with EPDM O-ring seals."
        ],
        [
          "4."
        ],
        [
          "Light Source: Replaceable UV lamp producing minimum target irradiation of 254-nm wavelength "
        ],
        [
          "light."
        ]
      ],
      "column_count": 10,
      "row_count": 11,
      "detection_method": "layout_analysis"
    },
    {
      "page": 10,
      "table_number": 70,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Test Kit: Manufacturer-recommended equipment and chemicals in a wall-mounting cabinet for testing "
        ],
        [
          "pH, TSS, inhibitor, chloride, alkalinity, and hardness; sulfite and testable polymer tests for high-pressure "
        ],
        [
          "boilers; and oxidizing biocide test for open cooling systems."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 10,
      "table_number": 71,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Size: ",
          "NPS 1/4",
          " (DN 8)",
          " tubing."
        ],
        [
          "b."
        ],
        [
          "Material: ASTM A 666, Type 316 stainless steel."
        ],
        [
          "c."
        ],
        [
          "Pressure Rating: Minimum ",
          "2000 psig",
          " (13 790 kPa)",
          "."
        ],
        [
          "d."
        ],
        [
          "Temperature Rating: Minimum ",
          "850 deg F",
          " (454 deg C)",
          "."
        ]
      ],
      "column_count": 4,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 10,
      "table_number": 72,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Material: ASTM A 666, Type 304 stainless steel."
        ],
        [
          "b."
        ],
        [
          "Pressure Rating: Minimum ",
          "250 psig",
          " (1725 kPa)",
          "."
        ],
        [
          "c."
        ],
        [
          "Temperature Rating: Minimum ",
          "450 deg F",
          " (232 deg C)",
          "."
        ]
      ],
      "column_count": 4,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 11,
      "table_number": 73,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 11,
      "table_number": 74,
      "headers": [],
      "data": [
        [
          "2)"
        ],
        [
          "Entering Temperature: [",
          "400 deg F",
          " (204 deg C)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Leaving Temperature: [",
          "88 deg F",
          " (31 deg C)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "4)"
        ],
        [
          "Pressure Loss: [",
          "6.5 psig",
          " (44.8 kPa)",
          "] <",
          "Insert value",
          ">."
        ]
      ],
      "column_count": 6,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 11,
      "table_number": 75,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Flow Rate: [",
          "3 gpm",
          " (0.19 L/s)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Entering Temperature: [",
          "70 deg F",
          " (21 deg C)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Pressure Loss: [",
          "1.0 psig",
          " (6.89 kPa)",
          "] <",
          "Insert value",
          ">."
        ]
      ],
      "column_count": 6,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 11,
      "table_number": 76,
      "headers": [
        "C."
      ],
      "data": [
        [
          "Corrosion Test-Coupon Assembly: Constructed of corrosive-resistant material, complete with piping, "
        ],
        [
          "valves, and mild steel and copper coupons. Locate copper coupon downstream from mild steel coupon in "
        ],
        [
          "the test-coupon assembly."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 11,
      "table_number": 77,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "[",
          "Two",
          "] <",
          "Insert number",
          ">-station rack for closed-loop systems."
        ],
        [
          "2."
        ],
        [
          "[",
          "Four",
          "] <",
          "Insert number",
          ">-station rack for open-loop systems."
        ]
      ],
      "column_count": 5,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 11,
      "table_number": 78,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Chemicals shall be as recommended by water-treatment system manufacturer that are compatible with "
        ],
        [
          "piping system components and connected equipment and that can attain water quality specified in "
        ],
        [
          "\"Performance Requirements\" Article."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 11,
      "table_number": 79,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Mineral: High-capacity, sulfonated-polystyrene ion-exchange resin that is stable over entire pH "
        ],
        [
          "range with good resistance to bead fracture from attrition or shock. Resin exchange capacity "
        ],
        [
          "minimum ",
          "30,000 grains/cu. ft.",
          " (69 kg/cu. m)",
          " of calcium carbonate of resin when regenerated with "
        ],
        [
          "15 lb",
          " (6.8 kg)",
          " of salt."
        ],
        [
          "2."
        ],
        [
          "Salt for Brine Tanks: High-purity sodium chloride, free of dirt and foreign material. Rock and "
        ],
        [
          "granulated forms are unacceptable."
        ]
      ],
      "column_count": 4,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 11,
      "table_number": 80,
      "headers": [
        "C."
      ],
      "data": [
        [
          "Electrical Components, Devices, and Accessories: Listed and labeled as defined in NFPA 70, by a "
        ],
        [
          "qualified testing agency, and marked for intended location and application."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 11,
      "table_number": 81,
      "headers": [
        "D."
      ],
      "data": [
        [
          "Fabricate supports and attachments to tanks with reinforcement strong enough to resist tank movement "
        ],
        [
          "during seismic event when tank supports are anchored to building structure as recommended in writing "
        ],
        [
          "by manufacturer."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 11,
      "table_number": 82,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Fabricate and label steel filter tanks to comply with ASME Boiler and Pressure Vessel Code: "
        ],
        [
          "Section VIII, Division 1."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 12,
      "table_number": 83,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 12,
      "table_number": 84,
      "headers": [],
      "data": [
        [
          "2."
        ],
        [
          "Fabricate and label Fiber Reinforced Plastic filter tanks to comply with ASME Boiler and Pressure "
        ],
        [
          "Vessel Code: Section X, if indicated."
        ],
        [
          "3."
        ],
        [
          "Pressure Rating: [",
          "100 psig",
          " (690 kPa)",
          "] [",
          "125 psig",
          " (860 kPa)",
          "] [",
          "150 psig",
          " (1035 kPa)",
          "] <",
          "Insert "
        ],
        [
          "value",
          "> minimum."
        ],
        [
          "4."
        ],
        [
          "Wetted Components: Suitable for water temperatures from [",
          "40 to at least 100 deg F",
          " (5 to at least "
        ],
        [
          "38 deg C)",
          "] <",
          "Insert range",
          ">."
        ],
        [
          "5."
        ],
        [
          "Freeboard: 50 percent, minimum, for backwash expansion above the normal resin bed level."
        ],
        [
          "6."
        ],
        [
          "Support Legs or Skirt: Constructed of structural steel, welded, or bonded to tank before testing and "
        ],
        [
          "labeling."
        ],
        [
          "7."
        ],
        [
          "Finish: Hot-dip galvanized on exterior and interior of tank after fabrication."
        ],
        [
          "8."
        ],
        [
          "Upper Distribution System: Single-point type, fabricated from galvanized-steel pipe and fittings."
        ],
        [
          "9."
        ],
        [
          "Lower Distribution System: Hub and radial-arm or header-lateral type; fabricated from PVC pipe "
        ],
        [
          "and fittings with individual, fine-slotted, nonclogging polyethylene strainers; arranged for even-"
        ],
        [
          "flow distribution through resin bed."
        ]
      ],
      "column_count": 11,
      "row_count": 22,
      "detection_method": "layout_analysis"
    },
    {
      "page": 12,
      "table_number": 85,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Adjustable duration of regeneration steps."
        ],
        [
          "2."
        ],
        [
          "Push-button start and complete manual operation override."
        ],
        [
          "3."
        ],
        [
          "Pointer on pilot-control valve shall indicate cycle of operation."
        ],
        [
          "4."
        ],
        [
          "Means of manual operation of pilot-control valve if power fails."
        ],
        [
          "5."
        ],
        [
          "Main Operating Valves: Industrial, automatic, multiport, diaphragm type with the following "
        ],
        [
          "features:"
        ]
      ],
      "column_count": 1,
      "row_count": 11,
      "detection_method": "layout_analysis"
    },
    {
      "page": 12,
      "table_number": 86,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Slow opening and closing, nonslam operation."
        ],
        [
          "b."
        ],
        [
          "Diaphragm guiding on full perimeter from fully open to fully closed."
        ],
        [
          "c."
        ],
        [
          "Isolated dissimilar metals within valve."
        ],
        [
          "d."
        ],
        [
          "Self-adjusting, internal, automatic brine injector that draws brine and rinses at constant rate "
        ],
        [
          "independent of pressure."
        ],
        [
          "e."
        ],
        [
          "Float-operated brine valve to automatically measure the correct amount of brine to the "
        ],
        [
          "softener and refill with fresh water."
        ],
        [
          "f."
        ],
        [
          "Sampling cocks for soft water."
        ]
      ],
      "column_count": 1,
      "row_count": 14,
      "detection_method": "layout_analysis"
    },
    {
      "page": 12,
      "table_number": 87,
      "headers": [],
      "data": [
        [
          "6."
        ],
        [
          "Flow Control: Automatic control of backwash and flush rates over variations in operating "
        ],
        [
          "pressures that do not require field adjustments. Equip mineral tanks with automatic-reset-head "
        ],
        [
          "water meter that electrically activates cycle controller to initiate regeneration at preset total in "
        ],
        [
          "gallons",
          " (liters)",
          " and that automatically resets after regeneration to preset total in ",
          "gallons",
          " (liters)",
          " for "
        ],
        [
          "next service run. Include alternator to regenerate one mineral tank with the other in service."
        ]
      ],
      "column_count": 6,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 12,
      "table_number": 88,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Tank and Cover Material: Fiberglass a minimum of ",
          "3/16 inch",
          " (4.8 mm)",
          " thick; or molded "
        ],
        [
          "polyethylene a minimum of ",
          "3/8 inch",
          " (9.5 mm)",
          " thick."
        ],
        [
          "2."
        ],
        [
          "Brine Valve: Float operated and plastic fitted for automatic control of brine withdrawn and "
        ],
        [
          "freshwater refill."
        ],
        [
          "3."
        ],
        [
          "Size: Large enough for at least four regenerations at full salting."
        ]
      ],
      "column_count": 4,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 13,
      "table_number": 89,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 13,
      "table_number": 90,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Piping, valves, tubing, and drains."
        ],
        [
          "2."
        ],
        [
          "Sampling cocks."
        ],
        [
          "3."
        ],
        [
          "Main-operating-valve position indicators."
        ],
        [
          "4."
        ],
        [
          "Water meters."
        ]
      ],
      "column_count": 1,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 13,
      "table_number": 91,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Continuous Service Flow Rate: <",
          "Insert ",
          "gpm",
          " (L/s)",
          "> at ",
          "15-psig",
          " (104-kPa)",
          " pressure loss."
        ],
        [
          "2."
        ],
        [
          "Peak Service Flow Rate: <",
          "Insert ",
          "gpm",
          " (L/s)",
          "> at ",
          "25-psig",
          " (173-kPa)",
          " pressure loss."
        ],
        [
          "3."
        ],
        [
          "Water Consumption: <",
          "Insert ",
          "gal./day",
          " (cu. m/day)",
          ">."
        ],
        [
          "4."
        ],
        [
          "Water Demand: <",
          "Insert number",
          "> hours/day."
        ],
        [
          "5."
        ],
        [
          "Electrical Characteristics:"
        ]
      ],
      "column_count": 8,
      "row_count": 10,
      "detection_method": "layout_analysis"
    },
    {
      "page": 13,
      "table_number": 92,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Volts: <",
          "Insert value",
          ">."
        ],
        [
          "b."
        ],
        [
          "Phase: <",
          "Insert value",
          ">."
        ],
        [
          "c."
        ],
        [
          "Hertz: <",
          "Insert value",
          ">."
        ],
        [
          "d."
        ],
        [
          "Full-Load Amperes: <",
          "Insert value",
          ">."
        ],
        [
          "e."
        ],
        [
          "Minimum Circuit Ampacity: <",
          "Insert value",
          ">."
        ],
        [
          "f."
        ],
        [
          "Maximum Overcurrent Protection: <",
          "Insert amperage",
          ">."
        ],
        [
          "g."
        ],
        [
          "Interrupting Capacity: <",
          "Insert amperage",
          ">."
        ]
      ],
      "column_count": 3,
      "row_count": 14,
      "detection_method": "layout_analysis"
    },
    {
      "page": 13,
      "table_number": 93,
      "headers": [
        "B."
      ],
      "data": [
        [
          "Description: Factory fabricated and tested with RO membrane elements in housings, high-pressure pumps "
        ],
        [
          "and motors, controls, valves, and prefilter; mounted on skid."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 13,
      "table_number": 94,
      "headers": [
        "C."
      ],
      "data": [
        [
          "Electrical Components, Devices, and Accessories: Listed and labeled as defined in NFPA 70, by a "
        ],
        [
          "qualified testing agency, and marked for intended location and application."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 13,
      "table_number": 95,
      "headers": [
        "D."
      ],
      "data": [
        [
          "Fabricate supports and attachments to tanks with reinforcement strong enough to resist tank movement "
        ],
        [
          "during seismic event when tank supports are anchored to building structure as recommended in writing "
        ],
        [
          "by manufacturer."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 13,
      "table_number": 96,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Element: Thin-film composite with U-cup brine seal with minimum 98 percent salt rejection based "
        ],
        [
          "on 2000-ppm water supplied at ",
          "225 psig",
          " (1551 kPa)",
          " and ",
          "77 deg F",
          " (25 deg C)",
          "."
        ],
        [
          "2."
        ],
        [
          "Housing: ASTM A 666, Type 304 stainless steel with PVC end caps held in place with stainless-"
        ],
        [
          "steel straps."
        ]
      ],
      "column_count": 7,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 14,
      "table_number": 97,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 14,
      "table_number": 98,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Vertical, multistage centrifugal operating at 3500 rpm with ASTM A 666, Type 304 "
        ],
        [
          "stainless-steel casing, shaft, impellers, and inlet and discharge casting."
        ],
        [
          "b."
        ],
        [
          "Bearings shall be tungsten carbide and ceramic."
        ],
        [
          "c."
        ],
        [
          "Cast-iron frame and flanged suction and discharge connections."
        ],
        [
          "d."
        ],
        [
          "Motor: NEMA-standard, C-faced totally enclosed, fan cooled motor supported on the "
        ],
        [
          "pump-bearing frame. General requirements for motors are specified in Section 230513 "
        ],
        [
          "\"Common Motor Requirements for HVAC Equipment.\""
        ]
      ],
      "column_count": 1,
      "row_count": 11,
      "detection_method": "layout_analysis"
    },
    {
      "page": 14,
      "table_number": 99,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Microprocessor-based controller with digital display."
        ],
        [
          "2."
        ],
        [
          "Interlock for remote start/stop control."
        ],
        [
          "3."
        ],
        [
          "Membrane flush sequence when pumps shut down."
        ],
        [
          "4."
        ],
        [
          "Run time indicator."
        ],
        [
          "5."
        ],
        [
          "Low-pressure safety cutoff."
        ],
        [
          "6."
        ],
        [
          "Panel-mounted gages as follows:"
        ]
      ],
      "column_count": 1,
      "row_count": 12,
      "detection_method": "layout_analysis"
    },
    {
      "page": 14,
      "table_number": 100,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Product and concentrate."
        ],
        [
          "b."
        ],
        [
          "Inlet, cartridge filter outlet, RO feed, RO concentrate, and RO product pressures."
        ],
        [
          "c."
        ],
        [
          "Product conductivity monitor."
        ]
      ],
      "column_count": 1,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 14,
      "table_number": 101,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Stainless-steel pump, concentrate, and recycle throttling valves rated for minimum ",
          "300 psig",
          " (2068 "
        ],
        [
          "kPa)",
          "."
        ],
        [
          "2."
        ],
        [
          "Automatic inlet shutoff valve, diaphragm type; solenoid actuated, normally closed, and "
        ],
        [
          "constructed of glass-reinforced noryl thermoplastic."
        ],
        [
          "3."
        ],
        [
          "PVC valves with EPDM seats and seals for isolation at inlet, and check and sample valves at "
        ],
        [
          "product and concentrate. Sample valves at cartridge filter outlet, concentrate, and product outlet."
        ]
      ],
      "column_count": 3,
      "row_count": 9,
      "detection_method": "layout_analysis"
    },
    {
      "page": 14,
      "table_number": 102,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Housing: Polypropylene with built-in relief or vent valve."
        ],
        [
          "2."
        ],
        [
          "Element: Spun-wound polypropylene."
        ]
      ],
      "column_count": 1,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 14,
      "table_number": 103,
      "headers": [
        "K."
      ],
      "data": [
        [
          "Inlet Water Tempering Valve: Thermostatic water-tempering valve to maintain [",
          "77 deg F",
          " (25 deg C)",
          "] "
        ],
        [
          "<",
          "Insert value",
          "> inlet water temperature to RO unit."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 14,
      "table_number": 104,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Media Tank: Fiberglass-reinforced polyester rated for minimum ",
          "150 psig",
          " (1035 kPa)",
          " with internal "
        ],
        [
          "backwash distributor and filtered water collector."
        ],
        [
          "2."
        ],
        [
          "Media: 12-by-40-mesh, bituminous coal-based activated carbon."
        ],
        [
          "3."
        ],
        [
          "Backwash Valve: Piston-operated control valve with drain-line, flow-control orifice."
        ],
        [
          "4."
        ],
        [
          "Backwash Control: Seven-day time clock."
        ]
      ],
      "column_count": 4,
      "row_count": 9,
      "detection_method": "layout_analysis"
    },
    {
      "page": 15,
      "table_number": 105,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 15,
      "table_number": 106,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Tank: Polyethylene single piece with closed top and flat bottom with manway in top, 0.2-micron "
        ],
        [
          "filter vent, inlet, discharge, and drain piping connections, and bulkhead fittings for level controls."
        ],
        [
          "2."
        ],
        [
          "Control: Level switches start and stop RO unit. Low-level limit shall stop repressurization pumps "
        ],
        [
          "and signal an alarm."
        ]
      ],
      "column_count": 1,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 15,
      "table_number": 107,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Pumps: Two close-coupled, single-stage centrifugal pumps with mechanical seals. Wetted "
        ],
        [
          "components ASTM A 666, Type 316 stainless steel."
        ],
        [
          "2."
        ],
        [
          "Controls: NEMA-4X pump control panel constructed of fiberglass to control pumps, one "
        ],
        [
          "operating and one standby, with automatic alternator and fail-over control."
        ],
        [
          "3."
        ],
        [
          "Motor: Open, drip proof motor supported on the pump-bearing frame. General requirements for "
        ],
        [
          "motors are specified in Section 230513 \"Common Motor Requirements for HVAC Equipment.\""
        ]
      ],
      "column_count": 1,
      "row_count": 9,
      "detection_method": "layout_analysis"
    },
    {
      "page": 15,
      "table_number": 108,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Electrical Components, Devices, and Accessories: Listed and labeled as defined in "
        ],
        [
          "NFPA 70, by a qualified testing agency, and marked for intended location and application."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 15,
      "table_number": 109,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "RO Product Flow Rate: <",
          "Insert ",
          "gpm",
          " (L/s)",
          ">."
        ],
        [
          "2."
        ],
        [
          "Total Water Flow Rate: <",
          "Insert ",
          "gpm",
          " (L/s)",
          ">."
        ],
        [
          "3."
        ],
        [
          "Daily Water Consumption: <",
          "Insert ",
          "gal./day",
          " (cu. m/day)",
          ">."
        ],
        [
          "4."
        ],
        [
          "Water Demand: <",
          "Insert number",
          "> hours/day."
        ],
        [
          "5."
        ],
        [
          "Storage Tank Size: <",
          "Insert ",
          "gal.",
          " (L)",
          ">."
        ],
        [
          "6."
        ],
        [
          "RO Inlet Operating Temperature: [",
          "77 deg F",
          " (25 deg C)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "7."
        ],
        [
          "High-Pressure Pump:"
        ]
      ],
      "column_count": 6,
      "row_count": 14,
      "detection_method": "layout_analysis"
    },
    {
      "page": 15,
      "table_number": 110,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Discharge Pressure: <",
          "Insert ",
          "psig",
          " (kPa)",
          ">."
        ],
        [
          "b."
        ],
        [
          "Flow Rate: <",
          "Insert ",
          "gpm",
          " (L/s)",
          ">."
        ],
        [
          "c."
        ],
        [
          "Horsepower: <",
          "Insert value",
          ">."
        ],
        [
          "d."
        ],
        [
          "Motor Speed: [",
          "3500",
          "] <",
          "Insert number",
          "> rpm."
        ]
      ],
      "column_count": 5,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 15,
      "table_number": 111,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Discharge Pressure: <",
          "Insert ",
          "psig",
          " (kPa)",
          ">."
        ],
        [
          "b."
        ],
        [
          "Flow Rate: <",
          "Insert ",
          "gpm",
          " (L/s)",
          ">."
        ],
        [
          "c."
        ],
        [
          "Horsepower: <",
          "Insert value",
          ">."
        ],
        [
          "d."
        ],
        [
          "Motor Speed: [",
          "3500",
          "] <",
          "Insert number",
          "> rpm."
        ]
      ],
      "column_count": 5,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 15,
      "table_number": 112,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Filter Efficiency: [",
          "98",
          "] <",
          "Insert number",
          "> percent."
        ],
        [
          "b."
        ],
        [
          "Particle Size: [",
          "5",
          "] <",
          "Insert number",
          "> microns and larger."
        ],
        [
          "c."
        ],
        [
          "Clean Pressure Loss: [",
          "2 psig",
          " (14 kPa)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "d."
        ],
        [
          "Replacement Pressure Loss: [",
          "6 psig",
          " (41 kPa)",
          "] <",
          "Insert value",
          ">."
        ]
      ],
      "column_count": 6,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 16,
      "table_number": 113,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 16,
      "table_number": 114,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Volts: <",
          "Insert value",
          ">."
        ],
        [
          "b."
        ],
        [
          "Phase: <",
          "Insert value",
          ">."
        ],
        [
          "c."
        ],
        [
          "Hertz: <",
          "Insert value",
          ">."
        ],
        [
          "d."
        ],
        [
          "Full-Load Amperes: <",
          "Insert value",
          ">."
        ],
        [
          "e."
        ],
        [
          "Minimum Circuit Ampacity: <",
          "Insert value",
          ">."
        ],
        [
          "f."
        ],
        [
          "Maximum Overcurrent Protection: <",
          "Insert amperage",
          ">."
        ],
        [
          "g."
        ],
        [
          "Interrupting Capacity: <",
          "Insert amperage",
          ">."
        ]
      ],
      "column_count": 3,
      "row_count": 14,
      "detection_method": "layout_analysis"
    },
    {
      "page": 16,
      "table_number": 115,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "<Double click here to find, evaluate, and insert list of manufacturers and products.>"
        ],
        [
          "2."
        ],
        [
          "Description: Factory-fabricated and -tested, simplex, multimedia filter system of filter tank, "
        ],
        [
          "media, strainer, circulating pump, piping, and controls for removing particles from water."
        ]
      ],
      "column_count": 1,
      "row_count": 5,
      "detection_method": "layout_analysis"
    },
    {
      "page": 16,
      "table_number": 116,
      "headers": [],
      "data": [
        [
          "3."
        ],
        [
          "Electrical Components, Devices, and Accessories: Listed and labeled as defined in NFPA 70, by a "
        ],
        [
          "qualified testing agency, and marked for intended location and application."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 16,
      "table_number": 117,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Fabricate and label steel filter tanks to comply with ASME Boiler and Pressure Vessel "
        ],
        [
          "Code: Section VIII, Division 1."
        ],
        [
          "b."
        ],
        [
          "Fabricate and label FRP filter tanks to comply with ASME Boiler and Pressure Vessel "
        ],
        [
          "Code: Section X, if indicated."
        ],
        [
          "c."
        ],
        [
          "Pipe Connections ",
          "NPS 2",
          " (DN 50)",
          " and Smaller: Threaded according to ASME B1.20.1."
        ],
        [
          "d."
        ],
        [
          "Steel Tank Pipe Connections ",
          "NPS 2-1/2",
          " (DN 65)",
          " and Larger: Steel, Class 150 flanges "
        ],
        [
          "according to ASME B16.5 or grooved according to AWWA C606."
        ],
        [
          "e."
        ],
        [
          "FRP Tank Pipe Connections ",
          "NPS 2-1/2",
          " (DN 65)",
          " and Larger: Type A, integral; "
        ],
        [
          "[",
          "Designation ",
          "E, 125-psig",
          " (0.862-MPa)",
          "] [",
          "or",
          "] [",
          "Designation F",
          ", 150-psig",
          " (1.034-MPa)",
          "] "
        ],
        [
          "pressure category flanges of grade same as tank material according to ASTM D 5421."
        ],
        [
          "f."
        ],
        [
          "Motorized Valves: Flanged or grooved-end, ductile-iron butterfly type with [",
          "EPDM",
          "] "
        ],
        [
          "<",
          "Insert material",
          "> valve seat and stem seal; with ASTM B 148 aluminum bronze disc."
        ],
        [
          "g."
        ],
        [
          "Strainer: Basket type mounted on pump suction."
        ],
        [
          "h."
        ],
        [
          "Piping: ASTM A 53/A 53M, Type S, F, or E; Grade B, Schedule 40 black steel, with "
        ],
        [
          "flanged, grooved, or threaded joints and malleable, steel welding, or ductile-iron fittings."
        ],
        [
          "i."
        ],
        [
          "Piping: ",
          "ASTM B 88, Type L",
          " (ASTM B 88M, Type B)",
          " copper water tube, copper-alloy "
        ],
        [
          "solder-joint fittings and brazed, flanged, or grooved joints."
        ],
        [
          "j."
        ],
        [
          "Safety Valves: Automatic pressure relief."
        ],
        [
          "k."
        ],
        [
          "Circulating Pump: Overhung impeller, close coupled, single stage, end suction, centrifugal. "
        ],
        [
          "Comply with UL 778 and with HI 1.1-1.2 and HI 1.3."
        ]
      ],
      "column_count": 11,
      "row_count": 31,
      "detection_method": "layout_analysis"
    },
    {
      "page": 17,
      "table_number": 118,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 17,
      "table_number": 119,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Casing: Radially split, cast iron."
        ],
        [
          "2)"
        ],
        [
          "Pressure Rating: [",
          "125 psig",
          " (860 kPa)",
          "] [",
          "150 psig",
          " (1035 kPa)",
          "] minimum."
        ],
        [
          "3)"
        ],
        [
          "Impeller: ASTM B 584, cast bronze; statically and dynamically balanced, closed, "
        ],
        [
          "and keyed to shaft."
        ],
        [
          "4)"
        ],
        [
          "Shaft and Shaft Sleeve: Steel shaft, with copper-alloy shaft sleeve."
        ],
        [
          "5)"
        ],
        [
          "Seal: Mechanical."
        ],
        [
          "6)"
        ],
        [
          "Motor: ODP motor supported on the pump-bearing frame. General requirements for "
        ],
        [
          "motors are specified in Section 230513 \"Common Motor Requirements for HVAC "
        ],
        [
          "Equipment.\""
        ]
      ],
      "column_count": 7,
      "row_count": 15,
      "detection_method": "layout_analysis"
    },
    {
      "page": 17,
      "table_number": 120,
      "headers": [],
      "data": [
        [
          "l."
        ],
        [
          "Controls: Automatic control of circulating pump and tank backwash; factory wired for "
        ],
        [
          "single electrical connection."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 17,
      "table_number": 121,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Panel: NEMA 250, [",
          "Type 4",
          "] <",
          "Insert type",
          "> enclosure with time clock and pressure "
        ],
        [
          "gages."
        ],
        [
          "2)"
        ],
        [
          "Pump: Automatic and manual switching; manual switch position bypasses safeties "
        ],
        [
          "and controls."
        ],
        [
          "3)"
        ],
        [
          "Backwash: Automatic; with time clock and differential pressure switch."
        ],
        [
          "4)"
        ],
        [
          "Backwash Valve: Tank mounted with valves interlocked to single actuator."
        ]
      ],
      "column_count": 5,
      "row_count": 10,
      "detection_method": "layout_analysis"
    },
    {
      "page": 17,
      "table_number": 122,
      "headers": [],
      "data": [
        [
          "m."
        ],
        [
          "Support: Skid mounting.[",
          " Fabricate supports and base and attachment to tank with "
        ],
        [
          "reinforcement strong enough to resist filter movement during a seismic event when "
        ],
        [
          "filter base is anchored to building structure.",
          "]"
        ]
      ],
      "column_count": 2,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 17,
      "table_number": 123,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Water Flow: <",
          "Insert ",
          "gpm",
          " (L/s)",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Clean Pressure Loss: [",
          "5 psig",
          " (34.5 kPa)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Maximum Media Flow Rate: [",
          "15 gpm/sq. ft.",
          " (10.2 L/s per sq. m)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "4)"
        ],
        [
          "Filtration Efficiency: [",
          "98",
          "] <",
          "Insert number",
          "> percent."
        ],
        [
          "5)"
        ],
        [
          "Particle-Specific Gravity: [",
          "1.8",
          "] <",
          "Insert number",
          ">."
        ],
        [
          "6)"
        ],
        [
          "Particle Size: [",
          "5",
          "] [",
          "10",
          "] [",
          "20",
          "] [",
          "45",
          "] <",
          "Insert number",
          "> microns."
        ]
      ],
      "column_count": 11,
      "row_count": 12,
      "detection_method": "layout_analysis"
    },
    {
      "page": 17,
      "table_number": 124,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Pressure Rating: <",
          "Insert ",
          "psig",
          " (kPa)",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Diameter: <",
          "Insert ",
          "inches",
          " (mm)",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Inlet and Outlet Size: <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ],
        [
          "4)"
        ],
        [
          "Blowdown Piping Outlet Size: <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ]
      ],
      "column_count": 5,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 17,
      "table_number": 125,
      "headers": [],
      "data": [
        [
          "c."
        ],
        [
          "Filter Media: <",
          "Insert material",
          ">."
        ],
        [
          "d."
        ],
        [
          "Start Backwash Pressure Loss: [",
          "13 psig",
          " (90 kPa)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "e."
        ],
        [
          "Backwash Period: [",
          "10",
          "] <",
          "Insert number",
          "> minutes."
        ],
        [
          "f."
        ],
        [
          "Circulating Pump:"
        ]
      ],
      "column_count": 6,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 17,
      "table_number": 126,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Capacity: <",
          "Insert ",
          "gpm",
          " (L/s)",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Total Dynamic Head: <",
          "Insert ",
          "feet",
          " (kPa)",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Motor Speed: <",
          "Insert number",
          "> rpm."
        ]
      ],
      "column_count": 5,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 18,
      "table_number": 127,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 18,
      "table_number": 128,
      "headers": [],
      "data": [
        [
          "4)"
        ],
        [
          "Inlet Size: <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ],
        [
          "5)"
        ],
        [
          "Outlet Size: <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ]
      ],
      "column_count": 5,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 18,
      "table_number": 129,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Horsepower: <",
          "Insert value",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Volts: [",
          "120",
          "] [",
          "208",
          "] [",
          "240",
          "] [",
          "277",
          "] [",
          "480",
          "] <",
          "Insert number",
          "> V."
        ],
        [
          "3)"
        ],
        [
          "Phase: [",
          "Single",
          "] [",
          "Three",
          "]."
        ],
        [
          "4)"
        ],
        [
          "Hertz: [",
          "60",
          "] <",
          "Insert number",
          "> Hz."
        ]
      ],
      "column_count": 13,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 18,
      "table_number": 130,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Full-Load Amperes: <",
          "Insert value",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Minimum Circuit Ampacity: <",
          "Insert value",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Maximum Overcurrent Protection: <",
          "Insert amperage",
          ">."
        ],
        [
          "4)"
        ],
        [
          "Interrupting Capacity: <",
          "Insert amperage",
          ">."
        ]
      ],
      "column_count": 3,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 18,
      "table_number": 131,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "<Double click here to find, evaluate, and insert list of manufacturers and products.>"
        ],
        [
          "2."
        ],
        [
          "Description: Factory-fabricated and -tested, ASTM A 126, Class B, cast-iron or steel, self-"
        ],
        [
          "cleaning strainer system of tank, strainer, backwash arm or cleaning spiral, drive and motor, "
        ],
        [
          "piping, and controls for removing particles from water."
        ]
      ],
      "column_count": 1,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 18,
      "table_number": 132,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Fabricate and label ASTM A 126, Class B, cast-iron or steel strainer tanks to comply with "
        ],
        [
          "ASME Boiler and Pressure Vessel Code: Section VIII, Division 1."
        ],
        [
          "b."
        ],
        [
          "Pipe Connections:"
        ]
      ],
      "column_count": 1,
      "row_count": 5,
      "detection_method": "layout_analysis"
    },
    {
      "page": 18,
      "table_number": 133,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "NPS 2",
          " (DN 50)",
          " and Smaller: Threaded according to ASME B1.20.1."
        ],
        [
          "2)"
        ],
        [
          "NPS 2-1/2",
          " (DN 65)",
          " and Larger: Steel, Class 150 flanges according to ASME B16.5 "
        ],
        [
          "or grooved according to AWWA C606."
        ]
      ],
      "column_count": 3,
      "row_count": 5,
      "detection_method": "layout_analysis"
    },
    {
      "page": 18,
      "table_number": 134,
      "headers": [],
      "data": [
        [
          "3."
        ],
        [
          "Motorized Valves: Flanged or grooved-end, ductile-iron angle type with [",
          "EPDM",
          "] <",
          "Insert "
        ],
        [
          "material",
          "> valve seat and stem seal; with ASTM B 148 aluminum bronze disc."
        ],
        [
          "4."
        ],
        [
          "Strainer: ASTM A 666, Type 316 stainless steel."
        ],
        [
          "5."
        ],
        [
          "Piping: ASTM A 53/A 53M, Type S, F, or E; Grade B, Schedule 40 black steel, with flanged, "
        ],
        [
          "grooved, or threaded joints and malleable, steel welding, or ductile-iron fittings."
        ],
        [
          "6."
        ],
        [
          "Safety Valves: Automatic pressure relief."
        ],
        [
          "7."
        ],
        [
          "Backwash Arm Drive:"
        ]
      ],
      "column_count": 4,
      "row_count": 12,
      "detection_method": "layout_analysis"
    },
    {
      "page": 18,
      "table_number": 135,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Drive Casing: Cast iron."
        ],
        [
          "b."
        ],
        [
          "Worm Gears: Immersed in oil."
        ],
        [
          "c."
        ],
        [
          "Motor: ODP motor supported on the strainer-bearing frame. General requirements for "
        ],
        [
          "motors are specified in Section 230513 \"Common Motor Requirements for HVAC "
        ],
        [
          "Equipment.\""
        ]
      ],
      "column_count": 1,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 19,
      "table_number": 136,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 19,
      "table_number": 137,
      "headers": [],
      "data": [
        [
          "b."
        ],
        [
          "Backwash Arm Drive: Automatic and manual switching; manual switch position bypasses "
        ],
        [
          "safeties and controls."
        ],
        [
          "c."
        ],
        [
          "Backwash: Automatic; with time clock and differential pressure switch."
        ],
        [
          "d."
        ],
        [
          "Backwash Valve: Electric actuator."
        ]
      ],
      "column_count": 1,
      "row_count": 7,
      "detection_method": "layout_analysis"
    },
    {
      "page": 19,
      "table_number": 138,
      "headers": [],
      "data": [
        [
          "9."
        ],
        [
          "Support: Skid mounting.[",
          " Fabricate supports and base and attachment to tank with "
        ],
        [
          "reinforcement strong enough to resist strainer movement during a seismic event when "
        ],
        [
          "strainer base is anchored to building structure.",
          "]"
        ],
        [
          "10."
        ],
        [
          "Capacities and Characteristics:"
        ]
      ],
      "column_count": 2,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 19,
      "table_number": 139,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Water Flow: <",
          "Insert ",
          "gpm",
          " (L/s)",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Clean Pressure Loss: [",
          "5 psig",
          " (34.5 kPa)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Strainer Mesh: [",
          "40",
          "] [",
          "60",
          "] [",
          "80",
          "] <",
          "Insert number",
          ">."
        ]
      ],
      "column_count": 9,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 19,
      "table_number": 140,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Material: [",
          "Cast iron",
          "] [",
          "Steel",
          "] <",
          "Insert material",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Pressure Rating: [",
          "150 psig",
          " (1034 kPa)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Inlet and Outlet Size: <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ],
        [
          "4)"
        ],
        [
          "Backwash Piping Outlet Size: <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ]
      ],
      "column_count": 7,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 19,
      "table_number": 141,
      "headers": [],
      "data": [
        [
          "c."
        ],
        [
          "Start Backwash: [",
          "10 psig",
          " (69 kPa)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "d."
        ],
        [
          "Backwash Period: [",
          "5",
          "] <",
          "Insert number",
          "> minutes."
        ],
        [
          "e."
        ],
        [
          "Drive Motor Size and Electrical Characteristics:"
        ]
      ],
      "column_count": 6,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 19,
      "table_number": 142,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Horsepower: <",
          "Insert value",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Volts: [",
          "120",
          "] [",
          "208",
          "] [",
          "240",
          "] [",
          "277",
          "] [",
          "480",
          "] <",
          "Insert number",
          "> V."
        ],
        [
          "3)"
        ],
        [
          "Phase: [",
          "Single",
          "] [",
          "Three",
          "]."
        ],
        [
          "4)"
        ],
        [
          "Hertz: [",
          "60",
          "] <",
          "Insert number",
          "> Hz."
        ]
      ],
      "column_count": 13,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 19,
      "table_number": 143,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Full-Load Amperes: <",
          "Insert value",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Minimum Circuit Ampacity: <",
          "Insert value",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Maximum Overcurrent Protection: <",
          "Insert amperage",
          ">."
        ],
        [
          "4)"
        ],
        [
          "Interrupting Capacity: <",
          "Insert amperage",
          ">."
        ]
      ],
      "column_count": 3,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 19,
      "table_number": 144,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "<Double click here to find, evaluate, and insert list of manufacturers and products.>"
        ],
        [
          "2."
        ],
        [
          "Description: Floor-mounting housing with filter [",
          "bags",
          "] [",
          "cartridges",
          "] for removing particles from "
        ],
        [
          "water."
        ]
      ],
      "column_count": 5,
      "row_count": 5,
      "detection_method": "layout_analysis"
    },
    {
      "page": 19,
      "table_number": 145,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Housing: Corrosion resistant; designed to separate inlet from outlet and to direct inlet "
        ],
        [
          "through [",
          "bag",
          "] [",
          "cartridge",
          "]-type water filter; with [",
          "bag support and ",
          "]base, feet, or skirt."
        ]
      ],
      "column_count": 7,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 19,
      "table_number": 146,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Pipe Connections ",
          "NPS 2",
          " (DN 50)",
          " and Smaller: Threaded according to "
        ],
        [
          "ASME B1.20.1."
        ]
      ],
      "column_count": 4,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 20,
      "table_number": 147,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 20,
      "table_number": 148,
      "headers": [],
      "data": [
        [
          "2)"
        ],
        [
          "Steel Housing Pipe Connections ",
          "NPS 2-1/2",
          " (DN 65)",
          " and Larger: Steel, Class 150 "
        ],
        [
          "flanges according to ASME B16.5 or grooved according to AWWA C606."
        ],
        [
          "3)"
        ],
        [
          "Plastic Housing Pipe Connections ",
          "NPS 2-1/2",
          " (DN 65)",
          " and Larger: ",
          "150-psig",
          " (1035-"
        ],
        [
          "kPa)",
          " plastic flanges."
        ]
      ],
      "column_count": 6,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 20,
      "table_number": 149,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Water Flow Rate: <",
          "Insert ",
          "gpm",
          " (L/s)",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Filtration Efficiency: [",
          "98",
          "] <",
          "Insert number",
          "> percent."
        ],
        [
          "3)"
        ],
        [
          "Particle Size: [",
          "10",
          "] [",
          "20",
          "] <",
          "Insert number",
          "> microns and larger."
        ],
        [
          "4)"
        ],
        [
          "Clean Pressure Loss: [",
          "2 psig",
          " (14 kPa)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "5)"
        ],
        [
          "Pressure Loss at Replacement: [",
          "6 psig",
          " (41 kPa)",
          "] <",
          "Insert value",
          ">."
        ]
      ],
      "column_count": 7,
      "row_count": 10,
      "detection_method": "layout_analysis"
    },
    {
      "page": 20,
      "table_number": 150,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Material: [",
          "Carbon steel",
          "] [",
          "Plastic",
          "]."
        ],
        [
          "2)"
        ],
        [
          "Pressure Rating: <",
          "Insert ",
          "psig",
          " (kPa)",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Seal Material: [",
          "Nitrile Rubber",
          "] <",
          "Insert material",
          ">."
        ],
        [
          "4)"
        ],
        [
          "Diameter: <",
          "Insert ",
          "inches",
          " (mm)",
          ">."
        ],
        [
          "5)"
        ],
        [
          "Height or Length: <",
          "Insert ",
          "inches",
          " (mm)",
          ">."
        ],
        [
          "6)"
        ],
        [
          "Inlet and Outlet Size: <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ],
        [
          "7)"
        ],
        [
          "Drain Size: [",
          "Not applicable",
          "] <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ],
        [
          "8)"
        ],
        [
          "Bag Support Basket Material: [",
          "Stainless steel",
          "] <",
          "Insert material",
          ">."
        ]
      ],
      "column_count": 7,
      "row_count": 16,
      "detection_method": "layout_analysis"
    },
    {
      "page": 20,
      "table_number": 151,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Number Required: <",
          "Insert number",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Nominal Diameter: <",
          "Insert ",
          "inches",
          " (mm)",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Nominal Length: <",
          "Insert ",
          "inches",
          " (mm)",
          ">."
        ],
        [
          "4)"
        ],
        [
          "Media Material: [",
          "Cotton",
          "] [",
          "Polyester",
          "] [",
          "Polypropylene",
          "] <",
          "Insert material",
          ">."
        ]
      ],
      "column_count": 9,
      "row_count": 8,
      "detection_method": "layout_analysis"
    },
    {
      "page": 20,
      "table_number": 152,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "<Double click here to find, evaluate, and insert list of manufacturers and products.>"
        ],
        [
          "2."
        ],
        [
          "Description: Simplex separator housing with baffles and chambers for removing particles from "
        ],
        [
          "water by centrifugal action and gravity."
        ],
        [
          "3."
        ],
        [
          "Housing: With manufacturer's proprietary system of baffles and chambers."
        ]
      ],
      "column_count": 1,
      "row_count": 7,
      "detection_method": "layout_analysis"
    },
    {
      "page": 20,
      "table_number": 153,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Construction: Fabricate and label steel separator housing to comply with ASME Boiler and "
        ],
        [
          "Pressure Vessel Code: Section VIII, Division 1."
        ],
        [
          "b."
        ],
        [
          "Inlet: Designed with tangential entry to produce centrifugal flow of feedwater."
        ],
        [
          "c."
        ],
        [
          "Vortex Chamber: Designed for downward vortex flow and gravity separation of particles."
        ],
        [
          "d."
        ],
        [
          "Collection Chamber: Designed to hold separated particles."
        ],
        [
          "e."
        ],
        [
          "Outlet: Near top of unit."
        ],
        [
          "f."
        ],
        [
          "Purge: At bottom of collection chamber."
        ]
      ],
      "column_count": 1,
      "row_count": 13,
      "detection_method": "layout_analysis"
    },
    {
      "page": 21,
      "table_number": 154,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 21,
      "table_number": 155,
      "headers": [],
      "data": [
        [
          "g."
        ],
        [
          "Pipe Connections ",
          "NPS 2",
          " (DN 50)",
          " and Smaller: Threaded according to ASME B1.20.1."
        ],
        [
          "h."
        ],
        [
          "Pipe Connections ",
          "NPS 2-1/2",
          " (DN 65)",
          " and Larger: Steel, Class 150 flanges according to "
        ],
        [
          "ASME B16.5 or grooved according to AWWA C606. Provide stainless-steel flanges if tank "
        ],
        [
          "is stainless steel."
        ]
      ],
      "column_count": 4,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 21,
      "table_number": 156,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Motorized Valves: Butterfly-type, flanged or grooved-end, ductile-iron body, with "
        ],
        [
          "[",
          "EPDM",
          "] <",
          "Insert material",
          "> valve seat and stem seal; with ASTM B 148 aluminum bronze "
        ],
        [
          "disc."
        ],
        [
          "b."
        ],
        [
          "Electrical Components, Devices, and Accessories: Listed and labeled as defined in "
        ],
        [
          "NFPA 70, by a qualified testing agency, and marked for intended location and application."
        ]
      ],
      "column_count": 5,
      "row_count": 7,
      "detection_method": "layout_analysis"
    },
    {
      "page": 21,
      "table_number": 157,
      "headers": [],
      "data": [
        [
          "5."
        ],
        [
          "Strainer: Stainless-steel basket type mounted on pump suction."
        ],
        [
          "6."
        ],
        [
          "Piping: ASTM A 53/A 53M, Type S, F, or E; Grade B, Schedule 40 black steel, with flanged, "
        ],
        [
          "grooved, or threaded joints and malleable, steel welding, or ductile-iron fittings."
        ],
        [
          "7."
        ],
        [
          "Piping: ",
          "ASTM B 88, Type L",
          " (ASTM B 88M, Type B)",
          " copper water tube, copper-alloy solder-joint "
        ],
        [
          "fittings, and brazed, flanged, or grooved joints."
        ],
        [
          "8."
        ],
        [
          "Circulating Pump: Overhung impeller, close coupled, single stage, end suction, centrifugal. "
        ],
        [
          "Comply with UL 778 and with HI 1.1-1.2 and HI 1.3."
        ]
      ],
      "column_count": 4,
      "row_count": 11,
      "detection_method": "layout_analysis"
    },
    {
      "page": 21,
      "table_number": 158,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Casing: Radially split, cast iron."
        ],
        [
          "b."
        ],
        [
          "Pressure Rating: [",
          "125 psig",
          " (860 kPa)",
          "] [",
          "150 psig",
          " (1035 kPa)",
          "] minimum."
        ],
        [
          "c."
        ],
        [
          "Impeller: ASTM B 584, cast bronze; statically and dynamically balanced, closed, and "
        ],
        [
          "keyed to shaft."
        ],
        [
          "d."
        ],
        [
          "Shaft and Shaft Sleeve: Steel shaft with copper-alloy shaft sleeve."
        ],
        [
          "e."
        ],
        [
          "Seal: Mechanical."
        ],
        [
          "f."
        ],
        [
          "Motor: ODP motor supported on the pump-bearing frame. General requirements for motors "
        ],
        [
          "are specified in Section 230513 \"Common Motor Requirements for HVAC Equipment.\""
        ],
        [
          "g."
        ],
        [
          "Electrical Components, Devices, and Accessories: Listed and labeled as defined in "
        ],
        [
          "NFPA 70, by a qualified testing agency, and marked for intended location and application."
        ]
      ],
      "column_count": 7,
      "row_count": 17,
      "detection_method": "layout_analysis"
    },
    {
      "page": 21,
      "table_number": 159,
      "headers": [],
      "data": [
        [
          "9."
        ],
        [
          "Controls: Automatic control of circulating pump and separator purge; factory wired for single "
        ],
        [
          "electrical connection."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 21,
      "table_number": 160,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Panel: NEMA 250, [",
          "Type 4",
          "] <",
          "Insert type",
          "> enclosure."
        ],
        [
          "b."
        ],
        [
          "Pump: Automatic and manual switching; manual switch position bypasses safeties and "
        ],
        [
          "controls."
        ],
        [
          "c."
        ],
        [
          "Separator Purge: Automatic and manual."
        ],
        [
          "d."
        ],
        [
          "TSS Controller Interlock: Open separator purge valve with bleed-off control."
        ]
      ],
      "column_count": 5,
      "row_count": 9,
      "detection_method": "layout_analysis"
    },
    {
      "page": 21,
      "table_number": 161,
      "headers": [],
      "data": [
        [
          "10."
        ],
        [
          "Support: Skid mounting.[",
          " Fabricate supports and base and attachment to separator housing "
        ],
        [
          "with reinforcement strong enough to resist separator movement during a seismic event when "
        ],
        [
          "separator base is anchored to building structure.",
          "]"
        ],
        [
          "11."
        ],
        [
          "Capacities and Characteristics:"
        ]
      ],
      "column_count": 2,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 22,
      "table_number": 162,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 22,
      "table_number": 163,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Water Flow Rate: <",
          "Insert ",
          "gpm",
          " (L/s)",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Pressure Loss: [",
          "5 psig",
          " (34.5 kPa)",
          "] <",
          "Insert value",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Separator Efficiency: [",
          "98",
          "] <",
          "Insert number",
          "> percent."
        ],
        [
          "4)"
        ],
        [
          "Particle-Specific Gravity: [",
          "1.8",
          "] <",
          "Insert number",
          ">."
        ],
        [
          "5)"
        ],
        [
          "Particle Size: [",
          "5",
          "] [",
          "10",
          "] [",
          "20",
          "] [",
          "45",
          "] <",
          "Insert number",
          "> microns."
        ]
      ],
      "column_count": 11,
      "row_count": 10,
      "detection_method": "layout_analysis"
    },
    {
      "page": 22,
      "table_number": 164,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Material: [",
          "Steel",
          "] [",
          "Stainless steel",
          "] [",
          "Plastic",
          "] [",
          "Fiberglass",
          "] <",
          "Insert material",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Pressure Rating: <",
          "Insert ",
          "psig",
          " (kPa)",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Diameter: <",
          "Insert ",
          "inches",
          " (mm)",
          ">."
        ],
        [
          "4)"
        ],
        [
          "Height: <",
          "Insert ",
          "inches",
          " (mm)",
          ">."
        ],
        [
          "5)"
        ],
        [
          "Inlet and Outlet Size: <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ],
        [
          "6)"
        ],
        [
          "Purge Size: <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ]
      ],
      "column_count": 11,
      "row_count": 12,
      "detection_method": "layout_analysis"
    },
    {
      "page": 22,
      "table_number": 165,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Capacity: <",
          "Insert ",
          "gpm",
          " (L/s)",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Total Dynamic Head: <",
          "Insert ",
          "feet",
          " (kPa)",
          ">."
        ],
        [
          "3)"
        ],
        [
          "Motor Speed: <",
          "Insert number",
          "> rpm."
        ],
        [
          "4)"
        ],
        [
          "Inlet Size: <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ],
        [
          "5)"
        ],
        [
          "Outlet Size: <",
          "Insert ",
          "NPS",
          " (DN)",
          ">."
        ]
      ],
      "column_count": 5,
      "row_count": 10,
      "detection_method": "layout_analysis"
    },
    {
      "page": 22,
      "table_number": 166,
      "headers": [],
      "data": [
        [
          "1)"
        ],
        [
          "Horsepower: <",
          "Insert value",
          ">."
        ],
        [
          "2)"
        ],
        [
          "Volts: [",
          "120",
          "] [",
          "208",
          "] [",
          "240",
          "] [",
          "277",
          "] [",
          "480",
          "] <",
          "Insert number",
          "> V."
        ],
        [
          "3)"
        ],
        [
          "Phase: [",
          "Single",
          "] [",
          "Three",
          "]."
        ],
        [
          "4)"
        ],
        [
          "Hertz: [",
          "60",
          "] <",
          "Insert number",
          "> Hz."
        ],
        [
          "5)"
        ],
        [
          "Full-Load Amperes: <",
          "Insert value",
          ">."
        ],
        [
          "6)"
        ],
        [
          "Minimum Circuit Ampacity: <",
          "Insert value",
          ">."
        ],
        [
          "7)"
        ],
        [
          "Maximum Overcurrent Protection: <",
          "Insert amperage",
          ">."
        ],
        [
          "8)"
        ],
        [
          "Interrupting Capacity: <",
          "Insert amperage",
          ">."
        ]
      ],
      "column_count": 13,
      "row_count": 16,
      "detection_method": "layout_analysis"
    },
    {
      "page": 22,
      "table_number": 167,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Install chemical application equipment on concrete bases level and plumb. Maintain manufacturer's "
        ],
        [
          "recommended clearances. Arrange units so controls and devices that require servicing are accessible. "
        ],
        [
          "Anchor chemical tanks and floor-mounting accessories to substrate."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 23,
      "table_number": 168,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 23,
      "table_number": 169,
      "headers": [
        "B."
      ],
      "data": [
        [
          "Install seismic restraints for equipment and floor-mounting accessories and anchor to building structure. "
        ],
        [
          "See Section 230548 \"Vibration and Seismic Controls for HVAC\" for seismic restraints."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 23,
      "table_number": 170,
      "headers": [
        "F."
      ],
      "data": [
        [
          "Bypass Feeders: Install in closed hydronic systems, including [",
          "hot-water heating",
          "] [",
          "chilled water",
          "] [",
          "dual-"
        ],
        [
          "temperature water",
          "] [",
          "and",
          "] [",
          "glycol cooling",
          "], and equipped with the following:"
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 23,
      "table_number": 171,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Install bypass feeder in a bypass circuit around circulating pumps unless otherwise indicated on "
        ],
        [
          "Drawings."
        ],
        [
          "2."
        ],
        [
          "Install water meter in makeup-water supply."
        ],
        [
          "3."
        ],
        [
          "Install test-coupon assembly in bypass circuit around circulating pumps unless otherwise indicated "
        ],
        [
          "on Drawings."
        ],
        [
          "4."
        ],
        [
          "Install a gate or full-port ball isolation valves on inlet, outlet, and drain below feeder inlet."
        ],
        [
          "5."
        ],
        [
          "Install a swing check on inlet after the isolation valve."
        ]
      ],
      "column_count": 1,
      "row_count": 12,
      "detection_method": "layout_analysis"
    },
    {
      "page": 23,
      "table_number": 172,
      "headers": [
        "G."
      ],
      "data": [
        [
          "Install automatic chemical-feed equipment for steam boiler and steam condensate systems and include the "
        ],
        [
          "following:"
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 23,
      "table_number": 173,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Install makeup-water softener."
        ],
        [
          "2."
        ],
        [
          "Install water meter in makeup-water supply."
        ],
        [
          "3."
        ],
        [
          "Install inhibitor injection pumps and solution tanks with injection timer sensing contacts in water "
        ],
        [
          "meter."
        ]
      ],
      "column_count": 1,
      "row_count": 7,
      "detection_method": "layout_analysis"
    },
    {
      "page": 23,
      "table_number": 174,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Pumps shall operate for timed interval when contacts close at water meter in makeup-water "
        ],
        [
          "supply connection."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 23,
      "table_number": 175,
      "headers": [],
      "data": [
        [
          "4."
        ],
        [
          "Install test equipment and furnish test-kit to Owner."
        ],
        [
          "5."
        ],
        [
          "Install RO unit for makeup water."
        ],
        [
          "6."
        ],
        [
          "Install TSS controller with sensor and bleed valves."
        ]
      ],
      "column_count": 1,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 23,
      "table_number": 176,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Pumps shall operate for timed interval on contact closure at water meter in makeup-water "
        ],
        [
          "supply connection. Injection pump shall discharge into main steam supply header."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 23,
      "table_number": 177,
      "headers": [
        "H."
      ],
      "data": [
        [
          "Install automatic chemical-feed equipment for [",
          "condenser",
          "] [",
          "fluid-cooler spray",
          "] water and include the "
        ],
        [
          "following:"
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 23,
      "table_number": 178,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Install makeup-water softener."
        ],
        [
          "2."
        ],
        [
          "Install water meter in makeup-water supply."
        ]
      ],
      "column_count": 1,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 24,
      "table_number": 179,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 24,
      "table_number": 180,
      "headers": [],
      "data": [
        [
          "3."
        ],
        [
          "Install inhibitor injection pumps and solution tanks with injection timer sensing contacts in water "
        ],
        [
          "meter."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 24,
      "table_number": 181,
      "headers": [],
      "data": [
        [
          "a."
        ],
        [
          "Pumps shall operate for timed interval on contact closure at water meter in makeup-water "
        ],
        [
          "supply connection. Injection pump shall discharge into boiler feedwater tank or feedwater "
        ],
        [
          "supply connection at boiler."
        ]
      ],
      "column_count": 1,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 24,
      "table_number": 182,
      "headers": [],
      "data": [
        [
          "4."
        ],
        [
          "Install test equipment and provide test-kit to Owner. Install test-coupon assembly in bypass circuit "
        ],
        [
          "around circulating pumps unless otherwise indicated on Drawings."
        ],
        [
          "5."
        ],
        [
          "Install TSS controller with sensor and bleed valves."
        ]
      ],
      "column_count": 1,
      "row_count": 5,
      "detection_method": "layout_analysis"
    },
    {
      "page": 24,
      "table_number": 183,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Install ozone generator and equipment on concrete bases level and plumb. Maintain manufacturer's "
        ],
        [
          "recommended clearances. Arrange units so controls and devices that require servicing are accessible. "
        ],
        [
          "Anchor mineral and brine tanks and floor-mounting accessories to substrate."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 24,
      "table_number": 184,
      "headers": [
        "B."
      ],
      "data": [
        [
          "Install seismic restraints for equipment and floor-mounting accessories and anchor to building structure. "
        ],
        [
          "See Section 230548 \"Vibration and Seismic Controls for HVAC\" for seismic restraints."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 24,
      "table_number": 185,
      "headers": [
        "C."
      ],
      "data": [
        [
          "Pipe ozone from ozone generator to condenser water with stainless-steel pipe and fittings with welded "
        ],
        [
          "joints."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 24,
      "table_number": 186,
      "headers": [
        "E."
      ],
      "data": [
        [
          "Pipe cooling water to ozone generator and to air-gap drain fitting with stainless-steel pipe and fittings "
        ],
        [
          "with welded joints where enclosed in ozone-generator room."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 25,
      "table_number": 187,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 25,
      "table_number": 188,
      "headers": [
        "I."
      ],
      "data": [
        [
          "Mount and install ozone detector, warning lights, and audible alarm inside ozone-generator room. Mount "
        ],
        [
          "another set of warning lights and audible alarm just outside the main entrance to ozone-generator room."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 25,
      "table_number": 189,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Install UV-irradiation units on concrete bases level and plumb. Maintain manufacturer's recommended "
        ],
        [
          "clearances. Arrange units so controls and devices that require servicing are accessible. Anchor mineral "
        ],
        [
          "and brine tanks and floor-mounting accessories to substrate."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 25,
      "table_number": 190,
      "headers": [
        "B."
      ],
      "data": [
        [
          "Install seismic restraints for UV-irradiation units and floor-mounting accessories and anchor to building "
        ],
        [
          "structure. See Section 230548 \"Vibration and Seismic Controls for HVAC\" for seismic restraints."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 25,
      "table_number": 191,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Install water softener equipment on concrete bases level and plumb. Maintain manufacturer's "
        ],
        [
          "recommended clearances. Arrange units so controls and devices that require servicing are accessible. "
        ],
        [
          "Anchor mineral and brine tanks and floor-mounting accessories to substrate."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 25,
      "table_number": 192,
      "headers": [
        "B."
      ],
      "data": [
        [
          "Install seismic restraints for tanks and floor-mounting accessories and anchor to building structure. See "
        ],
        [
          "Section 230548 \"Vibration and Seismic Controls for HVAC\" for seismic restraints."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 25,
      "table_number": 193,
      "headers": [
        "D."
      ],
      "data": [
        [
          "Prepare mineral-tank distribution system and underbed for minerals and place specified mineral into "
        ],
        [
          "mineral tanks."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 25,
      "table_number": 194,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Install RO unit and storage tank on concrete bases level and plumb. Maintain manufacturer's "
        ],
        [
          "recommended clearances. Arrange units so controls and devices that require servicing are accessible. "
        ],
        [
          "Anchor RO unit and storage tank with pumps to substrate."
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 25,
      "table_number": 195,
      "headers": [
        "B."
      ],
      "data": [
        [
          "Install seismic restraints for tanks and floor-mounting accessories and anchor to building structure. See "
        ],
        [
          "Section 230548 \"Vibration and Seismic Controls for HVAC\" for seismic restraints."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 26,
      "table_number": 196,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 26,
      "table_number": 197,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Piping installation requirements are specified in other Sections. Drawings indicate general arrangement of "
        ],
        [
          "piping, fittings, and specialties."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 26,
      "table_number": 198,
      "headers": [
        "C."
      ],
      "data": [
        [
          "Make piping connections between HVAC water-treatment equipment and dissimilar-metal piping with "
        ],
        [
          "dielectric fittings. Dielectric fittings are specified in Section 232113 \"Hydronic Piping.\""
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 26,
      "table_number": 199,
      "headers": [
        "D."
      ],
      "data": [
        [
          "Install shutoff valves on HVAC water-treatment equipment inlet and outlet. Metal general-duty valves are "
        ],
        [
          "specified in Section 230523.11 \"Globe Valves for HVAC Piping,\" Section 230523.12 \"Ball Valves for "
        ],
        [
          "HVAC Piping,\" Section 230523.13 \"Butterfly Valves for HVAC Piping,\" and Section 230523.15 \"Gate "
        ],
        [
          "Valves for HVAC Piping.\""
        ]
      ],
      "column_count": 1,
      "row_count": 4,
      "detection_method": "layout_analysis"
    },
    {
      "page": 26,
      "table_number": 200,
      "headers": [
        "E."
      ],
      "data": [
        [
          "See Section 221119 \"Domestic Water Piping Specialties\" for backflow preventers required in makeup-"
        ],
        [
          "water connections to potable-water systems."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 26,
      "table_number": 201,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Manufacturer's Field Service: Engage a factory-authorized service representative to test and inspect "
        ],
        [
          "components, assemblies, and equipment installations, including connections."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 26,
      "table_number": 202,
      "headers": [
        "B."
      ],
      "data": [
        [
          "Perform the following tests and inspections[",
          " with the assistance of a factory-authorized service "
        ],
        [
          "representative",
          "]:"
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    },
    {
      "page": 26,
      "table_number": 203,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Inspect field-assembled components and equipment installation, including piping and electrical "
        ],
        [
          "connections."
        ],
        [
          "2."
        ],
        [
          "Inspect piping and equipment to determine that systems and equipment have been cleaned, "
        ],
        [
          "flushed, and filled with water, and are fully operational before introducing chemicals for water-"
        ],
        [
          "treatment system."
        ],
        [
          "3."
        ],
        [
          "Place HVAC water-treatment system into operation and calibrate controls during the preliminary "
        ],
        [
          "phase of HVAC system's startup procedures."
        ],
        [
          "4."
        ],
        [
          "Do not enclose, cover, or put piping into operation until it is tested and satisfactory test results are "
        ],
        [
          "achieved."
        ],
        [
          "5."
        ],
        [
          "Test for leaks and defects. If testing is performed in segments, submit separate report for each test, "
        ],
        [
          "complete with diagram of portion of piping tested."
        ],
        [
          "6."
        ],
        [
          "Leave uncovered and unconcealed new, altered, extended, and replaced water piping until it has "
        ],
        [
          "been tested and approved. Expose work that has been covered or concealed before it has been "
        ],
        [
          "tested and approved."
        ]
      ],
      "column_count": 1,
      "row_count": 20,
      "detection_method": "layout_analysis"
    },
    {
      "page": 27,
      "table_number": 204,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 27,
      "table_number": 205,
      "headers": [],
      "data": [
        [
          "7."
        ],
        [
          "Cap and subject piping to static water pressure of ",
          "50 psig",
          " (345 kPa)",
          " above operating pressure, "
        ],
        [
          "without exceeding pressure rating of piping system materials. Isolate test source and allow test "
        ],
        [
          "pressure to stand for four hours. Leaks and loss in test pressure constitute defects."
        ],
        [
          "8."
        ],
        [
          "Repair leaks and defects with new materials and retest piping until no leaks exist."
        ]
      ],
      "column_count": 4,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 27,
      "table_number": 206,
      "headers": [
        "E."
      ],
      "data": [
        [
          "Sample boiler water at one-week intervals after boiler startup for a period of five weeks, and prepare test "
        ],
        [
          "report advising Owner of changes necessary to adhere to \"Performance Requirements\" Article for each "
        ],
        [
          "required characteristic. Sample boiler water at [",
          "four",
          "] [",
          "six",
          "] [",
          "eight",
          "] <",
          "Insert number",
          ">-week intervals "
        ],
        [
          "following the testing noted above to show that automatic chemical-feed systems are maintaining water "
        ],
        [
          "quality within performance requirements specified in this Section."
        ]
      ],
      "column_count": 1,
      "row_count": 5,
      "detection_method": "layout_analysis"
    },
    {
      "page": 27,
      "table_number": 207,
      "headers": [
        "F."
      ],
      "data": [
        [
          "At [",
          "four",
          "] [",
          "six",
          "] [",
          "eight",
          "] <",
          "Insert number",
          ">-week intervals following Substantial Completion, perform "
        ],
        [
          "separate water analyses on hydronic systems to show that automatic chemical-feed systems are "
        ],
        [
          "maintaining water quality within performance requirements specified in this Section. Submit written "
        ],
        [
          "reports of water analysis advising Owner of changes necessary to adhere to \"Performance Requirements\" "
        ],
        [
          "Article."
        ]
      ],
      "column_count": 1,
      "row_count": 5,
      "detection_method": "layout_analysis"
    },
    {
      "page": 27,
      "table_number": 208,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Silica: ASTM D 859."
        ],
        [
          "2."
        ],
        [
          "Steam System: ASTM D 1066."
        ],
        [
          "3."
        ],
        [
          "Acidity and Alkalinity: ASTM D 1067."
        ],
        [
          "4."
        ],
        [
          "Iron: ASTM D 1068."
        ],
        [
          "5."
        ],
        [
          "Water Hardness: ASTM D 1126."
        ]
      ],
      "column_count": 1,
      "row_count": 10,
      "detection_method": "layout_analysis"
    },
    {
      "page": 27,
      "table_number": 209,
      "headers": [
        "A."
      ],
      "data": [
        [
          "Scope of Maintenance Service: Provide chemicals and service program to maintain water conditions "
        ],
        [
          "required above to inhibit corrosion, scale formation, and biological growth for [",
          "cooling, chilled-water "
        ],
        [
          "piping",
          "] [",
          "heating, hot-water piping",
          "] [",
          "heating, steam and condensate piping",
          "] [",
          "steam and condensate "
        ],
        [
          "system for humidifier and cooking appliance applications",
          "] [",
          "condenser-water piping",
          "] and equipment. "
        ],
        [
          "Services and chemicals shall be provided for a period of one year from date of Substantial Completion "
        ],
        [
          "and shall include the following:"
        ]
      ],
      "column_count": 1,
      "row_count": 6,
      "detection_method": "layout_analysis"
    },
    {
      "page": 27,
      "table_number": 210,
      "headers": [],
      "data": [
        [
          "1."
        ],
        [
          "Initial water analysis and HVAC water-treatment recommendations."
        ],
        [
          "2."
        ],
        [
          "Startup assistance for Contractor to flush the systems, clean with detergents, and initially fill "
        ],
        [
          "systems with required chemical treatment prior to operation."
        ],
        [
          "3."
        ],
        [
          "Periodic field service and consultation."
        ],
        [
          "4."
        ],
        [
          "Customer report charts and log sheets."
        ],
        [
          "5."
        ],
        [
          "Laboratory technical analysis."
        ],
        [
          "6."
        ],
        [
          "Analyses and reports of all chemical items concerning safety and compliance with government "
        ],
        [
          "regulations."
        ]
      ],
      "column_count": 1,
      "row_count": 14,
      "detection_method": "layout_analysis"
    },
    {
      "page": 28,
      "table_number": 211,
      "headers": [],
      "data": [
        [
          "Copyright 2013 AIA"
        ],
        [
          "MasterSpec Premium"
        ],
        [
          "06/13"
        ]
      ],
      "column_count": 1,
      "row_count": 3,
      "detection_method": "layout_analysis"
    },
    {
      "page": 28,
      "table_number": 212,
      "headers": [
        "A."
      ],
      "data": [
        [
          "[",
          "Engage a factory-authorized service representative to train",
          "] [",
          "Train",
          "] Owner's maintenance personnel "
        ],
        [
          "to adjust, operate, and maintain HVAC water-treatment systems and equipment."
        ]
      ],
      "column_count": 1,
      "row_count": 2,
      "detection_method": "layout_analysis"
    }
  ],
  "summary": {},
  "validation": {
    "is_valid": false,
    "errors": [
      "Missing required metadata: page_count"
    ],
    "warnings": [
      "Missing optional metadata: keywords",
      "Section 'PART 1 - GENERAL' has very short content",
      "Section 'PART 2 - PRODUCTS' has very short content",
      "Section 'Steam Boiler and Steam Condensate:' has very short content",
      "Section 'Ozone Detector and Alarm Devices:' has very short content",
      "Section 'High-Pressure Pumps and Motors:' has very short content",
      "Section 'Capacities and Characteristics:' has very short content",
      "Section 'Capacities and Characteristics:' has very short content",
      "Section 'Capacities and Characteristics:' has very short content",
      "Section 'Capacities and Characteristics:' has very short content",
      "Section 'PART 3 - EXECUTION' has very short content"
    ]
  }
}

================
File: pipeline/data/tests/excel/sample.csv
================
Date,User,Project,Hours
2025-02-28,james.swanson,Meetings (non-project),8
2025-02-27,james.swanson,Meetings (non-project),8
2025-02-26,james.swanson,Meetings (non-project),1
2025-02-26,james.swanson,Projects (Post-Award),3
2025-02-26,james.swanson,Working ON Business,4
2025-02-25,keene.tanaka,Pursuits,8
2025-02-25,kevin.stoddard,Pursuits,2
2025-02-25,kevin.stoddard,Meetings (non-project),2
2025-02-25,james.swanson,Projects (Post-Award),8
2025-02-25,kevin.stoddard,Projects (Post-Award),4
2025-02-24,kevin.stoddard,Pursuits,2
2025-02-24,kevin.stoddard,Working ON Business,2
2025-02-24,kevin.stoddard,Relationship Building,2
2025-02-24,kevin.stoddard,Projects (Post-Award),2
2025-02-24,james.swanson,Projects (Post-Award),8
2025-02-24,keene.tanaka,Pursuits,8
2025-02-21,kevin.stoddard,Projects (Post-Award),8
2025-02-20,kevin.stoddard,Projects (Post-Award),8
2025-02-20,kevin.stoddard,Meetings (non-project),2.5
2025-02-20,kevin.stoddard,Pursuits,2
2025-02-19,kevin.stoddard,Projects (Post-Award),8
2025-02-19,kevin.stoddard,Meetings (non-project),2
2025-02-19,kevin.stoddard,Contracts,1.5
2025-02-19,kevin.stoddard,Working ON Business,2.5
2025-02-19,kevin.stoddard,Relationship Building,2
2025-02-18,kevin.stoddard,Meetings (non-project),3
2025-02-18,kevin.stoddard,Projects (Post-Award),4
2025-02-18,kevin.stoddard,Contracts,2
2025-02-18,kevin.stoddard,Relationship Building,1
2025-02-18,kevin.stoddard,Working ON Business,2
2025-02-18,kevin.stoddard,Pursuits,1
2025-02-17,keene.tanaka,Pursuits,8
2025-02-17,kevin.stoddard,Meetings (non-project),1.5
2025-02-17,kevin.stoddard,Working ON Business,5
2025-02-17,kevin.stoddard,Pursuits,8
2025-02-17,kevin.stoddard,Relationship Building,1.5
2025-02-17,kevin.stoddard,Projects (Post-Award),4

================
File: pipeline/data/tests/text/sample.txt
================
Sample Text File for Pipeline Testing
=======================================

This is a plain text file that contains various types of content for testing the pipeline tool's text extraction capabilities.

Section 1: Basic Text
--------------------
This section contains simple paragraphs of text. The pipeline should be able to extract this content and preserve its structure.

Lorem ipsum dolor sit amet, consectetur adipiscing elit. Sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.

Section 2: Lists
---------------
This section contains different types of lists:

Bulleted list:
* Item 1
* Item 2
* Item 3

Numbered list:
1. First item
2. Second item
3. Third item

Section 3: Table-like Content
----------------------------
This section contains content formatted like a table:

| Name       | Age | Department  |
|------------|-----|-------------|
| John Doe   | 30  | Engineering |
| Jane Doe   | 28  | Marketing   |
| Bob Smith  | 45  | Finance     |

Section 4: Special Characters
---------------------------
This section contains special characters and symbols:

Currency symbols: $, €, £, ¥
Mathematical symbols: +, -, ×, ÷, =, ≠, ≈, ∞
Punctuation: !, ?, ., :, ;, ", ', (, ), [, ], {, }

Section 5: Metadata
-----------------
Title: Sample Text File
Author: Pipeline Test Team
Date: 2025-03-14
Version: 1.0
Status: Draft

================
File: pipeline/docs/class_diagram.puml
================
@startuml Class Diagram

' Styling
skinparam class {
    BackgroundColor LightCyan
    ArrowColor #666666
    BorderColor #999999
}

' Title
title Pipeline Class Diagram

' Core Classes
class Pipeline {
    - config: Dict[str, Any]
    - logger: Logger
    - strategy_selector: StrategySelector
    + __init__(config: Optional[Dict[str, Any]])
    + run(input_path: str): Dict[str, Any]
    - _detect_document_type(input_path: str): str
    - _analyze_document(input_path: str, analyzer): Dict[str, Any]
    - _clean_content(analysis_result: Dict[str, Any], cleaner): Dict[str, Any]
    - _extract_data(cleaned_data: Dict[str, Any], extractor): Dict[str, Any]
    - _validate_data(extracted_data: Dict[str, Any], validator): Dict[str, Any]
    - _format_output(validated_data: Dict[str, Any], output_format: OutputFormat): Dict[str, Any]
    + save_output(output_data: Dict[str, Any], output_path: str): None
}

class PipelineProgress {
    - progress: Progress
    + __init__()
    + start(): None
    + stop(): None
    + add_task(description: str, total: Optional[float]): TaskID
    + update(task_id: TaskID, advance: float): None
    + display_stage_output(stage_name: str, data: Dict[str, Any], show_details: bool): None
    + display_summary(stages_data: Dict[str, Dict[str, Any]]): None
    + display_error(message: str): None
    + display_success(message: str): None
}

' Document Models
class Document {
    + metadata: DocumentMetadata
    + content: List[Section]
    + tables: List[Table]
    + schema: Schema
    + path: str
    + type: str
}

class DocumentMetadata {
    + title: str
    + author: str
    + subject: str
    + creator: str
    + producer: str
    + creation_date: str
    + modification_date: str
}

class Section {
    + title: str
    + content: str
    + children: List[Section]
    + level: int
}

class Table {
    + page: int
    + table_number: int
    + data: List[List[str]]
    + accuracy: Optional[float]
}

class Schema {
    + type: str
    + title: str
    + properties: Dict[str, Any]
    + required: List[str]
}

' Processing Classes
abstract class BaseProcessor {
    # logger: Logger
    + {abstract} process(data: Dict[str, Any]): Dict[str, Any]
}

class PDFAnalyzer {
    + analyze(input_path: str): Dict[str, Any]
}

class PDFCleaner {
    + clean(analysis_result: Dict[str, Any]): Dict[str, Any]
}

class PDFExtractor {
    + extract(cleaned_data: Dict[str, Any]): Dict[str, Any]
    - _extract_sections(doc): List[Dict[str, Any]]
    - _extract_tables(doc): List[Dict[str, Any]]
    - _extract_schema(sections: List[Dict[str, Any]]): Dict[str, Any]
}

class PDFValidator {
    + validate(extracted_data: Dict[str, Any]): Dict[str, Any]
}

' Formatters
abstract class BaseFormatter {
    + {abstract} format(data: Dict[str, Any]): Dict[str, Any]
    + {abstract} write(data: Dict[str, Any], path: str): None
}

class JSONFormatter {
    + format(data: Dict[str, Any]): Dict[str, Any]
    + write(data: Dict[str, Any], path: str): None
}

class MarkdownFormatter {
    + format(data: Dict[str, Any]): Dict[str, Any]
    + write(data: Dict[str, Any], path: str): None
}

' Relationships
Pipeline --> PipelineProgress : uses
Pipeline --> Document : processes
Document *-- DocumentMetadata
Document *-- "0..*" Section
Document *-- "0..*" Table
Document *-- Schema

BaseProcessor <|-- PDFAnalyzer
BaseProcessor <|-- PDFCleaner
BaseProcessor <|-- PDFExtractor
BaseProcessor <|-- PDFValidator

BaseFormatter <|-- JSONFormatter
BaseFormatter <|-- MarkdownFormatter

PDFAnalyzer --> Document : creates
PDFExtractor --> Section : creates
PDFExtractor --> Table : creates
PDFExtractor --> Schema : creates

' Notes
note right of Pipeline
  Main orchestrator that coordinates
  the document processing workflow
end note

note right of PipelineProgress
  Provides rich terminal output
  and progress tracking
end note

note right of Document
  Core data model representing
  a processed document
end note

@enduml

================
File: pipeline/docs/CLASSIFICATION_FIX.md
================
# Classification Override Fix

This document explains the fix for the classification override issue where HVAC documents with multiple tables were being classified as "FORM" instead of "HVAC_SPECIFICATION".

## Problem Description

HVAC specification documents with multiple tables were being classified as "FORM" instead of "HVAC_SPECIFICATION". This occurred because the generic classification rule in `rule_based.py` classified any document with more than 3 tables as a "FORM" with a confidence of 0.6, which overrode the specific HVAC classification rules.

## Root Cause Analysis

In `utils/pipeline/processors/classifiers/rule_based.py`, the `classify` method would fall back to generic classification whenever no specific document type matched with sufficient confidence. The `_classify_generic` method contained the following logic:

```python
def _classify_generic(self, document_data: Dict[str, Any], features: Dict[str, Any]) -> Dict[str, Any]:
    """
    Classify document into generic categories when specific types don't match.
    """
    # Check if it's a form
    if features.get("table_count", 0) > 3:
        return {
            "document_type": "FORM",
            "confidence": 0.6,
            "schema_pattern": "tabular_form",
            "key_features": ["multiple_tables", "structured_layout"],
        }
    
    # Other generic classifications...
```

The issue was that even when a specific document type like "HVAC_SPECIFICATION" matched with a reasonable confidence (e.g., 0.3), the classifier would still fall back to generic classification if the confidence wasn't high enough. Then, if the document had more than 3 tables, it would be classified as a "FORM" with a confidence of 0.6, overriding the specific classification.

## Fix Implementation

The fix modifies the `classify` method to only fall back to generic classification if the confidence of the best match is very low (less than 0.2). This ensures that specific document types with reasonable confidence are always preferred over generic types.

Here's the modified `classify` method:

```python
def classify(self, document_data: Dict[str, Any], features: Dict[str, Any]) -> Dict[str, Any]:
    """
    Classify the document using rule-based approach.
    """
    # Check filename patterns if path is available
    if "path" in document_data:
        filename = os.path.basename(document_data["path"])
        for doc_type, pattern in self.filename_patterns.items():
            if re.search(pattern, filename):
                self.logger.info(f"Matched filename pattern for {doc_type}: {filename}")
                return {
                    "document_type": doc_type,
                    "confidence": 0.8,  # High confidence for filename match
                    "schema_pattern": self.rules_config.get(doc_type, {}).get("schema_pattern", "standard"),
                    "key_features": ["filename_match"],
                }

    # Apply configured rules
    best_match = self._get_best_match(document_data, features)
    
    # Only use generic classification if confidence is very low
    if best_match[0] == "UNKNOWN" or best_match[1] < 0.2:  # Lower threshold for falling back to generic
        # If no specific type matched or confidence is very low, try to determine a generic type
        return self._classify_generic(document_data, features)

    return {
        "document_type": best_match[0],
        "confidence": best_match[1],
        "schema_pattern": best_match[2],
        "key_features": best_match[3],
    }
```

The key change is the condition for falling back to generic classification:
```python
# Only use generic classification if confidence is very low
if best_match[0] == "UNKNOWN" or best_match[1] < 0.2:  # Lower threshold for falling back to generic
    # If no specific type matched or confidence is very low, try to determine a generic type
    return self._classify_generic(document_data, features)
```

This ensures that specific document types with reasonable confidence (>= 0.2) are always preferred over generic types, regardless of the number of tables or other generic features.

## Verification

A test script has been created to verify the fix: `utils/pipeline/tests/test_classification_fix.py`. This script:

1. Creates a test document with HVAC content and multiple tables
2. Classifies the document using the RuleBasedClassifier with HVAC configuration
3. Verifies that the document is correctly classified as "HVAC_SPECIFICATION" instead of "FORM"
4. Simulates the behavior before the fix by directly calling the `_classify_generic` method

To run the test:

```bash
python -m utils.pipeline.tests.test_classification_fix
```

Expected output:

```
=== Testing Classification Override Fix ===
Testing classification with HVAC configuration (after fix):
Matched filename pattern for HVAC_SPECIFICATION: HVAC_SPECIFICATION_with_tables.pdf
Classification result: {'document_type': 'HVAC_SPECIFICATION', 'confidence': 0.8, 'schema_pattern': 'hvac_specification', 'key_features': ['filename_match']}
✅ Test PASSED: Document correctly classified as HVAC_SPECIFICATION

Simulating classification behavior before fix:
Classification result (before fix): {'document_type': 'FORM', 'confidence': 0.6, 'schema_pattern': 'tabular_form', 'key_features': ['multiple_tables', 'structured_layout']}
✅ Test PASSED: Document would have been classified as FORM before the fix
```

## Additional Notes

This fix addresses the fundamental issue of prioritization in the classification logic. It ensures that specific document types with reasonable confidence are always preferred over generic types, regardless of the number of tables or other generic features.

Alternative approaches that were considered:

1. Increasing the confidence threshold for HVAC documents in the configuration
2. Adding a special case for HVAC documents with tables in the `_classify_generic` method

The implemented solution was chosen because it addresses the root cause of the issue and provides a more general solution that will work for all document types, not just HVAC documents.

================
File: pipeline/docs/document_classification.md
================
# Document Classification

The pipeline now includes document classification capabilities that can automatically identify document types and match them against known schemas.

## Overview

Document classification analyzes the structure and content of processed documents to determine their type (e.g., proposal, quotation, specification) and identify common patterns. This information can be used to:

1. Organize documents by type
2. Extract relevant information based on document type
3. Match new documents against known schemas
4. Build a knowledge base of document structures

## Components

The document classification system consists of the following components:

### 1. Document Classifier

Located in `utils/pipeline/processors/document_classifier.py`, this component:
- Extracts features from document data
- Applies classification strategies to identify document types
- Returns classification results with confidence scores

### 2. Classification Strategies

Located in `utils/pipeline/processors/classifiers/`, these implement different approaches to document classification:

- **Rule-Based Classifier**: Uses predefined rules to identify document types based on structure and content patterns
- **Pattern Matcher**: Matches documents against known patterns to identify their type

### 3. Schema Registry

Located in `utils/pipeline/schema/registry.py`, this component:
- Stores known document schemas
- Matches new documents against known schemas
- Records new schemas for future matching

### 4. Schema Matchers

Located in `utils/pipeline/schema/matchers.py`, these implement different approaches to schema matching:

- **Structure Matcher**: Matches schemas based on their structure (section hierarchy, table structure, etc.)
- **Content Matcher**: Matches schemas based on their content patterns (section titles, keywords, etc.)

## Integration with Pipeline

The document classification is integrated into the pipeline as a new step between validation and formatting:

1. Analyze document structure
2. Clean and normalize content
3. Extract structured data
4. Validate extracted data
5. **Classify document type and identify schema pattern**
6. Format output
7. Verify output structure

## Configuration

Document classification can be configured in the pipeline configuration:

```python
config = {
    "enable_classification": True,  # Enable document classification
    "record_schemas": True,  # Record schemas for future matching
    "match_schemas": True,  # Match against known schemas
    "classification": {
        "type": "rule_based",  # Classification strategy (rule_based, pattern_matcher)
        "confidence_threshold": 0.6,  # Minimum confidence threshold
    },
}
```

## Classification Results

Classification results are added to the document data and include:

```json
{
  "classification": {
    "document_type": "PROPOSAL",
    "confidence": 0.85,
    "schema_pattern": "detailed_proposal",
    "key_features": [
      "has_payment_terms",
      "has_delivery_terms",
      "proposal_in_title"
    ]
  }
}
```

When schema matching is enabled, additional information may be included:

```json
{
  "classification": {
    "document_type": "PROPOSAL",
    "confidence": 0.85,
    "schema_pattern": "detailed_proposal",
    "key_features": [...],
    "schema_id": "proposal_20250314220145",
    "schema_match_confidence": 0.92,
    "schema_document_type": "PROPOSAL"
  }
}
```

## Example Usage

See `utils/pipeline/examples/document_classification_example.py` for a complete example of using document classification.

## Extending the System

### Adding New Classification Strategies

1. Create a new classifier in `utils/pipeline/processors/classifiers/`
2. Implement the `classify()` method
3. Update `DocumentClassifier` to use the new strategy

### Adding New Schema Matchers

1. Create a new matcher in `utils/pipeline/schema/matchers.py`
2. Implement the `match()` method
3. Update `SchemaMatcherFactory` to use the new matcher

### Adding Known Schema Templates

1. Create a new template in `utils/pipeline/schema/templates/`
2. Implement the schema structure
3. Update the schema registry to use the template

================
File: pipeline/docs/er_diagram.puml
================
@startuml ER Diagram

' Styling
!define table(x) class x << (T,#FFAAAA) >>
!define primary_key(x) <u>x</u>
!define foreign_key(x) #x#

' Title
title Pipeline Data Model ER Diagram

' Entities
table(Document) {
    primary_key(id)
    foreign_key(metadata_id)
    path: string
    type: string
    created_at: timestamp
    updated_at: timestamp
}

table(DocumentMetadata) {
    primary_key(id)
    title: string
    author: string
    subject: string
    creator: string
    producer: string
    creation_date: timestamp
    modification_date: timestamp
}

table(Section) {
    primary_key(id)
    foreign_key(document_id)
    foreign_key(parent_section_id)
    title: string
    content: text
    level: integer
    sequence: integer
}

table(Table) {
    primary_key(id)
    foreign_key(document_id)
    page: integer
    table_number: integer
    accuracy: float
}

table(TableRow) {
    primary_key(id)
    foreign_key(table_id)
    row_number: integer
}

table(TableCell) {
    primary_key(id)
    foreign_key(row_id)
    column_number: integer
    content: string
}

table(Schema) {
    primary_key(id)
    foreign_key(document_id)
    type: string
    title: string
}

table(SchemaProperty) {
    primary_key(id)
    foreign_key(schema_id)
    name: string
    type: string
    required: boolean
}

' Relationships
Document ||--|| DocumentMetadata
Document ||--o{ Section
Document ||--o{ Table
Document ||--|| Schema

Section }o--|| Section : parent

Table ||--o{ TableRow
TableRow ||--o{ TableCell

Schema ||--o{ SchemaProperty

' Notes
note right of Document
  Central entity representing
  a processed document
end note

note right of Section
  Hierarchical structure
  of document content
end note

note right of Table
  Tabular data extracted
  from documents
end note

note right of Schema
  Document structure and
  validation rules
end note

@enduml

================
File: pipeline/docs/pdf-extraction-implementation-plan.md
================
# Revised PDF Extraction Pipeline Implementation Plan

## Current Structure Analysis

The pipeline has these key directories that we should use:
- `analyzer/`: For document analysis components (PDF analyzer should go here)
- `cleaner/`: For content normalization components (PDF cleaner should go here)
- `processors/`: Contains extractor.py, formatter.py, and validator.py
- `strategies/`: Contains base.py with strategy interfaces
- `models/`: Contains data models
- `config/`: Contains configuration management
- `utils/`: Contains utility functions

## Implementation Plan

### 1. Set Up the Development Environment

```bash
cd utils/pipeline
uv pip install -e ".[pdf,dev]"
```

### 2. Implement Base Strategy Interfaces

Define the base strategy interfaces in `strategies/base.py` (already done).

### 3. Implement PDF Components

#### 3.1. PDF Analyzer

Create in `analyzer/pdf.py`:
```python
from typing import Any, Dict
import fitz  # PyMuPDF
from utils.pipeline.utils.logging import get_logger
from utils.pipeline.strategies.base import AnalyzerStrategy

class PDFAnalyzer(AnalyzerStrategy):
    """Analyzes PDF document structure and extracts metadata."""
    # Implementation...
```

#### 3.2. PDF Cleaner

Create in `cleaner/pdf.py`:
```python
from typing import Any, Dict
import fitz  # PyMuPDF
from utils.pipeline.utils.logging import get_logger
from utils.pipeline.strategies.base import CleanerStrategy

class PDFCleaner(CleanerStrategy):
    """Cleans and normalizes PDF content."""
    # Implementation...
```

#### 3.3. PDF Extractor

Create in `processors/pdf_extractor.py`:
```python
from typing import Any, Dict
import fitz  # PyMuPDF
from utils.pipeline.utils.logging import get_logger

class PDFExtractor:
    """Extracts structured data from PDF documents."""
    # Implementation...
```

#### 3.4. PDF Validator

Create in `processors/pdf_validator.py`:
```python
from typing import Any, Dict
from utils.pipeline.utils.logging import get_logger

class PDFValidator:
    """Validates extracted PDF data."""
    # Implementation...
```

#### 3.5. PDF Formatter

Create in `processors/pdf_formatter.py`:
```python
from typing import Any, Dict
from utils.pipeline.utils.logging import get_logger

class PDFFormatter:
    """Formats validated PDF data for output."""
    # Implementation...
```

### 4. Update Package Initialization

#### 4.1. Analyzer Package

Update `analyzer/__init__.py`:
```python
from .pdf import PDFAnalyzer

__all__ = ["PDFAnalyzer"]
```

#### 4.2. Cleaner Package

Update `cleaner/__init__.py`:
```python
from .pdf import PDFCleaner

__all__ = ["PDFCleaner"]
```

### 5. Create Example Usage

Create `examples/pdf_extraction_example.py`:
```python
from pipeline import Pipeline
from config.config import load_config

def main():
    config = load_config()
    pipeline = Pipeline(config)
    # Example usage...
```

### 6. Implementation Steps

1. Set up the environment with PDF dependencies
2. Move analyzer implementation to analyzer/pdf.py
3. Move cleaner implementation to cleaner/pdf.py
4. Implement PDF-specific processors
5. Update package __init__ files
6. Create usage example
7. Write tests

### 7. Testing Plan

Create tests for each PDF component:

```python
# tests/analyzer/test_pdf_analyzer.py
import pytest
from analyzer import PDFAnalyzer

def test_pdf_analyzer_with_sample_pdf(sample_pdf_path):
    """Test PDF analyzer with a sample PDF file."""
    analyzer = PDFAnalyzer()
    result = analyzer.analyze(sample_pdf_path)
    # Assertions...

# Similar tests for cleaner and processors
```

## Next Steps After Basic Implementation

1. **Refine Section Detection**: Improve the heuristics for detecting sections in PDFs
2. **Enhance Table Extraction**: Implement more sophisticated table extraction techniques
3. **Add OCR Support**: For scanned PDFs, integrate OCR capabilities
4. **Implement Custom Validators**: Create domain-specific validators for different types of PDFs
5. **Create Visualization Tools**: Add tools to visualize the extracted data

================
File: pipeline/docs/pipeline_c4_diagram.puml
================
@startuml "Pipeline C4 Diagram"
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Context.puml
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Container.puml
!include https://raw.githubusercontent.com/plantuml-stdlib/C4-PlantUML/master/C4_Component.puml

' LAYOUT_WITH_LEGEND()
LAYOUT_TOP_DOWN()
' LAYOUT_LEFT_RIGHT()

title "Document Pipeline Tool - C4 Architecture Diagram"

' Context diagram
Person(user, "User", "A person who wants to extract structured data from documents")
System(pipelineTool, "Document Pipeline Tool", "Extracts structured data from various document formats")
System_Ext(fileSystem, "File System", "Stores input documents and output data")
System_Ext(externalApis, "External APIs", "Optional integrations for enhanced processing")

Rel(user, pipelineTool, "Uses")
Rel(pipelineTool, fileSystem, "Reads from and writes to")
Rel(pipelineTool, externalApis, "May integrate with")

' Container diagram
Container_Boundary(pipelineToolBoundary, "Document Pipeline Tool") {
    Container(cliInterface, "CLI Interface", "Python", "Command-line interface for the pipeline tool")
    Container(pipelineCore, "Pipeline Core", "Python", "Orchestrates the document processing workflow")
    Container(strategyEngine, "Strategy Engine", "Python", "Selects and applies appropriate processing strategies")
    Container(dataStore, "Data Store", "YAML/JSON", "Stores extracted structured data")
    Container(configSystem, "Configuration System", "YAML", "Manages pipeline settings and options")
}

Rel(user, cliInterface, "Executes commands via")
Rel(cliInterface, pipelineCore, "Invokes")
Rel(pipelineCore, strategyEngine, "Uses")
Rel(pipelineCore, configSystem, "Reads configuration from")
Rel(pipelineCore, dataStore, "Writes extracted data to")
Rel(strategyEngine, fileSystem, "Reads documents from")
Rel(strategyEngine, externalApis, "May call")

' Component diagram for Pipeline Core
Component_Boundary(pipelineCoreBoundary, "Pipeline Core") {
    Component(orchestrator, "Pipeline Orchestrator", "Python", "Controls the flow of document processing")
    Component(analyzer, "Document Analyzer", "Python", "Analyzes document structure and content")
    Component(cleaner, "Content Cleaner", "Python", "Normalizes and cleans document content")
    Component(extractor, "Data Extractor", "Python", "Extracts structured data from documents")
    Component(validator, "Data Validator", "Python", "Validates extracted data against schemas")
    Component(formatter, "Output Formatter", "Python", "Formats data for output")
    Component(logger, "Logging System", "Python", "Records processing events and errors")
}

Rel(orchestrator, analyzer, "First sends document to")
Rel(analyzer, cleaner, "Passes analyzed document to")
Rel(cleaner, extractor, "Passes cleaned content to")
Rel(extractor, validator, "Passes extracted data to")
Rel(validator, formatter, "Passes validated data to")
Rel(orchestrator, logger, "Records events via")

' Component diagram for Strategy Engine
Component_Boundary(strategyEngineBoundary, "Strategy Engine") {
    Component(strategySelector, "Strategy Selector", "Python", "Selects appropriate strategies based on document type")
    Component(pdfStrategy, "PDF Strategy", "Python", "Handles PDF document processing")
    Component(excelStrategy, "Excel Strategy", "Python", "Handles Excel document processing")
    Component(wordStrategy, "Word Strategy", "Python", "Handles Word document processing")
    Component(textStrategy, "Text Strategy", "Python", "Handles plain text document processing")
    Component(strategyFactory, "Strategy Factory", "Python", "Creates strategy instances")
}

Rel(strategySelector, strategyFactory, "Requests strategy from")
Rel(strategyFactory, pdfStrategy, "Creates")
Rel(strategyFactory, excelStrategy, "Creates")
Rel(strategyFactory, wordStrategy, "Creates")
Rel(strategyFactory, textStrategy, "Creates")
Rel(pipelineCore, strategySelector, "Requests appropriate strategy from")

@enduml

================
File: pipeline/docs/pipeline_diagram.puml
================
@startuml Pipeline Architecture

' Define styles
skinparam componentStyle uml2
skinparam backgroundColor white
skinparam ArrowColor #666666
skinparam ComponentBorderColor #999999
skinparam ComponentBackgroundColor #EEEEEE
skinparam NoteBorderColor #999999
skinparam NoteBackgroundColor #EEEEEE
skinparam RectangleBorderColor #999999
skinparam RectangleBackgroundColor #EEEEEE

' Title
title Document Pipeline Architecture

' Main components
rectangle "Input" as input #LightBlue {
  file "PDF Documents" as pdf
  note right of pdf
    - Quotes
    - Specifications
    - Technical Documents
  end note
}

rectangle "Pipeline Core" as core #LightGreen {
  component "Pipeline" as pipeline
  component "PipelineProgress" as progress
  component "StrategySelector" as selector
  note right of progress
    Rich terminal output
    with progress tracking
  end note
}

rectangle "Processing Stages" as stages #LightYellow {
  component "PDFAnalyzer" as analyzer
  component "PDFCleaner" as cleaner
  component "PDFExtractor" as extractor
  component "PDFValidator" as validator
  note bottom of extractor
    Extracts structured data:
    - Sections
    - Tables
    - Schema
  end note
}

rectangle "Formatters" as formatters #LightPink {
  component "JSONFormatter" as jsonformat
  component "MarkdownFormatter" as mdformat
  note bottom of formatters
    Converts extracted data
    to desired output format
  end note
}

rectangle "Models" as models #LightCyan {
  component "Document" as doc
  component "Section" as section
  component "Table" as table
  component "Schema" as schema
}

rectangle "Utilities" as utils #LightGray {
  component "Logging" as logging
  component "FileIO" as fileio
  component "ErrorHandling" as error
}

rectangle "Output" as output #LightBlue {
  file "JSON" as json {
    file "Content" as content
    file "Metadata" as metadata
    file "Tables" as tables
    file "Validation" as validation
  }
  file "Markdown" as markdown
}

' Flow
input --> pipeline : Input file
pipeline --> progress : Updates progress
pipeline --> selector : Select strategy
selector --> stages : Configure processors

' Processing flow
pipeline --> analyzer : 1. Analyze
analyzer --> cleaner : 2. Clean
cleaner --> extractor : 3. Extract
extractor --> validator : 4. Validate
validator --> formatters : 5. Format
formatters --> output : 6. Save

' Component relationships
stages --> models : Populates
stages --> utils : Uses
pipeline --> utils : Uses
progress --> utils : Uses

' Legend
legend right
  **Pipeline Flow**
  1. Load document
  2. Analyze structure
  3. Clean content
  4. Extract data
  5. Validate schema
  6. Format output
  
  **Progress Tracking**
  - Rich terminal output
  - Stage completion
  - Error handling
end legend

@enduml

================
File: pipeline/docs/pipeline-plan.md
================
# **CSI MasterFormat PDF Extraction Tool: Architectural and Implementation Plan**

## **1. Executive Summary**

This document outlines the design and implementation plan for a modular, pipeline-based Python tool for extracting structured data from CSI MasterFormat PDF files into a YAML schema. It adheres to SOLID principles and employs the Strategy pattern to ensure extensibility, maintainability, and clear separation of concerns. The tool dynamically handles multiple input types (PDF, CSV, Excel, text) with automated pre-flight validation and robust extraction strategies.

## **2. System Overview**

The tool follows a structured pipeline approach:

- **Preflight Validation:** Validates document structure and extracts initial metadata.
- **Preprocessing:** Normalizes formatting and initial data preparation.
- **Data Extraction:** Parses and structures document data according to CSI MasterFormat standards.
- **YAML Formatting & Output:** Serializes structured data into a YAML schema.
- **Verification & Reporting:** Validates extracted data accuracy, completeness, and generates reports.

## **3. System Architecture**

### **3.1 Core Modules**

- **Configuration Module:** Manages paths, file types, parsing patterns, and schema definitions.
- **Validation Module:** Ensures document integrity and extracts initial metadata.
- **Preprocessing Module:** Standardizes and normalizes input documents for extraction, without detailed table extraction.
- **Data Extraction Module:** Performs detailed content extraction including text sections, tables, adhering to CSI MasterFormat standards.
- **Output Module:** Converts structured data into YAML format.
- **Verification Module:** Confirms data integrity post-extraction.
- **Report Generator:** Logs results and errors encountered.
- **Utility Module:** Provides common functions for logging, file I/O, regex operations, and data transformations.

### **3.2 Strategy Pattern**

- **Extraction Strategies:** Format-specific extraction logic (e.g., PDF, CSV, Excel).
- **Cleaning Strategies:** Format-specific content normalization.

### **3.3 Error Handling and Logging**

- Errors at each stage (validation, preprocessing, extraction) are logged.
- Robust exception handling via `try-except` blocks ensures pipeline resilience.

## **4. Pipeline Flow**

1. **Configuration Load:** Initialize settings from a configuration file.
2. **Validation:** Validate documents for format and metadata.
3. **Preprocessing:** Normalize input to a consistent state for extraction.
4. **Strategy Selection:** Dynamically select appropriate extraction strategies.
5. **Data Extraction:** Perform structured content extraction.
6. **Structuring:** Assemble extracted text, tables, and metadata into a structured Document object.
7. **YAML Output:** Generate and save YAML-formatted output.
8. **Verification & Reporting:** Generate comprehensive extraction reports.

## **5. Dynamic Input Handling & Type Safety**

Utilizes Python's `mypy` for explicit type annotations:

```python
from typing import Literal, Union
from typing_extensions import TypedDict

InputType = Literal['pdf', 'csv', 'excel', 'text']

class RawData(TypedDict):
    content: Union[str, list, dict]
```

## **6. Detailed Class Diagram (Pseudo-Class Diagram)**

```plaintext
ExtractorPipeline
├── ConfigManager
│   ├─ load(config_path) -> ConfigManager
│
├── DocumentValidator (interface)
│   ├─ validate(file_path) -> bool
│   └─ get_errors() -> list[str]
│   ├─ PDFValidator
│   ├─ CSVValidator
│   ├─ ExcelValidator
│   └─ TextValidator
│
├── DocumentPreprocessor
│   └─ preprocess(file_path) -> PreprocessedDocument
│
├── ExtractionStrategy (interface)
│   └─ extract(preprocessed_data) -> RawData
│   ├── PDFExtractionStrategy
│   ├── CSVExtractionStrategy
│   ├── ExcelExtractionStrategy
│   └── TextExtractionStrategy
│
├── CleanerStrategy (interface)
│   └─ clean(raw_data) -> StructuredData
│   ├── PDFCleanerStrategy
│   ├── CSVCleanerStrategy
│   ├── ExcelCleanerStrategy
│   └── TextCleanerStrategy
│
├── StructureBuilder
│   └─ build_document(structured_data, metadata) -> Document
│
├── YAMLFormatter
│   └─ format(document: Document) -> str
│
├── YAMLWriter
│   └─ write_file(yaml_content: str, file_path: str)
│
├── Verifier
│   └─ verify(document: Document) -> VerificationResult
│
├── ReportGenerator
│   ├─ record_error(file_path: str, error: str)
│   ├─ record_file_result(file_path: str, result: VerificationResult)
│   └─ generate_report() -> str
│
└── Utility
    ├─ log_error(msg: str)
    ├─ ensure_directory(path: str)
    ├─ save_file(path: str, content: str)
    └─ regex_helpers()
```

### **Class Responsibilities & Attributes**

- Each class maintains a clearly defined role and minimal coupling, supporting SOLID principles.
- Methods and attributes align explicitly with each class’s responsibility, promoting clear TDD practices.

## **6. Scalability and Future Considerations**

To scale effectively:

- Implement parallel processing for multiple documents.
- Optimize extraction algorithms and memory usage.

## **7. Test-Driven Development (TDD) Approach**

Employ unit tests developed incrementally for each module and class, beginning with tests to validate behaviors and outcomes.

## **8. Summary**

This plan ensures flexibility, clarity, and scalability, providing a robust basis for the CSI MasterFormat extraction tool’s effective and efficient development.

================
File: pipeline/docs/schema_analysis.md
================
# Schema Analysis and Visualization

The pipeline now includes schema analysis and visualization capabilities that can help you understand document patterns and relationships.

## Overview

Schema analysis examines the structure and patterns of document schemas to:

1. Identify common patterns across document types
2. Compare schemas to find similarities and differences
3. Visualize relationships between schemas
4. Extract insights about document structures

## Components

The schema analysis system consists of the following components:

### 1. Schema Analyzer

Located in `utils/pipeline/schema/analyzer.py`, this component:
- Analyzes schemas to extract patterns and insights
- Compares schemas to identify similarities and differences
- Clusters similar schemas together

### 2. Schema Vectorizer

Located in `utils/pipeline/schema/vectorizer.py`, this component:
- Converts schemas to numerical feature vectors
- Extracts features from schema structure and content
- Enables mathematical comparison of schemas

### 3. Schema Visualizer

Located in `utils/pipeline/schema/visualizer.py`, this component:
- Generates visualizations of schema patterns
- Creates cluster visualizations using dimensionality reduction
- Visualizes schema structure and features

### 4. Extended Schema Registry

Located in `utils/pipeline/schema/extended_registry.py`, this component:
- Extends the base SchemaRegistry with analysis capabilities
- Provides a unified interface for schema analysis and visualization

## Usage

### Example Script

The easiest way to use the schema analysis functionality is through the example script:

```bash
python -m utils.pipeline.examples.schema_analysis_example
```

This script will:
1. Load all available schemas
2. Analyze schema patterns
3. Display analysis results
4. Generate visualizations
5. Compare schemas

### Programmatic Usage

You can also use the schema analysis functionality programmatically:

```python
from utils.pipeline.schema.extended_registry import ExtendedSchemaRegistry

# Initialize registry
registry = ExtendedSchemaRegistry()

# Analyze schemas
analysis = registry.analyze()
print(f"Found {analysis['schema_count']} schemas")

# Compare schemas
schema_id1 = "form_20250314221847"
schema_id2 = "form_20250314221900"
comparison = registry.compare(schema_id1, schema_id2)
print(f"Similarity: {comparison['overall_similarity']:.2f}")

# Generate visualizations
viz_path = registry.visualize("clusters")
print(f"Visualization saved to: {viz_path}")
```

## Visualization Types

The system supports several types of visualizations:

1. **Clusters**: Visualizes relationships between schemas using dimensionality reduction
2. **Features**: Creates a heatmap comparing features across schemas
3. **Structure**: Visualizes the hierarchical structure of a schema
4. **Tables**: Visualizes table patterns in a schema

## Analysis Results

The schema analysis provides the following information:

1. **Document Types**: Distribution of document types in the registry
2. **Common Metadata**: Frequency of metadata fields across schemas
3. **Table Patterns**: Statistics about table usage and structure
4. **Section Patterns**: Statistics about section usage and structure

## Dependencies

The schema analysis functionality requires the following dependencies:

- **matplotlib**: For creating visualizations
- **numpy**: For numerical operations
- **scikit-learn**: For dimensionality reduction (optional, for cluster visualization)
- **networkx**: For graph visualization (optional, for structure visualization)
- **seaborn**: For enhanced visualizations (optional, for feature visualization)
- **pandas**: For data manipulation (optional, for feature visualization)

You can install these dependencies with:

```bash
pip install matplotlib numpy scikit-learn networkx seaborn pandas
```

## Extending the System

### Adding New Features

To add new features to the vectorization:

1. Update `SchemaVectorizer.vectorize_schema()` to extract the new features
2. Update `SchemaVectorizer.get_feature_names()` to include the new feature names

### Adding New Visualizations

To add new visualization types:

1. Add a new method to `SchemaVisualizer` for the visualization
2. Update `SchemaVisualizer.visualize()` to support the new visualization type

================
File: pipeline/ENHANCEMENT_CHECKLIST.md
================
# Document Processing Pipeline Enhancement Checklist

This checklist provides a detailed breakdown of the enhancements made to the document processing pipeline and how to verify each one.

## 1. Enhanced Data Extraction

### 1.1 Complete Content Extraction
- [x] **Enhancement**: Removed content truncation that was limiting section content to 100 characters
- [x] **Code Location**: `utils/pipeline/processors/pdf_extractor.py` in `_extract_sections` method
- [x] **Verification Method**: 
  - Run pipeline on a document with long sections
  - Check output JSON for complete section content
  - Compare with previous version if available

### 1.2 Improved Table Detection
- [x] **Enhancement**: Better structure recognition for tables in PDF documents
- [x] **Code Location**: `utils/pipeline/processors/pdf_extractor.py` in `_extract_tables` method
- [ ] **Verification Method**:
  - Run pipeline on a document with complex tables
  - Use `visualize_schema tables <schema_id>` to check table structure
  - Verify tables are correctly identified and structured

### 1.3 Table Headers and Column Information
- [x] **Enhancement**: Added support for extracting table headers and column information
- [x] **Code Location**: `utils/pipeline/processors/pdf_extractor.py` in `_extract_tables` method
- [ ] **Verification Method**:
  - Check output JSON for table headers and column count
  - Use `visualize_schema tables <schema_id>` to visualize headers
  - Verify column count matches actual document

### 1.4 Enhanced Schema Storage
- [x] **Enhancement**: Schema now includes actual content samples and table data
- [x] **Code Location**: `utils/pipeline/schema/registry.py` in `record` method
- [ ] **Verification Method**:
  - Check schema registry for content samples
  - Verify table data is stored in schema
  - Use visualization tools to confirm data is accessible

## 2. Configurable Document Classification

### 2.1 Central Configuration System
- [x] **Enhancement**: Added Pydantic models for document type rules in config.py
- [x] **Code Location**: `utils/pipeline/config/config.py`
- [ ] **Verification Method**:
  - Check configuration file structure
  - Verify Pydantic models are used for validation
  - Test with invalid configuration to ensure validation works


### 2.2 Rule-Based Classifier Configuration
- [x] **Enhancement**: Modified rule-based classifier to use configuration instead of hardcoded rules
- [x] **Code Location**: `utils/pipeline/processors/classifiers/rule_based.py`
- [ ] **Verification Method**:
  - Compare classifier behavior with different configurations
  - Verify rules from configuration are applied correctly
  - Test with custom rules to ensure they override defaults

### 2.3 Filename Pattern Matching
- [x] **Enhancement**: Added support for filename pattern matching to improve classification accuracy
- [x] **Code Location**: `utils/pipeline/processors/classifiers/rule_based.py` in `classify` method
- [ ] **Verification Method**:
  - Test with files matching filename patterns
  - Verify correct classification based on filename
  - Check confidence level for filename-based classification

### 2.4 Configuration Examples
- [x] **Enhancement**: Provided detailed configuration examples for different document types
- [x] **Code Location**: `utils/pipeline/config/example_config.yaml` and `utils/pipeline/config/hvac_config.yaml`
- [ ] **Verification Method**:
  - Review configuration examples for completeness
  - Test each example with appropriate documents
  - Verify configurations produce expected results

## 3. Schema Visualization Improvements

### 3.1 Table Headers Visualization
- [x] **Enhancement**: Added visualization of table headers and sample data
- [x] **Code Location**: `utils/pipeline/schema/visualizer.py`
- [ ] **Verification Method**:
  - Generate table visualization for a schema
  - Check for header information in visualization
  - Verify sample data is displayed correctly

### 3.2 Column Count Visualization
- [x] **Enhancement**: Added column count visualization
- [x] **Code Location**: `utils/pipeline/schema/visualizer.py`
- [ ] **Verification Method**:
  - Generate table visualization for a schema
  - Check for column count information
  - Verify counts match actual document

### 3.3 Command-Line Interface Improvements
- [x] **Enhancement**: Improved the command-line interface for schema visualization
- [x] **Code Location**: `utils/pipeline/visualize_schema.py`
- [ ] **Verification Method**:
  - Test various command-line options
  - Verify help text is clear and accurate
  - Check error handling for invalid inputs

## 4. Documentation Updates

### 4.1 Schema Visualization Documentation
- [ ] **Enhancement**: Created comprehensive documentation for visualization tools
- [ ] **Code Location**: `utils/pipeline/SCHEMA_VISUALIZATION.md`
- [ ] **Verification Method**:
  - Review documentation for completeness
  - Verify examples match actual command syntax
  - Check for clear explanations of visualization types

### 4.2 Pipeline Usage Documentation
- [ ] **Enhancement**: Created comprehensive guide to pipeline usage and configuration
- [ ] **Code Location**: `utils/pipeline/PIPELINE_USAGE.md`
- [ ] **Verification Method**:
  - Review documentation for completeness
  - Verify examples match actual command syntax
  - Check for clear explanations of configuration options

### 4.3 Example Configurations
- [ ] **Enhancement**: Created example configurations with all available options
- [ ] **Code Location**: `utils/pipeline/config/example_config.yaml` and `utils/pipeline/config/hvac_config.yaml`
- [ ] **Verification Method**:
  - Review configurations for completeness
  - Verify all options are documented
  - Test configurations with appropriate documents

## 5. Known Issues and Limitations

### 5.1 Classification Override Issue
- [ ] **Issue**: Generic classification rules may override specific rules
- [ ] **Code Location**: `utils/pipeline/processors/classifiers/rule_based.py` in `_classify_generic` method
- [ ] **Potential Fix**: Modify method to check specific rules first or adjust confidence thresholds

### 5.2 Table Detection Limitations
- [ ] **Issue**: Complex tables may not be detected correctly
- [ ] **Code Location**: `utils/pipeline/processors/pdf_extractor.py` in `_extract_tables` method
- [ ] **Potential Fix**: Improve table detection algorithm or add configuration options for table detection

### 5.3 Performance Considerations
- [ ] **Issue**: Enhanced extraction may impact performance
- [ ] **Code Location**: Various
- [ ] **Potential Fix**: Add configuration options for performance vs. accuracy tradeoffs

================
File: pipeline/ENHANCEMENT_SUMMARY.md
================
# Document Processing Pipeline Enhancement Summary

This document provides a comprehensive summary of the enhancements made to the document processing pipeline, the verification plan, and next steps.

## Overview of Enhancements

The document processing pipeline has been enhanced in several key areas:

1. **Enhanced Data Extraction**
   - Removed content truncation to capture complete document content
   - Improved table detection with better structure recognition
   - Added support for extracting table headers and column information
   - Enhanced schema storage to include actual content samples and table data

2. **Configurable Document Classification**
   - Created Pydantic models for document type rules in config.py
   - Modified the rule-based classifier to use configuration instead of hardcoded rules
   - Added support for filename pattern matching to improve classification accuracy
   - Provided detailed configuration examples for different document types

3. **Improved Schema Visualization**
   - Added visualization of table headers and sample data
   - Added column count visualization
   - Improved the command-line interface for schema visualization
   - Created comprehensive documentation for the visualization tools

## Verification Status

The following verification documents have been created to track the status of the enhancements:

1. [**VERIFICATION_PLAN.md**](./VERIFICATION_PLAN.md) - Outlines the testing methodology and expected results
2. [**ENHANCEMENT_CHECKLIST.md**](./ENHANCEMENT_CHECKLIST.md) - Provides a detailed breakdown of each enhancement and how to verify it
3. [**ISSUE_FIXES.md**](./ISSUE_FIXES.md) - Describes specific issues and proposed fixes

## Key Findings

During our analysis, we identified several key issues:

1. **Classification Override Issue**
   - HVAC specification documents with multiple tables are being classified as "FORM" instead of "HVAC_SPECIFICATION"
   - This occurs because the generic classification rule in `rule_based.py` classifies any document with more than 3 tables as a "FORM" with a confidence of 0.6
   - This may override the specific HVAC classification rules

2. **Table Detection Limitations**
   - Complex tables in PDF documents may not be detected correctly
   - Current implementation uses two approaches (layout analysis and text-based detection) but both have limitations
   - Enhanced table detection algorithm proposed in [ISSUE_FIXES.md](./ISSUE_FIXES.md)

3. **Content Truncation**
   - Previous implementation limited section content to 100 characters
   - Fix has been implemented by removing the truncation

4. **Schema Storage Limitations**
   - Schema storage did not include actual content samples and table data
   - Enhanced schema storage proposed in [ISSUE_FIXES.md](./ISSUE_FIXES.md)

## Recommended Next Steps

Based on our analysis, we recommend the following next steps:

1. **Execute the Verification Plan**
   - Run the pipeline with default configuration and HVAC configuration
   - List schemas to find schema IDs
   - Verify table extraction enhancements
   - Verify content extraction enhancements
   - Examine output JSON files

2. **Implement the Proposed Fixes**
   - Modify the rule-based classifier to prioritize specific rules over generic types
   - Enhance the table detection algorithm
   - Enhance the schema storage to include content samples and table data

3. **Update Documentation**
   - Update PIPELINE_USAGE.md with examples of using the enhanced configuration system
   - Update SCHEMA_VISUALIZATION.md to reflect new visualization capabilities
   - Create additional example configurations for different document types

4. **Create Automated Tests**
   - Develop automated tests to verify the enhancements
   - Include tests for classification, table detection, and content extraction
   - Add regression tests to ensure fixes don't break existing functionality

## Execution Plan

The following steps should be executed in order:

1. **Verification**
   - Execute the verification plan to confirm current behavior
   - Document any discrepancies between expected and actual behavior

2. **Implementation**
   - Implement the proposed fixes in order of priority:
     1. Classification override fix
     2. Table detection enhancements
     3. Schema storage enhancements

3. **Testing**
   - Test each fix individually to ensure it works as expected
   - Test all fixes together to ensure they work in combination

4. **Documentation**
   - Update documentation to reflect the changes
   - Create examples and tutorials for using the enhanced features

## Conclusion

The document processing pipeline has been significantly enhanced to provide better data extraction, configurable classification, and improved visualization. The verification plan and proposed fixes will ensure that these enhancements work as expected and provide value to users.

By following the recommended next steps and execution plan, we can ensure that the enhancements are properly verified, implemented, and documented, resulting in a robust and reliable document processing pipeline.

================
File: pipeline/ENHANCEMENTS_README.md
================
# Document Processing Pipeline Enhancements

This README provides an overview of the enhancements made to the document processing pipeline and the documentation available for understanding, verifying, and implementing these enhancements.

## Documentation Overview

The following documentation has been created to support the pipeline enhancements:

1. [**ENHANCEMENT_SUMMARY.md**](./ENHANCEMENT_SUMMARY.md) - Comprehensive summary of all enhancements, findings, and next steps
2. [**VERIFICATION_PLAN.md**](./VERIFICATION_PLAN.md) - Detailed testing methodology and expected results
3. [**ENHANCEMENT_CHECKLIST.md**](./ENHANCEMENT_CHECKLIST.md) - Breakdown of each enhancement and verification methods
4. [**ISSUE_FIXES.md**](./ISSUE_FIXES.md) - Specific issues identified and proposed fixes with code examples

## Enhancement Areas

The pipeline enhancements focus on three main areas:

1. **Enhanced Data Extraction**
   - Complete content extraction (no truncation)
   - Improved table detection and structure recognition
   - Table headers and column information extraction
   - Enhanced schema storage with content samples

2. **Configurable Document Classification**
   - Central configuration system for document type rules
   - Rule-based classifier using configuration instead of hardcoded rules
   - Filename pattern matching for improved classification
   - Configuration examples for different document types

3. **Improved Schema Visualization**
   - Table headers and sample data visualization
   - Column count visualization
   - Enhanced command-line interface
   - Comprehensive documentation

## How to Use This Documentation

### For Verification

1. Start with [**VERIFICATION_PLAN.md**](./VERIFICATION_PLAN.md) to understand the testing methodology
2. Use the commands provided to test each enhancement
3. Check off items in [**ENHANCEMENT_CHECKLIST.md**](./ENHANCEMENT_CHECKLIST.md) as they are verified
4. Document any discrepancies or issues found during verification

### For Implementation

1. Review [**ISSUE_FIXES.md**](./ISSUE_FIXES.md) for detailed code changes needed
2. Implement the fixes in order of priority as outlined in [**ENHANCEMENT_SUMMARY.md**](./ENHANCEMENT_SUMMARY.md)
3. Test each fix individually and then together
4. Update documentation as needed

### For Understanding the Enhancements

1. Start with [**ENHANCEMENT_SUMMARY.md**](./ENHANCEMENT_SUMMARY.md) for a high-level overview
2. Dive into specific areas of interest using the other documentation
3. Refer to the existing pipeline documentation for context:
   - [**PIPELINE_USAGE.md**](./PIPELINE_USAGE.md) - General pipeline usage
   - [**SCHEMA_VISUALIZATION.md**](./SCHEMA_VISUALIZATION.md) - Schema visualization tools

## Testing Commands

Here are the key commands for testing the pipeline enhancements:

### Run Pipeline with Default Configuration
```bash
python -m utils.pipeline.run_pipeline --file "utils/pipeline/data/input/MF-SPECS_232500 FL - HVAC WATER TREATMENT.pdf" --output utils/pipeline/data/output
```

### Run Pipeline with HVAC Configuration
```bash
python -m utils.pipeline.run_pipeline --file "utils/pipeline/data/input/MF-SPECS_232500 FL - HVAC WATER TREATMENT.pdf" --output utils/pipeline/data/output --config utils/pipeline/config/hvac_config.json
```

### List Available Schemas
```bash
python -m utils.pipeline.visualize_schema list
```

### Visualize Table Patterns
```bash
python -m utils.pipeline.visualize_schema tables <schema_id>
```

### Visualize Schema Structure
```bash
python -m utils.pipeline.visualize_schema structure <schema_id>
```

## Known Issues and Limitations

The following issues have been identified and are addressed in [**ISSUE_FIXES.md**](./ISSUE_FIXES.md):

1. **Classification Override Issue** - HVAC documents with tables being classified as forms
2. **Table Detection Limitations** - Complex tables may not be detected correctly
3. **Schema Storage Limitations** - Schema storage needs enhancement for content samples and table data

## Next Steps

After verification, the following steps are recommended:

1. Implement the proposed fixes
2. Update documentation to reflect the changes
3. Create automated tests for the enhancements
4. Create additional example configurations for different document types

## Conclusion

These enhancements significantly improve the document processing pipeline's ability to extract, classify, and visualize document data. By following the verification plan and implementing the proposed fixes, the pipeline will provide more accurate and comprehensive document processing capabilities.

================
File: pipeline/examples/batch_processing_example.py
================
"""
Example script demonstrating batch PDF extraction using the FileProcessor.

This example shows how to process multiple PDF files from an input directory
and generate output files in various formats.
"""

import sys
from pathlib import Path

# Add parent directory to path to allow relative imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

from utils.pipeline.core.file_processor import FileProcessor
from utils.pipeline.utils.progress import PipelineProgress


def main():
    """Run batch PDF extraction example."""
    progress = PipelineProgress()

    try:
        # Get the current directory
        current_dir = Path(__file__).parent.parent

        # Set up paths
        input_dir = current_dir / "data" / "input"
        output_dir = current_dir / "data" / "output"

        # Display setup info
        progress.display_success(f"Processing files from {input_dir}")

        # Initialize configuration
        config = {
            "output_format": "json",  # Default format
            "strategies": {
                "pdf": {
                    "analyzer": "utils.pipeline.analyzer.pdf.PDFAnalyzer",
                    "cleaner": "utils.pipeline.cleaner.pdf.PDFCleaner",
                    "extractor": "utils.pipeline.processors.pdf_extractor.PDFExtractor",
                    "validator": "utils.pipeline.processors.pdf_validator.PDFValidator",
                },
            },
            "file_processing": {
                "input": {
                    "patterns": ["*.pdf"],  # Process all PDF files
                    "recursive": False,  # Don't search subdirectories
                },
                "output": {
                    "formats": ["json", "markdown"],  # Generate both formats
                    "directory": str(output_dir),
                    "structure": "flat",  # All files in the same directory
                    "naming": {
                        "template": "{original_name}",  # Use original filename
                    },
                    "overwrite": True,  # Overwrite existing files
                },
                "reporting": {
                    "summary": True,
                    "detailed": True,
                    "format": "json",
                    "save_path": "processing_report.json",
                },
            },
        }

        # Initialize file processor
        processor = FileProcessor(input_dir, output_dir, config)

        # Process all files
        results = processor.process_all_files()

        # Display final summary
        summary = {
            f"{r['file']}": {
                "status": r["status"],
                "outputs": r.get("outputs", []),
            }
            for r in results
        }
        progress.display_summary(summary)

    except Exception as e:
        progress.display_error(f"Error processing files: {e}")
        raise


if __name__ == "__main__":
    main()

================
File: pipeline/examples/config.yaml
================
input_dir: data/tests/pdf
output_dir: data/output
output_format: yaml
log_level: INFO
validation_level: basic
strategies:
  pdf:
    analyzer: utils.pipeline.analyzer.pdf.PDFAnalyzer
    cleaner: utils.pipeline.cleaner.pdf.PDFCleaner
    extractor: utils.pipeline.processors.pdf_extractor.PDFExtractor
    validator: utils.pipeline.processors.pdf_validator.PDFValidator
    formatter: utils.pipeline.processors.pdf_formatter.PDFFormatter
  excel: strategies.excel
  word: strategies.word
  text: strategies.text

================
File: pipeline/examples/document_classification_example.py
================
"""
Example script demonstrating document classification functionality.
"""

from pathlib import Path

from utils.pipeline.pipeline import Pipeline
from utils.pipeline.utils.progress import PipelineProgress


def main():
    """Run document classification example."""
    progress = PipelineProgress()

    try:
        # Get the current directory
        current_dir = Path(__file__).parent.parent

        # Set up paths
        input_dir = current_dir / "data" / "input"
        output_dir = current_dir / "data" / "output"
        output_dir.mkdir(parents=True, exist_ok=True)

        # Display minimal setup info
        progress.display_success(f"Processing files from {input_dir}")

        # Initialize pipeline with configuration
        config = {
            "output_format": "json",  # Default format
            "enable_classification": True,  # Enable document classification
            "record_schemas": True,  # Record schemas for future matching
            "match_schemas": True,  # Match against known schemas
            "classification": {
                "type": "rule_based",  # Use rule-based classifier
                "confidence_threshold": 0.6,  # Minimum confidence threshold
            },
            "strategies": {
                "pdf": {
                    "analyzer": "utils.pipeline.analyzer.pdf.PDFAnalyzer",
                    "cleaner": "utils.pipeline.cleaner.pdf.PDFCleaner",
                    "extractor": "utils.pipeline.processors.pdf_extractor.PDFExtractor",
                    "validator": "utils.pipeline.processors.pdf_validator.PDFValidator",
                },
            },
        }

        pipeline = Pipeline(config)

        # Process all PDF files in the input directory
        for pdf_file in input_dir.glob("*.pdf"):
            progress.display_success(f"Processing {pdf_file.name}")

            # Process the PDF with JSON output
            output_data = pipeline.run(str(pdf_file))

            # Save JSON output
            json_output = output_dir / f"{pdf_file.stem}.json"
            pipeline.save_output(output_data, str(json_output))
            progress.display_success(f"JSON output saved to: {json_output.name}")

            # Process the PDF with Markdown output
            pipeline.config["output_format"] = "markdown"
            output_data = pipeline.run(str(pdf_file))

            # Save Markdown output
            md_output = output_dir / f"{pdf_file.stem}.md"
            pipeline.save_output(output_data, str(md_output))
            progress.display_success(f"Markdown output saved to: {md_output.name}")

            # Display classification results
            if "classification" in output_data:
                classification = output_data["classification"]
                progress.display_success(
                    f"Document classified as: {classification['document_type']} "
                    f"(confidence: {classification['confidence']:.2f})"
                )
                progress.display_success(
                    f"Schema pattern: {classification['schema_pattern']}"
                )
                progress.display_success(
                    f"Key features: {', '.join(classification['key_features'])}"
                )

            # Reset output format for next file
            pipeline.config["output_format"] = "json"

        # Display final summary
        progress.display_success("Processing complete!")
        progress.display_success(
            f"Files Processed: {len(list(input_dir.glob('*.pdf')))}"
        )
        progress.display_success(
            f"Outputs Generated: {len(list(output_dir.glob('*.*')))}"
        )
        progress.display_success("Classification: Enabled")
        progress.display_success("Schema Recording: Enabled")

    except Exception as e:
        progress.display_error(f"Error processing documents: {e}")
        raise


if __name__ == "__main__":
    main()

================
File: pipeline/examples/pdf_extraction_example.py
================
"""
Example script demonstrating PDF extraction pipeline usage.

This example shows how to process a single PDF file using the FileProcessor
for backward compatibility with the original example.
"""

import sys
from pathlib import Path

# Add parent directory to path to allow relative imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

from utils.pipeline.core.file_processor import FileProcessor
from utils.pipeline.utils.progress import PipelineProgress


def main():
    """Run PDF extraction example."""
    progress = PipelineProgress()

    try:
        # Get the current directory
        current_dir = Path(__file__).parent.parent

        # Set up paths
        input_file = (
            current_dir
            / "data"
            / "input"
            / "Quotation 79520-4 - Rocky Vista HS 100%CD (25-03-12).pdf"
        )
        output_dir = current_dir / "data" / "output"
        output_dir.mkdir(parents=True, exist_ok=True)

        # Display minimal setup info
        progress.display_success(f"Processing {input_file.name}")

        # Initialize configuration
        config = {
            "output_format": "json",  # Default format
            "strategies": {
                "pdf": {
                    "analyzer": "utils.pipeline.analyzer.pdf.PDFAnalyzer",
                    "cleaner": "utils.pipeline.cleaner.pdf.PDFCleaner",
                    "extractor": "utils.pipeline.processors.pdf_extractor.PDFExtractor",
                    "validator": "utils.pipeline.processors.pdf_validator.PDFValidator",
                },
            },
            "file_processing": {
                "output": {
                    "formats": ["json", "markdown"],  # Support both formats
                    "naming": {
                        "template": "sample_output",  # Use fixed name for backward compatibility
                    },
                    "overwrite": True,
                },
            },
        }

        # Initialize file processor
        processor = FileProcessor(current_dir, output_dir, config)

        # Process the PDF with JSON output
        progress.display_success("Starting JSON output processing")
        json_data, json_path = processor.process_single_file(input_file, "json")
        progress.display_success(f"JSON output saved to: {Path(json_path).name}")

        # Process the PDF with Markdown output
        progress.display_success("Starting Markdown output processing")
        md_data, md_path = processor.process_single_file(input_file, "markdown")
        progress.display_success(f"Markdown output saved to: {Path(md_path).name}")

        # Display final summary
        progress.display_summary(
            {
                "JSON": {"path": json_path, "status": "Complete"},
                "Markdown": {"path": md_path, "status": "Complete"},
            }
        )

    except Exception as e:
        progress.display_error(f"Error processing PDF: {e}")
        raise


if __name__ == "__main__":
    main()

================
File: pipeline/examples/schema_analysis_example.py
================
"""
Example script demonstrating schema analysis and visualization.
"""

from utils.pipeline.schema.extended_registry import ExtendedSchemaRegistry
from utils.pipeline.utils.progress import PipelineProgress


def main():
    """Run schema analysis example."""
    progress = PipelineProgress()

    try:
        # Initialize extended schema registry
        registry = ExtendedSchemaRegistry()
        schemas = registry.list_schemas()

        if not schemas:
            progress.display_error("No schemas found. Process some documents first.")
            return

        progress.display_success(f"Found {len(schemas)} schemas")

        # Analyze schemas
        progress.display_success("Analyzing schemas...")
        analysis = registry.analyze()

        # Display analysis results
        progress.display_success("\nSchema Analysis Results:")
        progress.display_success(f"Total Schemas: {analysis.get('schema_count', 0)}")

        doc_types = analysis.get("document_types", {})
        if doc_types:
            progress.display_success("\nDocument Types:")
            for doc_type, count in doc_types.items():
                progress.display_success(f"  {doc_type}: {count}")

        # Display common metadata fields
        common_metadata = analysis.get("common_metadata", {})
        if common_metadata:
            progress.display_success("\nCommon Metadata Fields:")
            for field, frequency in sorted(
                common_metadata.items(), key=lambda x: x[1], reverse=True
            ):
                progress.display_success(f"  {field}: {frequency:.2f}")

        # Display table patterns
        table_patterns = analysis.get("table_patterns", {})
        if table_patterns:
            progress.display_success("\nTable Patterns:")
            progress.display_success(
                f"  Schemas with tables: {table_patterns.get('schemas_with_tables', 0)}"
            )
            progress.display_success(
                f"  Average tables per schema: {table_patterns.get('avg_tables_per_schema', 0):.2f}"
            )
            progress.display_success(
                f"  Average rows per table: {table_patterns.get('avg_rows_per_table', 0):.2f}"
            )

        # Generate visualizations if there are multiple schemas
        if len(schemas) >= 2:
            progress.display_success("\nGenerating visualizations...")

            # Create visualizations directory
            import os

            viz_dir = os.path.join(
                "utils", "pipeline", "schema", "data", "visualizations"
            )
            os.makedirs(viz_dir, exist_ok=True)

            # Generate cluster visualization
            try:
                cluster_viz = registry.visualize("clusters", output_dir=viz_dir)
                progress.display_success(
                    f"Cluster visualization saved to: {cluster_viz}"
                )
            except Exception as e:
                progress.display_error(
                    f"Error generating cluster visualization: {str(e)}"
                )

            # Generate feature visualization
            try:
                feature_viz = registry.visualize("features", output_dir=viz_dir)
                progress.display_success(
                    f"Feature visualization saved to: {feature_viz}"
                )
            except Exception as e:
                progress.display_error(
                    f"Error generating feature visualization: {str(e)}"
                )

            # Compare first two schemas
            schema_id1 = schemas[0]["id"]
            schema_id2 = schemas[1]["id"]

            progress.display_success(
                f"\nComparing schemas: {schema_id1} vs {schema_id2}"
            )
            comparison = registry.compare(schema_id1, schema_id2)

            progress.display_success(
                f"Overall Similarity: {comparison.get('overall_similarity', 0):.2f}"
            )
            progress.display_success(
                f"Same Document Type: {comparison.get('same_document_type', False)}"
            )

            # Generate structure visualizations
            try:
                structure_viz = registry.visualize(
                    "structure", [schema_id1, schema_id2], viz_dir
                )
                progress.display_success(
                    f"Structure visualizations saved to: {structure_viz}"
                )
            except Exception as e:
                progress.display_error(
                    f"Error generating structure visualization: {str(e)}"
                )

        progress.display_success("\nSchema analysis complete!")

    except Exception as e:
        progress.display_error(f"Error analyzing schemas: {str(e)}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    main()

================
File: pipeline/IMPLEMENTATION_PLAN.md
================
# Document Processing Pipeline Implementation Plan

This document outlines the specific steps to implement the fixes and enhancements identified in the document processing pipeline.

## Priority 1: Classification Override Fix (✅ COMPLETED)

### Step 1: Modify Rule-Based Classifier (✅ COMPLETED)
**File**: `utils/pipeline/processors/classifiers/rule_based.py`
**Change**: Update the `classify` method to prioritize specific document types over generic types

The `classify` method has been modified to only fall back to generic classification if the confidence of the best match is very low (less than 0.2). This ensures that specific document types with reasonable confidence are always preferred over generic types.

### Step 2: Test Classification Fix (✅ COMPLETED)
A test script has been created to verify the fix: `utils/pipeline/tests/test_classification_fix.py`

The test script:
1. Creates a test document with HVAC content and multiple tables
2. Classifies the document using the RuleBasedClassifier with HVAC configuration
3. Verifies that the document is correctly classified as "HVAC_SPECIFICATION" instead of "FORM"
4. Simulates the behavior before the fix by directly calling the `_classify_generic` method

To run the test:
```bash
python -m utils.pipeline.tests.test_classification_fix
```

### Step 3: Document the Fix (✅ COMPLETED)
A documentation file has been created to explain the fix: `utils/pipeline/docs/CLASSIFICATION_FIX.md`

The documentation includes:
1. Problem description
2. Root cause analysis
3. Fix implementation
4. Verification steps
5. Additional notes and alternative approaches considered

## Priority 2: Table Detection Enhancements

### Step 1: Add Helper Methods for Table Detection
**File**: `utils/pipeline/processors/pdf_extractor.py`
**Change**: Add new helper methods for improved table detection

```python
def _is_likely_table(self, block):
    """
    Determine if a block is likely to be a table based on structure.
    """
    if "lines" not in block or len(block["lines"]) < 3:
        return False
    
    # Check for consistent number of spans across lines
    span_counts = [len(line.get("spans", [])) for line in block["lines"]]
    if len(set(span_counts)) <= 1:  # All lines have same number of spans
        return False  # Probably just regular text
    
    # Check for alignment patterns
    x_positions = []
    for line in block["lines"]:
        for span in line.get("spans", []):
            x_positions.append(span["origin"][0])
    
    # Count unique x-positions (potential column starts)
    unique_x = set(round(x, 1) for x in x_positions)
    if len(unique_x) >= 3:  # At least 3 distinct column positions
        return True
    
    return False

def _extract_table_data(self, block):
    """
    Extract structured data from a table block.
    """
    table_data = []
    headers = []
    
    # Identify potential column positions
    x_positions = []
    for line in block["lines"]:
        for span in line.get("spans", []):
            x_positions.append(span["origin"][0])
    
    # Group x-positions to identify column boundaries
    x_clusters = self._cluster_positions(x_positions)
    
    # Process rows
    for row_idx, line in enumerate(block["lines"]):
        if "spans" not in line:
            continue
        
        # Map spans to columns based on x-position
        row_data = [""] * len(x_clusters)
        for span in line["spans"]:
            col_idx = self._get_column_index(span["origin"][0], x_clusters)
            if col_idx >= 0:
                row_data[col_idx] += span["text"] + " "
        
        # Clean up row data
        row_data = [cell.strip() for cell in row_data]
        
        # First row might be headers
        if row_idx == 0 and any(cell.isupper() for cell in row_data if cell):
            headers = row_data
        else:
            # Only add non-empty rows
            if any(cell for cell in row_data):
                table_data.append(row_data)
    
    # Determine column count
    column_count = len(headers) if headers else (max(len(row) for row in table_data) if table_data else 0)
    
    return table_data, headers, column_count

def _cluster_positions(self, positions, threshold=10):
    """
    Cluster x-positions to identify column boundaries.
    """
    if not positions:
        return []
    
    # Sort positions
    sorted_pos = sorted(positions)
    
    # Initialize clusters
    clusters = [[sorted_pos[0]]]
    
    # Cluster positions
    for pos in sorted_pos[1:]:
        if pos - clusters[-1][-1] <= threshold:
            # Add to existing cluster
            clusters[-1].append(pos)
        else:
            # Start new cluster
            clusters.append([pos])
    
    # Get average position for each cluster
    return [sum(cluster) / len(cluster) for cluster in clusters]

def _get_column_index(self, x_position, column_positions):
    """
    Determine which column a span belongs to based on its x-position.
    """
    for i, pos in enumerate(column_positions):
        if abs(x_position - pos) <= 20:  # Threshold for matching
            return i
    return -1
```

### Step 2: Update Extract Tables Method
**File**: `utils/pipeline/processors/pdf_extractor.py`
**Change**: Update the `_extract_tables` method to use the new helper methods

```python
def _extract_tables(self, doc) -> List[Dict[str, Any]]:
    """
    Extract tables from the PDF document with improved structure detection.
    """
    tables = []
    
    try:
        # Use PyMuPDF's improved table detection
        for page_num, page in enumerate(doc):
            # First try to detect tables using layout analysis
            try:
                # Get blocks that might be tables
                blocks = page.get_text("dict")["blocks"]
                
                # Identify potential table blocks based on multiple criteria
                for block in blocks:
                    # Check if block has multiple lines (potential table)
                    if "lines" in block and len(block["lines"]) > 2:
                        # Additional checks for table-like structure
                        is_table = self._is_likely_table(block)
                        
                        if is_table:
                            table_data, headers, column_count = self._extract_table_data(block)
                            
                            # Only add if we have actual data
                            if table_data:
                                # Add table with structure
                                tables.append({
                                    "page": page_num + 1,
                                    "table_number": len(tables) + 1,
                                    "headers": headers,
                                    "data": table_data,
                                    "column_count": column_count,
                                    "row_count": len(table_data),
                                    "detection_method": "layout_analysis",
                                })
            except Exception as layout_error:
                self.logger.warning(f"Layout analysis failed: {str(layout_error)}")
            
            # Fallback to text-based table detection
            if not any(table["page"] == page_num + 1 for table in tables):
                text = page.get_text("text")
                
                # Look for common table indicators
                if any(pattern in text for pattern in ["TABLE", "Table", "|", "+"]):
                    # Try to detect table structure from text
                    lines = text.split("\n")
                    table_start = -1
                    table_end = -1
                    
                    # Find table boundaries
                    for i, line in enumerate(lines):
                        if "TABLE" in line.upper() and table_start == -1:
                            table_start = i
                        elif table_start != -1 and not line.strip():
                            # Empty line might indicate end of table
                            if i > table_start + 2:  # At least 2 rows
                                table_end = i
                                break
                    
                    # If we found a table
                    if table_start != -1 and table_end != -1:
                        table_lines = lines[table_start:table_end]
                        
                        # Try to detect headers and data
                        headers = []
                        data = []
                        
                        # First non-empty line after title might be headers
                        for i, line in enumerate(table_lines):
                            if i > 0 and line.strip():  # Skip title
                                # Split by common delimiters
                                cells = re.split(r"\s{2,}|\t|\|", line)
                                cells = [cell.strip() for cell in cells if cell.strip()]
                                
                                if not headers and any(cell.isupper() for cell in cells):
                                    headers = cells
                                else:
                                    data.append(cells)
                        
                        # Add table with structure
                        if data:  # Only add if we have data
                            tables.append({
                                "page": page_num + 1,
                                "table_number": len(tables) + 1,
                                "headers": headers,
                                "data": data,
                                "column_count": len(headers) if headers else (max(len(row) for row in data) if data else 0),
                                "row_count": len(data),
                                "detection_method": "text_analysis",
                            })
    except Exception as e:
        self.logger.warning(f"Error during table extraction: {str(e)}")
    
    return tables
```

### Step 3: Test Table Detection Enhancements
1. Run pipeline on a document with complex tables
2. Verify that tables are correctly detected and structured
3. Check for headers and column information in the output
4. Visualize tables using `visualize_schema tables <schema_id>`

## Priority 3: Schema Storage Enhancements

### Step 1: Update Record Method in Schema Registry
**File**: `utils/pipeline/schema/registry.py`
**Change**: Update the `record` method to store content samples and table data

```python
def record(self, document_data: Dict[str, Any], document_type: str, document_name: Optional[str] = None) -> str:
    """
    Record a document schema in the registry.
    
    Args:
        document_data: Document data to record
        document_type: Type of the document
        document_name: Optional name of the document
        
    Returns:
        Schema ID
    """
    # Generate schema ID
    schema_id = f"{document_type.lower()}_{int(time.time())}"
    
    # Extract metadata
    metadata = document_data.get("metadata", {})
    
    # Extract content samples (up to 5 sections)
    content_samples = []
    for section in document_data.get("content", [])[:5]:
        # Store title and a sample of the content
        content_sample = {
            "title": section.get("title", ""),
            "content_sample": section.get("content", "")[:200] + "..." if len(section.get("content", "")) > 200 else section.get("content", ""),
            "content_length": len(section.get("content", "")),
        }
        content_samples.append(content_sample)
    
    # Extract table data (up to 3 tables)
    table_samples = []
    for table in document_data.get("tables", [])[:3]:
        # Store table structure and sample data
        table_sample = {
            "headers": table.get("headers", []),
            "column_count": table.get("column_count", 0),
            "row_count": table.get("row_count", 0),
            "data_sample": table.get("data", [])[:3],  # First 3 rows
        }
        table_samples.append(table_sample)
    
    # Create schema record
    schema = {
        "id": schema_id,
        "document_type": document_type,
        "document_name": document_name,
        "recorded_at": datetime.now().isoformat(),
        "metadata": metadata,
        "content_samples": content_samples,
        "table_samples": table_samples,
        "section_count": len(document_data.get("content", [])),
        "table_count": len(document_data.get("tables", [])),
    }
    
    # Save schema to registry
    self._save_schema(schema_id, schema)
    
    return schema_id
```

### Step 2: Test Schema Storage Enhancements
1. Run pipeline on a document
2. Check schema registry for content samples and table data
3. Verify that schema includes accurate counts of sections and tables
4. Use visualization tools to confirm data is accessible

## Priority 4: Documentation Updates

### Step 1: Update PIPELINE_USAGE.md
**File**: `utils/pipeline/PIPELINE_USAGE.md`
**Change**: Add examples of using the enhanced configuration system

### Step 2: Update SCHEMA_VISUALIZATION.md
**File**: `utils/pipeline/SCHEMA_VISUALIZATION.md`
**Change**: Update to reflect new visualization capabilities for tables and content

### Step 3: Create Additional Example Configurations
**File**: `utils/pipeline/config/electrical_config.json`
**Change**: Create a new example configuration for electrical specifications

## Testing and Verification

After implementing each fix, follow these verification steps:

1. **Classification Fix Verification**
   - Run pipeline with default configuration and HVAC configuration
   - Compare classification results
   - Verify that HVAC documents with tables are correctly classified

2. **Table Detection Verification**
   - Run pipeline on documents with various table structures
   - Visualize table patterns
   - Check for headers, column counts, and data samples

3. **Schema Storage Verification**
   - Check schema registry for content samples and table data
   - Verify that schema includes accurate counts of sections and tables
   - Use visualization tools to confirm data is accessible

4. **Documentation Verification**
   - Review updated documentation for accuracy and completeness
   - Test examples to ensure they work as described
   - Verify that configuration examples produce expected results

## Implementation Timeline

1. **Day 1**: Implement and test Classification Override Fix
2. **Day 2**: Implement and test Table Detection Enhancements
3. **Day 3**: Implement and test Schema Storage Enhancements
4. **Day 4**: Update documentation and create additional example configurations
5. **Day 5**: Final testing and verification of all enhancements

## Conclusion

This implementation plan provides a clear roadmap for implementing the fixes and enhancements identified in the document processing pipeline. By following this plan, the pipeline will be enhanced to provide more accurate classification, better table detection, and improved schema storage.

================
File: pipeline/ISSUE_FIXES.md
================
# Document Processing Pipeline Issue Fixes

This document outlines specific issues identified in the document processing pipeline and proposes detailed fixes for each one.

## 1. Classification Override Issue

### Problem Description
HVAC specification documents with multiple tables are being classified as "FORM" instead of "HVAC_SPECIFICATION". This occurs because the generic classification rule in `rule_based.py` classifies any document with more than 3 tables as a "FORM" with a confidence of 0.6, which may override the specific HVAC classification rules.

### Code Analysis
In `utils/pipeline/processors/classifiers/rule_based.py`, the `_classify_generic` method is called when no specific document type matches with sufficient confidence. This method contains the following logic:

```python
def _classify_generic(self, document_data: Dict[str, Any], features: Dict[str, Any]) -> Dict[str, Any]:
    """
    Classify document into generic categories when specific types don't match.
    """
    # Check if it's a form
    if features.get("table_count", 0) > 3:
        return {
            "document_type": "FORM",
            "confidence": 0.6,
            "schema_pattern": "tabular_form",
            "key_features": ["multiple_tables", "structured_layout"],
        }
    
    # Other generic classifications...
```

### Proposed Fixes

#### Option 1: Modify Rule-Based Classifier to Prioritize Specific Rules

```python
def classify(self, document_data: Dict[str, Any], features: Dict[str, Any]) -> Dict[str, Any]:
    """
    Classify the document using rule-based approach.
    """
    # Check filename patterns if path is available
    if "path" in document_data:
        filename = os.path.basename(document_data["path"])
        for doc_type, pattern in self.filename_patterns.items():
            if re.search(pattern, filename):
                self.logger.info(f"Matched filename pattern for {doc_type}: {filename}")
                return {
                    "document_type": doc_type,
                    "confidence": 0.8,  # High confidence for filename match
                    "schema_pattern": self.rules_config.get(doc_type, {}).get("schema_pattern", "standard"),
                    "key_features": ["filename_match"],
                }

    # Apply configured rules
    best_match = self._get_best_match(document_data, features)
    
    # Only use generic classification if confidence is very low
    if best_match[0] == "UNKNOWN" or best_match[1] < 0.2:  # Lower threshold for falling back to generic
        # If no specific type matched, try to determine a generic type
        return self._classify_generic(document_data, features)

    return {
        "document_type": best_match[0],
        "confidence": best_match[1],
        "schema_pattern": best_match[2],
        "key_features": best_match[3],
    }
```

#### Option 2: Increase Confidence Threshold for HVAC Documents in Configuration

In `utils/pipeline/config/hvac_config.json`, increase the confidence threshold for HVAC documents:

```json
"HVAC_SPECIFICATION": {
  "title_keywords": [
    "hvac",
    "heating",
    "ventilation",
    "air conditioning",
    "mechanical",
    "air handling",
    "ductwork",
    "refrigeration",
    "cooling",
    "thermal"
  ],
  "content_keywords": [
    "temperature",
    "humidity",
    "airflow",
    "ductwork",
    "refrigerant",
    "cooling",
    "heating",
    "ventilation",
    "air handling unit",
    "ahu",
    "vav",
    "chiller",
    "boiler",
    "condenser",
    "evaporator",
    "thermostat",
    "diffuser",
    "damper",
    "plenum",
    "insulation",
    "filter",
    "air quality",
    "ashrae"
  ],
  "patterns": [
    "°f",
    "°c",
    "cfm",
    "btu",
    "btuh",
    "ton",
    "kw",
    "hp",
    "psi",
    "inWC",
    "inH2O",
    "fpm",
    "rpm",
    "db",
    "wb",
    "rh%",
    "merv"
  ],
  "weights": {
    "title_match": 0.4,
    "content_match": 0.4,
    "pattern_match": 0.2
  },
  "threshold": 0.3,  // Change to 0.7 to ensure it overrides the generic FORM classification
  "schema_pattern": "hvac_specification"
}
```

#### Option 3: Add Special Case for HVAC Documents with Tables

Add a special case in the `_classify_generic` method to check for HVAC-specific features even when there are multiple tables:

```python
def _classify_generic(self, document_data: Dict[str, Any], features: Dict[str, Any]) -> Dict[str, Any]:
    """
    Classify document into generic categories when specific types don't match.
    """
    # Check for HVAC documents with tables
    content = " ".join([section.get("content", "") for section in document_data.get("content", [])])
    hvac_keywords = ["hvac", "heating", "ventilation", "air conditioning", "temperature", "humidity", "airflow"]
    hvac_keyword_count = sum(1 for keyword in hvac_keywords if keyword.lower() in content.lower())
    
    if hvac_keyword_count >= 3 and features.get("table_count", 0) > 3:
        return {
            "document_type": "HVAC_SPECIFICATION",
            "confidence": 0.65,  # Slightly higher than FORM confidence
            "schema_pattern": "hvac_specification",
            "key_features": ["hvac_keywords", "multiple_tables"],
        }
    
    # Check if it's a form
    if features.get("table_count", 0) > 3:
        return {
            "document_type": "FORM",
            "confidence": 0.6,
            "schema_pattern": "tabular_form",
            "key_features": ["multiple_tables", "structured_layout"],
        }
    
    # Other generic classifications...
```

### Recommended Approach

Option 1 is the most robust solution as it addresses the fundamental issue of prioritization in the classification logic. It ensures that specific document types with reasonable confidence are always preferred over generic types, regardless of the number of tables or other generic features.

## 2. Table Detection Limitations

### Problem Description
Complex tables in PDF documents may not be detected correctly, leading to incomplete or incorrect table structure information.

### Code Analysis
In `utils/pipeline/processors/pdf_extractor.py`, the `_extract_tables` method uses two approaches for table detection:
1. Layout analysis using PyMuPDF's block structure
2. Text-based table detection as a fallback

Both approaches have limitations with complex tables, especially those with merged cells, irregular structures, or tables that span multiple pages.

### Proposed Fix
Enhance the table detection algorithm with a more sophisticated approach that combines layout analysis with text pattern recognition:

```python
def _extract_tables(self, doc) -> List[Dict[str, Any]]:
    """
    Extract tables from the PDF document with improved structure detection.
    """
    tables = []
    
    try:
        # Use PyMuPDF's improved table detection
        for page_num, page in enumerate(doc):
            # First try to detect tables using layout analysis
            try:
                # Get blocks that might be tables
                blocks = page.get_text("dict")["blocks"]
                
                # Identify potential table blocks based on multiple criteria
                for block in blocks:
                    # Check if block has multiple lines (potential table)
                    if "lines" in block and len(block["lines"]) > 2:
                        # Additional checks for table-like structure
                        is_table = self._is_likely_table(block)
                        
                        if is_table:
                            table_data, headers, column_count = self._extract_table_data(block)
                            
                            # Only add if we have actual data
                            if table_data:
                                # Add table with structure
                                tables.append({
                                    "page": page_num + 1,
                                    "table_number": len(tables) + 1,
                                    "headers": headers,
                                    "data": table_data,
                                    "column_count": column_count,
                                    "row_count": len(table_data),
                                    "detection_method": "layout_analysis",
                                })
            except Exception as layout_error:
                self.logger.warning(f"Layout analysis failed: {str(layout_error)}")
            
            # Try advanced text-based table detection if no tables found
            if not any(table["page"] == page_num + 1 for table in tables):
                text_tables = self._detect_tables_from_text(page)
                tables.extend(text_tables)
                
    except Exception as e:
        self.logger.warning(f"Error during table extraction: {str(e)}")
    
    return tables

def _is_likely_table(self, block):
    """
    Determine if a block is likely to be a table based on structure.
    """
    if "lines" not in block or len(block["lines"]) < 3:
        return False
    
    # Check for consistent number of spans across lines
    span_counts = [len(line.get("spans", [])) for line in block["lines"]]
    if len(set(span_counts)) <= 1:  # All lines have same number of spans
        return False  # Probably just regular text
    
    # Check for alignment patterns
    x_positions = []
    for line in block["lines"]:
        for span in line.get("spans", []):
            x_positions.append(span["origin"][0])
    
    # Count unique x-positions (potential column starts)
    unique_x = set(round(x, 1) for x in x_positions)
    if len(unique_x) >= 3:  # At least 3 distinct column positions
        return True
    
    return False

def _extract_table_data(self, block):
    """
    Extract structured data from a table block.
    """
    table_data = []
    headers = []
    
    # Identify potential column positions
    x_positions = []
    for line in block["lines"]:
        for span in line.get("spans", []):
            x_positions.append(span["origin"][0])
    
    # Group x-positions to identify column boundaries
    x_clusters = self._cluster_positions(x_positions)
    
    # Process rows
    for row_idx, line in enumerate(block["lines"]):
        if "spans" not in line:
            continue
        
        # Map spans to columns based on x-position
        row_data = [""] * len(x_clusters)
        for span in line["spans"]:
            col_idx = self._get_column_index(span["origin"][0], x_clusters)
            if col_idx >= 0:
                row_data[col_idx] += span["text"] + " "
        
        # Clean up row data
        row_data = [cell.strip() for cell in row_data]
        
        # First row might be headers
        if row_idx == 0 and any(cell.isupper() for cell in row_data if cell):
            headers = row_data
        else:
            # Only add non-empty rows
            if any(cell for cell in row_data):
                table_data.append(row_data)
    
    # Determine column count
    column_count = len(headers) if headers else (max(len(row) for row in table_data) if table_data else 0)
    
    return table_data, headers, column_count

def _cluster_positions(self, positions, threshold=10):
    """
    Cluster x-positions to identify column boundaries.
    """
    if not positions:
        return []
    
    # Sort positions
    sorted_pos = sorted(positions)
    
    # Initialize clusters
    clusters = [[sorted_pos[0]]]
    
    # Cluster positions
    for pos in sorted_pos[1:]:
        if pos - clusters[-1][-1] <= threshold:
            # Add to existing cluster
            clusters[-1].append(pos)
        else:
            # Start new cluster
            clusters.append([pos])
    
    # Get average position for each cluster
    return [sum(cluster) / len(cluster) for cluster in clusters]

def _get_column_index(self, x_position, column_positions):
    """
    Determine which column a span belongs to based on its x-position.
    """
    for i, pos in enumerate(column_positions):
        if abs(x_position - pos) <= 20:  # Threshold for matching
            return i
    return -1

def _detect_tables_from_text(self, page):
    """
    Detect tables using text patterns.
    """
    tables = []
    text = page.get_text("text")
    
    # Look for common table indicators
    if any(pattern in text for pattern in ["TABLE", "Table", "|", "+"]):
        # Implementation of advanced text-based table detection
        # ...
    
    return tables
```

This enhanced implementation would:
1. Use more sophisticated criteria to identify tables
2. Better handle column alignment and structure
3. Cluster x-positions to identify column boundaries
4. Provide more accurate header detection

## 3. Content Truncation Fix

### Problem Description
Previous implementation limited section content to 100 characters, resulting in truncated content in the output.

### Code Analysis
In `utils/pipeline/processors/pdf_extractor.py`, the `_extract_sections` method was truncating content:

```python
# Add to current section content WITH truncation
current_section["content"] += line[:100] + "\n"
```

### Fix Implementation
The fix has already been implemented by removing the truncation:

```python
# Add to current section content WITHOUT truncation
current_section["content"] += line + "\n"
```

This change ensures that the full content of each section is captured in the output.

## 4. Schema Storage Enhancement

### Problem Description
The schema storage did not include actual content samples and table data, limiting the usefulness of the schema for analysis and visualization.

### Code Analysis
In `utils/pipeline/schema/registry.py`, the `record` method was not storing content samples and table data.

### Proposed Fix
Enhance the `record` method to store content samples and table data:

```python
def record(self, document_data: Dict[str, Any], document_type: str, document_name: Optional[str] = None) -> str:
    """
    Record a document schema in the registry.
    
    Args:
        document_data: Document data to record
        document_type: Type of the document
        document_name: Optional name of the document
        
    Returns:
        Schema ID
    """
    # Generate schema ID
    schema_id = f"{document_type.lower()}_{int(time.time())}"
    
    # Extract metadata
    metadata = document_data.get("metadata", {})
    
    # Extract content samples (up to 5 sections)
    content_samples = []
    for section in document_data.get("content", [])[:5]:
        # Store title and a sample of the content
        content_sample = {
            "title": section.get("title", ""),
            "content_sample": section.get("content", "")[:200] + "..." if len(section.get("content", "")) > 200 else section.get("content", ""),
            "content_length": len(section.get("content", "")),
        }
        content_samples.append(content_sample)
    
    # Extract table data (up to 3 tables)
    table_samples = []
    for table in document_data.get("tables", [])[:3]:
        # Store table structure and sample data
        table_sample = {
            "headers": table.get("headers", []),
            "column_count": table.get("column_count", 0),
            "row_count": table.get("row_count", 0),
            "data_sample": table.get("data", [])[:3],  # First 3 rows
        }
        table_samples.append(table_sample)
    
    # Create schema record
    schema = {
        "id": schema_id,
        "document_type": document_type,
        "document_name": document_name,
        "recorded_at": datetime.now().isoformat(),
        "metadata": metadata,
        "content_samples": content_samples,
        "table_samples": table_samples,
        "section_count": len(document_data.get("content", [])),
        "table_count": len(document_data.get("tables", [])),
    }
    
    # Save schema to registry
    self._save_schema(schema_id, schema)
    
    return schema_id
```

This enhancement ensures that the schema includes:
1. Content samples from the document
2. Table structure information including headers
3. Sample table data for visualization
4. Accurate counts of sections and tables

These enhancements will make the schema more useful for analysis and visualization, and will support the improved visualization tools.

================
File: pipeline/models/models.py
================
from typing import Any, Dict, Optional


class PipelineData:
    """Base data model for pipeline data."""

    def __init__(self, data: Optional[Dict[str, Any]] = None):
        """
        Initialize pipeline data.

        Args:
            data: Optional dictionary of data. If None, an empty dict is used.
        """
        self.data = data.copy() if data is not None else {}

================
File: pipeline/PIPELINE_USAGE.md
================
# Pipeline Usage Guide

This document provides instructions for using the document processing pipeline.

## Overview

The pipeline processes documents through several stages:
1. **Analysis**: Extract raw content and metadata from documents
2. **Cleaning**: Clean and normalize the extracted content
3. **Extraction**: Extract structured data from the cleaned content
4. **Classification**: Classify the document based on its content
5. **Schema Recording**: Record the document schema for future reference

## Installation

### Prerequisites

- Python 3.8 or higher
- Required packages:
  ```bash
  pip install -r requirements.txt
  ```

### Optional Dependencies

For PDF processing:
```bash
pip install pymupdf
```

For Excel processing:
```bash
pip install openpyxl
```

For Word processing:
```bash
pip install python-docx
```

## Basic Usage

### Command-Line Interface

Process a single file:
```bash
python -m utils.pipeline.run_pipeline --file path/to/document.pdf --output path/to/output
```

Process all files in a directory:
```bash
python -m utils.pipeline.run_pipeline --input path/to/input_dir --output path/to/output_dir
```

### Output Formats

Specify output formats:
```bash
python -m utils.pipeline.run_pipeline --input path/to/input_dir --output path/to/output_dir --formats json,markdown
```

### Recursive Processing

Process files in subdirectories:
```bash
python -m utils.pipeline.run_pipeline --input path/to/input_dir --output path/to/output_dir --recursive
```

### File Patterns

Process only specific file types:
```bash
python -m utils.pipeline.run_pipeline --input path/to/input_dir --output path/to/output_dir --pattern "*.pdf"
```

## Configuration

### Configuration File

Create a YAML configuration file:

```yaml
# pipeline_config.yaml
input_dir: "data/input"
output_dir: "data/output"
output_format: "json"
log_level: "INFO"
validation_level: "basic"

strategies:
  pdf:
    analyzer: "utils.pipeline.analyzer.pdf.PDFAnalyzer"
    cleaner: "utils.pipeline.cleaner.pdf.PDFCleaner"
    extractor: "utils.pipeline.processors.pdf_extractor.PDFExtractor"
    validator: "utils.pipeline.processors.pdf_validator.PDFValidator"

classification:
  enabled: true
  method: "rule_based"
  default_threshold: 0.3
  
  # Document type rules
  rules:
    SPECIFICATION:
      title_keywords: ["specification", "spec", "technical", "requirements"]
      content_keywords: ["dimensions", "capacity", "performance", "material", "compliance", "standard"]
      patterns: ["mm", "cm", "m", "kg", "lb", "°c", "°f", "hz", "mhz", "ghz", "kw", "hp"]
      weights:
        title_match: 0.4
        content_match: 0.3
        pattern_match: 0.3
      threshold: 0.4
      schema_pattern: "detailed_specification"
    
    INVOICE:
      title_keywords: ["invoice", "bill", "receipt"]
      content_keywords: ["invoice #", "invoice no", "payment", "due date"]
      patterns: ["\\$\\d+\\.\\d{2}", "total", "subtotal"]
      threshold: 0.5
      schema_pattern: "detailed_invoice"
  
  # Filename pattern matching
  filename_patterns:
    SPECIFICATION: "(?i)spec|specification"
    INVOICE: "(?i)invoice|bill"
```

Use the configuration file:
```bash
python -m utils.pipeline.run_pipeline --input path/to/input_dir --output path/to/output_dir --config pipeline_config.yaml
```

### Environment Variables

You can also configure the pipeline using environment variables:

```bash
export PIPELINE_LOG_LEVEL=DEBUG
export PIPELINE_OUTPUT_FORMAT=json
python -m utils.pipeline.run_pipeline --input path/to/input_dir --output path/to/output_dir
```

## Document Classification

The pipeline includes a document classification system that categorizes documents based on their content and structure. This classification is used to organize schemas and can be customized through configuration.

### Classification Configuration

The classification system can be configured in the pipeline configuration file:

```yaml
classification:
  # Enable/disable classification
  enabled: true
  
  # Default confidence threshold
  default_threshold: 0.3
  
  # Classification method (rule_based, pattern_matcher, etc.)
  method: "rule_based"
  
  # Document type rules
  rules:
    SPECIFICATION:
      # Keywords to look for in section titles
      title_keywords: ["specification", "spec", "technical", "requirements"]
      
      # Keywords to look for in document content
      content_keywords: ["dimensions", "capacity", "performance", "material", "compliance", "standard"]
      
      # Patterns to match (e.g., measurements)
      patterns: ["mm", "cm", "m", "kg", "lb", "°c", "°f", "hz", "mhz", "ghz", "kw", "hp"]
      
      # Confidence weights for different features
      weights:
        title_match: 0.4
        content_match: 0.3
        pattern_match: 0.3
      
      # Minimum confidence threshold to classify as this type
      threshold: 0.4
      
      # Schema pattern to use for this document type
      schema_pattern: "detailed_specification"
  
  # Filename pattern matching (optional)
  filename_patterns:
    SPECIFICATION: "(?i)spec|specification"
    INVOICE: "(?i)invoice|bill"
```

### Adding Custom Document Types

You can add custom document types by defining rules for them in the configuration:

```yaml
classification:
  rules:
    HVAC_SPECIFICATION:
      title_keywords: ["hvac", "heating", "ventilation", "air conditioning"]
      content_keywords: ["temperature", "humidity", "airflow", "ductwork", "refrigerant"]
      patterns: ["°f", "°c", "cfm", "btu"]
      threshold: 0.4
      schema_pattern: "hvac_specification"
```

### Filename Pattern Matching

The classification system can also use filename patterns to help classify documents:

```yaml
classification:
  filename_patterns:
    HVAC_SPECIFICATION: "(?i)hvac|heating|ventilation"
    ELECTRICAL_SPECIFICATION: "(?i)electrical|wiring|circuit"
```

## Schema Management

### Analyzing Schemas

Analyze existing schemas:
```bash
python -m utils.pipeline.run_pipeline --analyze-schemas
```

Filter by document type:
```bash
python -m utils.pipeline.run_pipeline --analyze-schemas --document-type SPECIFICATION
```

### Comparing Schemas

Compare two schemas:
```bash
python -m utils.pipeline.run_pipeline --compare-schemas schema1_id schema2_id
```

### Visualizing Schemas

Visualize schemas:
```bash
python -m utils.pipeline.run_pipeline --visualize-schemas clusters
```

For more detailed information on schema visualization, see [SCHEMA_VISUALIZATION.md](SCHEMA_VISUALIZATION.md).

## Programmatic Usage

You can also use the pipeline programmatically:

```python
from utils.pipeline.pipeline import Pipeline

# Initialize pipeline
pipeline = Pipeline()

# Process a document
output_data = pipeline.run("path/to/document.pdf")

# Save output
pipeline.save_output(output_data, "path/to/output.json")
```

## Customization

### Custom Analyzers

Create a custom analyzer:

```python
from utils.pipeline.analyzer.base import BaseAnalyzer

class CustomAnalyzer(BaseAnalyzer):
    def analyze(self, input_path):
        # Custom analysis logic
        return {
            "metadata": {...},
            "content": [...],
            "path": input_path
        }
```

### Custom Cleaners

Create a custom cleaner:

```python
from utils.pipeline.cleaner.base import BaseCleaner

class CustomCleaner(BaseCleaner):
    def clean(self, data):
        # Custom cleaning logic
        return {
            "metadata": data["metadata"],
            "content": [...],  # Cleaned content
            "path": data["path"]
        }
```

### Custom Extractors

Create a custom extractor:

```python
from utils.pipeline.processors.base import BaseExtractor

class CustomExtractor(BaseExtractor):
    def extract(self, cleaned_data):
        # Custom extraction logic
        return {
            "metadata": cleaned_data["metadata"],
            "sections": [...],
            "tables": [...],
            "path": cleaned_data["path"]
        }
```

## Troubleshooting

### Common Issues

1. **File not found**: Ensure the input file or directory exists
2. **Permission denied**: Check file permissions
3. **Unsupported file type**: Ensure the file type is supported
4. **Missing dependencies**: Install required packages

### Debugging

Enable debug logging:
```bash
export PIPELINE_LOG_LEVEL=DEBUG
python -m utils.pipeline.run_pipeline --file path/to/document.pdf --output path/to/output
```

## Advanced Features

### Batch Processing

Process files in batches:
```bash
python -m utils.pipeline.run_pipeline --input path/to/input_dir --output path/to/output_dir --batch-size 10
```

### Error Handling

Continue processing on error:
```bash
python -m utils.pipeline.run_pipeline --input path/to/input_dir --output path/to/output_dir --continue-on-error
```

### Reporting

Generate a processing report:
```bash
python -m utils.pipeline.run_pipeline --input path/to/input_dir --output path/to/output_dir --report path/to/report.json

================
File: pipeline/pipeline.py
================
"""
Main pipeline orchestrator module.

This module provides the core pipeline functionality for document processing.
"""

import importlib
import os
from typing import Any, Dict, Optional

from utils.pipeline.processors.formatters.factory import FormatterFactory, OutputFormat
from utils.pipeline.utils.logging import get_logger
from utils.pipeline.utils.progress import PipelineProgress
from utils.pipeline.verify.factory import VerifierFactory, VerifierType


class Pipeline:
    """
    Main pipeline orchestrator that manages the flow of document processing.

    The pipeline follows these steps:
    1. Analyze document structure
    2. Clean and normalize content
    3. Extract structured data
    4. Validate extracted data
    5. Format output
    6. Verify output structure
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize the pipeline with configuration.

        Args:
            config: Configuration dictionary with pipeline settings
        """
        self.config = config or {}
        self.logger = get_logger(__name__)

        # Initialize strategy selector
        self.strategy_selector = StrategySelector(self.config)

        self.logger.info("Pipeline initialized with config: %s", self.config)

    def run(self, input_path: str, show_progress: bool = True) -> Dict[str, Any]:
        """
        Run the pipeline on the input document.

        Args:
            input_path: Path to the input document
            show_progress: Whether to display progress bars (default: True)

        Returns:
            Processed output data as a dictionary
        """
        self.logger.info("Starting pipeline processing for: %s", input_path)
        progress = PipelineProgress()

        try:
            if not show_progress:
                # Process without progress display
                doc_type = self._detect_document_type(input_path)
                strategies = self.strategy_selector.get_strategies(doc_type)

                # Track stage outputs
                stages_data = {}
                stages_data["setup"] = {"path": input_path, "type": doc_type}

                # 1. Analyze document structure
                analysis_result = self._analyze_document(
                    input_path, strategies.analyzer
                )
                stages_data["analyze"] = analysis_result

                # 2. Clean and normalize content
                cleaned_data = self._clean_content(analysis_result, strategies.cleaner)
                stages_data["clean"] = cleaned_data

                # 3. Extract structured data
                extracted_data = self._extract_data(cleaned_data, strategies.extractor)
                stages_data["extract"] = extracted_data

                # 4. Validate extracted data
                validated_data = self._validate_data(
                    extracted_data, strategies.validator
                )
                stages_data["validate"] = validated_data

                # 5. Classify document type and identify schema pattern
                if self.config.get("enable_classification", True):
                    classification_result = self._classify_document(validated_data)
                    validated_data["classification"] = classification_result

                    # Record schema if configured
                    if self.config.get("record_schemas", False):
                        self._record_schema(
                            validated_data, classification_result["document_type"]
                        )

                # 6. Format output
                output_format = self._get_output_format()
                output_data = self._format_output(validated_data, output_format)
                stages_data["format"] = output_data

                # 7. Verify output structure
                self._verify_output_structure(output_data, output_format)

                return output_data

            # Process with progress display
            with progress:
                progress.start()
                overall_task = progress.add_task(
                    "Processing document", total=7
                )  # Increased to 7 steps

                # Determine document type and select appropriate strategies
                doc_type = self._detect_document_type(input_path)
                self.logger.info("Detected document type: %s", doc_type)
                strategies = self.strategy_selector.get_strategies(doc_type)

                # Track stage outputs
                stages_data = {}

                # Initial document info
                stages_data["setup"] = {"path": input_path, "type": doc_type}
                progress.display_success(f"Processing {os.path.basename(input_path)}")

                # 1. Analyze document structure
                analyze_task = progress.add_task("Step 1: Analyzing document structure")
                analysis_result = self._analyze_document(
                    input_path, strategies.analyzer
                )
                stages_data["analyze"] = analysis_result
                progress.update(analyze_task, advance=1)
                progress.update(overall_task, advance=1)
                progress.display_success("Document structure analyzed")

                # 2. Clean and normalize content
                clean_task = progress.add_task(
                    "Step 2: Cleaning and normalizing content"
                )
                cleaned_data = self._clean_content(analysis_result, strategies.cleaner)
                stages_data["clean"] = cleaned_data
                progress.update(clean_task, advance=1)
                progress.update(overall_task, advance=1)
                progress.display_success("Content cleaned and normalized")

                # 3. Extract structured data
                extract_task = progress.add_task("Step 3: Extracting structured data")
                extracted_data = self._extract_data(cleaned_data, strategies.extractor)
                stages_data["extract"] = extracted_data
                progress.update(extract_task, advance=1)
                progress.update(overall_task, advance=1)
                progress.display_success("Data extracted")

                # 4. Validate extracted data
                validate_task = progress.add_task("Step 4: Validating extracted data")
                validated_data = self._validate_data(
                    extracted_data, strategies.validator
                )
                stages_data["validate"] = validated_data
                progress.update(validate_task, advance=1)
                progress.update(overall_task, advance=1)
                progress.display_success("Data validated")

                # 5. Classify document type and identify schema
                if self.config.get("enable_classification", True):
                    classify_task = progress.add_task(
                        "Step 5: Classifying document type"
                    )
                    classification_result = self._classify_document(validated_data)

                    # Add classification to the data
                    validated_data["classification"] = classification_result

                    # Record schema if configured
                    if self.config.get("record_schemas", False):
                        self._record_schema(
                            validated_data, classification_result["document_type"]
                        )

                    progress.update(classify_task, advance=1)
                    progress.update(overall_task, advance=1)
                    progress.display_success(
                        f"Document classified as: {classification_result['document_type']}"
                    )
                else:
                    # Skip classification but still advance overall progress
                    progress.update(overall_task, advance=1)

                # 6. Format output
                format_task = progress.add_task("Step 6: Formatting output")
                output_format = self._get_output_format()
                output_data = self._format_output(validated_data, output_format)
                stages_data["format"] = output_data
                progress.update(format_task, advance=1)
                progress.update(overall_task, advance=1)
                progress.display_success("Output formatted")

                # 7. Verify output structure
                verify_task = progress.add_task("Step 7: Verifying output structure")
                self._verify_output_structure(output_data, output_format)
                progress.update(verify_task, advance=1)
                progress.update(overall_task, advance=1)

                # Show concise summary
                summary = {
                    "sections": len(output_data.get("content", [])),
                    "tables": len(output_data.get("tables", [])),
                    "validation": output_data.get("validation", {}),
                }

                # Add classification to summary if available
                if "classification" in validated_data:
                    summary["classification"] = validated_data["classification"]

                progress.display_summary(summary)
                progress.display_success("Pipeline processing completed successfully")
                return output_data

        except Exception as e:
            error_msg = f"Pipeline processing failed: {str(e)}"
            self.logger.error(error_msg, exc_info=True)
            progress.display_error(error_msg)
            raise PipelineError(error_msg) from e

    def _classify_document(self, validated_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Classify document type and identify schema pattern.

        Args:
            validated_data: Validated document data

        Returns:
            Classification result with document type, confidence, and schema pattern
        """
        # Get classifier configuration
        classifier_config = self.config.get("classification", {})
        classifier_type = classifier_config.get("type", "rule_based")

        # Import the document classifier
        from utils.pipeline.processors.document_classifier import DocumentClassifier

        classifier = DocumentClassifier(classifier_type, classifier_config)

        # Perform classification
        classification = classifier.classify(validated_data)

        # Check if we should match against known schemas
        if self.config.get("match_schemas", False):
            self._match_schema(validated_data, classification)

        return classification

    def _match_schema(
        self, document_data: Dict[str, Any], classification: Dict[str, Any]
    ) -> None:
        """

                Match document against known schemas and update classification.

        Args:
            document_data: Document data to match
            classification: Classification result to update
        """
        # Import the schema registry
        from utils.pipeline.schema.registry import SchemaRegistry

        registry = SchemaRegistry()

        # Match against known schemas
        schema_id, confidence = registry.match(document_data)

        if schema_id and confidence > 0.7:  # Only use if high confidence
            # Get the schema
            schema = registry.get_schema(schema_id)
            if schema:
                # Update classification with schema information
                classification["schema_id"] = schema_id
                classification["schema_match_confidence"] = confidence
                classification["schema_document_type"] = schema.get(
                    "document_type", "UNKNOWN"
                )

    def _record_schema(self, document_data: Dict[str, Any], document_type: str) -> None:
        """
        Record document schema in the registry.

        Args:
            document_data: Document data to record
            document_type: Type of the document
        """
        # Import the schema registry
        from utils.pipeline.schema.registry import SchemaRegistry

        registry = SchemaRegistry()

        # Get document name from metadata or path
        document_name = None
        if "metadata" in document_data and "title" in document_data["metadata"]:
            document_name = document_data["metadata"]["title"]
        elif "setup" in document_data and "path" in document_data["setup"]:
            document_name = os.path.basename(document_data["setup"]["path"])

        # Record the schema with document name
        registry.record(document_data, document_type, document_name)

    def _detect_document_type(self, input_path: str) -> str:
        """Detect the document type based on file extension or content analysis."""
        _, ext = os.path.splitext(input_path)
        ext = ext.lower()

        if ext == ".pdf":
            return "pdf"
        elif ext in [".xlsx", ".xls"]:
            return "excel"
        elif ext in [".docx", ".doc"]:
            return "word"
        elif ext == ".txt":
            return "text"
        else:
            # Default to generic type
            return "generic"

    def _analyze_document(self, input_path: str, analyzer) -> Dict[str, Any]:
        """Analyze document structure and content."""
        return analyzer.analyze(input_path)

    def _clean_content(
        self, analysis_result: Dict[str, Any], cleaner
    ) -> Dict[str, Any]:
        """Clean and normalize document content."""
        return cleaner.clean(analysis_result)

    def _extract_data(self, cleaned_data: Dict[str, Any], extractor) -> Dict[str, Any]:
        """Extract structured data from cleaned content."""
        return extractor.extract(cleaned_data)

    def _validate_data(
        self, extracted_data: Dict[str, Any], validator
    ) -> Dict[str, Any]:
        """Validate extracted data against schemas."""
        return validator.validate(extracted_data)

    def _format_output(
        self, validated_data: Dict[str, Any], output_format: OutputFormat
    ) -> Dict[str, Any]:
        """Format validated data using the specified formatter."""
        formatter = FormatterFactory.create_formatter(output_format)
        return formatter.format(validated_data)

    def _verify_output_structure(
        self, output_data: Dict[str, Any], output_format: OutputFormat
    ) -> None:
        """
        Verify the structure of formatted output.

        Args:
            output_data: Formatted output data to verify
            output_format: Format type of the output

        Raises:
            PipelineError: If verification fails
        """
        # Map output format to verifier type
        verifier_map = {
            OutputFormat.JSON: VerifierType.JSON_TREE,
            OutputFormat.MARKDOWN: VerifierType.MARKDOWN,
        }

        verifier_type = verifier_map.get(output_format)
        if not verifier_type:
            self.logger.warning(f"No verifier available for format: {output_format}")
            return

        try:
            verifier = VerifierFactory.create_verifier(verifier_type)
            is_valid, errors, warnings = verifier.verify(output_data)

            # Log warnings
            for warning in warnings:
                self.logger.warning(f"Structure warning: {warning}")

            # Raise error if validation failed
            if not is_valid:
                error_msg = "\n".join(errors)
                raise PipelineError(
                    f"Output structure verification failed:\n{error_msg}"
                )

        except ValueError as e:
            self.logger.warning(f"Verification skipped: {str(e)}")

    def _get_output_format(self) -> OutputFormat:
        """Get output format from config or use default."""
        format_name = self.config.get("output_format", "json").upper()
        try:
            return OutputFormat[format_name]
        except KeyError:
            self.logger.warning(f"Unsupported output format: {format_name}, using JSON")
            return OutputFormat.JSON

    def save_output(self, output_data: Dict[str, Any], output_path: str) -> None:
        """Save the output data to a file."""
        self.logger.info("Saving output to: %s", output_path)

        # Ensure directory exists
        os.makedirs(os.path.dirname(os.path.abspath(output_path)), exist_ok=True)

        # Get formatter based on file extension
        output_format = self._get_format_from_path(output_path)
        formatter = FormatterFactory.create_formatter(output_format)

        # Format and write the data
        formatter.write(output_data, output_path)

    def _get_format_from_path(self, path: str) -> OutputFormat:
        """Determine output format from file extension."""
        _, ext = os.path.splitext(path)
        ext = ext.lower()

        format_map = {
            ".json": OutputFormat.JSON,
            ".md": OutputFormat.MARKDOWN,
            ".markdown": OutputFormat.MARKDOWN,
        }

        return format_map.get(ext, OutputFormat.JSON)


class StrategySelector:
    """Selects appropriate processing strategies based on document type."""

    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.logger = get_logger(__name__ + ".StrategySelector")

    def get_strategies(self, doc_type: str) -> "StrategySet":
        """Get the set of strategies for a document type."""
        self.logger.info("Selecting strategies for document type: %s", doc_type)

        try:
            # Get strategy paths from config
            strategy_paths = self.config.get("strategies", {})
            if not strategy_paths:
                raise ImportError("No strategy paths configured")

            # Get the strategy paths for this document type
            doc_strategies = strategy_paths.get(doc_type)
            if not doc_strategies:
                raise ImportError(f"No strategy paths configured for {doc_type}")

            # If the strategy is a string, use it as a legacy format
            if isinstance(doc_strategies, str):
                return self._get_legacy_strategies(doc_strategies)

            # Import each strategy component
            analyzer = self._import_strategy(doc_strategies.get("analyzer"))
            cleaner = self._import_strategy(doc_strategies.get("cleaner"))
            extractor = self._import_strategy(doc_strategies.get("extractor"))
            validator = self._import_strategy(doc_strategies.get("validator"))

            return StrategySet(
                analyzer=analyzer,
                cleaner=cleaner,
                extractor=extractor,
                validator=validator,
                formatter=None,  # Formatter now handled by factory
            )

        except (ImportError, AttributeError) as e:
            self.logger.error(
                "Failed to import strategies for %s: %s", doc_type, str(e)
            )
            # Fall back to mock strategies for now
            return StrategySet(
                analyzer=MockStrategy(),
                cleaner=MockStrategy(),
                extractor=MockStrategy(),
                validator=MockStrategy(),
                formatter=None,
            )

    def _import_strategy(self, strategy_path: Optional[str]) -> Any:
        """Import a strategy class and create an instance."""
        if not strategy_path:
            return MockStrategy()

        try:
            module_path, class_name = strategy_path.rsplit(".", 1)
            module = importlib.import_module(module_path)
            strategy_class = getattr(module, class_name)
            return strategy_class()
        except (ImportError, AttributeError) as e:
            self.logger.error(f"Failed to import strategy {strategy_path}: {str(e)}")
            return MockStrategy()

    def _get_legacy_strategies(self, strategy_path: str) -> "StrategySet":
        """Handle legacy format where all strategies come from one module."""
        try:
            module_path = strategy_path
            module = importlib.import_module(module_path)

            return StrategySet(
                analyzer=module.Analyzer(),
                cleaner=module.Cleaner(),
                extractor=module.Extractor(),
                validator=module.Validator(),
                formatter=None,
            )
        except (ImportError, AttributeError) as e:
            self.logger.error(f"Failed to import legacy strategies: {str(e)}")
            return StrategySet(
                analyzer=MockStrategy(),
                cleaner=MockStrategy(),
                extractor=MockStrategy(),
                validator=MockStrategy(),
                formatter=None,
            )


class StrategySet:
    """A set of strategies for processing a document."""

    def __init__(self, analyzer, cleaner, extractor, validator, formatter):
        self.analyzer = analyzer
        self.cleaner = cleaner
        self.extractor = extractor
        self.validator = validator
        self.formatter = formatter


class MockStrategy:
    """A mock strategy for testing or when real strategies are not available."""

    def analyze(self, input_path):
        if not os.path.exists(input_path):
            raise FileNotFoundError(f"File not found: {input_path}")
        return {"mock_analysis": True, "path": input_path}

    def clean(self, data):
        return {"mock_cleaned": True, "data": data}

    def extract(self, data):
        return {"mock_extracted": True, "data": data}

    def validate(self, data):
        return {"mock_validated": True, "data": data}


class PipelineError(Exception):
    """Exception raised for errors in the pipeline processing."""

    pass

================
File: pipeline/processors/classifiers/__init__.py
================
"""
Document classifiers package.

This package contains various document classification strategies.
"""

================
File: pipeline/processors/classifiers/pattern_matcher.py
================
"""
Pattern matcher document classifier.

This module provides a pattern matching approach to document classification.
"""

from typing import Any, Dict, List, Optional

from utils.pipeline.utils.logging import get_logger


class PatternMatcherClassifier:
    """
    Classifies documents using pattern matching.

    This classifier uses predefined patterns to identify document types
    based on their structure, content, and metadata.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize the pattern matcher classifier.

        Args:
            config: Configuration dictionary for the classifier
        """
        self.config = config or {}
        self.logger = get_logger(__name__)

        # Define document patterns
        self.patterns = self._load_patterns()

    def classify(
        self, document_data: Dict[str, Any], features: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Classify the document using pattern matching.

        Args:
            document_data: Processed document data
            features: Extracted features from the document

        Returns:
            Classification result with document type, confidence, and schema pattern
        """
        self.logger.info("Classifying document using pattern matching")

        try:
            # Find best matching pattern
            best_match = self._find_best_match(document_data, features)

            self.logger.info(
                f"Document classified as: {best_match['document_type']} with confidence: {best_match['confidence']}"
            )
            return best_match

        except Exception as e:
            self.logger.error(f"Error classifying document: {str(e)}", exc_info=True)
            # Return unknown classification on error
            return {
                "document_type": "UNKNOWN",
                "confidence": 0.0,
                "schema_pattern": "unknown",
                "key_features": [],
            }

    def _load_patterns(self) -> List[Dict[str, Any]]:
        """
        Load document patterns from configuration or use defaults.

        Returns:
            List of document patterns
        """
        # Use patterns from config if available
        if "patterns" in self.config:
            return self.config["patterns"]

        # Default patterns
        return [
            {
                "name": "PROPOSAL",
                "schema_pattern": "standard_proposal",
                "required_features": ["has_payment_terms", "has_delivery_terms"],
                "optional_features": ["proposal_in_title", "has_regarding_section"],
                "section_patterns": [
                    "proposal",
                    "regarding",
                    "company",
                    "payment",
                    "delivery",
                ],
                "content_patterns": ["proposal", "offer", "proposed", "scope of work"],
            },
            {
                "name": "QUOTATION",
                "schema_pattern": "standard_quotation",
                "required_features": ["has_dollar_amounts"],
                "optional_features": ["has_subtotal", "has_total", "has_quantities"],
                "section_patterns": [
                    "quote",
                    "quotation",
                    "estimate",
                    "pricing",
                    "subtotal",
                    "total",
                ],
                "content_patterns": [
                    "quote",
                    "price",
                    "cost",
                    "amount",
                    "total",
                    "subtotal",
                    "$",
                ],
            },
            {
                "name": "SPECIFICATION",
                "schema_pattern": "technical_specification",
                "required_features": ["has_technical_terms", "has_measurements"],
                "optional_features": ["spec_in_title"],
                "section_patterns": [
                    "specification",
                    "spec",
                    "technical",
                    "requirements",
                    "dimensions",
                ],
                "content_patterns": [
                    "specification",
                    "technical",
                    "dimensions",
                    "performance",
                    "material",
                ],
            },
            {
                "name": "INVOICE",
                "schema_pattern": "standard_invoice",
                "required_features": ["has_dollar_amounts"],
                "optional_features": ["has_subtotal", "has_total", "invoice_in_title"],
                "section_patterns": [
                    "invoice",
                    "bill",
                    "receipt",
                    "payment",
                    "due date",
                ],
                "content_patterns": [
                    "invoice",
                    "bill",
                    "amount due",
                    "payment",
                    "total",
                    "$",
                ],
            },
            {
                "name": "TERMS_AND_CONDITIONS",
                "schema_pattern": "legal_terms",
                "required_features": ["has_legal_language"],
                "optional_features": ["has_caps_sections", "terms_in_title"],
                "section_patterns": [
                    "terms",
                    "conditions",
                    "agreement",
                    "contract",
                    "warranty",
                    "liability",
                ],
                "content_patterns": [
                    "shall",
                    "herein",
                    "pursuant",
                    "liability",
                    "warranty",
                    "indemnify",
                ],
            },
        ]

    def _find_best_match(
        self, document_data: Dict[str, Any], features: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Find the best matching pattern for the document.

        Args:
            document_data: Processed document data
            features: Extracted features from the document

        Returns:
            Classification result with document type, confidence, and schema pattern
        """
        best_match = {
            "document_type": "UNKNOWN",
            "confidence": 0.0,
            "schema_pattern": "unknown",
            "key_features": [],
        }

        # Extract content for pattern matching
        content = document_data.get("content", [])
        all_content = " ".join(
            [section.get("content", "").lower() for section in content]
        )
        section_titles = features.get("section_titles", [])

        # Check each pattern
        for pattern in self.patterns:
            confidence = 0.0
            matched_features = []

            # Check required features
            required_count = len(pattern["required_features"])
            matched_required = 0

            for feature in pattern["required_features"]:
                if features.get(feature, False):
                    matched_required += 1
                    matched_features.append(feature)

            # If not all required features match, skip this pattern
            if matched_required < required_count:
                continue

            # Add confidence for required features
            confidence += 0.5 * (matched_required / max(1, required_count))

            # Check optional features
            optional_count = len(pattern["optional_features"])
            matched_optional = 0

            for feature in pattern["optional_features"]:
                if features.get(feature, False):
                    matched_optional += 1
                    matched_features.append(feature)

            # Add confidence for optional features
            if optional_count > 0:
                confidence += 0.3 * (matched_optional / optional_count)

            # Check section patterns
            section_matches = 0
            for section_pattern in pattern["section_patterns"]:
                if any(section_pattern in title for title in section_titles):
                    section_matches += 1
                    matched_features.append(f"section_contains_{section_pattern}")

            # Add confidence for section patterns
            if len(pattern["section_patterns"]) > 0:
                confidence += 0.1 * (section_matches / len(pattern["section_patterns"]))

            # Check content patterns
            content_matches = 0
            for content_pattern in pattern["content_patterns"]:
                if content_pattern in all_content:
                    content_matches += 1
                    matched_features.append(f"content_contains_{content_pattern}")

            # Add confidence for content patterns
            if len(pattern["content_patterns"]) > 0:
                confidence += 0.1 * (content_matches / len(pattern["content_patterns"]))

            # Update best match if this pattern has higher confidence
            if confidence > best_match["confidence"]:
                best_match = {
                    "document_type": pattern["name"],
                    "confidence": min(1.0, confidence),  # Cap at 1.0
                    "schema_pattern": pattern["schema_pattern"],
                    "key_features": matched_features,
                }

        return best_match

================
File: pipeline/processors/classifiers/rule_based.py
================
"""
Rule-based document classifier.

This module provides a rule-based approach to document classification.
"""

import os
import re
from typing import Any, Dict, List, Optional, Tuple

from utils.pipeline.utils.logging import get_logger


class RuleBasedClassifier:
    """
    Classifies documents using a rule-based approach.

    This classifier uses a set of predefined rules to identify document types
    based on their structure, content, and metadata.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize the rule-based classifier.

        Args:
            config: Configuration dictionary for the classifier
        """
        self.config = config or {}
        self.logger = get_logger(__name__)

        # Get classification rules from config
        self.classification_config = self.config.get("classification", {})
        self.rules_config = self.classification_config.get("rules", {})
        self.default_threshold = self.classification_config.get(
            "default_threshold", 0.3
        )
        self.filename_patterns = self.classification_config.get("filename_patterns", {})

    def classify(
        self, document_data: Dict[str, Any], features: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Classify the document using rule-based approach.

        Args:
            document_data: Processed document data
            features: Extracted features from the document

        Returns:
            Classification result with document type, confidence, and schema pattern
        """
        # Check filename patterns if path is available
        if "path" in document_data:
            filename = os.path.basename(document_data["path"])
            for doc_type, pattern in self.filename_patterns.items():
                if re.search(pattern, filename):
                    self.logger.info(
                        f"Matched filename pattern for {doc_type}: {filename}"
                    )
                    return {
                        "document_type": doc_type,
                        "confidence": 0.8,  # High confidence for filename match
                        "schema_pattern": self.rules_config.get(doc_type, {}).get(
                            "schema_pattern", "standard"
                        ),
                        "key_features": ["filename_match"],
                    }

        # Apply configured rules
        best_match = self._get_best_match(document_data, features)

        # Only use generic classification if confidence is very low
        if (
            best_match[0] == "UNKNOWN" or best_match[1] < 0.2
        ):  # Lower threshold for falling back to generic
            # If no specific type matched or confidence is very low, try to determine a generic type
            return self._classify_generic(document_data, features)

        return {
            "document_type": best_match[0],
            "confidence": best_match[1],
            "schema_pattern": best_match[2],
            "key_features": best_match[3],
        }

    def _get_best_match(
        self, document_data: Dict[str, Any], features: Dict[str, Any]
    ) -> Tuple[str, float, str, List[str]]:
        """
        Apply all configured rules and get the best matching document type.

        Args:
            document_data: Processed document data
            features: Extracted features from the document

        Returns:
            Tuple of (document_type, confidence, schema_pattern, key_features)
        """
        best_match = ("UNKNOWN", 0.0, "unknown", [])

        # Apply each configured rule
        for doc_type, rule in self.rules_config.items():
            confidence = 0.0
            key_features = []

            # Check title keywords
            section_titles = features.get("section_titles", [])
            title_keywords = rule.get("title_keywords", [])
            if title_keywords:
                matches = sum(
                    1
                    for keyword in title_keywords
                    if any(keyword.lower() in title.lower() for title in section_titles)
                )
                if matches > 0:
                    title_weight = rule.get("weights", {}).get("title_match", 0.4)
                    confidence += title_weight * (matches / len(title_keywords))
                    key_features.append("title_match")

            # Check content keywords
            content = " ".join(
                [
                    section.get("content", "")
                    for section in document_data.get("content", [])
                ]
            )
            content_keywords = rule.get("content_keywords", [])
            if content_keywords:
                matches = sum(
                    1
                    for keyword in content_keywords
                    if keyword.lower() in content.lower()
                )
                if matches > 0:
                    content_weight = rule.get("weights", {}).get("content_match", 0.3)
                    confidence += content_weight * (matches / len(content_keywords))
                    key_features.append("content_match")

            # Check patterns
            patterns = rule.get("patterns", [])
            if patterns:
                matches = sum(
                    1 for pattern in patterns if pattern.lower() in content.lower()
                )
                if matches > 0:
                    pattern_weight = rule.get("weights", {}).get("pattern_match", 0.3)
                    confidence += pattern_weight * (matches / len(patterns))
                    key_features.append("pattern_match")

            # Check if confidence exceeds threshold
            threshold = rule.get("threshold", 0.5)
            if confidence > threshold and confidence > best_match[1]:
                schema_pattern = rule.get("schema_pattern", "standard")
                best_match = (doc_type, confidence, schema_pattern, key_features)

        return best_match

    def _classify_generic(
        self, document_data: Dict[str, Any], features: Dict[str, Any]
    ) -> Dict[str, Any]:
        """
        Classify document into generic categories when specific types don't match.

        Args:
            document_data: Processed document data
            features: Extracted features from the document

        Returns:
            Classification result with generic document type
        """
        # Check if it's a form
        if features.get("table_count", 0) > 3:
            return {
                "document_type": "FORM",
                "confidence": 0.6,
                "schema_pattern": "tabular_form",
                "key_features": ["multiple_tables", "structured_layout"],
            }

        # Check if it's a report
        if features.get("section_count", 0) > 10:
            return {
                "document_type": "REPORT",
                "confidence": 0.5,
                "schema_pattern": "sectioned_document",
                "key_features": ["multiple_sections", "hierarchical_structure"],
            }

        # Default to generic document
        return {
            "document_type": "GENERIC_DOCUMENT",
            "confidence": self.default_threshold,
            "schema_pattern": "unknown",
            "key_features": [],
        }

================
File: pipeline/processors/document_classifier.py
================
"""
Document classifier module.

This module provides functionality for classifying documents based on their structure and content.
"""

from typing import Any, Dict, Optional

from utils.pipeline.utils.logging import get_logger


class DocumentClassifier:
    """
    Classifies documents based on their structure and content patterns.

    This classifier analyzes the document structure to identify patterns that match
    known document types such as proposals, quotations, specifications, etc.
    """

    def __init__(
        self,
        classifier_type: str = "rule_based",
        config: Optional[Dict[str, Any]] = None,
    ):
        """
        Initialize the document classifier.

        Args:
            classifier_type: Type of classifier to use (rule_based, pattern_matcher, etc.)
            config: Configuration dictionary for the classifier
        """
        self.classifier_type = classifier_type
        self.config = config or {}
        self.logger = get_logger(__name__)

        # Initialize classifier strategy based on type
        if classifier_type == "rule_based":
            from utils.pipeline.processors.classifiers.rule_based import (
                RuleBasedClassifier,
            )

            self.classifier_strategy = RuleBasedClassifier(self.config)
        elif classifier_type == "pattern_matcher":
            from utils.pipeline.processors.classifiers.pattern_matcher import (
                PatternMatcherClassifier,
            )

            self.classifier_strategy = PatternMatcherClassifier(self.config)
        else:
            # Default to rule-based
            from utils.pipeline.processors.classifiers.rule_based import (
                RuleBasedClassifier,
            )

            self.classifier_strategy = RuleBasedClassifier(self.config)
            self.logger.warning(
                f"Unknown classifier type: {classifier_type}, using rule_based"
            )

    def classify(self, document_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Classify the document based on its structure and content.

        Args:
            document_data: Processed document data

        Returns:
            Classification result with document type, confidence, and schema pattern
        """
        self.logger.info("Classifying document")

        try:
            # Extract features from document
            features = self._extract_features(document_data)

            # Classify document using strategy
            classification = self.classifier_strategy.classify(document_data, features)

            self.logger.info(
                f"Document classified as: {classification['document_type']} with confidence: {classification['confidence']}"
            )
            return classification

        except Exception as e:
            self.logger.error(f"Error classifying document: {str(e)}", exc_info=True)
            # Return unknown classification on error
            return {
                "document_type": "UNKNOWN",
                "confidence": 0.0,
                "schema_pattern": "unknown",
                "key_features": [],
            }

    def _extract_features(self, document_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract features from document data for classification.

        Args:
            document_data: Processed document data

        Returns:
            Dictionary of extracted features
        """
        features = {}

        # Extract metadata features
        metadata = document_data.get("metadata", {})
        features["has_title"] = bool(metadata.get("title"))
        features["has_author"] = bool(metadata.get("author"))
        features["creator"] = metadata.get("creator", "")
        features["producer"] = metadata.get("producer", "")

        # Extract content features
        content = document_data.get("content", [])
        features["section_count"] = len(content)

        # Extract section titles
        section_titles = [
            section.get("title", "").lower()
            for section in content
            if section.get("title")
        ]
        features["section_titles"] = section_titles

        # Check for common document patterns
        features["has_payment_terms"] = any(
            "payment" in title for title in section_titles
        )
        features["has_delivery_terms"] = any(
            "delivery" in title for title in section_titles
        )
        features["has_subtotal"] = any("subtotal" in title for title in section_titles)
        features["has_total"] = any("total" in title for title in section_titles)

        # Check for pricing patterns in content
        all_content = " ".join([section.get("content", "") for section in content])
        features["has_dollar_amounts"] = "$" in all_content
        features["has_quantities"] = any(word.isdigit() for word in all_content.split())

        # Check for tables
        tables = document_data.get("tables", [])
        features["table_count"] = len(tables)

        return features

================
File: pipeline/processors/formatters/factory.py
================
"""
Formatter factory implementation.

This module provides a factory for creating different output formatters.
"""

from enum import Enum, auto
from typing import Dict, Type

from utils.pipeline.processors.formatters.json_formatter import JSONFormatter
from utils.pipeline.processors.formatters.markdown_formatter import MarkdownFormatter
from utils.pipeline.strategies.formatter import FormatterStrategy
from utils.pipeline.utils.logging import get_logger


class OutputFormat(Enum):
    """Supported output formats."""

    JSON = auto()
    MARKDOWN = auto()


class FormatterFactory:
    """Factory for creating formatter instances."""

    _formatters: Dict[OutputFormat, Type[FormatterStrategy]] = {
        OutputFormat.JSON: JSONFormatter,
        OutputFormat.MARKDOWN: MarkdownFormatter,
    }

    @classmethod
    def create_formatter(cls, format_type: OutputFormat) -> FormatterStrategy:
        """
        Create a formatter instance for the specified format.

        Args:
            format_type: Type of formatter to create

        Returns:
            Formatter instance

        Raises:
            ValueError: If format type is not supported
        """
        logger = get_logger(__name__)

        try:
            formatter_class = cls._formatters[format_type]
            return formatter_class()
        except KeyError:
            logger.error(f"Unsupported format type: {format_type}")
            raise ValueError(f"Unsupported format type: {format_type}")

    @classmethod
    def register_formatter(
        cls, format_type: OutputFormat, formatter_class: Type[FormatterStrategy]
    ) -> None:
        """
        Register a new formatter type.

        Args:
            format_type: Format type to register
            formatter_class: Formatter class to use for this format
        """
        logger = get_logger(__name__)
        logger.info(
            f"Registering formatter for {format_type}: {formatter_class.__name__}"
        )
        cls._formatters[format_type] = formatter_class

================
File: pipeline/processors/formatters/json_formatter.py
================
"""
JSON formatter implementation.

This module provides functionality for formatting extracted PDF content into JSON.
"""

import json
from typing import Any, Dict, List

from utils.pipeline.strategies.formatter import FormatterStrategy
from utils.pipeline.utils.logging import get_logger


class JSONFormatter(FormatterStrategy):
    """Formats extracted PDF content into readable JSON with proper indentation."""

    def __init__(self):
        self.logger = get_logger(__name__)

    def format(self, analyzed_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Format the analyzed data into a hierarchical JSON structure.

        Args:
            analyzed_data: Data from the PDF analyzer

        Returns:
            Formatted JSON structure with proper indentation
        """
        self.logger.info("Formatting PDF content as JSON")

        try:
            # Build hierarchical structure
            formatted_data = {
                "document": {
                    "metadata": analyzed_data.get("metadata", {}),
                    "path": analyzed_data.get("path", ""),
                    "type": analyzed_data.get("type", ""),
                },
                "content": self._build_content_tree(analyzed_data.get("sections", [])),
                "tables": analyzed_data.get("tables", []),
                "summary": analyzed_data.get("summary", {}),
                "validation": analyzed_data.get("validation", {}),
            }

            return formatted_data

        except Exception as e:
            self.logger.error(f"Error formatting PDF content: {str(e)}", exc_info=True)
            raise

    def _build_content_tree(
        self, sections: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Build a hierarchical tree structure from flat sections list.

        Args:
            sections: List of section dictionaries

        Returns:
            List of sections with hierarchical structure
        """
        if not sections:
            return []

        # Initialize with root level sections
        result = []
        current_section = None
        current_level = 0
        section_stack = []  # [(section, level)]

        for section in sections:
            title = section["title"]
            level = self._determine_section_level(title)

            new_section = {
                "title": title,
                "content": section.get("content", ""),
                "children": [],
                "level": level,
            }

            # Add any additional metadata
            if "font" in section:
                new_section["font"] = section["font"]

            # Handle section nesting
            if not current_section:
                # First section
                result.append(new_section)
                current_section = new_section
                current_level = level
                section_stack.append((current_section, current_level))
            else:
                if level > current_level:
                    # Child section
                    current_section["children"].append(new_section)
                    section_stack.append((current_section, current_level))
                    current_section = new_section
                    current_level = level
                else:
                    # Sibling or uncle section
                    while section_stack and section_stack[-1][1] >= level:
                        section_stack.pop()

                    if section_stack:
                        # Add as child to nearest parent
                        parent, _ = section_stack[-1]
                        parent["children"].append(new_section)
                    else:
                        # No parent found, add to root
                        result.append(new_section)

                    current_section = new_section
                    current_level = level
                    section_stack.append((current_section, current_level))

        return result

    def _determine_section_level(self, title: str) -> int:
        """
        Determine section level based on title format.

        Args:
            title: Section title

        Returns:
            Integer indicating section level (0 = top level)
        """
        # Main section headers (e.g., "HEATING SYSTEMS")
        if title.isupper() and len(title.split()) > 1:
            return 0

        # Numbered sections (e.g., "1.0", "2.1", etc.)
        if any(title.startswith(str(i) + ".") for i in range(1, 20)):
            return 1

        # Lettered subsections (e.g., "A.", "B.", etc.)
        if len(title) == 2 and title[0].isupper() and title[1] == ".":
            return 2

        # Numbered subsections (e.g., "1.", "2.", etc.)
        if title.rstrip(".").isdigit():
            return 2

        # Default to deepest level
        return 3

    def write(self, data: Dict[str, Any], output_path: str) -> None:
        """
        Write formatted data to a JSON file with proper indentation.

        Args:
            data: Formatted data to write
            output_path: Path to output file
        """
        with open(output_path, "w", encoding="utf-8") as f:
            json.dump(data, f, indent=2, ensure_ascii=False)

================
File: pipeline/processors/formatters/markdown_formatter.py
================
"""
Markdown formatter implementation.

This module provides functionality for formatting extracted PDF content into Markdown.
"""

from typing import Any, Dict, List

from utils.pipeline.strategies.formatter import FormatterStrategy
from utils.pipeline.utils.logging import get_logger


class MarkdownFormatter(FormatterStrategy):
    """Formats extracted PDF content into readable Markdown."""

    def __init__(self):
        self.logger = get_logger(__name__)

    def format(self, analyzed_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Format the analyzed data into a Markdown structure.

        Args:
            analyzed_data: Data from the PDF analyzer

        Returns:
            Formatted data structure with Markdown content
        """
        self.logger.info("Formatting PDF content as Markdown")

        try:
            # Build hierarchical structure
            content_tree = self._build_content_tree(analyzed_data.get("sections", []))

            # Convert content tree to markdown string
            content_markdown = ""
            for section in content_tree:
                content_markdown += self._format_section_to_markdown(section)

            # Convert tables to markdown string
            tables_markdown = ""
            for table in analyzed_data.get("tables", []):
                tables_markdown += self._format_table_to_markdown(table)

            # Create formatted data with strings for content and tables
            formatted_data = {
                "document": {
                    "metadata": analyzed_data.get("metadata", {}),
                    "path": analyzed_data.get("path", ""),
                    "type": analyzed_data.get("type", ""),
                },
                "content": content_markdown,
                "tables": tables_markdown,
                "summary": analyzed_data.get("summary", {}),
                "validation": analyzed_data.get("validation", {}),
            }

            # Add classification if present
            if "classification" in analyzed_data:
                formatted_data["classification"] = analyzed_data["classification"]

            return formatted_data

        except Exception as e:
            self.logger.error(f"Error formatting PDF content: {str(e)}", exc_info=True)
            raise

    def _build_content_tree(
        self, sections: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Build a hierarchical tree structure from flat sections list.
        This matches the structure returned by JSONFormatter._build_content_tree().

        Args:
            sections: List of section dictionaries

        Returns:
            List of sections with hierarchical structure
        """
        if not sections:
            return []

        # Initialize with root level sections
        result = []
        current_section = None
        current_level = 0
        section_stack = []  # [(section, level)]

        for section in sections:
            title = section.get("title", "")
            level = section.get("level", 0)
            content = section.get("content", "")

            new_section = {
                "title": title,
                "content": content,
                "children": [],
                "level": level,
            }

            # Add any additional metadata
            if "font" in section:
                new_section["font"] = section["font"]

            # Handle section nesting
            if not current_section:
                # First section
                result.append(new_section)
                current_section = new_section
                current_level = level
                section_stack.append((current_section, current_level))
            else:
                if level > current_level:
                    # Child section
                    current_section["children"].append(new_section)
                    section_stack.append((current_section, current_level))
                    current_section = new_section
                    current_level = level
                else:
                    # Sibling or uncle section
                    while section_stack and section_stack[-1][1] >= level:
                        section_stack.pop()

                    if section_stack:
                        # Add as child to nearest parent
                        parent, _ = section_stack[-1]
                        parent["children"].append(new_section)
                    else:
                        # No parent found, add to root
                        result.append(new_section)

                    current_section = new_section
                    current_level = level
                    section_stack.append((current_section, current_level))

        return result

    def _format_section_to_markdown(self, section: Dict[str, Any]) -> str:
        """
        Convert a section dictionary to markdown text.

        Args:
            section: Section dictionary with title, content, children, and level

        Returns:
            Markdown formatted string for the section
        """
        markdown_lines = []

        # Add section header with appropriate level
        if section.get("title"):
            level = section.get("level", 0)
            markdown_lines.append(f"{'#' * (level + 1)} {section['title']}\n")

        # Add section content
        if section.get("content"):
            markdown_lines.append(f"{section['content']}\n")

        # Process children recursively
        for child in section.get("children", []):
            markdown_lines.append(self._format_section_to_markdown(child))

        return "\n".join(markdown_lines)

    def _format_table_to_markdown(self, table: Dict[str, Any]) -> str:
        """
        Format a table dictionary to markdown.

        Args:
            table: Table dictionary with headers and data

        Returns:
            Markdown formatted table string
        """
        markdown_lines = []

        if "headers" in table and "data" in table:
            # Add table headers
            headers = table["headers"]
            markdown_lines.append("| " + " | ".join(headers) + " |")
            markdown_lines.append("| " + " | ".join(["---"] * len(headers)) + " |")

            # Add table data
            for row in table["data"]:
                markdown_lines.append(
                    "| " + " | ".join(str(cell) for cell in row) + " |"
                )

            markdown_lines.append("")  # Add empty line after table

        return "\n".join(markdown_lines)

    def write(self, data: Dict[str, Any], output_path: str) -> None:
        """
        Write formatted data to a Markdown file.

        Args:
            data: Formatted data to write
            output_path: Path to output file
        """
        with open(output_path, "w", encoding="utf-8") as f:
            # Write document metadata
            doc = data.get("document", {})
            f.write("# Document Information\n\n")
            f.write(f"- Path: {doc.get('path', '')}\n")
            f.write(f"- Type: {doc.get('type', '')}\n\n")

            # Write metadata
            metadata = doc.get("metadata", {})
            if metadata:
                f.write("## Metadata\n\n")
                for key, value in metadata.items():
                    f.write(f"- {key}: {value}\n")
                f.write("\n")

            # Write content
            content = data.get("content", "")
            if content:
                f.write("# Content\n\n")
                f.write(content)
                f.write("\n")

            # Write tables
            tables = data.get("tables", "")
            if tables:
                f.write("# Tables\n\n")
                f.write(tables)
                f.write("\n")

            # Write summary
            summary = data.get("summary", {})
            if summary:
                f.write("# Summary\n\n")
                for key, value in summary.items():
                    f.write(f"## {key}\n\n{value}\n\n")

            # Write classification if present
            classification = data.get("classification", {})
            if classification:
                f.write("# Classification\n\n")
                f.write(
                    f"- Document Type: {classification.get('document_type', 'Unknown')}\n"
                )
                f.write(f"- Confidence: {classification.get('confidence', 0.0):.2f}\n")
                f.write(
                    f"- Schema Pattern: {classification.get('schema_pattern', 'Unknown')}\n"
                )

                key_features = classification.get("key_features", [])
                if key_features:
                    f.write("- Key Features:\n")
                    for feature in key_features:
                        f.write(f"  - {feature}\n")
                f.write("\n")

================
File: pipeline/processors/pdf_extractor.py
================
"""
PDF data extractor implementation.

This module provides functionality for extracting structured data from PDF content.
"""

import re
from typing import Any, Dict, List

import fitz  # PyMuPDF

from utils.pipeline.strategies.base import ExtractorStrategy
from utils.pipeline.utils.logging import get_logger


class PDFExtractor(ExtractorStrategy):
    """Extracts structured data from PDF content."""

    def __init__(self):
        self.logger = get_logger(__name__)

    def extract(self, cleaned_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract structured data from cleaned PDF content.

        Args:
            cleaned_data: Cleaned data from the PDF cleaner

        Returns:
            Extracted structured data including schema
        """
        self.logger.info(
            f"Extracting data from PDF: {cleaned_data.get('path', 'unknown')}"
        )

        try:
            # Extract sections and content
            doc = fitz.open(cleaned_data["path"])

            # Extract text by sections
            sections = self._extract_sections(doc)

            # Extract tables if present
            tables = self._extract_tables(doc)

            # Extract schema structure
            schema = self._extract_schema(sections)

            doc.close()

            # Return extracted data
            return {
                "metadata": cleaned_data["metadata"],
                "sections": sections,
                "tables": tables,
                "schema": schema,
                "path": cleaned_data["path"],
            }

        except Exception as e:
            self.logger.error(
                f"Error extracting data from PDF: {str(e)}", exc_info=True
            )
            raise

    def _extract_schema(self, sections: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        Extract schema structure from sections.

        Args:
            sections: List of extracted sections

        Returns:
            Schema structure
        """
        schema = {
            "type": "object",
            "title": "CSI Specification Schema",
            "properties": {},
            "required": [],
        }

        # Track section numbers and their hierarchy
        current_section = None
        section_pattern = re.compile(r"^([A-Z][0-9]+(?:\.[0-9]+)*)")

        for section in sections:
            title = section.get("title", "")
            match = section_pattern.match(title)

            if match:
                section_number = match.group(1)
                section_name = title.replace(section_number, "").strip()

                # Add to schema properties
                schema["properties"][section_number] = {
                    "type": "object",
                    "title": section_name,
                    "properties": {
                        "content": {"type": "string"},
                        "subsections": {"type": "object"},
                    },
                }

                # Track required fields
                schema["required"].append(section_number)

                # Handle subsections
                if "children" in section:
                    subsections_schema = self._extract_schema(section["children"])
                    schema["properties"][section_number]["properties"][
                        "subsections"
                    ] = subsections_schema

        return schema

    def _extract_sections(self, doc) -> List[Dict[str, Any]]:
        """
        Extract sections from the PDF document.

        Args:
            doc: PyMuPDF document

        Returns:
            List of sections with titles and content
        """
        sections = []
        current_section = {"title": "Introduction", "content": ""}

        for page in doc:
            text = page.get_text("text")

            # Split text into lines
            lines = text.split("\n")

            for line in lines:
                line = line.strip()
                if not line:
                    continue

                # Heuristic for section headers (customize based on document)
                if (
                    re.match(r"^[0-9.]+\s+[A-Z]", line)
                    or line.isupper()
                    or len(line) < 50
                    and line.endswith(":")
                ):
                    # Save previous section if it has content
                    if current_section["content"]:
                        sections.append(current_section)

                    # Start new section
                    current_section = {"title": line, "content": ""}
                else:
                    # Add to current section content WITHOUT truncation
                    current_section["content"] += line + "\n"

        # Add the last section
        if current_section["content"]:
            sections.append(current_section)

        return sections

    def _extract_tables(self, doc) -> List[Dict[str, Any]]:
        """
        Extract tables from the PDF document with improved structure detection.

        Args:
            doc: PyMuPDF document

        Returns:
            List of extracted tables with structure
        """
        tables = []

        try:
            # Use PyMuPDF's improved table detection
            for page_num, page in enumerate(doc):
                # First try to detect tables using layout analysis
                try:
                    # Get blocks that might be tables
                    blocks = page.get_text("dict")["blocks"]

                    for block in blocks:
                        # Check if block has multiple lines (potential table)
                        if "lines" in block and len(block["lines"]) > 2:
                            table_data = []
                            headers = []

                            # Process rows
                            for row_idx, line in enumerate(block["lines"]):
                                if "spans" not in line:
                                    continue

                                row_data = [span["text"] for span in line["spans"]]

                                # First row might be headers
                                if row_idx == 0 and any(
                                    cell.isupper() for cell in row_data if cell
                                ):
                                    headers = row_data
                                else:
                                    table_data.append(row_data)

                            # Only add if we have actual data
                            if table_data:
                                # Add table with structure
                                tables.append(
                                    {
                                        "page": page_num + 1,
                                        "table_number": len(tables) + 1,
                                        "headers": headers,
                                        "data": table_data,
                                        "column_count": len(headers)
                                        if headers
                                        else (
                                            max(len(row) for row in table_data)
                                            if table_data
                                            else 0
                                        ),
                                        "row_count": len(table_data),
                                        "detection_method": "layout_analysis",
                                    }
                                )
                except Exception as layout_error:
                    self.logger.warning(f"Layout analysis failed: {str(layout_error)}")

                # Fallback to text-based table detection
                if not any(table["page"] == page_num + 1 for table in tables):
                    text = page.get_text("text")

                    # Look for common table indicators
                    if any(pattern in text for pattern in ["TABLE", "Table", "|", "+"]):
                        # Try to detect table structure from text
                        lines = text.split("\n")
                        table_start = -1
                        table_end = -1

                        # Find table boundaries
                        for i, line in enumerate(lines):
                            if "TABLE" in line.upper() and table_start == -1:
                                table_start = i
                            elif table_start != -1 and not line.strip():
                                # Empty line might indicate end of table
                                if i > table_start + 2:  # At least 2 rows
                                    table_end = i
                                    break

                        # If we found a table
                        if table_start != -1 and table_end != -1:
                            table_lines = lines[table_start:table_end]

                            # Try to detect headers and data
                            headers = []
                            data = []

                            # First non-empty line after title might be headers
                            for i, line in enumerate(table_lines):
                                if i > 0 and line.strip():  # Skip title
                                    # Split by common delimiters
                                    cells = re.split(r"\s{2,}|\t|\|", line)
                                    cells = [
                                        cell.strip() for cell in cells if cell.strip()
                                    ]

                                    if not headers and any(
                                        cell.isupper() for cell in cells
                                    ):
                                        headers = cells
                                    else:
                                        data.append(cells)

                            # Add table with structure
                            if data:  # Only add if we have data
                                tables.append(
                                    {
                                        "page": page_num + 1,
                                        "table_number": len(tables) + 1,
                                        "headers": headers,
                                        "data": data,
                                        "column_count": len(headers)
                                        if headers
                                        else (
                                            max(len(row) for row in data) if data else 0
                                        ),
                                        "row_count": len(data),
                                        "detection_method": "text_analysis",
                                    }
                                )
        except Exception as e:
            self.logger.warning(f"Error during table extraction: {str(e)}")
            # Continue processing even if table extraction fails

        return tables

================
File: pipeline/processors/pdf_formatter.py
================
"""
PDF formatter implementation.

This module provides functionality for formatting validated PDF data for output.
"""

from typing import Any, Dict

from utils.pipeline.strategies.base import FormatterStrategy
from utils.pipeline.utils.logging import get_logger


class PDFFormatter(FormatterStrategy):
    """Formats validated PDF data for output."""

    def __init__(self):
        self.logger = get_logger(__name__)

    def format(self, validated_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Format validated PDF data for output.

        Args:
            validated_data: Validated data from the PDF validator

        Returns:
            Formatted output data
        """
        self.logger.info(
            f"Formatting output for: {validated_data.get('path', 'unknown')}"
        )

        # Create a clean output structure
        output = {
            "document": {
                "type": "pdf",
                "path": validated_data.get("path", ""),
                "metadata": self._format_metadata(validated_data.get("metadata", {})),
            },
            "content": {
                "sections": self._format_sections(validated_data.get("sections", [])),
                "tables": self._format_tables(validated_data.get("tables", [])),
            },
            "validation": validated_data.get("validation", {"is_valid": True}),
        }

        # Add summary information
        output["summary"] = self._create_summary(output)

        return output

    def _format_metadata(self, metadata: Dict[str, Any]) -> Dict[str, Any]:
        """Format metadata section."""
        formatted_metadata = {}

        # Format standard metadata fields
        standard_fields = [
            "page_count",
            "title",
            "author",
            "subject",
            "keywords",
            "creator",
            "producer",
            "creation_date",
            "modification_date",
        ]

        for field in standard_fields:
            value = metadata.get(field)
            if value is not None:
                formatted_metadata[field] = value

        # Format any additional metadata fields
        for key, value in metadata.items():
            if key not in standard_fields and value is not None:
                formatted_metadata[key] = value

        return formatted_metadata

    def _format_sections(self, sections: list) -> list:
        """Format document sections."""
        formatted_sections = []

        for section in sections:
            if not isinstance(section, dict):
                continue

            formatted_section = {
                "title": section.get("title", "").strip(),
                "content": self._clean_content(section.get("content", "")),
            }

            # Add any additional section metadata if present
            for key, value in section.items():
                if key not in ["title", "content"] and value is not None:
                    formatted_section[key] = value

            formatted_sections.append(formatted_section)

        return formatted_sections

    def _format_tables(self, tables: list) -> list:
        """Format extracted tables."""
        formatted_tables = []

        for table in tables:
            if not isinstance(table, dict):
                continue

            formatted_table = {
                "page": table.get("page"),
                "table_number": table.get("table_number"),
                "data": table.get("data"),
            }

            # Add accuracy score if available
            accuracy = table.get("accuracy")
            if accuracy is not None:
                formatted_table["accuracy"] = accuracy

            # Add any additional table metadata if present
            for key, value in table.items():
                if (
                    key not in ["page", "table_number", "data", "accuracy"]
                    and value is not None
                ):
                    formatted_table[key] = value

            formatted_tables.append(formatted_table)

        return formatted_tables

    def _clean_content(self, content: str) -> str:
        """Clean and normalize content text."""
        if not content:
            return ""

        # Remove any trailing whitespace from lines while preserving intentional line breaks
        lines = [line.rstrip() for line in content.splitlines()]

        # Remove any empty lines at the start and end while preserving internal empty lines
        while lines and not lines[0].strip():
            lines.pop(0)
        while lines and not lines[-1].strip():
            lines.pop()

        return "\n".join(lines)

    def _create_summary(self, output: Dict[str, Any]) -> Dict[str, Any]:
        """Create a summary of the document content."""
        content = output["content"]
        validation = output["validation"]

        summary = {
            "title": output["document"]["metadata"].get("title", "Untitled"),
            "page_count": output["document"]["metadata"].get("page_count", 0),
            "section_count": len(content["sections"]),
            "table_count": len(content["tables"]),
            "is_valid": validation.get("is_valid", True),
            "has_errors": bool(validation.get("errors", [])),
            "has_warnings": bool(validation.get("warnings", [])),
        }

        # Add error and warning counts if present
        errors = validation.get("errors", [])
        warnings = validation.get("warnings", [])
        if errors:
            summary["error_count"] = len(errors)
        if warnings:
            summary["warning_count"] = len(warnings)

        return summary

================
File: pipeline/processors/pdf_validator.py
================
"""
PDF validator implementation.

This module provides functionality for validating extracted PDF data.
"""

from typing import Any, Dict

from utils.pipeline.strategies.base import ValidatorStrategy
from utils.pipeline.utils.logging import get_logger


class PDFValidator(ValidatorStrategy):
    """Validates extracted PDF data."""

    def __init__(self):
        self.logger = get_logger(__name__)

    def validate(self, extracted_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Validate extracted PDF data.

        Args:
            extracted_data: Data extracted from the PDF

        Returns:
            Validated data with validation results
        """
        self.logger.info(
            f"Validating extracted data for: {extracted_data.get('path', 'unknown')}"
        )

        validation_results = {
            "is_valid": True,
            "errors": [],
            "warnings": [],
        }

        # Validate metadata
        self._validate_metadata(extracted_data, validation_results)

        # Validate sections
        self._validate_sections(extracted_data, validation_results)

        # Validate tables
        self._validate_tables(extracted_data, validation_results)

        # Update validation status
        if validation_results["errors"]:
            validation_results["is_valid"] = False

        # Return validated data
        return {
            **extracted_data,
            "validation": validation_results,
        }

    def _validate_metadata(
        self, extracted_data: Dict[str, Any], validation_results: Dict[str, Any]
    ) -> None:
        """Validate metadata section."""
        metadata = extracted_data.get("metadata", {})
        if not metadata:
            validation_results["warnings"].append("Missing or empty metadata")
            return

        # Check required metadata fields
        required_fields = ["page_count"]
        for field in required_fields:
            if field not in metadata:
                validation_results["errors"].append(
                    f"Missing required metadata: {field}"
                )

        # Check optional metadata fields
        optional_fields = ["title", "author", "subject", "keywords"]
        for field in optional_fields:
            if not metadata.get(field):
                validation_results["warnings"].append(
                    f"Missing optional metadata: {field}"
                )

    def _validate_sections(
        self, extracted_data: Dict[str, Any], validation_results: Dict[str, Any]
    ) -> None:
        """Validate sections content."""
        sections = extracted_data.get("sections", [])
        if not sections:
            validation_results["warnings"].append("No sections extracted")
            return

        for i, section in enumerate(sections):
            # Validate section structure
            if not isinstance(section, dict):
                validation_results["errors"].append(
                    f"Invalid section structure at index {i}"
                )
                continue

            # Validate section title
            if not section.get("title"):
                validation_results["errors"].append(f"Section {i + 1} missing title")

            # Validate section content
            if not section.get("content"):
                validation_results["warnings"].append(
                    f"Section '{section.get('title', f'Section {i + 1}')}' has no content"
                )

            # Check for reasonable content length
            content = section.get("content", "")
            if len(content) < 10:  # Arbitrary minimum length
                validation_results["warnings"].append(
                    f"Section '{section.get('title', f'Section {i + 1}')}' has very short content"
                )

    def _validate_tables(
        self, extracted_data: Dict[str, Any], validation_results: Dict[str, Any]
    ) -> None:
        """Validate extracted tables."""
        tables = extracted_data.get("tables", [])
        if not tables:
            validation_results["warnings"].append("No tables extracted")
            return

        for i, table in enumerate(tables):
            # Validate table structure
            if not isinstance(table, dict):
                validation_results["errors"].append(
                    f"Invalid table structure at index {i}"
                )
                continue

            # Validate required table fields
            required_fields = ["page", "table_number", "data"]
            for field in required_fields:
                if field not in table:
                    validation_results["errors"].append(
                        f"Table {i + 1} missing required field: {field}"
                    )

            # Validate table data
            data = table.get("data")
            if isinstance(data, str):
                # This is likely a fallback message when table extraction failed
                validation_results["warnings"].append(
                    f"Table {i + 1} contains placeholder data: {data}"
                )
            elif isinstance(data, list):
                if not data:
                    validation_results["warnings"].append(f"Table {i + 1} is empty")

================
File: pipeline/pyproject.toml
================
[project]
name = "pipeline"
version = "0.1.0"
description = "Document processing pipeline"
authors = [
    {name = "Your Name", email = "your.email@example.com"},
]
dependencies = [
    "pyyaml>=6.0.1",
    "rich>=13.7.0",
    "pypdf>=4.0.1",
    "python-docx>=1.1.0",
    "PyMuPDF>=1.23.8",  # fitz
    "camelot-py[cv]>=0.11.0",  # table extraction
    "opencv-python-headless>=4.9.0.80",  # for camelot
    "ghostscript>=0.7",  # for camelot
]
requires-python = ">=3.9"

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.ruff]
line-length = 88
target-version = "py39"

[tool.ruff.lint]
select = [
    "E",  # pycodestyle errors
    "W",  # pycodestyle warnings
    "F",  # pyflakes
    "I",  # isort
    "B",  # flake8-bugbear
]
ignore = [
    "E501",  # line too long, handled by formatter
]

[tool.ruff.format]
quote-style = "double"
indent-style = "space"
skip-magic-trailing-comma = false
line-ending = "auto"

================
File: pipeline/pytest.ini
================
[pytest]
testpaths = tests
python_files = test_*.py
python_classes = Test*
python_functions = test_*

markers =
    unit: marks tests as unit tests
    integration: marks tests as integration tests
    slow: marks tests as slow (skipped by default)

addopts = --strict-markers -v

# Disable pytest-asyncio warnings
filterwarnings =
    ignore::DeprecationWarning:pytest_asyncio.*:

================
File: pipeline/README.md
================
# Document Pipeline Tool

A modular, pipeline-based Python tool for extracting structured data from various document formats (PDF, Excel, Word) into structured formats. This tool adheres to SOLID principles and employs the Strategy pattern to ensure extensibility, maintainability, and clear separation of concerns.

## Overview

The pipeline tool follows a structured approach:

- **Validation:** Validates document structure and extracts initial metadata
- **Preprocessing:** Normalizes formatting and prepares data
- **Data Extraction:** Parses and structures document data
- **Output Formatting:** Serializes structured data into the desired format
- **Verification & Reporting:** Validates extraction accuracy and generates reports

## Directory Structure

```
utils/pipeline/
├── __init__.py                # Package initialization
├── pipeline.py                # Core pipeline orchestration
├── pyproject.toml             # Project dependencies and configuration
├── config/                    # Configuration settings
├── data/                      # Sample data and output files
├── docs/                      # Documentation
│   └── pipeline-plan.md       # Architectural plan
├── models/                    # Data models and type definitions
├── processors/                # Core processing components
│   ├── validator.py           # Input validation
│   ├── extractor.py           # Data extraction
│   └── formatter.py           # Output formatting
├── strategies/                # Strategy pattern implementations
│   └── base.py                # Base strategy interfaces
└── utils/                     # Utility functions
    └── helpers.py             # Common helper functions
```

## Setup

### Prerequisites

- Python 3.8 or higher
- UV package manager (recommended)

### Creating a Virtual Environment

```bash
# Navigate to the pipeline directory
cd utils/pipeline

# Create a virtual environment with UV
uv venv

# Activate the virtual environment (Windows)
.venv\Scripts\activate

# Activate the virtual environment (Unix/Linux/Mac)
# source .venv/bin/activate
```

### Installing Dependencies

The project uses optional dependency groups to manage different document format processors:

```bash
# Install base dependencies only
uv pip install -e .

# Install specific document format processors
uv pip install -e ".[pdf]"     # PDF processing
uv pip install -e ".[excel]"   # Excel processing
uv pip install -e ".[word]"    # Word processing

# Install text analysis tools
uv pip install -e ".[analysis]"

# Install development tools
uv pip install -e ".[dev]"

# Install a minimal set of all document processors
uv pip install -e ".[all]"

# Install everything
uv pip install -e ".[pdf,excel,word,analysis,dev]"
```

If you encounter issues with the editable install syntax, you can install dependencies directly:

```bash
# Install base dependencies
uv pip install pyyaml typing-extensions

# Install document processors
uv pip install PyPDF2 pdfminer.six pymupdf pandas openpyxl python-docx
```

## Basic Usage

```python
from pipeline import Pipeline
from config import load_config

# Load configuration
config = load_config()

# Initialize pipeline
pipeline = Pipeline(config)

# Process a document
result = pipeline.run("path/to/document.pdf")

# Save the result
result.save("output.yaml")
```

## Extending the Pipeline

### Adding a New Document Format

1. Create a new strategy in the `strategies` directory
2. Implement the required interfaces (validation, extraction, formatting)
3. Register the strategy in the configuration

Example:

```python
# strategies/json_strategy.py
from strategies.base import ExtractionStrategy

class JSONExtractionStrategy(ExtractionStrategy):
    def extract(self, preprocessed_data):
        # Implementation for JSON extraction
        pass

# In your configuration
config = {
    "strategies": {
        "json": "strategies.json_strategy.JSONExtractionStrategy"
    }
}
```

## Development

### Testing

The project follows a Test-Driven Development (TDD) approach. Tests are organized in the `tests/` directory and mirror the structure of the main codebase.

#### Setting Up the Test Environment with UV

We recommend using UV for managing the Python environment and dependencies:

```bash
# Install UV if you don't have it already
# On Windows:
pip install uv
# On Unix/Linux/Mac:
# pip install uv

# Navigate to the pipeline directory
cd utils/pipeline

# Install pytest and dependencies
uv pip install pytest pytest-cov pytest-mock

# Install the pipeline package in development mode
uv pip install -e .
```

#### Running Tests with UV

After setting up the environment with UV, you can run the tests:

```bash
# Run all tests
uv run python -m pytest

# Run specific test files
uv run python -m pytest tests/test_config.py

# Run tests with specific markers
uv run python -m pytest -m "unit"
uv run python -m pytest -m "integration"

# Run tests with verbose output
uv run python -m pytest -v

# Run tests with coverage reporting
uv run python -m pytest --cov=.
```

#### Alternative: Using Traditional Virtual Environment

If you prefer using a traditional virtual environment approach:

```bash
# Set up the pytest environment
python setup_pytest_env.py

# Activate the virtual environment
# On Windows:
.venv\Scripts\activate
# On Unix/Linux/Mac:
# source .venv/bin/activate

# Run all tests
pytest

# Run specific test files
pytest tests/test_config.py
```

For convenience, we also provide a `run_tests.py` script that handles activating the virtual environment:

```bash
# Run all tests with coverage reporting
python run_tests.py

# Run specific test files
python run_tests.py tests/test_config.py
```

#### Test Data

Sample test data files are located in the `data/tests/` directory, organized by document type:

- `data/tests/pdf/`: Sample PDF files
- `data/tests/excel/`: Sample Excel files
- `data/tests/word/`: Sample Word files
- `data/tests/text/`: Sample text files

#### Test Coverage

The project uses pytest-cov for test coverage reporting and is configured to maintain a minimum coverage threshold of 80%. Coverage settings are defined in pyproject.toml:

```toml
[tool.coverage.run]
source = ["."]
omit = ["tests/*", "**/__init__.py", "**/__pycache__/*"]

[tool.coverage.report]
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "raise NotImplementedError",
    "if __name__ == .__main__.:",
    "pass",
    "raise ImportError",
]
show_missing = true
fail_under = 80
```

To set up and run test coverage:

1. Install development dependencies (includes pytest-cov):
```bash
cd utils/pipeline
uv pip install -e ".[dev]"
```

2. Run tests with coverage reporting:
```bash
# Basic coverage report
python -m pytest --cov=.

# Detailed coverage report showing missing lines
python -m pytest --cov=. --cov-report=term-missing

# Generate HTML coverage report
python -m pytest --cov=. --cov-report=html

# Run specific test file with coverage
python -m pytest tests/test_pipeline.py --cov=.
```

3. View coverage reports:
- Terminal report: Shows coverage percentage and optionally missing lines
- HTML report: Open coverage_html/index.html in your browser for a detailed interactive report

4. Coverage enforcement:
- Tests will fail if coverage drops below 80%
- Use `# pragma: no cover` to exclude specific lines that shouldn't be counted
- Edit fail_under in pyproject.toml to adjust the minimum coverage threshold

#### Test Configuration

The pytest configuration is defined in `pytest.ini` and includes:

- Test discovery patterns
- Test markers for categorizing tests
- Command-line options

### Code Style

The project uses ruff for linting and formatting:

```bash
# Check code style
ruff check .

# Format code
ruff format .
```

### Type Checking

The project uses mypy for static type checking:

```bash
# Run type checking
mypy .
```

## Architecture

For detailed information about the architecture and design principles, see [pipeline-plan.md](docs/pipeline-plan.md).

### Architecture Diagrams

#### Pipeline Flow Diagram

A visual representation of the pipeline architecture is available as a PlantUML diagram at [pipeline_diagram.puml](docs/pipeline_diagram.puml).

This diagram shows the high-level flow: Input → Analyzer → Cleaner → Extractor → Validator → Output, along with the relationships between all modules in the system.

#### C4 Architecture Diagram

A more detailed C4 model architecture diagram is available at [pipeline_c4_diagram.puml](docs/pipeline_c4_diagram.puml).

The C4 diagram provides multiple levels of abstraction:
1. **Context Level**: Shows how the pipeline tool interacts with users and external systems
2. **Container Level**: Shows the high-level components of the pipeline tool
3. **Component Level**: Shows the internal components of the Pipeline Core and Strategy Engine

### Visualizing the Diagrams

You can visualize these diagrams in several ways:

1. **VSCode Extension**: Install the "PlantUML" extension in VSCode, then open the .puml file and use Alt+D to preview.

2. **Online PlantUML Server**: Copy the content of the .puml file and paste it into the [PlantUML Online Server](http://www.plantuml.com/plantuml/uml/).

3. **Command Line**:
   ```bash
   # Install PlantUML (requires Java)
   # On Windows with Chocolatey
   choco install plantuml
   
   # On macOS with Homebrew
   brew install plantuml
   
   # Generate PNG image
   plantuml docs/pipeline_diagram.puml
   plantuml docs/pipeline_c4_diagram.puml
   ```

Note: The C4 diagram requires internet access during rendering to fetch the C4 PlantUML standard library.

================
File: pipeline/rename_input_files.py
================
"""
Script to rename input files with a QUOTE_ prefix.
"""

import shutil
from pathlib import Path


def rename_files_with_prefix(directory, prefix="QUOTE_"):
    """
    Rename all files in the directory with the given prefix.

    Args:
        directory: Directory containing files to rename
        prefix: Prefix to add to filenames
    """
    directory_path = Path(directory)

    if not directory_path.exists() or not directory_path.is_dir():
        print(f"Directory {directory} does not exist or is not a directory")
        return

    # Create a backup directory
    backup_dir = directory_path / "original_files_backup"
    backup_dir.mkdir(exist_ok=True)

    # Get all files in the directory
    files = [f for f in directory_path.iterdir() if f.is_file()]

    renamed_count = 0
    for file_path in files:
        # Skip files that already have the prefix
        if file_path.name.startswith(prefix):
            continue

        # Create backup
        backup_path = backup_dir / file_path.name
        shutil.copy2(file_path, backup_path)

        # Create new filename with prefix
        new_name = f"{prefix}{file_path.name}"
        new_path = file_path.parent / new_name

        # Rename file
        try:
            file_path.rename(new_path)
            renamed_count += 1
            print(f"Renamed: {file_path.name} -> {new_name}")
        except Exception as e:
            print(f"Error renaming {file_path.name}: {str(e)}")

    print(f"\nRenamed {renamed_count} files")
    print(f"Original files backed up to {backup_dir}")


if __name__ == "__main__":
    input_dir = Path(__file__).parent / "data" / "input"
    rename_files_with_prefix(input_dir, "QUOTE_")

================
File: pipeline/requirements-dev.txt
================
# Development dependencies with specific versions to avoid compatibility issues
pytest==7.4.0
pytest-cov==4.1.0
pytest-mock==3.11.1
pytest-xdist==3.3.1
pytest-sugar==0.9.7

# Type checking
mypy==1.5.1
types-PyYAML==6.0.12.12

# Linting and formatting
ruff==0.0.292
black==23.7.0

# Documentation
sphinx==7.2.6
sphinx-rtd-theme==1.3.0

# Core dependencies
pyyaml>=6.0.1
typing-extensions>=4.7.1

================
File: pipeline/run_pipeline.py
================
#!/usr/bin/env python3
"""
Pipeline command-line entry point.

This script provides a command-line interface for running the pipeline on input files.
It supports both single file and batch processing modes.
"""

import argparse
import json
import sys
from pathlib import Path
from typing import Dict, Optional

from utils.pipeline.core.file_processor import FileProcessor
from utils.pipeline.utils.logging import get_logger
from utils.pipeline.utils.progress import PipelineProgress

# Default configuration
DEFAULT_CONFIG = {
    "output_format": "json",
    "strategies": {
        "pdf": {
            "analyzer": "utils.pipeline.analyzer.pdf.PDFAnalyzer",
            "cleaner": "utils.pipeline.cleaner.pdf.PDFCleaner",
            "extractor": "utils.pipeline.processors.pdf_extractor.PDFExtractor",
            "validator": "utils.pipeline.processors.pdf_validator.PDFValidator",
        },
    },
    "file_processing": {
        "input": {
            "patterns": ["*.pdf"],
            "recursive": False,
        },
        "output": {
            "formats": ["json"],
            "structure": "flat",
            "naming": {
                "template": "{original_name}",
            },
            "overwrite": True,
        },
        "reporting": {
            "summary": True,
            "detailed": True,
            "format": "json",
            "save_path": "processing_report.json",
        },
    },
}


def load_config(config_path: Optional[Path] = None) -> Dict:
    """
    Load configuration from file or use defaults.

    Args:
        config_path: Optional path to configuration file

    Returns:
        Configuration dictionary
    """
    config = DEFAULT_CONFIG.copy()

    if config_path and config_path.exists():
        with open(config_path) as f:
            file_config = json.load(f)
            # Deep merge configs
            for key, value in file_config.items():
                if isinstance(value, dict) and key in config:
                    config[key].update(value)
                else:
                    config[key] = value

    return config


def parse_args() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Process documents using the pipeline",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Process all PDFs in input directory
  python -m utils.pipeline.run_pipeline --input data/input --output data/output

  # Process specific file
  python -m utils.pipeline.run_pipeline --file document.pdf --output output/

  # Use custom config file
  python -m utils.pipeline.run_pipeline --input data/input --config pipeline_config.json

  # Specify output formats
  python -m utils.pipeline.run_pipeline --input data/input --formats json,markdown
  
  # Analyze schemas
  python -m utils.pipeline.run_pipeline --analyze-schemas
  
  # Compare schemas
  python -m utils.pipeline.run_pipeline --compare-schemas schema1_id schema2_id
  
  # Visualize schemas
  python -m utils.pipeline.run_pipeline --visualize-schemas clusters
""",
    )

    input_group = parser.add_mutually_exclusive_group()
    input_group.add_argument(
        "-i",
        "--input",
        type=Path,
        help="Input directory containing files to process",
    )
    input_group.add_argument("-f", "--file", type=Path, help="Single file to process")

    # Schema analysis arguments
    input_group.add_argument(
        "--analyze-schemas", action="store_true", help="Analyze existing schemas"
    )
    input_group.add_argument(
        "--compare-schemas",
        nargs=2,
        metavar=("SCHEMA1", "SCHEMA2"),
        help="Compare two schemas",
    )
    input_group.add_argument(
        "--visualize-schemas",
        choices=["clusters", "features", "structure", "tables"],
        help="Visualize schemas",
    )

    parser.add_argument("--document-type", help="Filter schemas by document type")

    parser.add_argument(
        "-o",
        "--output",
        type=Path,
        help="Output directory for processed files",
    )
    parser.add_argument("-c", "--config", type=Path, help="Path to configuration file")
    parser.add_argument(
        "--formats",
        help="Comma-separated list of output formats (e.g., json,markdown)",
    )
    parser.add_argument(
        "-r",
        "--recursive",
        action="store_true",
        help="Recursively process subdirectories",
    )
    parser.add_argument(
        "-p",
        "--pattern",
        help="File pattern to match (e.g., '*.pdf', defaults to all PDFs)",
    )
    parser.add_argument(
        "--report",
        type=Path,
        help="Path to save processing report (defaults to output_dir/processing_report.json)",
    )

    return parser.parse_args()


def update_config_from_args(config: Dict, args: argparse.Namespace) -> Dict:
    """
    Update configuration with command line arguments.

    Args:
        config: Base configuration dictionary
        args: Parsed command line arguments

    Returns:
        Updated configuration dictionary
    """
    # Update formats if specified
    if args.formats:
        formats = [fmt.strip().lower() for fmt in args.formats.split(",")]
        config["file_processing"]["output"]["formats"] = formats

    # Update input settings
    if args.pattern:
        config["file_processing"]["input"]["patterns"] = [args.pattern]
    config["file_processing"]["input"]["recursive"] = args.recursive

    # Update report path if specified
    if args.report:
        config["file_processing"]["reporting"]["save_path"] = str(args.report)

    return config


def main():
    """Main entry point for the pipeline."""
    # Add parent directory to path to allow imports
    sys.path.insert(0, str(Path(__file__).parent.parent.parent))

    # Set up logging
    logger = get_logger(__name__)
    progress = PipelineProgress()

    try:
        # Parse arguments
        args = parse_args()

        # Handle schema analysis commands
        if args.analyze_schemas or args.compare_schemas or args.visualize_schemas:
            from utils.pipeline.schema.extended_registry import ExtendedSchemaRegistry

            registry = ExtendedSchemaRegistry()

            if args.analyze_schemas:
                progress.display_success("Analyzing schemas...")
                analysis = registry.analyze(args.document_type)

                # Display analysis results
                progress.display_success("\nSchema Analysis Results:")
                progress.display_success(
                    f"Total Schemas: {analysis.get('schema_count', 0)}"
                )

                doc_types = analysis.get("document_types", {})
                if doc_types:
                    progress.display_success("\nDocument Types:")
                    for doc_type, count in doc_types.items():
                        progress.display_success(f"  {doc_type}: {count}")

                # Display common metadata fields
                common_metadata = analysis.get("common_metadata", {})
                if common_metadata:
                    progress.display_success("\nCommon Metadata Fields:")
                    for field, frequency in sorted(
                        common_metadata.items(), key=lambda x: x[1], reverse=True
                    ):
                        progress.display_success(f"  {field}: {frequency:.2f}")

                return

            elif args.compare_schemas:
                schema_id1, schema_id2 = args.compare_schemas
                progress.display_success(
                    f"Comparing schemas: {schema_id1} vs {schema_id2}"
                )

                comparison = registry.compare(schema_id1, schema_id2)

                progress.display_success(
                    f"Overall Similarity: {comparison.get('overall_similarity', 0):.2f}"
                )
                progress.display_success(
                    f"Same Document Type: {comparison.get('same_document_type', False)}"
                )

                # Display metadata comparison
                metadata_comparison = comparison.get("metadata_comparison", {})
                if metadata_comparison:
                    progress.display_success("\nMetadata Comparison:")
                    progress.display_success(
                        f"  Similarity: {metadata_comparison.get('similarity', 0):.2f}"
                    )
                    progress.display_success(
                        f"  Common Fields: {len(metadata_comparison.get('common_fields', []))}"
                    )

                return

            elif args.visualize_schemas:
                viz_type = args.visualize_schemas
                progress.display_success(f"Generating {viz_type} visualization...")

                # Create visualizations directory
                import os

                viz_dir = os.path.join(
                    "utils", "pipeline", "schema", "data", "visualizations"
                )
                os.makedirs(viz_dir, exist_ok=True)

                viz_path = registry.visualize(viz_type, output_dir=viz_dir)
                progress.display_success(f"Visualization saved to: {viz_path}")
                return

        # Load and update configuration
        config = load_config(args.config)
        config = update_config_from_args(config, args)

        # Check if required arguments are provided for document processing
        if not args.input and not args.file:
            progress.display_error(
                "Error: Either --input or --file is required for document processing"
            )
            sys.exit(1)

        if not args.output:
            progress.display_error(
                "Error: --output is required for document processing"
            )
            sys.exit(1)

        # Create output directory
        args.output.mkdir(parents=True, exist_ok=True)

        # Initialize processor
        if args.file:
            # Single file mode
            processor = FileProcessor(args.file.parent, args.output, config)
            progress.display_success(f"Processing single file: {args.file.name}")
            data, path = processor.process_single_file(args.file)
            progress.display_success(f"Output saved to: {Path(path).name}")

        else:
            # Batch mode
            processor = FileProcessor(args.input, args.output, config)
            progress.display_success(f"Processing files from: {args.input}")
            results = processor.process_all_files()

            # Display summary
            summary = {
                f"{r['file']}": {
                    "status": r["status"],
                    "outputs": r.get("outputs", []),
                }
                for r in results
            }
            progress.display_summary(summary)

    except Exception as e:
        logger.error(f"Pipeline processing failed: {str(e)}", exc_info=True)
        progress.display_error(f"Error: {str(e)}")
        sys.exit(1)


if __name__ == "__main__":
    main()

================
File: pipeline/run_tests.py
================
#!/usr/bin/env python
"""
Script to run tests with the pytest environment.

This script:
1. Activates the virtual environment if it exists
2. Runs pytest with the specified arguments
3. Generates a coverage report
"""

import os
import subprocess
import sys
from pathlib import Path


def find_venv_python():
    """Find the Python executable in the virtual environment."""
    script_dir = Path(__file__).resolve().parent
    venv_dir = script_dir / ".venv"

    if sys.platform == "win32":
        python_exe = venv_dir / "Scripts" / "python.exe"
    else:
        python_exe = venv_dir / "bin" / "python"

    if python_exe.exists():
        return str(python_exe)

    return sys.executable


def run_tests(args=None):
    """Run tests with coverage reporting."""
    if args is None:
        args = []

    # Get the directory of this script
    script_dir = Path(__file__).resolve().parent

    # Change to the script directory
    os.chdir(script_dir)

    # Find the Python executable in the virtual environment
    python_exe = find_venv_python()

    # Build the command
    cmd = [
        python_exe,
        "-m",
        "pytest",
        "--cov=.",
        "--cov-report=term",
        "--cov-report=html:coverage_html",
    ]
    cmd.extend(args)

    print(f"Running: {' '.join(cmd)}")

    try:
        # Run the command
        result = subprocess.run(cmd, capture_output=False)

        if result.returncode == 0:
            print("\n✅ All tests passed!")
        else:
            print("\n❌ Some tests failed.")

        print("\nCoverage report generated in coverage_html/index.html")
        return result.returncode
    except Exception as e:
        print(f"Error running tests: {e}")
        return 1


def check_venv():
    """Check if the virtual environment is set up."""
    script_dir = Path(__file__).resolve().parent
    venv_dir = script_dir / ".venv"

    if not venv_dir.exists():
        print("Virtual environment not found.")
        print("Please run setup_pytest_env.py to create it:")
        print("  python setup_pytest_env.py")
        return False

    return True


def main():
    """Main entry point."""
    if not check_venv():
        return 1

    # Pass any command line arguments to pytest
    args = sys.argv[1:]
    return run_tests(args)


if __name__ == "__main__":
    sys.exit(main())

================
File: pipeline/SCHEMA_VISUALIZATION.md
================
# Schema Visualization

This document explains how to use the schema visualization tools to explore and understand document schemas.

## Overview

The schema visualization tools allow you to:

1. Visualize the structure of document schemas
2. Compare schemas across different document types
3. Explore table patterns and structures
4. Analyze common features across schemas

## Prerequisites

The visualization tools require several Python packages:

```bash
pip install matplotlib numpy networkx scikit-learn seaborn pandas
```

For improved graph layouts, you may also want to install:

```bash
pip install pygraphviz
```

## Command-Line Usage

The `visualize_schema.py` script provides a command-line interface for schema visualization:

```bash
# List all available schemas
python -m utils.pipeline.visualize_schema list

# Generate cluster visualization (all schemas)
python -m utils.pipeline.visualize_schema clusters

# Generate feature comparison (all schemas)
python -m utils.pipeline.visualize_schema features

# Generate structure visualization for a specific schema
python -m utils.pipeline.visualize_schema structure <schema_id>

# Generate table pattern visualization for a specific schema
python -m utils.pipeline.visualize_schema tables <schema_id>

# Show help
python -m utils.pipeline.visualize_schema help
```

## Visualization Types

### Cluster Visualization

The cluster visualization uses t-SNE dimensionality reduction to plot schemas in a 2D space based on their similarity. Schemas that are more similar will appear closer together. This can help identify patterns and groupings across document types.

![Cluster Visualization Example](schema/data/visualizations/schema_clusters.png)

### Feature Comparison

The feature comparison creates a heatmap showing key features across schemas, such as:
- Number of metadata fields
- Section count
- Table count
- Average rows per table
- Maximum depth of section hierarchy
- Number of tables with headers

This visualization helps identify similarities and differences in schema structure.

![Feature Comparison Example](schema/data/visualizations/schema_features.png)

### Structure Visualization

The structure visualization creates a hierarchical graph showing the structure of a specific schema, including:
- Metadata fields
- Section hierarchy
- Table information

This visualization helps understand the organization of a specific document.

![Structure Visualization Example](schema/data/visualizations/structure_example.png)

### Table Pattern Visualization

The table pattern visualization provides insights into table structures within a schema:

1. **Table Size Distribution**: Shows the distribution of table sizes (rows per table)
2. **Table Size Categories**: Categorizes tables as small, medium, or large
3. **Common Headers**: Shows the most common table headers (if available)
4. **Column Count Distribution**: Shows the distribution of column counts
5. **Sample Table Data**: Displays a sample of actual table data (if available)

![Table Pattern Example](schema/data/visualizations/tables_example.png)

## Programmatic Usage

You can also use the visualization tools programmatically:

```python
from utils.pipeline.schema.extended_registry import ExtendedSchemaRegistry

# Initialize registry
registry = ExtendedSchemaRegistry()

# Generate visualizations
output_dir = "path/to/output/directory"

# Cluster visualization
registry.visualize("clusters", output_dir=output_dir)

# Feature comparison
registry.visualize("features", output_dir=output_dir)

# Structure visualization for a specific schema
registry.visualize("structure", ["schema_id"], output_dir=output_dir)

# Table pattern visualization for a specific schema
registry.visualize("tables", ["schema_id"], output_dir=output_dir)
```

## Enhanced Schema Data

The visualizations now take advantage of enhanced schema data, including:

- Actual metadata values (not just field names)
- Content samples from document sections
- Table headers and sample data
- Column counts and structure

This enhanced data provides more detailed and informative visualizations, especially for table patterns.

## Customizing Visualizations

You can customize the visualizations by modifying the `SchemaVisualizer` class in `utils/pipeline/schema/visualizer.py`. For example, you can:

- Change color schemes
- Adjust figure sizes
- Add new visualization types
- Modify existing visualizations

## Troubleshooting

If you encounter issues with the visualizations:

1. **Missing dependencies**: Ensure you have installed all required packages
2. **No schemas found**: Run the pipeline on some documents to generate schemas
3. **Visualization errors**: Check the error message for specific issues
4. **Empty visualizations**: Ensure the schemas contain the necessary data

## Configuration

The schema visualization tools use the same configuration as the pipeline. You can customize the visualization behavior by modifying the pipeline configuration.

================
File: pipeline/schema/__init__.py
================
"""
Schema package for document classification.

This package provides functionality for managing document schemas.
"""

================
File: pipeline/schema/analyzer.py
================
"""
Schema analyzer module.

This module provides functionality for analyzing and comparing document schemas.
"""

import json
from typing import Any, Dict, List, Optional

from utils.pipeline.utils.logging import get_logger


class SchemaAnalyzer:
    """
    Analyzes document schemas to extract patterns and insights.

    This class provides functionality for:
    1. Analyzing schemas to extract patterns and insights
    2. Comparing schemas to identify similarities and differences
    3. Clustering similar schemas together
    """

    def __init__(self, registry, config: Optional[Dict[str, Any]] = None):
        """
        Initialize the schema analyzer.

        Args:
            registry: Schema registry instance
            config: Configuration dictionary for the analyzer
        """
        self.registry = registry
        self.config = config or {}
        self.logger = get_logger(__name__)

        # Default configuration
        self.default_config = {
            "similarity_threshold": 0.7,
            "cluster_method": "hierarchical",
            "feature_weights": {"metadata": 0.3, "structure": 0.4, "tables": 0.3},
        }

        # Merge with provided config
        for key, value in self.default_config.items():
            if key not in self.config:
                self.config[key] = value

    def analyze_schemas(self, document_type: Optional[str] = None) -> Dict[str, Any]:
        """
        Analyze schemas to extract patterns and insights.

        Args:
            document_type: Optional document type to filter by

        Returns:
            Analysis results
        """
        # Get schemas to analyze
        schemas = self.registry.list_schemas(document_type)

        if not schemas:
            return {"error": "No schemas found for analysis"}

        # Analyze document types
        doc_types = {}
        for schema in schemas:
            doc_type = schema.get("document_type", "UNKNOWN")
            doc_types[doc_type] = doc_types.get(doc_type, 0) + 1

        # Analyze metadata fields
        common_metadata = self._find_common_metadata(schemas)

        # Analyze table patterns
        table_patterns = self._analyze_table_patterns(schemas)

        # Analyze section patterns
        section_patterns = self._analyze_section_patterns(schemas)

        return {
            "schema_count": len(schemas),
            "document_types": doc_types,
            "common_metadata": common_metadata,
            "table_patterns": table_patterns,
            "section_patterns": section_patterns,
        }

    def compare_schemas(self, schema_id1: str, schema_id2: str) -> Dict[str, Any]:
        """
        Compare two schemas and identify similarities and differences.

        Args:
            schema_id1: ID of first schema
            schema_id2: ID of second schema

        Returns:
            Comparison results
        """
        schema1 = self.registry.get_schema(schema_id1)
        schema2 = self.registry.get_schema(schema_id2)

        if not schema1:
            return {"error": f"Schema {schema_id1} not found"}
        if not schema2:
            return {"error": f"Schema {schema_id2} not found"}

        # Use existing matcher for comparison
        from utils.pipeline.schema.matchers import StructureMatcher

        matcher = StructureMatcher()
        similarity = matcher.match(schema1, schema2)

        # Detailed comparison
        comparison = {
            "overall_similarity": similarity,
            "same_document_type": schema1.get("document_type")
            == schema2.get("document_type"),
            "metadata_comparison": self._compare_metadata(schema1, schema2),
            "structure_comparison": self._compare_structure(schema1, schema2),
            "table_comparison": self._compare_tables(schema1, schema2),
        }

        return comparison

    def cluster_schemas(
        self, similarity_threshold: Optional[float] = None
    ) -> List[List[str]]:
        """
        Cluster schemas based on similarity.

        Args:
            similarity_threshold: Minimum similarity threshold for clustering

        Returns:
            List of clusters, where each cluster is a list of schema IDs
        """
        if similarity_threshold is None:
            similarity_threshold = self.config["similarity_threshold"]

        # Get all schemas
        schemas = self.registry.list_schemas()
        if not schemas:
            return []

        # Extract schema IDs
        schema_ids = [schema["id"] for schema in schemas]

        # Implement a simple hierarchical clustering
        clusters = []
        processed = set()

        for schema_id1 in schema_ids:
            if schema_id1 in processed:
                continue

            cluster = [schema_id1]
            processed.add(schema_id1)

            for schema_id2 in schema_ids:
                if schema_id2 in processed or schema_id1 == schema_id2:
                    continue

                comparison = self.compare_schemas(schema_id1, schema_id2)
                if (
                    "error" not in comparison
                    and comparison["overall_similarity"] >= similarity_threshold
                ):
                    cluster.append(schema_id2)
                    processed.add(schema_id2)

            clusters.append(cluster)

        return clusters

    def get_schema_summary(self, schema_id: Optional[str] = None) -> Dict[str, Any]:
        """
        Get a summary of a schema or all schemas.

        Args:
            schema_id: ID of the schema to summarize, or None for all schemas

        Returns:
            Dictionary with schema summary information
        """
        if schema_id:
            schema = self.registry.get_schema(schema_id)
            if not schema:
                return {"error": f"Schema {schema_id} not found"}
            return self._summarize_schema(schema_id, schema)

        # Summarize all schemas
        summaries = {}
        for schema in self.registry.list_schemas():
            if "id" in schema:
                schema_id = schema["id"]
                summaries[schema_id] = self._summarize_schema(schema_id, schema)

        return summaries

    def export_analysis(
        self, analysis: Dict[str, Any], output_path: str, format: str = "json"
    ) -> str:
        """
        Export analysis results to file.

        Args:
            analysis: Analysis results to export
            output_path: Path to save the results
            format: Export format (json, csv)

        Returns:
            Path to the exported file
        """
        try:
            if format == "json":
                with open(output_path, "w", encoding="utf-8") as f:
                    json.dump(analysis, f, indent=2)
            elif format == "csv":
                # Convert to CSV format
                try:
                    import pandas as pd

                    # Convert analysis to DataFrame
                    # This is a simplified conversion - would need to be adapted for different analyses
                    if "document_types" in analysis:
                        df = pd.DataFrame(
                            list(analysis["document_types"].items()),
                            columns=["Document Type", "Count"],
                        )
                        df.to_csv(output_path, index=False)
                    else:
                        # Generic fallback
                        with open(output_path, "w", encoding="utf-8") as f:
                            f.write(
                                "Analysis results cannot be converted to CSV format\n"
                            )
                            f.write(
                                f"Please use JSON format instead: {json.dumps(analysis, indent=2)}"
                            )
                except ImportError:
                    return "Error: pandas is required for CSV export. Please install it or use JSON format."
            else:
                return f"Unsupported export format: {format}"

            return output_path
        except Exception as e:
            self.logger.error(f"Error exporting analysis: {str(e)}", exc_info=True)
            return f"Error exporting analysis: {str(e)}"

    def _find_common_metadata(self, schemas: List[Dict[str, Any]]) -> Dict[str, float]:
        """Find common metadata fields across schemas."""
        field_counts = {}

        for schema in schemas:
            metadata_fields = schema.get("metadata_fields", [])
            for field in metadata_fields:
                field_counts[field] = field_counts.get(field, 0) + 1

        # Calculate frequency (percentage of schemas with each field)
        total_schemas = len(schemas)
        return {field: count / total_schemas for field, count in field_counts.items()}

    def _analyze_table_patterns(self, schemas: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analyze table patterns across schemas."""
        # Count schemas with tables
        schemas_with_tables = sum(
            1 for schema in schemas if schema.get("table_count", 0) > 0
        )

        # Calculate average tables per schema
        total_tables = sum(schema.get("table_count", 0) for schema in schemas)
        avg_tables = total_tables / len(schemas) if schemas else 0

        # Analyze table structures
        row_counts = []
        header_counts = []

        for schema in schemas:
            table_structures = schema.get("table_structure", [])
            for table in table_structures:
                row_counts.append(table.get("row_count", 0))
                header_counts.append(table.get("header_count", 0))

        return {
            "schemas_with_tables": schemas_with_tables,
            "schemas_with_tables_pct": schemas_with_tables / len(schemas)
            if schemas
            else 0,
            "avg_tables_per_schema": avg_tables,
            "avg_rows_per_table": sum(row_counts) / len(row_counts)
            if row_counts
            else 0,
            "avg_headers_per_table": sum(header_counts) / len(header_counts)
            if header_counts
            else 0,
            "tables_with_headers_pct": sum(1 for h in header_counts if h > 0)
            / len(header_counts)
            if header_counts
            else 0,
        }

    def _analyze_section_patterns(
        self, schemas: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """Analyze section patterns across schemas."""
        # Count schemas with sections
        schemas_with_sections = sum(
            1 for schema in schemas if schema.get("section_count", 0) > 0
        )

        # Calculate average sections per schema
        total_sections = sum(schema.get("section_count", 0) for schema in schemas)
        avg_sections = total_sections / len(schemas) if schemas else 0

        return {
            "schemas_with_sections": schemas_with_sections,
            "schemas_with_sections_pct": schemas_with_sections / len(schemas)
            if schemas
            else 0,
            "avg_sections_per_schema": avg_sections,
        }

    def _summarize_schema(
        self, schema_id: Any, schema: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Generate a summary for a single schema."""
        summary = {
            "schema_id": schema_id,
            "document_type": schema.get("document_type", "UNKNOWN"),
            "recorded_at": schema.get("recorded_at", "Unknown"),
            "metadata_fields": len(schema.get("metadata_fields", [])),
            "section_count": schema.get("section_count", 0),
            "table_count": schema.get("table_count", 0),
        }

        # Analyze table structure
        table_structure = schema.get("table_structure", [])
        if table_structure:
            summary["avg_rows_per_table"] = sum(
                t.get("row_count", 0) for t in table_structure
            ) / len(table_structure)
            summary["tables_with_headers"] = sum(
                1 for t in table_structure if t.get("has_headers", False)
            )

        # Analyze content structure
        content_structure = schema.get("content_structure", [])
        if content_structure:
            summary["max_section_depth"] = self._get_max_section_depth(
                content_structure
            )

        return summary

    def _get_max_section_depth(self, structure, current_depth=1):
        """Recursively find the maximum depth of nested sections."""
        if not structure:
            return current_depth - 1

        max_depth = current_depth
        for section in structure:
            if "children" in section and section["children"]:
                child_depth = self._get_max_section_depth(
                    section["children"], current_depth + 1
                )
                max_depth = max(max_depth, child_depth)

        return max_depth

    def _compare_metadata(
        self, schema1: Dict[str, Any], schema2: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Compare metadata fields between schemas."""
        fields1 = set(schema1.get("metadata_fields", []))
        fields2 = set(schema2.get("metadata_fields", []))

        common = fields1.intersection(fields2)
        only_in_1 = fields1 - fields2
        only_in_2 = fields2 - fields1

        return {
            "common_fields": list(common),
            "only_in_schema1": list(only_in_1),
            "only_in_schema2": list(only_in_2),
            "similarity": len(common) / len(fields1.union(fields2))
            if fields1 or fields2
            else 1.0,
        }

    def _compare_structure(
        self, schema1: Dict[str, Any], schema2: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Compare content structure between schemas."""
        section_count1 = schema1.get("section_count", 0)
        section_count2 = schema2.get("section_count", 0)

        structure1 = schema1.get("content_structure", [])
        structure2 = schema2.get("content_structure", [])

        # Use a simplified structure comparison
        return {
            "section_count_1": section_count1,
            "section_count_2": section_count2,
            "section_count_diff": abs(section_count1 - section_count2),
            "similarity": min(section_count1, section_count2)
            / max(section_count1, section_count2)
            if max(section_count1, section_count2) > 0
            else 1.0,
        }

    def _compare_tables(
        self, schema1: Dict[str, Any], schema2: Dict[str, Any]
    ) -> Dict[str, Any]:
        """Compare table structure between schemas."""
        table_count1 = schema1.get("table_count", 0)
        table_count2 = schema2.get("table_count", 0)

        tables1 = schema1.get("table_structure", [])
        tables2 = schema2.get("table_structure", [])

        # Calculate average rows per table
        avg_rows1 = (
            sum(t.get("row_count", 0) for t in tables1) / table_count1
            if table_count1 > 0
            else 0
        )
        avg_rows2 = (
            sum(t.get("row_count", 0) for t in tables2) / table_count2
            if table_count2 > 0
            else 0
        )

        return {
            "table_count_1": table_count1,
            "table_count_2": table_count2,
            "table_count_diff": abs(table_count1 - table_count2),
            "avg_rows_1": avg_rows1,
            "avg_rows_2": avg_rows2,
            "avg_rows_diff": abs(avg_rows1 - avg_rows2),
            "count_similarity": min(table_count1, table_count2)
            / max(table_count1, table_count2)
            if max(table_count1, table_count2) > 0
            else 1.0,
        }

================
File: pipeline/schema/data/schemas/form_20250314231329.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 18
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 13
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    }
  ],
  "section_count": 0,
  "table_count": 77,
  "document_type": "FORM",
  "recorded_at": "2025-03-14T23:13:29.840125",
  "document_name": "TO"
}

================
File: pipeline/schema/data/schemas/form_20250314231331.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 18
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 13
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    }
  ],
  "section_count": 0,
  "table_count": 77,
  "document_type": "FORM",
  "recorded_at": "2025-03-14T23:13:31.290767",
  "document_name": "TO"
}

================
File: pipeline/schema/data/schemas/form_20250314231332.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 25
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 21
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 18
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 15
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    }
  ],
  "section_count": 0,
  "table_count": 6,
  "document_type": "FORM",
  "recorded_at": "2025-03-14T23:13:32.962343"
}

================
File: pipeline/schema/data/schemas/form_20250314231335.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 9
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    }
  ],
  "section_count": 0,
  "table_count": 10,
  "document_type": "FORM",
  "recorded_at": "2025-03-14T23:13:35.438838",
  "document_name": "2022 Denver Building and Fire Code"
}

================
File: pipeline/schema/data/schemas/form_20250314231336.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 9
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    }
  ],
  "section_count": 0,
  "table_count": 10,
  "document_type": "FORM",
  "recorded_at": "2025-03-14T23:13:36.420014",
  "document_name": "2022 Denver Building and Fire Code"
}

================
File: pipeline/schema/data/schemas/form_20250314231339.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 16
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 12
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 20
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 9
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 15
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 9
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 13
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 9
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 14
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 15
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 15
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 14
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 9
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 9
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 55
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 56
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 55
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 53
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 26
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 9
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 21
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 15
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 46
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 30
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 53
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 22
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 12
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 9
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 12
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 12
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 16
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 12
    }
  ],
  "section_count": 0,
  "table_count": 308,
  "document_type": "FORM",
  "recorded_at": "2025-03-14T23:13:39.091050",
  "document_name": "HVAC Quality Installation Specification (ACCA Standard 5)"
}

================
File: pipeline/schema/data/schemas/form_20250314231340.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 25
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 16
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    }
  ],
  "section_count": 0,
  "table_count": 10,
  "document_type": "FORM",
  "recorded_at": "2025-03-14T23:13:40.779781"
}

================
File: pipeline/schema/data/schemas/form_20250314231341.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 25
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 16
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    }
  ],
  "section_count": 0,
  "table_count": 10,
  "document_type": "FORM",
  "recorded_at": "2025-03-14T23:13:41.442894"
}

================
File: pipeline/schema/data/schemas/form_20250314231343.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 13
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 14
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 14
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 12
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 12
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 12
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 9
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 27
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 14
    }
  ],
  "section_count": 0,
  "table_count": 76,
  "document_type": "FORM",
  "recorded_at": "2025-03-14T23:13:43.484251"
}

================
File: pipeline/schema/data/schemas/form_20250314231344.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 13
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 14
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 3
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 14
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 12
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 7
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 8
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 12
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 12
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 5
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 9
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 6
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 11
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 10
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 27
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 4
    },
    {
      "has_headers": false,
      "header_count": 0,
      "row_count": 14
    }
  ],
  "section_count": 0,
  "table_count": 76,
  "document_type": "FORM",
  "recorded_at": "2025-03-14T23:13:44.640555"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314230806.json
================
{
  "metadata_fields": [],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:08:06.952208"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314230807.json
================
{
  "metadata_fields": [],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:08:07.450032"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314230809.json
================
{
  "metadata_fields": [],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:08:09.725308"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231152.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:11:52.739084",
  "document_name": "SECTION 230516 - EXPANSION FITTINGS AND LOOPS FOR HVAC PIPING"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231153.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:11:53.324648",
  "document_name": "SECTION 230516 - EXPANSION FITTINGS AND LOOPS FOR HVAC PIPING"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231154.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:11:54.803852",
  "document_name": "SECTION 232500 - HVAC WATER TREATMENT"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231156.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:11:56.756326",
  "document_name": "SECTION 232513 - WATER TREATMENT FOR CLOSED-LOOP HYDRONIC SYSTEMS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231157.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:11:57.948976",
  "document_name": "SECTION 232516 - WATER TREATMENT FOR OPEN-LOOP HYDRONIC SYSTEMS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231158.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:11:58.688729",
  "document_name": "SECTION 232516 - WATER TREATMENT FOR OPEN-LOOP HYDRONIC SYSTEMS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231159.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:11:59.325442",
  "document_name": "SECTION 232519 - WATER TREATMENT FOR STEAM SYSTEM FEEDWATER"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231200.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:00.125113",
  "document_name": "SECTION 232519 - WATER TREATMENT FOR STEAM SYSTEM FEEDWATER"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231201.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:01.163891",
  "document_name": "SECTION 233713 - DIFFUSERS, REGISTERS, AND GRILLES"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231202.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:02.092485",
  "document_name": "SECTION 233713 - DIFFUSERS, REGISTERS, AND GRILLES"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231203.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:03.332300",
  "document_name": "SECTION 233723 - HVAC GRAVITY VENTILATORS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231204.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:04.245900",
  "document_name": "SECTION 233723 - HVAC GRAVITY VENTILATORS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231205.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:05.775581",
  "document_name": "SECTION 233813 - COMMERCIAL-KITCHEN HOODS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231206.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:06.915813",
  "document_name": "SECTION 233813 - COMMERCIAL-KITCHEN HOODS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231208.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:08.027039",
  "document_name": "SECTION 234100 - PARTICULATE AIR FILTRATION"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231209.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:09.218839",
  "document_name": "SECTION 234100 - PARTICULATE AIR FILTRATION"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231210.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:10.962606",
  "document_name": "SECTION 234133 - HIGH-EFFICIENCY PARTICULATE FILTRATION"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231212.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:12.138170",
  "document_name": "SECTION 234200 - GAS-PHASE AIR FILTRATION"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231213.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:13.901364",
  "document_name": "SECTION 234300 - ELECTRONIC AIR CLEANERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231214.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:14.513084",
  "document_name": "SECTION 234300 - ELECTRONIC AIR CLEANERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231215.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:15.958116",
  "document_name": "SECTION 235113.16 - VENT DAMPERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231216.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:16.738036",
  "document_name": "SECTION 235116 - FABRICATED BREECHINGS AND ACCESSORIES"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231217.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:17.790394",
  "document_name": "SECTION 235123 - GAS VENTS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231218.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:18.392135",
  "document_name": "SECTION 235133 - INSULATED SECTIONAL CHIMNEYS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231219.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:19.728270",
  "document_name": "SECTION 235213 - ELECTRIC BOILERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231220.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:20.821985",
  "document_name": "SECTION 235216 - CONDENSING BOILERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231221.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:21.883812",
  "document_name": "SECTION 235216 - CONDENSING BOILERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231222.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:22.915981",
  "document_name": "SECTION 235223 - CAST-IRON BOILERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231223.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:23.963882",
  "document_name": "SECTION 235223 - CAST-IRON BOILERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231224.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:24.522020",
  "document_name": "SECTION 235233 - - WATER-TUBE BOILERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231225.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:25.083088",
  "document_name": "SECTION 235233 - - WATER-TUBE BOILERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231227.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:27.230825",
  "document_name": "SECTION 235239 - - FIRE-TUBE BOILERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231229.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:29.339287",
  "document_name": "SECTION 235239 - - FIRE-TUBE BOILERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231230.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:30.329711",
  "document_name": "SECTION 235313 - BOILER FEEDWATER PUMPS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231231.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:31.291046",
  "document_name": "SECTION 235313 - BOILER FEEDWATER PUMPS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231232.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:32.246100",
  "document_name": "SECTION 235316 - DEAERATORS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231233.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:33.180216",
  "document_name": "SECTION 235316 - DEAERATORS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231234.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:34.824041",
  "document_name": "SECTION 235413 - ELECTRIC-RESISTANCE FURNACES"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231235.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:35.949922",
  "document_name": "SECTION 235416.13 - GAS-FIRED FURNACES"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231237.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:37.888149",
  "document_name": "SECTION 235416.16 - OIL-FIRED FURNACES"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231238.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:38.739364",
  "document_name": "SECTION 235416.16 - OIL-FIRED FURNACES"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231239.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:39.812055",
  "document_name": "SECTION 235513.16 - GAS-FIRED DUCT HEATERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231240.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:40.831081",
  "document_name": "SECTION 235523.13 - LOW-INTENSITY, GAS-FIRED, RADIANT HEATERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231241.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:41.725546",
  "document_name": "SECTION 235523.13 - LOW-INTENSITY, GAS-FIRED, RADIANT HEATERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231242.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:42.885661",
  "document_name": "SECTION 235523.16 - HIGH-INTENSITY, GAS-FIRED, RADIANT HEATERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231243.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:43.981237",
  "document_name": "SECTION 235533.13 - OIL-FIRED UNIT HEATERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231244.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:44.626411",
  "document_name": "SECTION 235533.16 - GAS-FIRED UNIT HEATERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231245.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:45.677212",
  "document_name": "SECTION 235613.13 - HEATING, FLAT-PLATE, SOLAR COLLECTORS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231246.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:46.616090",
  "document_name": "SECTION 235613.19 - HEATING, SOLAR, VACUUM-TUBE COLLECTORS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231247.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:47.862927",
  "document_name": "SECTION 235700 - HEAT EXCHANGERS FOR HVAC"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231248.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:48.716554",
  "document_name": "SECTION 235700 - HEAT EXCHANGERS FOR HVAC"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231249.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:49.682277",
  "document_name": "SECTION 236200 - PACKAGED COMPRESSOR AND CONDENSER UNITS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231250.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:50.709458",
  "document_name": "SECTION 236200 - PACKAGED COMPRESSOR AND CONDENSER UNITS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231251.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:51.990651",
  "document_name": "SECTION 236313 - AIR-COOLED REFRIGERANT CONDENSERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231253.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:53.623556",
  "document_name": "SECTION 236333 - EVAPORATIVE REFRIGERANT CONDENSERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231255.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:55.414779",
  "document_name": "SECTION 236333 - EVAPORATIVE REFRIGERANT CONDENSERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231256.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:56.774289",
  "document_name": "SECTION 236413.13 - DIRECT-FIRED ABSORPTION WATER CHILLERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231258.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:12:58.806834",
  "document_name": "SECTION 236413.16 - INDIRECT-FIRED ABSORPTION WATER CHILLERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231300.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:00.618809",
  "document_name": "SECTION 236413.16 - INDIRECT-FIRED ABSORPTION WATER CHILLERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231302.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:02.817353",
  "document_name": "SECTION 236416 - CENTRIFUGAL WATER CHILLERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231305.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:05.169309",
  "document_name": "SECTION 236416 - CENTRIFUGAL WATER CHILLERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231306.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:06.655770",
  "document_name": "SECTION 236419 - RECIPROCATING WATER CHILLERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231308.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:08.131352",
  "document_name": "SECTION 236419 - RECIPROCATING WATER CHILLERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231309.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:09.589233",
  "document_name": "SECTION 236423 - SCROLL WATER CHILLERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231310.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:10.929395",
  "document_name": "SECTION 236423 - SCROLL WATER CHILLERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231311.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:11.742826",
  "document_name": "SECTION 236426 - ROTARY-SCREW WATER CHILLERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231312.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:12.509619",
  "document_name": "SECTION 236426 - ROTARY-SCREW WATER CHILLERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231316.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:16.469525",
  "document_name": "SECTION 236500 - COOLING TOWERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231320.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:20.925897",
  "document_name": "SECTION 236500 - COOLING TOWERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231321.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:21.554685",
  "document_name": "SECTION 237200 - AIR-TO-AIR ENERGY RECOVERY EQUIPMENT"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231322.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:22.102648",
  "document_name": "SECTION 237200 - AIR-TO-AIR ENERGY RECOVERY EQUIPMENT"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231323.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:23.009667",
  "document_name": "SECTION 238113.13 - PACKAGED TERMINAL AIR-CONDITIONERS, OUTDOOR, WALL-MOUNTED UNITS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231324.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:24.784936",
  "document_name": "SECTION 238119 - SELF-CONTAINED AIR-CONDITIONERS"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231325.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:25.918824"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231326.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:26.637656",
  "document_name": "1795 W"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231327.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:27.917241",
  "document_name": "Quotation No"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231328.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:28.565288",
  "document_name": "Quotation No"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231333.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:33.735206",
  "document_name": "Microsoft Word - 2018-05-08_MF 2018 Master List of Numbers Titles and Explanations (MD EDIT)(working).docx"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231334.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:34.414991",
  "document_name": "Microsoft Word - 2018-05-08_MF 2018 Master List of Numbers Titles and Explanations (MD EDIT)(working).docx"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231341.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:41.916566",
  "document_name": "Rocky Vista HS proposal 031325.xlsm"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231342.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:42.353679",
  "document_name": "Rocky Vista HS proposal 031325.xlsm"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231345.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:45.927164"
}

================
File: pipeline/schema/data/schemas/generic_document_20250314231346.json
================
{
  "metadata_fields": [
    "title",
    "author",
    "subject",
    "creator",
    "producer",
    "creation_date",
    "modification_date"
  ],
  "content_structure": [],
  "table_structure": [],
  "section_count": 0,
  "table_count": 0,
  "document_type": "GENERIC_DOCUMENT",
  "recorded_at": "2025-03-14T23:13:46.179901"
}

================
File: pipeline/schema/extended_registry.py
================
"""
Extended schema registry module.

This module extends the SchemaRegistry with analysis and visualization capabilities.
"""

from typing import Any, Dict, List, Optional, Union

from utils.pipeline.schema.registry import SchemaRegistry


class ExtendedSchemaRegistry(SchemaRegistry):
    """
    Extended registry for document schemas with analysis and visualization capabilities.

    This class extends SchemaRegistry with:
    1. Schema analysis functionality
    2. Schema comparison functionality
    3. Schema visualization functionality
    """

    def analyze(self, document_type: Optional[str] = None) -> Dict[str, Any]:
        """
        Analyze schemas of the specified document type.

        Args:
            document_type: Optional document type to filter by

        Returns:
            Analysis results
        """
        from utils.pipeline.schema.analyzer import SchemaAnalyzer

        analyzer = SchemaAnalyzer(self)
        return analyzer.analyze_schemas(document_type)

    def compare(self, schema_id1: str, schema_id2: str) -> Dict[str, Any]:
        """
        Compare two schemas and identify similarities/differences.

        Args:
            schema_id1: ID of first schema
            schema_id2: ID of second schema

        Returns:
            Comparison results
        """
        from utils.pipeline.schema.analyzer import SchemaAnalyzer

        analyzer = SchemaAnalyzer(self)
        return analyzer.compare_schemas(schema_id1, schema_id2)

    def visualize(
        self,
        visualization_type: str = "clusters",
        schema_ids: Optional[List[str]] = None,
        output_dir: Optional[str] = None,
    ) -> Union[str, List[str]]:
        """
        Generate visualizations for schemas.

        Args:
            visualization_type: Type of visualization to generate
            schema_ids: List of schema IDs to visualize, or None for all schemas
            output_dir: Directory to save visualizations, or None for default

        Returns:
            Path(s) to the generated visualization(s)
        """
        from utils.pipeline.schema.visualizer import SchemaVisualizer

        visualizer = SchemaVisualizer(self)
        return visualizer.visualize(visualization_type, schema_ids, output_dir)

================
File: pipeline/schema/matchers.py
================
"""
Schema matchers module.

This module provides functionality for matching document schemas.
"""

from typing import Any, Dict, List, Optional

from utils.pipeline.utils.logging import get_logger


class SchemaMatcher:
    """
    Base class for schema matchers.

    Schema matchers are used to compare document schemas and determine
    if they match a known pattern.
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize the schema matcher.

        Args:
            config: Configuration dictionary for the matcher
        """
        self.config = config or {}
        self.logger = get_logger(__name__)

    def match(self, schema: Dict[str, Any], known_schema: Dict[str, Any]) -> float:
        """
        Match a schema against a known schema.

        Args:
            schema: Schema to match
            known_schema: Known schema to match against

        Returns:
            Confidence score between 0.0 and 1.0
        """
        raise NotImplementedError("Subclasses must implement match()")


class StructureMatcher(SchemaMatcher):
    """
    Matches schemas based on their structure.

    This matcher compares the structure of documents, including:
    - Section hierarchy
    - Table structure
    - Metadata fields
    """

    def match(self, schema: Dict[str, Any], known_schema: Dict[str, Any]) -> float:
        """
        Match a schema against a known schema based on structure.

        Args:
            schema: Schema to match
            known_schema: Known schema to match against

        Returns:
            Confidence score between 0.0 and 1.0
        """
        score = 0.0
        total_weight = 0.0

        # Compare metadata fields (weight: 0.2)
        weight = 0.2
        total_weight += weight

        metadata1 = set(schema.get("metadata_fields", []))
        metadata2 = set(known_schema.get("metadata_fields", []))

        if metadata1 and metadata2:
            common = len(metadata1.intersection(metadata2))
            total = len(metadata1.union(metadata2))
            score += weight * (common / total if total > 0 else 0.0)

        # Compare section counts (weight: 0.3)
        weight = 0.3
        total_weight += weight

        section_count1 = schema.get("section_count", 0)
        section_count2 = known_schema.get("section_count", 0)

        if section_count1 > 0 and section_count2 > 0:
            # Calculate similarity based on ratio
            ratio = min(section_count1, section_count2) / max(
                section_count1, section_count2
            )
            score += weight * ratio

        # Compare table counts (weight: 0.2)
        weight = 0.2
        total_weight += weight

        table_count1 = schema.get("table_count", 0)
        table_count2 = known_schema.get("table_count", 0)

        if table_count1 > 0 or table_count2 > 0:
            # Calculate similarity based on ratio
            max_count = max(table_count1, table_count2)
            min_count = min(table_count1, table_count2)
            ratio = min_count / max_count if max_count > 0 else 0.0
            score += weight * ratio
        elif table_count1 == 0 and table_count2 == 0:
            # Both have no tables, consider it a match
            score += weight

        # Compare content structure (weight: 0.3)
        weight = 0.3
        total_weight += weight

        # Compare structure recursively
        structure1 = schema.get("content_structure", [])
        structure2 = known_schema.get("content_structure", [])

        structure_sim = self._compare_structures(structure1, structure2)
        score += weight * structure_sim

        # Normalize score
        return score / total_weight if total_weight > 0 else 0.0

    def _compare_structures(
        self, structure1: List[Dict[str, Any]], structure2: List[Dict[str, Any]]
    ) -> float:
        """
        Compare two content structures recursively.

        Args:
            structure1: First structure
            structure2: Second structure

        Returns:
            Similarity score between 0.0 and 1.0
        """
        if not structure1 or not structure2:
            return 0.0 if structure1 or structure2 else 1.0  # Both empty = match

        # Compare counts
        count_sim = min(len(structure1), len(structure2)) / max(
            len(structure1), len(structure2)
        )

        # Compare levels
        levels1 = [s.get("level", 0) for s in structure1]
        levels2 = [s.get("level", 0) for s in structure2]

        avg_level1 = sum(levels1) / len(levels1) if levels1 else 0
        avg_level2 = sum(levels2) / len(levels2) if levels2 else 0

        level_diff = abs(avg_level1 - avg_level2)
        level_sim = 1.0 / (
            1.0 + level_diff
        )  # Similarity decreases as difference increases

        # Compare children
        child_sims = []
        for i in range(min(len(structure1), len(structure2))):
            s1 = structure1[i]
            s2 = structure2[i]

            # Compare basic properties
            prop_sim = 0.0
            prop_count = 0

            # Compare has_title
            if "has_title" in s1 and "has_title" in s2:
                prop_sim += 1.0 if s1["has_title"] == s2["has_title"] else 0.0
                prop_count += 1

            # Compare has_content
            if "has_content" in s1 and "has_content" in s2:
                prop_sim += 1.0 if s1["has_content"] == s2["has_content"] else 0.0
                prop_count += 1

            # Compare has_children
            if "has_children" in s1 and "has_children" in s2:
                prop_sim += 1.0 if s1["has_children"] == s2["has_children"] else 0.0
                prop_count += 1

            # Calculate property similarity
            prop_sim = prop_sim / prop_count if prop_count > 0 else 0.0

            # Compare children recursively
            children1 = s1.get("children", [])
            children2 = s2.get("children", [])

            child_sim = self._compare_structures(children1, children2)

            # Combine property and child similarity
            section_sim = 0.7 * prop_sim + 0.3 * child_sim
            child_sims.append(section_sim)

        # Calculate average child similarity
        avg_child_sim = sum(child_sims) / len(child_sims) if child_sims else 0.0

        # Combine all similarities
        return 0.4 * count_sim + 0.3 * level_sim + 0.3 * avg_child_sim


class ContentMatcher(SchemaMatcher):
    """
    Matches schemas based on their content patterns.

    This matcher compares the content patterns of documents, including:
    - Section titles
    - Content keywords
    - Table headers
    """

    def match(self, schema: Dict[str, Any], known_schema: Dict[str, Any]) -> float:
        """
        Match a schema against a known schema based on content patterns.

        Args:
            schema: Schema to match
            known_schema: Known schema to match against

        Returns:
            Confidence score between 0.0 and 1.0
        """
        # This is a placeholder implementation
        # In a real implementation, we would extract and compare content patterns

        # For now, return a simple structural match
        structure_matcher = StructureMatcher(self.config)
        return structure_matcher.match(schema, known_schema)


class SchemaMatcherFactory:
    """Factory for creating schema matchers."""

    @staticmethod
    def create_matcher(
        matcher_type: str, config: Optional[Dict[str, Any]] = None
    ) -> SchemaMatcher:
        """
        Create a schema matcher of the specified type.

        Args:
            matcher_type: Type of matcher to create
            config: Configuration dictionary for the matcher

        Returns:
            Schema matcher instance
        """
        if matcher_type == "structure":
            return StructureMatcher(config)
        elif matcher_type == "content":
            return ContentMatcher(config)
        else:
            # Default to structure matcher
            return StructureMatcher(config)

================
File: pipeline/schema/registry.py
================
"""
Schema registry module.

This module provides functionality for managing document schemas.
"""

import json
import os
from datetime import datetime
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from utils.pipeline.utils.logging import get_logger


class SchemaRegistry:
    """
    Registry for document schemas.

    This class provides functionality for:
    1. Storing known document schemas
    2. Matching new documents against known schemas
    3. Recording new schemas
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize the schema registry.

        Args:
            config: Configuration dictionary for the registry
        """
        self.config = config or {}
        self.logger = get_logger(__name__)

        # Set up registry storage
        self.storage_dir = self._get_storage_dir()
        self._ensure_storage_dir()

        # Load existing schemas
        self.schemas = self._load_schemas()

    def record(
        self,
        document_data: Dict[str, Any],
        document_type: str,
        document_name: Optional[str] = None,
    ) -> bool:
        """
        Record a document schema in the registry.

        Args:
            document_data: Document data to record
            document_type: Type of the document
            document_name: Name of the document (optional)

        Returns:
            True if schema was recorded successfully, False otherwise
        """
        try:
            # Extract schema from document data
            schema = self._extract_schema(document_data)

            # Add metadata
            schema["document_type"] = document_type
            schema["recorded_at"] = datetime.now().isoformat()

            # Add document name if provided
            if document_name:
                schema["document_name"] = document_name

            # Generate schema ID
            schema_id = self._generate_schema_id(document_type)

            # Save schema to storage
            self._save_schema(schema_id, schema)

            # Update in-memory schemas
            self.schemas[schema_id] = schema

            self.logger.info(
                f"Recorded schema {schema_id} for document type {document_type}"
            )
            return True

        except Exception as e:
            self.logger.error(f"Error recording schema: {str(e)}", exc_info=True)
            return False

    def match(self, document_data: Dict[str, Any]) -> Tuple[Optional[str], float]:
        """
        Match a document against known schemas.

        Args:
            document_data: Document data to match

        Returns:
            Tuple of (schema_id, confidence) for the best matching schema
        """
        if not self.schemas:
            return None, 0.0

        # Extract schema from document data
        schema = self._extract_schema(document_data)

        # Find best matching schema
        best_match = None
        best_confidence = 0.0

        for schema_id, known_schema in self.schemas.items():
            confidence = self._calculate_match_confidence(schema, known_schema)
            if confidence > best_confidence:
                best_match = schema_id
                best_confidence = confidence

        return best_match, best_confidence

    def get_schema(self, schema_id: str) -> Optional[Dict[str, Any]]:
        """
        Get a schema by ID.

        Args:
            schema_id: ID of the schema to get

        Returns:
            Schema dictionary or None if not found
        """
        return self.schemas.get(schema_id)

    def list_schemas(self, document_type: Optional[str] = None) -> List[Dict[str, Any]]:
        """
        List all schemas or schemas of a specific type.

        Args:
            document_type: Optional document type to filter by

        Returns:
            List of schema dictionaries
        """
        if document_type:
            return [
                {"id": schema_id, **schema}
                for schema_id, schema in self.schemas.items()
                if schema.get("document_type") == document_type
            ]

        return [
            {"id": schema_id, **schema} for schema_id, schema in self.schemas.items()
        ]

    def _get_storage_dir(self) -> Path:
        """Get the storage directory for schemas."""
        # Use configured directory if available
        if "storage_dir" in self.config:
            return Path(self.config["storage_dir"])

        # Default to package directory
        return Path(__file__).parent / "data" / "schemas"

    def _ensure_storage_dir(self) -> None:
        """Ensure the storage directory exists."""
        os.makedirs(self.storage_dir, exist_ok=True)

    def _load_schemas(self) -> Dict[str, Dict[str, Any]]:
        """Load existing schemas from storage."""
        schemas = {}

        try:
            # Load all JSON files in the storage directory
            for file_path in self.storage_dir.glob("*.json"):
                try:
                    with open(file_path, "r", encoding="utf-8") as f:
                        schema = json.load(f)
                        schema_id = file_path.stem
                        schemas[schema_id] = schema
                except Exception as e:
                    self.logger.warning(f"Error loading schema {file_path}: {str(e)}")

            self.logger.info(f"Loaded {len(schemas)} schemas from storage")

        except Exception as e:
            self.logger.error(f"Error loading schemas: {str(e)}", exc_info=True)

        return schemas

    def _save_schema(self, schema_id: str, schema: Dict[str, Any]) -> None:
        """
        Save a schema to storage.

        Args:
            schema_id: ID of the schema
            schema: Schema dictionary
        """
        file_path = self.storage_dir / f"{schema_id}.json"

        with open(file_path, "w", encoding="utf-8") as f:
            json.dump(schema, f, indent=2, ensure_ascii=False)

    def _extract_schema(self, document_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract enhanced schema from document data.

        Args:
            document_data: Document data to extract schema from

        Returns:
            Enhanced schema dictionary with more detailed information
        """
        # Extract metadata with values (not just field names)
        metadata = document_data.get("metadata", {})

        # Extract content structure with sample content
        content = document_data.get("content", [])
        content_structure = self._extract_content_structure(content)

        # Extract table structure with headers and sample data
        tables = document_data.get("tables", [])
        table_structure = self._extract_table_structure(tables)

        # Build enhanced schema
        schema = {
            # Basic schema information
            "metadata_fields": list(metadata.keys()),
            "content_structure": content_structure,
            "table_structure": table_structure,
            "section_count": len(content),
            "table_count": len(tables),
            # Enhanced schema information
            "metadata_values": {
                k: str(v)[:500] for k, v in metadata.items()
            },  # Store actual values (truncated for very large values)
            # Content samples
            "content_samples": [
                {
                    "title": section.get("title", ""),
                    "sample": section.get("content", "")[:500]
                    if section.get("content")
                    else "",
                }
                for section in content[:5]  # First 5 sections
            ],
            # Document path for reference
            "document_path": document_data.get("path", ""),
        }

        return schema

    def _extract_content_structure(
        self, content: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Extract structure from content sections.

        Args:
            content: List of content sections

        Returns:
            List of section structures
        """
        structure = []

        for section in content:
            # Extract basic section structure
            section_structure = {
                "level": section.get("level", 0),
                "has_title": bool(section.get("title")),
                "has_content": bool(section.get("content")),
                "has_children": bool(section.get("children")),
                "child_count": len(section.get("children", [])),
            }

            # Add to structure
            structure.append(section_structure)

            # Process children recursively
            if section.get("children"):
                child_structure = self._extract_content_structure(section["children"])
                section_structure["children"] = child_structure

        return structure

    def _extract_table_structure(
        self, tables: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        Extract enhanced structure from tables.

        Args:
            tables: List of tables

        Returns:
            List of enhanced table structures with headers and sample data
        """
        structure = []

        for table in tables:
            # Extract enhanced table structure
            table_structure = {
                # Basic structure information
                "has_headers": "headers" in table and bool(table.get("headers")),
                "header_count": len(table.get("headers", [])),
                "row_count": len(table.get("data", [])),
                "column_count": table.get("column_count", 0),
                # Enhanced structure information
                "headers": table.get("headers", []),  # Store actual headers
                "data_sample": table.get("data", [])[
                    :3
                ],  # Store sample data (first 3 rows)
                "detection_method": table.get("detection_method", "unknown"),
                "page": table.get("page", 0),
            }

            structure.append(table_structure)

        return structure

    def _generate_schema_id(self, document_type: str) -> str:
        """
        Generate a unique schema ID.

        Args:
            document_type: Type of the document

        Returns:
            Unique schema ID
        """
        # Use timestamp for uniqueness
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S")

        # Clean document type for use in filename
        clean_type = document_type.lower().replace(" ", "_")

        return f"{clean_type}_{timestamp}"

    def _calculate_match_confidence(
        self, schema1: Dict[str, Any], schema2: Dict[str, Any]
    ) -> float:
        """
        Calculate match confidence between two schemas.

        Args:
            schema1: First schema
            schema2: Second schema

        Returns:
            Confidence score between 0.0 and 1.0
        """
        score = 0.0
        total_weight = 0.0

        # Compare metadata fields (weight: 0.2)
        weight = 0.2
        total_weight += weight

        metadata1 = set(schema1.get("metadata_fields", []))
        metadata2 = set(schema2.get("metadata_fields", []))

        if metadata1 and metadata2:
            common = len(metadata1.intersection(metadata2))
            total = len(metadata1.union(metadata2))
            score += weight * (common / total if total > 0 else 0.0)

        # Compare section counts (weight: 0.3)
        weight = 0.3
        total_weight += weight

        section_count1 = schema1.get("section_count", 0)
        section_count2 = schema2.get("section_count", 0)

        if section_count1 > 0 and section_count2 > 0:
            # Calculate similarity based on ratio
            ratio = min(section_count1, section_count2) / max(
                section_count1, section_count2
            )
            score += weight * ratio

        # Compare table counts (weight: 0.2)
        weight = 0.2
        total_weight += weight

        table_count1 = schema1.get("table_count", 0)
        table_count2 = schema2.get("table_count", 0)

        if table_count1 > 0 or table_count2 > 0:
            # Calculate similarity based on ratio
            max_count = max(table_count1, table_count2)
            min_count = min(table_count1, table_count2)
            ratio = min_count / max_count if max_count > 0 else 0.0
            score += weight * ratio
        elif table_count1 == 0 and table_count2 == 0:
            # Both have no tables, consider it a match
            score += weight

        # Compare content structure (weight: 0.3)
        weight = 0.3
        total_weight += weight

        # Simple structure comparison based on section levels
        structure1 = schema1.get("content_structure", [])
        structure2 = schema2.get("content_structure", [])

        if structure1 and structure2:
            # Compare level distributions
            levels1 = [s.get("level", 0) for s in structure1]
            levels2 = [s.get("level", 0) for s in structure2]

            # Calculate average level
            avg1 = sum(levels1) / len(levels1) if levels1 else 0
            avg2 = sum(levels2) / len(levels2) if levels2 else 0

            # Calculate similarity based on average level difference
            level_diff = abs(avg1 - avg2)
            level_sim = 1.0 / (
                1.0 + level_diff
            )  # Similarity decreases as difference increases

            score += weight * level_sim

        # Normalize score
        return score / total_weight if total_weight > 0 else 0.0

================
File: pipeline/schema/templates/__init__.py
================
"""
Schema templates package.

This package contains templates for different document types.
"""

================
File: pipeline/schema/vectorizer.py
================
"""
Schema vectorizer module.

This module provides functionality for converting document schemas to numerical vectors.
"""

from typing import Any, Dict, List, Optional

from utils.pipeline.utils.logging import get_logger


class SchemaVectorizer:
    """
    Converts document schemas to numerical feature vectors.

    This class provides functionality for:
    1. Converting schemas to numerical vectors for comparison
    2. Extracting features from schema structure and content
    """

    def __init__(self, config: Optional[Dict[str, Any]] = None):
        """
        Initialize the schema vectorizer.

        Args:
            config: Configuration dictionary for the vectorizer
        """
        self.config = config or {}
        self.logger = get_logger(__name__)

    def vectorize_schema(self, schema: Dict[str, Any]) -> List[float]:
        """
        Convert a schema to a numerical feature vector.

        Args:
            schema: Schema to vectorize

        Returns:
            List representing the schema features
        """
        # Initialize feature vector components
        features = []

        # 1. Metadata features
        metadata_fields = schema.get("metadata_fields", [])
        features.append(float(len(metadata_fields)))

        # Common metadata fields (one-hot encoding)
        common_fields = [
            "title",
            "author",
            "subject",
            "creator",
            "producer",
            "creation_date",
        ]
        for field in common_fields:
            features.append(1.0 if field in metadata_fields else 0.0)

        # 2. Structure features
        features.append(float(schema.get("section_count", 0)))

        # Calculate hierarchy depth and distribution
        content_structure = schema.get("content_structure", [])
        max_depth = self._calculate_max_depth(content_structure)
        features.append(float(max_depth))

        # Level distribution (percentage of sections at each level, up to 5 levels)
        level_counts = self._count_sections_by_level(content_structure)
        total_sections = sum(level_counts.values())

        for level in range(1, 6):  # Levels 1-5
            if total_sections > 0:
                features.append(level_counts.get(level, 0) / total_sections)
            else:
                features.append(0.0)

        # 3. Table features
        table_count = schema.get("table_count", 0)
        features.append(float(table_count))

        table_structure = schema.get("table_structure", [])

        # Average rows per table
        if table_count > 0:
            avg_rows = (
                sum(table.get("row_count", 0) for table in table_structure)
                / table_count
            )
        else:
            avg_rows = 0.0
        features.append(avg_rows)

        # Average headers per table
        if table_count > 0:
            avg_headers = (
                sum(table.get("header_count", 0) for table in table_structure)
                / table_count
            )
        else:
            avg_headers = 0.0
        features.append(avg_headers)

        # Percentage of tables with headers
        if table_count > 0:
            tables_with_headers = sum(
                1 for table in table_structure if table.get("has_headers", False)
            )
            features.append(tables_with_headers / table_count)
        else:
            features.append(0.0)

        # Table size distribution (small: <5 rows, medium: 5-15 rows, large: >15 rows)
        small_tables = sum(
            1 for table in table_structure if table.get("row_count", 0) < 5
        )
        medium_tables = sum(
            1 for table in table_structure if 5 <= table.get("row_count", 0) <= 15
        )
        large_tables = sum(
            1 for table in table_structure if table.get("row_count", 0) > 15
        )

        if table_count > 0:
            features.append(small_tables / table_count)
            features.append(medium_tables / table_count)
            features.append(large_tables / table_count)
        else:
            features.append(0.0)
            features.append(0.0)
            features.append(0.0)

        return features

    def get_feature_names(self) -> List[str]:
        """
        Get names of features in the vector.

        Returns:
            List of feature names
        """
        feature_names = [
            "metadata_field_count",
        ]

        # Common metadata fields
        common_fields = [
            "title",
            "author",
            "subject",
            "creator",
            "producer",
            "creation_date",
        ]
        for field in common_fields:
            feature_names.append(f"has_{field}")

        # Structure features
        feature_names.extend(
            [
                "section_count",
                "max_depth",
            ]
        )

        # Level distribution
        for level in range(1, 6):
            feature_names.append(f"level_{level}_pct")

        # Table features
        feature_names.extend(
            [
                "table_count",
                "avg_rows_per_table",
                "avg_headers_per_table",
                "tables_with_headers_pct",
                "small_tables_pct",
                "medium_tables_pct",
                "large_tables_pct",
            ]
        )

        return feature_names

    def _calculate_max_depth(self, structure, current_depth=1):
        """Calculate maximum depth of the section hierarchy."""
        if not structure:
            return current_depth - 1

        max_depth = current_depth
        for section in structure:
            if "children" in section and section["children"]:
                child_depth = self._calculate_max_depth(
                    section["children"], current_depth + 1
                )
                max_depth = max(max_depth, child_depth)

        return max_depth

    def _count_sections_by_level(self, structure, current_level=1, counts=None):
        """Count sections at each level of the hierarchy."""
        if counts is None:
            counts = {}

        if not structure:
            return counts

        # Count sections at this level
        counts[current_level] = counts.get(current_level, 0) + len(structure)

        # Count children
        for section in structure:
            if "children" in section and section["children"]:
                self._count_sections_by_level(
                    section["children"], current_level + 1, counts
                )

        return counts

================
File: pipeline/schema/visualizer.py
================
"""
Schema visualizer module.

This module provides functionality for visualizing document schemas.
"""

import os
from typing import Any, Dict, List, Optional, Union

from utils.pipeline.utils.logging import get_logger


class SchemaVisualizer:
    """
    Visualizes document schemas.

    This class provides functionality for:
    1. Generating visualizations of schema patterns
    2. Creating cluster visualizations using dimensionality reduction
    3. Visualizing schema structure and features
    """

    def __init__(self, registry, config: Optional[Dict[str, Any]] = None):
        """
        Initialize the schema visualizer.

        Args:
            registry: Schema registry instance
            config: Configuration dictionary for the visualizer
        """
        self.registry = registry
        self.config = config or {}
        self.logger = get_logger(__name__)

    def visualize(
        self,
        visualization_type: str = "clusters",
        schema_ids: Optional[List[str]] = None,
        output_dir: Optional[str] = None,
    ) -> Union[str, List[str]]:
        """
        Generate visualizations for schemas.

        Args:
            visualization_type: Type of visualization to generate
                - "clusters": Cluster visualization using dimensionality reduction
                - "features": Feature heatmap comparison
                - "structure": Hierarchical structure visualization
                - "tables": Table pattern visualization
            schema_ids: List of schema IDs to visualize, or None for all/automatic
            output_dir: Directory to save visualizations, or None for default

        Returns:
            Path(s) to the generated visualization(s)
        """
        # Set up output directory
        if not output_dir:
            # Use a default directory relative to the schema storage directory
            try:
                from utils.pipeline.schema.registry import SchemaRegistry

                registry_instance = SchemaRegistry()
                base_dir = os.path.dirname(registry_instance.storage_dir)
                output_dir = os.path.join(base_dir, "visualizations")
            except Exception:
                # Fallback to a relative path
                output_dir = os.path.join(
                    "utils", "pipeline", "schema", "data", "visualizations"
                )

        os.makedirs(output_dir, exist_ok=True)

        # Generate visualization based on type
        try:
            if visualization_type == "clusters":
                output_path = os.path.join(output_dir, "schema_clusters.png")
                return self.visualize_schema_clusters(output_path)

            elif visualization_type == "features":
                output_path = os.path.join(output_dir, "schema_features.png")
                return self.visualize_schema_features(schema_ids, output_path)

            elif visualization_type == "structure":
                if not schema_ids or len(schema_ids) == 0:
                    # Use first schema if none specified
                    schemas = self.registry.list_schemas()
                    if not schemas:
                        return "No schemas available for visualization"
                    schema_ids = [schemas[0]["id"]]

                # Generate structure visualization for each schema
                output_paths = []
                for schema_id in schema_ids:
                    output_path = os.path.join(output_dir, f"structure_{schema_id}.png")
                    result = self.visualize_schema_structure(schema_id, output_path)
                    output_paths.append(result)

                return output_paths

            elif visualization_type == "tables":
                if not schema_ids or len(schema_ids) == 0:
                    # Use first schema if none specified
                    schemas = self.registry.list_schemas()
                    if not schemas:
                        return "No schemas available for visualization"
                    schema_ids = [schemas[0]["id"]]

                # Generate table visualization for each schema
                output_paths = []
                for schema_id in schema_ids:
                    output_path = os.path.join(output_dir, f"tables_{schema_id}.png")
                    result = self.visualize_table_patterns(schema_id, output_path)
                    output_paths.append(result)

                return output_paths

            else:
                return f"Unknown visualization type: {visualization_type}"
        except ImportError as e:
            return f"Error: Missing dependency - {str(e)}"
        except Exception as e:
            self.logger.error(
                f"Error generating visualization: {str(e)}", exc_info=True
            )
            return f"Error generating visualization: {str(e)}"

    def visualize_schema_clusters(self, output_path: str) -> str:
        """
        Visualize schema clusters using dimensionality reduction.

        Args:
            output_path: Path to save the visualization

        Returns:
            Path to the saved visualization
        """
        try:
            import matplotlib.pyplot as plt
            import numpy as np

            # Check if we have scikit-learn for dimensionality reduction
            try:
                from sklearn.manifold import TSNE
            except ImportError:
                return "Error: scikit-learn is required for cluster visualization. Please install it with 'pip install scikit-learn'."

            # Get all schemas
            schemas = self.registry.list_schemas()
            if len(schemas) < 2:
                return "Not enough schemas for cluster visualization (need at least 2)"

            # Extract schema IDs and document types
            schema_ids = [
                schema.get("id", f"schema_{i}") for i, schema in enumerate(schemas)
            ]
            doc_types = [schema.get("document_type", "UNKNOWN") for schema in schemas]

            # Vectorize schemas
            from utils.pipeline.schema.vectorizer import SchemaVectorizer

            vectorizer = SchemaVectorizer()
            vectors = [vectorizer.vectorize_schema(schema) for schema in schemas]

            # Convert to numpy array
            vectors = np.array(vectors)

            # Apply t-SNE for dimensionality reduction
            # Use a lower perplexity value (default is 30) that's less than n_samples
            perplexity = min(5, len(vectors) - 1)  # Ensure perplexity < n_samples
            tsne = TSNE(n_components=2, random_state=42, perplexity=perplexity)
            vectors_2d = tsne.fit_transform(vectors)

            # Create plot
            plt.figure(figsize=(12, 8))

            # Get unique document types for coloring
            unique_types = list(set(doc_types))
            # Create colors for each document type
            color_indices = np.linspace(0, 1, len(unique_types))

            # Plot each schema with different colors by document type

            # Plot each schema
            for i, (x, y) in enumerate(vectors_2d):
                doc_type = doc_types[i]
                color_idx = unique_types.index(doc_type)
                # Use a basic color cycle with simple colors
                colors = [
                    "red",
                    "blue",
                    "green",
                    "orange",
                    "purple",
                    "cyan",
                    "magenta",
                    "yellow",
                ]
                color = colors[color_idx % len(colors)]
                plt.scatter(x, y, color=color, s=100, alpha=0.7)
                plt.text(x, y, schema_ids[i], fontsize=9)

            # Define colors for legend
            colors = [
                "red",
                "blue",
                "green",
                "orange",
                "purple",
                "cyan",
                "magenta",
                "yellow",
            ]
            for i, doc_type in enumerate(unique_types):
                plt.scatter([], [], color=colors[i % len(colors)], label=doc_type)
            plt.legend()

            plt.title("Schema Similarity Map")
            plt.xlabel("Dimension 1")
            plt.ylabel("Dimension 2")
            plt.tight_layout()

            # Save figure
            plt.savefig(output_path, dpi=300)
            plt.close()

            return output_path
        except Exception as e:
            self.logger.error(
                f"Error visualizing schema clusters: {str(e)}", exc_info=True
            )
            return f"Error visualizing schema clusters: {str(e)}"

    def visualize_schema_features(
        self,
        schema_ids: Optional[List[str]] = None,
        output_path: str = "schema_features.png",
    ) -> str:
        """
        Visualize schema features as a heatmap.

        Args:
            schema_ids: List of schema IDs to visualize, or None for all schemas
            output_path: Path to save the visualization

        Returns:
            Path to the saved visualization
        """
        try:
            import matplotlib.pyplot as plt

            # Check if we have seaborn for heatmap
            try:
                import seaborn as sns
            except ImportError:
                return "Error: seaborn is required for feature visualization. Please install it with 'pip install seaborn'."

            # Get schemas to visualize
            if schema_ids:
                schemas = [
                    self.registry.get_schema(schema_id) for schema_id in schema_ids
                ]
                schemas = [s for s in schemas if s]  # Filter out None values
            else:
                schemas = self.registry.list_schemas()

            if not schemas:
                return "No schemas found for visualization"

            # Define features to extract
            features = [
                ("Metadata Fields", lambda s: len(s.get("metadata_fields", []))),
                ("Section Count", lambda s: s.get("section_count", 0)),
                ("Table Count", lambda s: s.get("table_count", 0)),
                (
                    "Avg Rows/Table",
                    lambda s: sum(
                        t.get("row_count", 0) for t in s.get("table_structure", [])
                    )
                    / max(1, s.get("table_count", 0)),
                ),
                (
                    "Max Depth",
                    lambda s: self._calculate_max_depth(s.get("content_structure", [])),
                ),
                (
                    "Tables with Headers",
                    lambda s: sum(
                        1
                        for t in s.get("table_structure", [])
                        if t.get("has_headers", False)
                    ),
                ),
            ]

            # Extract feature values
            feature_names = [f[0] for f in features]
            data = []

            for schema in schemas:
                schema_id = schema.get("id", "unknown")
                row = [schema_id]
                for _, feature_func in features:
                    row.append(feature_func(schema))
                data.append(row)

            # Create DataFrame
            try:
                import pandas as pd

                df = pd.DataFrame(data, columns=["Schema ID"] + feature_names)
                df = df.set_index("Schema ID")

                # Normalize data for heatmap
                df_norm = (df - df.min()) / (df.max() - df.min())

                # Create plot
                plt.figure(figsize=(12, max(8, len(schemas) * 0.4)))
                sns.heatmap(
                    df_norm,
                    annot=df.round(1),
                    fmt=".1f",
                    cmap="YlGnBu",
                    linewidths=0.5,
                    cbar_kws={"label": "Normalized Value"},
                )

                plt.title("Schema Feature Comparison")
                plt.tight_layout()

                # Save figure
                plt.savefig(output_path, dpi=300, bbox_inches="tight")
                plt.close()

                return output_path
            except ImportError:
                return "Error: pandas is required for feature visualization. Please install it with 'pip install pandas'."
        except Exception as e:
            self.logger.error(
                f"Error visualizing schema features: {str(e)}", exc_info=True
            )
            return f"Error visualizing schema features: {str(e)}"

    def visualize_schema_structure(self, schema_id: str, output_path: str) -> str:
        """
        Visualize the hierarchical structure of a schema.

        Args:
            schema_id: ID of the schema to visualize
            output_path: Path to save the visualization

        Returns:
            Path to the saved visualization
        """
        try:
            import matplotlib.pyplot as plt

            # Check if we have networkx for graph visualization
            try:
                import networkx as nx
            except ImportError:
                return "Error: networkx is required for structure visualization. Please install it with 'pip install networkx'."

            schema = self.registry.get_schema(schema_id)
            if not schema:
                return f"Schema {schema_id} not found"

            # Create directed graph
            G = nx.DiGraph()

            # Add root node
            root_name = f"{schema_id}\n({schema.get('document_type', 'UNKNOWN')})"
            G.add_node(root_name)

            # Add metadata node
            metadata_fields = schema.get("metadata_fields", [])
            if metadata_fields:
                metadata_name = f"Metadata\n({len(metadata_fields)} fields)"
                G.add_node(metadata_name)
                G.add_edge(root_name, metadata_name)

            # Add content structure
            content_structure = schema.get("content_structure", [])
            if content_structure:
                self._add_structure_to_graph(G, root_name, content_structure, "Section")

            # Add tables
            table_structure = schema.get("table_structure", [])
            if table_structure:
                tables_name = f"Tables\n({len(table_structure)} tables)"
                G.add_node(tables_name)
                G.add_edge(root_name, tables_name)

                # Add individual tables (limit to first 10 to avoid overcrowding)
                for i, table in enumerate(table_structure[:10]):
                    table_name = f"Table {i + 1}\n({table.get('row_count', 0)} rows)"
                    G.add_node(table_name)
                    G.add_edge(tables_name, table_name)

                # Add ellipsis if more tables
                if len(table_structure) > 10:
                    G.add_node("...")
                    G.add_edge(tables_name, "...")

            # Create plot
            plt.figure(figsize=(12, 8))

            # Check if we have pygraphviz for better layout
            try:
                pos = nx.drawing.nx_agraph.graphviz_layout(G, prog="dot")
            except (ImportError, Exception):
                # Fall back to spring layout
                pos = nx.spring_layout(G, seed=42)

            # Draw nodes and edges
            nx.draw(
                G,
                pos,
                with_labels=True,
                node_size=3000,
                node_color="lightblue",
                font_size=10,
                font_weight="bold",
                arrows=True,
            )

            plt.title(f"Schema Structure: {schema_id}")
            plt.tight_layout()

            # Save figure
            plt.savefig(output_path, dpi=300, bbox_inches="tight")
            plt.close()

            return output_path
        except Exception as e:
            self.logger.error(
                f"Error visualizing schema structure: {str(e)}", exc_info=True
            )
            return f"Error visualizing schema structure: {str(e)}"

    def visualize_table_patterns(
        self, schema_id: str, output_path: str
    ) -> Union[str, List[str]]:
        """
        Visualize table patterns in a schema with enhanced information.

        Args:
            schema_id: ID of the schema to visualize
            output_path: Path to save the visualization

        Returns:
            Path(s) to the saved visualization(s)
        """
        try:
            from collections import Counter

            import matplotlib.pyplot as plt

            schema = self.registry.get_schema(schema_id)
            if not schema:
                return f"Schema {schema_id} not found"

            table_structure = schema.get("table_structure", [])
            if not table_structure:
                return f"No tables found in schema {schema_id}"

            # Extract row counts
            row_counts = [table.get("row_count", 0) for table in table_structure]

            # Create base directory for visualizations
            output_dir = os.path.dirname(output_path)
            os.makedirs(output_dir, exist_ok=True)

            # List to store all output paths
            output_paths = [output_path]

            # Create histogram
            plt.figure(figsize=(12, 6))

            # Plot histogram of row counts
            plt.subplot(1, 2, 1)
            plt.hist(row_counts, bins=10, color="skyblue", edgecolor="black")
            plt.title("Distribution of Table Sizes")
            plt.xlabel("Rows per Table")
            plt.ylabel("Number of Tables")

            # Plot table size categories
            plt.subplot(1, 2, 2)
            categories = ["Small (<5 rows)", "Medium (5-15 rows)", "Large (>15 rows)"]
            counts = [
                sum(1 for rc in row_counts if rc < 5),
                sum(1 for rc in row_counts if 5 <= rc <= 15),
                sum(1 for rc in row_counts if rc > 15),
            ]

            plt.bar(categories, counts, color=["lightblue", "skyblue", "steelblue"])
            plt.title("Table Size Categories")
            plt.ylabel("Number of Tables")
            plt.xticks(rotation=45, ha="right")

            plt.suptitle(f"Table Patterns in Schema: {schema_id}")
            plt.tight_layout()

            # Save figure
            plt.savefig(output_path, dpi=300)
            plt.close()

            # Create additional visualizations if enhanced data is available

            # 1. Table Headers Visualization
            if any(
                "headers" in table and table["headers"] for table in table_structure
            ):
                # Collect all headers
                all_headers = []
                for table in table_structure:
                    if "headers" in table and table["headers"]:
                        all_headers.extend(table["headers"])

                if all_headers:
                    # Count header frequency
                    header_counts = Counter(all_headers)

                    # Plot top 15 headers (or fewer if less available)
                    top_headers = header_counts.most_common(min(15, len(header_counts)))

                    plt.figure(figsize=(14, 8))
                    plt.bar(
                        [h[0] for h in top_headers],
                        [h[1] for h in top_headers],
                        color="skyblue",
                    )
                    plt.title(f"Common Table Headers in Schema: {schema_id}")
                    plt.xticks(rotation=45, ha="right")
                    plt.tight_layout()

                    # Save additional visualization
                    headers_path = os.path.join(output_dir, f"headers_{schema_id}.png")
                    plt.savefig(headers_path, dpi=300)
                    plt.close()
                    output_paths.append(headers_path)

            # 2. Column Count Visualization
            column_counts = [
                table.get("column_count", 0)
                for table in table_structure
                if "column_count" in table
            ]
            if column_counts:
                plt.figure(figsize=(10, 6))
                plt.hist(
                    column_counts,
                    bins=max(5, min(10, max(column_counts))),
                    color="lightgreen",
                    edgecolor="black",
                )
                plt.title(f"Distribution of Table Column Counts in Schema: {schema_id}")
                plt.xlabel("Columns per Table")
                plt.ylabel("Number of Tables")
                plt.tight_layout()

                # Save additional visualization
                columns_path = os.path.join(output_dir, f"columns_{schema_id}.png")
                plt.savefig(columns_path, dpi=300)
                plt.close()
                output_paths.append(columns_path)

            # 3. Table Data Sample Visualization (if available)
            tables_with_samples = [
                table
                for table in table_structure
                if "data_sample" in table and table["data_sample"]
            ]
            if tables_with_samples:
                # Create a sample table visualization (first table with samples)
                sample_table = tables_with_samples[0]
                headers = sample_table.get("headers", [])
                data_sample = sample_table.get("data_sample", [])

                if data_sample:
                    plt.figure(figsize=(12, 6))

                    # Create a table visualization
                    table_data = data_sample[
                        : min(5, len(data_sample))
                    ]  # Limit to 5 rows

                    # If we have headers, add them as the first row
                    if headers:
                        table_data = [headers] + table_data

                    # Create the table
                    table = plt.table(
                        cellText=table_data,
                        loc="center",
                        cellLoc="center",
                        colWidths=[0.2] * len(table_data[0])
                        if table_data and table_data[0]
                        else None,
                    )

                    # Style the table
                    table.auto_set_font_size(False)
                    table.set_fontsize(9)
                    table.scale(1, 1.5)

                    # Hide axes
                    plt.axis("off")

                    plt.title(f"Sample Table Data from Schema: {schema_id}")
                    plt.tight_layout()

                    # Save additional visualization
                    sample_path = os.path.join(output_dir, f"sample_{schema_id}.png")
                    plt.savefig(sample_path, dpi=300, bbox_inches="tight")
                    plt.close()
                    output_paths.append(sample_path)

            return output_paths
        except Exception as e:
            self.logger.error(
                f"Error visualizing table patterns: {str(e)}", exc_info=True
            )
            return f"Error visualizing table patterns: {str(e)}"

    def _add_structure_to_graph(self, G, parent_name, structure, prefix, level=1):
        """Add hierarchical structure to graph recursively."""
        for i, section in enumerate(structure):
            has_title = section.get("has_title", False)
            has_content = section.get("has_content", False)
            has_children = section.get("has_children", False)

            # Create node name
            node_name = f"{prefix} {level}.{i + 1}"
            if has_title:
                node_name += "\n(with title)"
            if has_content:
                node_name += "\n(with content)"

            G.add_node(node_name)
            G.add_edge(parent_name, node_name)

            # Add children recursively
            if has_children and "children" in section:
                self._add_structure_to_graph(
                    G, node_name, section["children"], prefix, level + 1
                )

    def _calculate_max_depth(self, structure, current_depth=1):
        """Calculate maximum depth of the section hierarchy."""
        if not structure:
            return current_depth - 1

        max_depth = current_depth
        for section in structure:
            if "children" in section and section["children"]:
                child_depth = self._calculate_max_depth(
                    section["children"], current_depth + 1
                )
                max_depth = max(max_depth, child_depth)

        return max_depth

================
File: pipeline/setup_pytest_env.py
================
#!/usr/bin/env python
"""
Script to set up a proper pytest environment for the pipeline project.

This script:
1. Creates a virtual environment if it doesn't exist
2. Installs the required dependencies
3. Installs the pipeline package in development mode
"""

import os
import subprocess
import sys
from pathlib import Path


def run_command(cmd, cwd=None):
    """Run a command and return its output."""
    print(f"Running: {' '.join(cmd)}")
    try:
        result = subprocess.run(cmd, cwd=cwd, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"Error: {result.stderr}")
            return False
        print(result.stdout)
        return True
    except Exception as e:
        print(f"Error executing command: {e}")
        return False


def setup_env():
    """Set up the pytest environment."""
    # Get the directory of this script
    script_dir = Path(__file__).resolve().parent

    # Change to the script directory
    os.chdir(script_dir)

    # Check if virtual environment exists
    venv_dir = script_dir / ".venv"
    if not venv_dir.exists():
        print("Creating virtual environment...")
        if not run_command([sys.executable, "-m", "venv", str(venv_dir)]):
            return False

    # Determine the pip executable
    if sys.platform == "win32":
        pip_exe = venv_dir / "Scripts" / "pip"
    else:
        pip_exe = venv_dir / "bin" / "pip"

    # Upgrade pip
    print("Upgrading pip...")
    if not run_command([str(pip_exe), "install", "--upgrade", "pip"]):
        return False

    # Install pytest and related packages
    print("Installing pytest and related packages...")
    if not run_command([str(pip_exe), "install", "-r", "requirements-dev.txt"]):
        return False

    # Install the pipeline package in development mode
    print("Installing pipeline package in development mode...")
    if not run_command([str(pip_exe), "install", "-e", "."]):
        return False

    # Print success message
    print("\nPytest environment set up successfully!")
    print("\nTo activate the virtual environment:")
    if sys.platform == "win32":
        print(f"  {venv_dir}\\Scripts\\activate")
    else:
        print(f"  source {venv_dir}/bin/activate")

    print("\nTo run the tests:")
    print("  pytest")
    print("  pytest -v")
    print("  pytest --cov=.")

    return True


if __name__ == "__main__":
    if not setup_env():
        sys.exit(1)

================
File: pipeline/strategies/__init__.py
================
"""
Strategy pattern implementations for document processing.
"""

================
File: pipeline/strategies/base.py
================
"""
Base strategy interfaces for document processing.

This module defines the abstract base classes for the strategy pattern
used in the document processing pipeline.
"""

from abc import ABC, abstractmethod
from typing import Any, Dict


class AnalyzerStrategy(ABC):
    """Base interface for document analyzer strategies."""

    @abstractmethod
    def analyze(self, input_path: str) -> Dict[str, Any]:
        """
        Analyze document structure and extract metadata.

        Args:
            input_path: Path to the document

        Returns:
            Dictionary with document structure and metadata
        """
        pass


class CleanerStrategy(ABC):
    """Base interface for document cleaner strategies."""

    @abstractmethod
    def clean(self, analysis_result: Dict[str, Any]) -> Dict[str, Any]:
        """
        Clean and normalize document content.

        Args:
            analysis_result: Result from the document analyzer

        Returns:
            Cleaned data dictionary
        """
        pass


class ExtractorStrategy(ABC):
    """Base interface for document extractor strategies."""

    @abstractmethod
    def extract(self, cleaned_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Extract structured data from cleaned content.

        Args:
            cleaned_data: Cleaned data from the document cleaner

        Returns:
            Extracted structured data
        """
        pass


class ValidatorStrategy(ABC):
    """Base interface for document validator strategies."""

    @abstractmethod
    def validate(self, extracted_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Validate extracted document data.

        Args:
            extracted_data: Data extracted from the document

        Returns:
            Validated data with validation results
        """
        pass


class FormatterStrategy(ABC):
    """Base interface for document formatter strategies."""

    @abstractmethod
    def format(self, validated_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Format validated document data for output.

        Args:
            validated_data: Validated data from the document validator

        Returns:
            Formatted output data
        """
        pass

================
File: pipeline/strategies/formatter.py
================
"""
Base formatter strategy.

This module provides the base strategy interface for formatters.
"""

from abc import ABC, abstractmethod
from typing import Any, Dict


class FormatterStrategy(ABC):
    """Base strategy for formatters."""

    @abstractmethod
    def format(self, analyzed_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        Format the analyzed data into a specific output structure.

        Args:
            analyzed_data: Data to format

        Returns:
            Formatted data structure
        """
        pass

    @abstractmethod
    def write(self, data: Dict[str, Any], output_path: str) -> None:
        """
        Write formatted data to a file.

        Args:
            data: Formatted data to write
            output_path: Path to output file
        """
        pass

================
File: pipeline/SYSTEM_DIAGRAMS.md
================
# System Diagrams

This document provides visual diagrams of the Document Pipeline Tool and Schema Visualization systems, along with explanations of how they interact.

## Pipeline System Architecture

The Document Pipeline Tool follows a sequential processing approach to extract structured data from various document formats.

```mermaid
flowchart TD
    subgraph "Document Pipeline System"
        Input[Document Input] --> Analyzer
        Analyzer[1. Document Analyzer] --> Cleaner
        Cleaner[2. Content Cleaner] --> Extractor
        Extractor[3. Data Extractor] --> Validator
        Validator[4. Data Validator] --> Classifier
        Classifier[5. Document Classifier] --> Formatter
        Formatter[6. Output Formatter] --> Verifier
        Verifier[7. Output Verifier] --> Output[Structured Output]
        
        SchemaReg[(Schema Registry)]
        Classifier -- Record Schema --> SchemaReg
        Classifier -- Match Schema --> SchemaReg
    end
    
    style Analyzer fill:#f9d5e5,stroke:#333,stroke-width:2px
    style Cleaner fill:#eeac99,stroke:#333,stroke-width:2px
    style Extractor fill:#e06377,stroke:#333,stroke-width:2px
    style Validator fill:#c83349,stroke:#333,stroke-width:2px
    style Classifier fill:#5b9aa0,stroke:#333,stroke-width:2px
    style Formatter fill:#d6e1c7,stroke:#333,stroke-width:2px
    style Verifier fill:#88b04b,stroke:#333,stroke-width:2px
    style SchemaReg fill:#ffc857,stroke:#333,stroke-width:2px
```

### Pipeline Components

1. **Document Analyzer**: Examines the document structure and extracts metadata
2. **Content Cleaner**: Normalizes and standardizes document content
3. **Data Extractor**: Extracts structured data from the cleaned content
4. **Data Validator**: Validates the extracted data against expected schemas
5. **Document Classifier**: Identifies document type and matches against known schemas
6. **Output Formatter**: Formats the validated data into the desired output format
7. **Output Verifier**: Verifies the structure of the formatted output
8. **Schema Registry**: Stores and manages document schemas for classification and matching

## Schema Visualization System

The Schema Visualization system provides tools for visualizing and analyzing document schemas stored in the Schema Registry.

```mermaid
flowchart TD
    subgraph "Schema Visualization System"
        SchemaReg[(Schema Registry)] --> ExtReg[Extended Schema Registry]
        ExtReg --> Analyzer[Schema Analyzer]
        ExtReg --> Visualizer[Schema Visualizer]
        ExtReg --> Comparator[Schema Comparator]
        
        Visualizer --> ClusterViz[Cluster Visualization]
        Visualizer --> FeatureViz[Feature Visualization]
        Visualizer --> StructureViz[Structure Visualization]
        Visualizer --> TableViz[Table Visualization]
        
        Vectorizer[Schema Vectorizer] --> ClusterViz
        Vectorizer --> FeatureViz
    end
    
    style SchemaReg fill:#ffc857,stroke:#333,stroke-width:2px
    style ExtReg fill:#ff9a3c,stroke:#333,stroke-width:2px
    style Analyzer fill:#6b5b95,stroke:#333,stroke-width:2px
    style Visualizer fill:#88b04b,stroke:#333,stroke-width:2px
    style Comparator fill:#34568b,stroke:#333,stroke-width:2px
    style ClusterViz fill:#92a8d1,stroke:#333,stroke-width:2px
    style FeatureViz fill:#955251,stroke:#333,stroke-width:2px
    style StructureViz fill:#b565a7,stroke:#333,stroke-width:2px
    style TableViz fill:#009b77,stroke:#333,stroke-width:2px
    style Vectorizer fill:#dd4124,stroke:#333,stroke-width:2px
```

### Schema Visualization Components

1. **Schema Registry**: Core storage for document schemas
2. **Extended Schema Registry**: Extends the base registry with analysis and visualization capabilities
3. **Schema Analyzer**: Analyzes schemas to identify patterns and characteristics
4. **Schema Visualizer**: Generates visual representations of schemas
5. **Schema Comparator**: Compares schemas to identify similarities and differences
6. **Schema Vectorizer**: Converts schemas to numerical vectors for analysis
7. **Visualization Types**:
   - **Cluster Visualization**: Shows schema similarity using dimensionality reduction
   - **Feature Visualization**: Compares schema features across documents
   - **Structure Visualization**: Displays hierarchical structure of schemas
   - **Table Visualization**: Shows table patterns within schemas

## System Interaction

The Pipeline and Schema Visualization systems interact primarily through the Schema Registry, which serves as a shared data store.

```mermaid
flowchart TD
    subgraph "Document Pipeline System"
        Pipeline[Pipeline Processor]
        Classifier[Document Classifier]
        Pipeline --> Classifier
    end
    
    subgraph "Schema Registry"
        SchemaReg[(Schema Storage)]
        SchemaMatch[Schema Matcher]
    end
    
    subgraph "Schema Visualization System"
        ExtReg[Extended Schema Registry]
        Visualizer[Schema Visualizer]
        CLI[Visualization CLI]
        ExtReg --> Visualizer
        CLI --> Visualizer
    end
    
    Classifier -- Record Schema --> SchemaReg
    Classifier -- Match Document --> SchemaMatch
    SchemaMatch -- Return Match --> Classifier
    SchemaReg -- Load Schemas --> ExtReg
    
    User[User] -- Process Document --> Pipeline
    User -- Request Visualization --> CLI
    
    style Pipeline fill:#f9d5e5,stroke:#333,stroke-width:2px
    style Classifier fill:#5b9aa0,stroke:#333,stroke-width:2px
    style SchemaReg fill:#ffc857,stroke:#333,stroke-width:2px
    style SchemaMatch fill:#ff9a3c,stroke:#333,stroke-width:2px
    style ExtReg fill:#ff9a3c,stroke:#333,stroke-width:2px
    style Visualizer fill:#88b04b,stroke:#333,stroke-width:2px
    style CLI fill:#6b5b95,stroke:#333,stroke-width:2px
    style User fill:#c83349,stroke:#333,stroke-width:2px
```

### Key Interactions

1. **Schema Recording**: The Pipeline's Document Classifier records document schemas to the Schema Registry
2. **Schema Matching**: The Pipeline matches new documents against known schemas in the registry
3. **Schema Loading**: The Extended Schema Registry loads schemas from the Schema Registry for visualization
4. **User Interaction**: Users interact with both systems - processing documents through the Pipeline and requesting visualizations through the CLI

## Data Flow Diagram

This diagram shows the flow of data through both systems, from document input to visualization output.

```mermaid
flowchart LR
    Document[Document Input] --> Pipeline[Pipeline Processing]
    Pipeline --> StructuredData[Structured Data]
    Pipeline -- Record Schema --> SchemaReg[(Schema Registry)]
    
    SchemaReg --> ExtReg[Extended Schema Registry]
    ExtReg --> Visualizer[Schema Visualizer]
    
    VisualizationRequest[Visualization Request] --> CLI[Visualization CLI]
    CLI -- Schema ID --> ExtReg
    Visualizer --> Visualization[Visualization Output]
    
    style Document fill:#f9d5e5,stroke:#333,stroke-width:2px
    style Pipeline fill:#e06377,stroke:#333,stroke-width:2px
    style StructuredData fill:#c83349,stroke:#333,stroke-width:2px
    style SchemaReg fill:#ffc857,stroke:#333,stroke-width:2px
    style ExtReg fill:#ff9a3c,stroke:#333,stroke-width:2px
    style Visualizer fill:#88b04b,stroke:#333,stroke-width:2px
    style VisualizationRequest fill:#5b9aa0,stroke:#333,stroke-width:2px
    style CLI fill:#6b5b95,stroke:#333,stroke-width:2px
    style Visualization fill:#009b77,stroke:#333,stroke-width:2px
```

## Goal of the Schema Visualization Tool

The Schema Visualization Tool serves several important purposes:

1. **Understanding Document Structures**: Helps users understand the structure and patterns in their document collections by visualizing schema characteristics.

2. **Document Classification Improvement**: Provides insights that can be used to improve document classification by identifying distinguishing features between document types.

3. **Schema Pattern Discovery**: Reveals patterns and relationships between different document schemas that might not be apparent from examining the raw data.

4. **Quality Assurance**: Helps identify outliers or anomalies in document processing that might indicate issues with the extraction process.

5. **Document Type Clustering**: Automatically groups similar document types based on their schema characteristics, which can help in organizing large document collections.

6. **Schema Evolution Tracking**: Allows tracking how document schemas evolve over time as new documents are processed.

7. **Processing Pipeline Optimization**: Provides feedback that can be used to optimize the document processing pipeline for specific document types.

```mermaid
mindmap
  root((Schema Visualization Goals))
    Understanding
      Document Structure
      Content Patterns
      Hierarchical Relationships
    Analysis
      Schema Comparison
      Feature Extraction
      Similarity Measurement
    Optimization
      Pipeline Tuning
      Extraction Improvement
      Classification Enhancement
    Organization
      Document Clustering
      Type Identification
      Collection Management
    Quality
      Anomaly Detection
      Consistency Checking
      Validation Support
```

In summary, the Schema Visualization Tool transforms abstract schema data into intuitive visual representations that help users understand, analyze, and optimize their document processing workflows. It bridges the gap between the technical aspects of document processing and the human need for visual pattern recognition and insight discovery.

================
File: pipeline/tests/__init__.py
================
"""
Test suite for the pipeline package.
"""

================
File: pipeline/tests/analyzer/test_pdf_analyzer.py
================
"""
Tests for the PDF analyzer component.
"""

import os
from pathlib import Path

import pytest

from utils.pipeline.analyzer import PDFAnalyzer


@pytest.fixture
def sample_pdf_path():
    """Fixture to provide a sample PDF path."""
    # Get the path to the test data directory
    test_dir = Path(__file__).parent.parent
    data_dir = test_dir / "data"

    # Create the data directory if it doesn't exist
    data_dir.mkdir(exist_ok=True)

    # Return a path to a sample PDF file
    # In a real test, this would be a path to an actual PDF file
    return str(data_dir / "sample.pdf")


def test_pdf_analyzer_initialization():
    """Test PDF analyzer initialization."""
    analyzer = PDFAnalyzer()
    assert analyzer is not None
    assert hasattr(analyzer, "analyze")


def test_pdf_analyzer_with_sample_pdf(sample_pdf_path, monkeypatch):
    """Test PDF analyzer with a sample PDF file."""

    # Mock the open function to avoid actually opening a file
    class MockPdfReader:
        def __init__(self, *args, **kwargs):
            self.metadata = {
                "/Title": "Sample PDF",
                "/Author": "Test Author",
                "/Subject": "Test Subject",
                "/Creator": "Test Creator",
                "/Producer": "Test Producer",
                "/CreationDate": "D:20250315000000",
                "/ModDate": "D:20250315000000",
            }
            self.pages = [MockPage(), MockPage()]

    class MockPage:
        def __init__(self):
            self.mediabox = [0, 0, 612, 792]

        def get(self, key, default=None):
            if key == "/Rotate":
                return 0
            return default

        def extract_text(self):
            return "SECTION 1\nThis is sample content for section 1.\n\nSECTION 2\nThis is sample content for section 2."

    # Apply the monkeypatch
    monkeypatch.setattr("pypdf.PdfReader", MockPdfReader)

    # Create a mock file to avoid FileNotFoundError
    if not os.path.exists(sample_pdf_path):
        os.makedirs(os.path.dirname(sample_pdf_path), exist_ok=True)
        with open(sample_pdf_path, "w") as f:
            f.write("Mock PDF content")

    # Test the analyzer
    analyzer = PDFAnalyzer()
    result = analyzer.analyze(sample_pdf_path)

    # Verify the result structure
    assert result is not None
    assert "path" in result
    assert "type" in result
    assert "metadata" in result
    assert "pages" in result
    assert "sections" in result

    # Verify metadata
    assert result["metadata"]["title"] == "Sample PDF"
    assert result["metadata"]["author"] == "Test Author"

    # Verify pages
    assert len(result["pages"]) == 2

    # Verify sections
    assert len(result["sections"]) > 0
    assert "title" in result["sections"][0]
    assert "content" in result["sections"][0]
    assert "level" in result["sections"][0]


def test_pdf_analyzer_error_handling(sample_pdf_path, monkeypatch):
    """Test PDF analyzer error handling."""

    # Mock the open function to raise an exception
    def mock_open(*args, **kwargs):
        raise Exception("Test exception")

    # Apply the monkeypatch
    monkeypatch.setattr("builtins.open", mock_open)

    # Test the analyzer
    analyzer = PDFAnalyzer()
    result = analyzer.analyze(sample_pdf_path)

    # Verify the result structure for error case
    assert result is not None
    assert "path" in result
    assert "type" in result
    assert "metadata" in result
    assert "sections" in result

    # Verify error section
    assert len(result["sections"]) == 1
    assert result["sections"][0]["title"] == "Error"
    assert "Failed to analyze PDF" in result["sections"][0]["content"]

================
File: pipeline/tests/cleaner/test_pdf_cleaner.py
================
"""
Tests for the PDF cleaner component.
"""

import pytest

from utils.pipeline.cleaner import PDFCleaner


@pytest.fixture
def sample_analysis_result():
    """Fixture to provide a sample analysis result."""
    return {
        "path": "sample.pdf",
        "type": "pdf",
        "metadata": {
            "title": "Sample PDF",
            "author": "Test Author",
            "subject": "Test Subject",
            "creator": "Test Creator",
            "producer": "Test Producer",
            "creation_date": "D:20250315000000",
            "modification_date": "D:20250315000000",
        },
        "pages": [
            {
                "number": 1,
                "size": [0, 0, 612, 792],
                "rotation": 0,
                "content": "SECTION 1\nThis is sample content for section 1.\n\nSECTION 2\nThis is sample content for section 2.",
            },
            {
                "number": 2,
                "size": [0, 0, 612, 792],
                "rotation": 0,
                "content": "SECTION 3\nThis is sample content for section 3.\n\nSECTION 4\nThis is sample content for section 4.",
            },
        ],
        "sections": [
            {
                "title": "SECTION 1",
                "content": "This is sample content for section 1.\n",
                "level": 0,
            },
            {
                "title": "SECTION 2",
                "content": "This is sample content for section 2.\n",
                "level": 0,
            },
            {
                "title": "SECTION 3",
                "content": "This is sample content for section 3.\n",
                "level": 0,
            },
            {
                "title": "SECTION 4",
                "content": "This is sample content for section 4.\n",
                "level": 0,
            },
        ],
    }


def test_pdf_cleaner_initialization():
    """Test PDF cleaner initialization."""
    cleaner = PDFCleaner()
    assert cleaner is not None
    assert hasattr(cleaner, "clean")


def test_pdf_cleaner_with_sample_data(sample_analysis_result):
    """Test PDF cleaner with sample analysis result."""
    cleaner = PDFCleaner()
    result = cleaner.clean(sample_analysis_result)

    # Verify the result structure
    assert result is not None
    assert "path" in result
    assert "type" in result
    assert "metadata" in result
    assert "pages" in result
    assert "sections" in result

    # Verify metadata
    assert result["metadata"]["title"] == "Sample PDF"
    assert result["metadata"]["author"] == "Test Author"

    # Verify pages
    assert len(result["pages"]) == 2
    assert (
        result["pages"][0]["content"]
        == "SECTION 1 This is sample content for section 1. SECTION 2 This is sample content for section 2."
    )

    # Verify sections
    assert len(result["sections"]) == 4
    assert result["sections"][0]["title"] == "SECTION 1"
    assert "This is sample content for section 1" in result["sections"][0]["content"]


def test_pdf_cleaner_with_empty_sections(sample_analysis_result):
    """Test PDF cleaner with empty sections."""
    # Modify the sample data to include an empty section
    sample_analysis_result["sections"].append(
        {"title": "EMPTY SECTION", "content": "", "level": 0}
    )

    cleaner = PDFCleaner()
    result = cleaner.clean(sample_analysis_result)

    # Verify that empty sections are filtered out
    assert len(result["sections"]) == 4  # Still 4, not 5
    assert not any(
        section["title"] == "EMPTY SECTION" for section in result["sections"]
    )


def test_pdf_cleaner_error_handling():
    """Test PDF cleaner error handling."""
    cleaner = PDFCleaner()

    # Test with invalid input
    invalid_input = {"path": "sample.pdf"}  # Missing required fields
    result = cleaner.clean(invalid_input)

    # Should return the original data on error
    assert result == invalid_input


def test_clean_section():
    """Test the _clean_section method."""
    cleaner = PDFCleaner()

    # Test with various content formats
    section = {
        "title": "  TEST SECTION  ",
        "content": "  This is a test.\n\n  With multiple lines.  \n  And extra spaces.  ",
        "level": 0,
    }

    result = cleaner._clean_section(section)

    # Verify cleaning
    assert result["title"] == "TEST SECTION"
    assert "This is a test." in result["content"]
    assert "With multiple lines." in result["content"]
    assert "And extra spaces." in result["content"]
    assert result["level"] == 0


def test_clean_metadata():
    """Test the _clean_metadata method."""
    cleaner = PDFCleaner()

    # Test with various metadata formats
    metadata = {
        "title": "  Test Title  ",
        "author": "  Test Author  ",
        "subject": "Test\nSubject",
        "keywords": ["keyword1", "keyword2"],
        "non_printable": "Test\x00With\x01Non\x02Printable\x03Chars",
    }

    result = cleaner._clean_metadata(metadata)

    # Verify cleaning
    assert result["title"] == "Test Title"
    assert result["author"] == "Test Author"
    assert result["subject"] == "Test Subject"
    assert result["keywords"] == ["keyword1", "keyword2"]  # Lists should be preserved
    assert "Non" in result["non_printable"]
    assert "\x00" not in result["non_printable"]  # Non-printable chars removed

================
File: pipeline/tests/conftest.py
================
"""
Pytest configuration file for the pipeline package.

This file contains fixtures that can be used across multiple test files.
"""

import os
import shutil
import tempfile
from typing import Any, Callable, Dict, Generator, List
from unittest.mock import MagicMock

import pytest

# Define test data directory
TEST_DATA_DIR = os.path.join(
    os.path.dirname(os.path.dirname(__file__)), "data", "tests"
)


# ---- Configuration Fixtures ----


@pytest.fixture
def sample_config() -> Dict[str, Any]:
    """Return a sample configuration for testing."""
    return {
        "input_dir": "data/input",
        "output_dir": "data/output",
        "log_level": "INFO",
        "strategies": {
            "pdf": "strategies.pdf",
            "excel": "strategies.excel",
            "word": "strategies.word",
        },
    }


# ---- File System Fixtures ----


@pytest.fixture
def temp_dir() -> Generator[str, None, None]:
    """Create a temporary directory for test files."""
    temp_dir = tempfile.mkdtemp()
    yield temp_dir
    shutil.rmtree(temp_dir)


@pytest.fixture
def create_temp_file() -> Callable[[str, str], str]:
    """Return a function that creates a temporary file with given content."""

    def _create_temp_file(content: str, extension: str) -> str:
        fd, path = tempfile.mkstemp(suffix=extension)
        try:
            with os.fdopen(fd, "w") as f:
                f.write(content)
        except:
            os.close(fd)
            raise
        return path

    return _create_temp_file


# ---- Sample Document Fixtures ----


@pytest.fixture
def sample_pdf_path() -> str:
    """Return the path to a sample PDF file for testing."""
    return os.path.join(TEST_DATA_DIR, "pdf", "sample.pdf")


@pytest.fixture
def sample_excel_path() -> str:
    """Return the path to a sample Excel file for testing."""
    return os.path.join(TEST_DATA_DIR, "excel", "sample.xlsx")


@pytest.fixture
def sample_word_path() -> str:
    """Return the path to a sample Word file for testing."""
    return os.path.join(TEST_DATA_DIR, "word", "sample.docx")


@pytest.fixture
def sample_text_path() -> str:
    """Return the path to a sample text file for testing."""
    return os.path.join(TEST_DATA_DIR, "text", "sample.txt")


# ---- Mock Strategy Fixtures ----


@pytest.fixture
def mock_analyzer() -> MagicMock:
    """Return a mock analyzer strategy."""
    mock = MagicMock()
    mock.analyze.return_value = {
        "mock_analysis": True,
        "metadata": {"title": "Test Document"},
    }
    return mock


@pytest.fixture
def mock_cleaner() -> MagicMock:
    """Return a mock cleaner strategy."""
    mock = MagicMock()
    mock.clean.return_value = {"mock_cleaned": True, "content": "Cleaned content"}
    return mock


@pytest.fixture
def mock_extractor() -> MagicMock:
    """Return a mock extractor strategy."""
    mock = MagicMock()
    mock.extract.return_value = {"mock_extracted": True, "data": {"key": "value"}}
    return mock


@pytest.fixture
def mock_validator() -> MagicMock:
    """Return a mock validator strategy."""
    mock = MagicMock()
    mock.validate.return_value = {"mock_validated": True, "is_valid": True}
    return mock


@pytest.fixture
def mock_formatter() -> MagicMock:
    """Return a mock formatter strategy."""
    mock = MagicMock()
    mock.format.return_value = {"mock_formatted": True, "output": {"formatted": "data"}}
    return mock


@pytest.fixture
def mock_strategy_set(
    mock_analyzer, mock_cleaner, mock_extractor, mock_validator, mock_formatter
) -> MagicMock:
    """Return a mock strategy set with all components."""
    mock = MagicMock()
    mock.analyzer = mock_analyzer
    mock.cleaner = mock_cleaner
    mock.extractor = mock_extractor
    mock.validator = mock_validator
    mock.formatter = mock_formatter
    return mock


# ---- Parameterization Helpers ----


@pytest.fixture
def document_types() -> List[str]:
    """Return a list of document types for parameterized tests."""
    return ["pdf", "excel", "word", "text"]


@pytest.fixture
def document_paths(
    sample_pdf_path, sample_excel_path, sample_word_path, sample_text_path
) -> Dict[str, str]:
    """Return a dictionary mapping document types to sample paths."""
    return {
        "pdf": sample_pdf_path,
        "excel": sample_excel_path,
        "word": sample_word_path,
        "text": sample_text_path,
    }

================
File: pipeline/tests/processors/test_pdf_extractor.py
================
"""
Tests for the PDF extractor component.
"""

from unittest.mock import MagicMock, patch

import pytest

from utils.pipeline.processors.pdf_extractor import PDFExtractor


@pytest.fixture
def sample_cleaned_data():
    """Fixture to provide sample cleaned data."""
    return {
        "path": "sample.pdf",
        "type": "pdf",
        "metadata": {
            "title": "Sample PDF",
            "author": "Test Author",
            "subject": "Test Subject",
            "creator": "Test Creator",
            "producer": "Test Producer",
            "creation_date": "D:20250315000000",
            "modification_date": "D:20250315000000",
        },
        "pages": [
            {
                "number": 1,
                "size": [0, 0, 612, 792],
                "rotation": 0,
                "content": "SECTION 1\nThis is sample content for section 1.\n\nSECTION 2\nThis is sample content for section 2.",
            },
            {
                "number": 2,
                "size": [0, 0, 612, 792],
                "rotation": 0,
                "content": "SECTION 3\nThis is sample content for section 3.\n\nSECTION 4\nThis is sample content for section 4.",
            },
        ],
        "sections": [
            {
                "title": "SECTION 1",
                "content": "This is sample content for section 1.",
                "level": 0,
            },
            {
                "title": "SECTION 2",
                "content": "This is sample content for section 2.",
                "level": 0,
            },
            {
                "title": "SECTION 3",
                "content": "This is sample content for section 3.",
                "level": 0,
            },
            {
                "title": "SECTION 4",
                "content": "This is sample content for section 4.",
                "level": 0,
            },
        ],
    }


def test_pdf_extractor_initialization():
    """Test PDF extractor initialization."""
    extractor = PDFExtractor()
    assert extractor is not None
    assert hasattr(extractor, "extract")


@patch("fitz.open")
def test_pdf_extractor_with_sample_data(mock_fitz_open, sample_cleaned_data):
    """Test PDF extractor with sample cleaned data."""
    # Create mock document and page
    mock_doc = MagicMock()
    mock_page = MagicMock()

    # Configure mock page to return text
    mock_page.get_text.return_value = "A1 GENERAL INFORMATION\nThis is general information.\n\nA2 SPECIFICATIONS\nThese are specifications."

    # Configure mock document to return pages
    mock_doc.__iter__.return_value = [mock_page, mock_page]

    # Configure mock page to return blocks for table detection
    mock_blocks = {
        "blocks": [
            {
                "lines": [
                    {"spans": [{"text": "Header 1"}, {"text": "Header 2"}]},
                    {"spans": [{"text": "Data 1"}, {"text": "Data 2"}]},
                    {"spans": [{"text": "Data 3"}, {"text": "Data 4"}]},
                ]
            }
        ]
    }
    mock_page.get_text.side_effect = (
        lambda format_type: mock_blocks if format_type == "dict" else "Sample text"
    )

    # Configure mock fitz.open to return mock document
    mock_fitz_open.return_value = mock_doc

    # Test the extractor
    extractor = PDFExtractor()
    result = extractor.extract(sample_cleaned_data)

    # Verify the result structure
    assert result is not None
    assert "metadata" in result
    assert "sections" in result
    assert "tables" in result
    assert "schema" in result
    assert "path" in result

    # Verify metadata
    assert result["metadata"] == sample_cleaned_data["metadata"]

    # Verify sections
    assert len(result["sections"]) > 0

    # Verify tables
    assert len(result["tables"]) > 0
    assert "headers" in result["tables"][0]
    assert "data" in result["tables"][0]
    assert "column_count" in result["tables"][0]
    assert "row_count" in result["tables"][0]

    # Verify schema
    assert "type" in result["schema"]
    assert "properties" in result["schema"]
    assert "required" in result["schema"]


@patch("fitz.open")
def test_pdf_extractor_section_extraction(mock_fitz_open, sample_cleaned_data):
    """Test section extraction functionality."""
    # Create mock document and page
    mock_doc = MagicMock()
    mock_page = MagicMock()

    # Configure mock page to return text with section headers
    mock_page.get_text.return_value = "A1 GENERAL INFORMATION\nThis is general information.\n\nA2 SPECIFICATIONS\nThese are specifications."

    # Configure mock document to return pages
    mock_doc.__iter__.return_value = [mock_page]

    # Configure mock fitz.open to return mock document
    mock_fitz_open.return_value = mock_doc

    # Test the extractor
    extractor = PDFExtractor()
    sections = extractor._extract_sections(mock_doc)

    # Verify sections
    assert len(sections) >= 2
    assert any(section["title"] == "A1 GENERAL INFORMATION" for section in sections)
    assert any(section["title"] == "A2 SPECIFICATIONS" for section in sections)
    assert any(
        "This is general information" in section["content"] for section in sections
    )
    assert any("These are specifications" in section["content"] for section in sections)


@patch("fitz.open")
def test_pdf_extractor_table_extraction(mock_fitz_open, sample_cleaned_data):
    """Test table extraction functionality."""
    # Create mock document and page
    mock_doc = MagicMock()
    mock_page = MagicMock()

    # Configure mock page to return text with table indicators
    mock_page.get_text.return_value = (
        "TABLE 1: Sample Table\nHeader 1\tHeader 2\nData 1\tData 2\nData 3\tData 4\n\n"
    )

    # Configure mock document to return pages
    mock_doc.__iter__.return_value = [mock_page]

    # Configure mock page to return blocks for table detection
    mock_blocks = {
        "blocks": [
            {
                "lines": [
                    {"spans": [{"text": "Header 1"}, {"text": "Header 2"}]},
                    {"spans": [{"text": "Data 1"}, {"text": "Data 2"}]},
                    {"spans": [{"text": "Data 3"}, {"text": "Data 4"}]},
                ]
            }
        ]
    }
    mock_page.get_text.side_effect = (
        lambda format_type: mock_blocks
        if format_type == "dict"
        else "TABLE 1: Sample Table\nHeader 1\tHeader 2\nData 1\tData 2\nData 3\tData 4\n\n"
    )

    # Test the extractor
    extractor = PDFExtractor()
    tables = extractor._extract_tables(mock_doc)

    # Verify tables
    assert len(tables) > 0
    assert tables[0]["page"] == 1
    assert tables[0]["table_number"] == 1
    assert len(tables[0]["headers"]) > 0
    assert len(tables[0]["data"]) > 0
    assert tables[0]["column_count"] > 0
    assert tables[0]["row_count"] > 0


@patch("fitz.open")
def test_pdf_extractor_schema_extraction(mock_fitz_open, sample_cleaned_data):
    """Test schema extraction functionality."""
    # Create sample sections with CSI-style section numbers
    sections = [
        {"title": "A1 GENERAL INFORMATION", "content": "This is general information."},
        {"title": "A2 SPECIFICATIONS", "content": "These are specifications."},
        {"title": "B1.1 MATERIALS", "content": "Material specifications."},
        {"title": "B1.2 EXECUTION", "content": "Execution requirements."},
    ]

    # Test the extractor
    extractor = PDFExtractor()
    schema = extractor._extract_schema(sections)

    # Verify schema structure
    assert schema["type"] == "object"
    assert "properties" in schema
    assert "required" in schema

    # Verify schema properties
    assert "A1" in schema["properties"]
    assert "A2" in schema["properties"]
    assert "B1.1" in schema["properties"]
    assert "B1.2" in schema["properties"]

    # Verify property structure
    assert "title" in schema["properties"]["A1"]
    assert "properties" in schema["properties"]["A1"]
    assert "content" in schema["properties"]["A1"]["properties"]


@patch("fitz.open")
def test_pdf_extractor_error_handling(mock_fitz_open, sample_cleaned_data):
    """Test error handling in PDF extractor."""
    # Configure mock fitz.open to raise an exception
    mock_fitz_open.side_effect = Exception("Test exception")

    # Test the extractor
    extractor = PDFExtractor()

    # Verify that exception is propagated
    with pytest.raises(Exception) as excinfo:
        extractor.extract(sample_cleaned_data)

    # Verify exception message
    assert "Test exception" in str(excinfo.value)

================
File: pipeline/tests/test_classification_fix.py
================
"""
Test script to verify the classification override fix.

This script tests the fix for the classification override issue where HVAC documents
with multiple tables were being classified as "FORM" instead of "HVAC_SPECIFICATION".
"""

import os
import sys
from pathlib import Path

# Add parent directory to path to allow imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

from utils.pipeline.processors.classifiers.rule_based import RuleBasedClassifier
from utils.pipeline.utils.logging import get_logger

# Set up logging
logger = get_logger(__name__)


def create_test_document(table_count=5):
    """
    Create a test document with HVAC content and multiple tables.

    Args:
        table_count: Number of tables to include in the document

    Returns:
        Dictionary representing a document with HVAC content and tables
    """
    # Create a document with HVAC content
    document = {
        "path": "test_documents/HVAC_SPECIFICATION_with_tables.pdf",
        "content": [
            {
                "title": "HVAC System Specifications",
                "content": """
                This document outlines the specifications for the HVAC system.
                The system includes heating, ventilation, and air conditioning components.
                Temperature control is maintained through thermostats.
                Humidity levels are monitored and controlled.
                Airflow is regulated through dampers and diffusers.
                """,
            },
            {
                "title": "System Components",
                "content": """
                The HVAC system includes the following components:
                - Air handling units (AHU)
                - Variable air volume (VAV) boxes
                - Chillers and boilers
                - Ductwork and piping
                - Thermostats and sensors
                """,
            },
        ],
        "metadata": {
            "title": "HVAC Specification Document",
            "author": "Test Author",
            "date": "2025-03-15",
        },
    }

    # Add tables to the document
    document["tables"] = []
    for i in range(table_count):
        document["tables"].append(
            {
                "page": 1,
                "table_number": i + 1,
                "headers": ["Component", "Capacity", "Efficiency", "Manufacturer"],
                "data": [
                    ["AHU-1", "10,000 CFM", "95%", "Carrier"],
                    ["Chiller-1", "500 tons", "0.6 kW/ton", "Trane"],
                    ["Boiler-1", "2,000 MBH", "95%", "Cleaver-Brooks"],
                ],
                "column_count": 4,
                "row_count": 3,
                "detection_method": "layout_analysis",
            }
        )

    return document


def create_features(document):
    """
    Extract features from a document for classification.

    Args:
        document: Document data

    Returns:
        Dictionary of features
    """
    # Extract section titles
    section_titles = [
        section.get("title", "") for section in document.get("content", [])
    ]

    # Count tables and sections
    table_count = len(document.get("tables", []))
    section_count = len(document.get("content", []))

    return {
        "section_titles": section_titles,
        "table_count": table_count,
        "section_count": section_count,
    }


def test_classification_with_hvac_config():
    """
    Test classification with HVAC configuration.

    This test verifies that an HVAC document with multiple tables is correctly
    classified as "HVAC_SPECIFICATION" instead of "FORM" when using the HVAC
    configuration.
    """
    # Load HVAC configuration
    try:
        import json

        config_path = os.path.join("utils", "pipeline", "config", "hvac_config.json")
        with open(config_path, "r") as f:
            config = json.load(f)
    except Exception as e:
        logger.error(f"Error loading HVAC configuration: {str(e)}")
        config = {}

    # Create classifier with HVAC configuration
    classifier = RuleBasedClassifier(config)

    # Create test document with multiple tables
    document = create_test_document(table_count=5)
    features = create_features(document)

    # Classify document
    result = classifier.classify(document, features)

    # Print classification result
    logger.info(f"Classification result: {result}")

    # Check if document was correctly classified as HVAC_SPECIFICATION
    if result.get("document_type") == "HVAC_SPECIFICATION":
        logger.info(
            "✅ Test PASSED: Document correctly classified as HVAC_SPECIFICATION"
        )
    else:
        logger.error(
            f"❌ Test FAILED: Document classified as {result.get('document_type')} instead of HVAC_SPECIFICATION"
        )
        logger.error(f"Confidence: {result.get('confidence')}")
        logger.error(f"Key features: {result.get('key_features')}")


def test_classification_before_fix():
    """
    Simulate classification behavior before the fix.

    This test demonstrates how the document would have been classified before
    the fix by forcing the classifier to use generic classification.
    """
    # Load HVAC configuration
    try:
        import json

        config_path = os.path.join("utils", "pipeline", "config", "hvac_config.json")
        with open(config_path, "r") as f:
            config = json.load(f)
    except Exception as e:
        logger.error(f"Error loading HVAC configuration: {str(e)}")
        config = {}

    # Create classifier with HVAC configuration
    classifier = RuleBasedClassifier(config)

    # Create test document with multiple tables
    document = create_test_document(table_count=5)
    features = create_features(document)

    # Force generic classification (simulating behavior before fix)
    result = classifier._classify_generic(document, features)

    # Print classification result
    logger.info(f"Classification result (before fix): {result}")

    # Check if document would have been classified as FORM
    if result.get("document_type") == "FORM":
        logger.info(
            "✅ Test PASSED: Document would have been classified as FORM before the fix"
        )
    else:
        logger.error(
            f"❌ Test FAILED: Document would have been classified as {result.get('document_type')} instead of FORM"
        )


if __name__ == "__main__":
    # Run tests
    logger.info("=== Testing Classification Override Fix ===")
    logger.info("Testing classification with HVAC configuration (after fix):")
    test_classification_with_hvac_config()

    logger.info("\nSimulating classification behavior before fix:")
    test_classification_before_fix()

================
File: pipeline/tests/test_config.py
================
"""
Tests for the configuration module.

This file demonstrates TDD approach for the configuration module.
"""

import os
from pathlib import Path

import pytest
import yaml
from pydantic import ValidationError

from config.config import LogLevel, PipelineConfig, load_config


def test_default_config():
    """Test that the default configuration is returned when no config file is provided."""
    config = load_config()
    default = PipelineConfig.get_default()
    assert config == default
    assert config is not default  # Should be a different instance


def test_load_config_from_file(temp_dir):
    """Test loading configuration from a YAML file."""
    # Create a test configuration
    test_config = {
        "input_dir": "test/input",
        "output_dir": "test/output",
        "log_level": "DEBUG",
        "strategies": {
            "pdf": "custom.pdf_strategy",
            "excel": "custom.excel_strategy",
        },
    }

    # Write the test configuration to a temporary file
    config_path = os.path.join(temp_dir, "test_config.yaml")
    with open(config_path, "w") as f:
        yaml.dump(test_config, f)

    # Load the configuration from the file
    config = load_config(config_path)

    # Verify the loaded configuration
    assert config.input_dir == "test/input"
    assert config.output_dir == "test/output"
    assert config.log_level == "DEBUG"
    assert config.strategies.pdf == "custom.pdf_strategy"
    assert config.strategies.excel == "custom.excel_strategy"


def test_load_config_with_invalid_file():
    """Test that an error is raised when an invalid config file is provided."""
    with pytest.raises(FileNotFoundError):
        load_config("nonexistent_file.yaml")


def test_load_config_with_invalid_yaml(temp_dir):
    """Test that an error is raised when the config file contains invalid YAML."""
    # Create an invalid YAML file
    config_path = os.path.join(temp_dir, "invalid_config.yaml")
    with open(config_path, "w") as f:
        f.write("invalid: yaml: content: - [")

    with pytest.raises(yaml.YAMLError):
        load_config(config_path)


def test_config_validation():
    """Test that the configuration is validated."""
    # Create an invalid configuration (empty required field)
    invalid_config = {
        "input_dir": "test/input",
        "output_dir": "",  # Empty output_dir should fail validation
    }

    with pytest.raises(ValueError, match="Output directory cannot be empty"):
        load_config(config_dict=invalid_config)

    # Test with None value
    invalid_config2 = {
        "input_dir": "test/input",
        "output_dir": None,  # None output_dir should fail validation
    }

    with pytest.raises(ValidationError):
        load_config(config_dict=invalid_config2)


def test_config_with_environment_variables(temp_dir):
    """Test that environment variables can override configuration values."""
    # Create a temporary directory for the test
    env_input_dir = Path(temp_dir) / "env_input"
    env_input_dir.mkdir(parents=True, exist_ok=True)

    try:
        # Set environment variables with valid paths
        os.environ["PIPELINE_INPUT_DIR"] = str(env_input_dir)
        os.environ["PIPELINE_LOG_LEVEL"] = "ERROR"

        # Load configuration with environment variable support
        config = load_config(use_env=True)

        # Verify that environment variables override default values
        # Convert both paths to forward slashes for comparison
        expected_path = str(env_input_dir).replace("\\", "/")
        assert config.input_dir == expected_path
        assert config.log_level == "ERROR"

        # Verify that other values are still defaults
        default = PipelineConfig.get_default()
        assert config.output_format == default.output_format

    finally:
        # Clean up environment variables
        if "PIPELINE_INPUT_DIR" in os.environ:
            del os.environ["PIPELINE_INPUT_DIR"]
        if "PIPELINE_LOG_LEVEL" in os.environ:
            del os.environ["PIPELINE_LOG_LEVEL"]


def test_merge_configs():
    """Test that configurations can be merged."""
    base_config = {
        "input_dir": "base/input",
        "output_dir": "base/output",
        "log_level": "INFO",
        "strategies": {
            "pdf": "base.pdf_strategy",
            "excel": "base.excel_strategy",
        },
    }

    override_config = {
        "input_dir": "override/input",
        "log_level": "DEBUG",
        "strategies": {
            "pdf": "override.pdf_strategy",
            "word": "override.word_strategy",
        },
    }

    # Merge the configurations
    merged_config = load_config(config_dict=base_config, override_dict=override_config)

    # Verify the merged configuration
    assert merged_config.input_dir == "override/input"  # Overridden
    assert merged_config.output_dir == "base/output"  # Not overridden
    assert merged_config.log_level == "DEBUG"  # Overridden

    # Verify that nested dictionaries are merged correctly
    assert merged_config.strategies.pdf == "override.pdf_strategy"  # Overridden
    assert merged_config.strategies.excel == "base.excel_strategy"  # Not overridden
    assert merged_config.strategies.word == "override.word_strategy"  # Added


def test_config_dictionary_access():
    """Test that configuration can be accessed like a dictionary."""
    config = PipelineConfig(
        input_dir="test/input",
        output_dir="test/output",
        log_level=LogLevel.DEBUG,
    )

    # Test dictionary-like access
    assert config["input_dir"] == "test/input"
    assert config["output_dir"] == "test/output"
    assert config["log_level"] == LogLevel.DEBUG

    # Test equality with dictionary
    assert config == {
        "input_dir": "test/input",
        "output_dir": "test/output",
        "log_level": "DEBUG",
        "output_format": "yaml",
        "validation_level": "basic",
        "strategies": {
            "pdf": "strategies.pdf",
            "excel": "strategies.excel",
            "word": "strategies.word",
            "text": "strategies.text",
        },
    }

================
File: pipeline/tests/test_logging.py
================
"""
Tests for the logging module.

This file tests the centralized logging configuration.
"""

import logging

from ..utils.logging import (
    DEFAULT_LEVEL,
    disable_logging,
    enable_debug_logging,
    get_logger,
    set_log_level,
    setup_logger,
)


def test_setup_logger_default():
    """Test logger setup with default configuration."""
    logger = setup_logger("test")
    assert logger.level == DEFAULT_LEVEL
    assert len(logger.handlers) == 1
    assert isinstance(logger.handlers[0], logging.StreamHandler)


def test_setup_logger_custom_level():
    """Test logger setup with custom log level."""
    # Test with string level
    logger = setup_logger("test.level.string", level="DEBUG")
    assert logger.level == logging.DEBUG

    # Test with integer level
    logger = setup_logger("test.level.int", level=logging.ERROR)
    assert logger.level == logging.ERROR


def test_setup_logger_with_file(tmp_path):
    """Test logger setup with file output."""
    log_file = tmp_path / "test.log"
    logger = setup_logger("test.file", log_file=str(log_file))

    # Should have both console and file handlers
    assert len(logger.handlers) == 2
    assert any(isinstance(h, logging.FileHandler) for h in logger.handlers)
    assert any(isinstance(h, logging.StreamHandler) for h in logger.handlers)

    # Test that the log directory is created
    nested_log_file = tmp_path / "logs" / "nested" / "test.log"
    logger = setup_logger("test.file.nested", log_file=str(nested_log_file))
    assert nested_log_file.parent.exists()


def test_get_logger():
    """Test the convenience get_logger function."""
    logger = get_logger("test.get")
    assert logger.level == DEFAULT_LEVEL
    assert len(logger.handlers) == 1
    assert isinstance(logger.handlers[0], logging.StreamHandler)


def test_set_log_level():
    """Test setting log level for all pipeline loggers."""
    # Create some test loggers
    logger1 = get_logger("pipeline.test1")
    logger2 = get_logger("pipeline.test2")
    other_logger = get_logger("other.logger")  # Should not be affected

    # Test setting level with string
    set_log_level("DEBUG")
    assert logger1.level == logging.DEBUG
    assert logger2.level == logging.DEBUG
    assert other_logger.level == DEFAULT_LEVEL  # Should not change

    # Test setting level with integer
    set_log_level(logging.ERROR)
    assert logger1.level == logging.ERROR
    assert logger2.level == logging.ERROR
    assert other_logger.level == DEFAULT_LEVEL  # Should not change


def test_enable_debug_logging():
    """Test enabling debug logging."""
    logger = get_logger("pipeline.debug")
    enable_debug_logging()
    assert logger.level == logging.DEBUG


def test_disable_logging():
    """Test disabling logging."""
    logger = get_logger("pipeline.disabled")
    disable_logging()
    assert logger.level == logging.CRITICAL


def test_logger_output(tmp_path, capsys):
    """Test actual logger output."""
    # Test console output
    logger = get_logger("test.output")
    test_message = "Test log message"
    logger.info(test_message)
    captured = capsys.readouterr()
    assert test_message in captured.err

    # Test file output
    log_file = tmp_path / "output.log"
    logger = setup_logger("test.output.file", log_file=str(log_file))
    logger.info(test_message)

    with open(log_file) as f:
        log_content = f.read()
        assert test_message in log_content


def test_multiple_setup_calls():
    """Test that multiple setup calls don't duplicate handlers."""
    logger_name = "test.multiple"
    logger1 = setup_logger(logger_name)
    initial_handlers = len(logger1.handlers)

    # Second setup call should not add handlers
    logger2 = setup_logger(logger_name)
    assert len(logger2.handlers) == initial_handlers
    assert logger1 is logger2  # Should be the same logger instance

================
File: pipeline/tests/test_models.py
================
"""
Tests for the models module.

This file tests the base data models used in the pipeline.
"""

from models.models import PipelineData


def test_pipeline_data_init_with_data():
    """Test PipelineData initialization with data."""
    test_data = {"key": "value", "nested": {"inner": "data"}}
    data = PipelineData(test_data)
    assert data.data == test_data
    assert data.data is not test_data  # Should be a copy


def test_pipeline_data_init_without_data():
    """Test PipelineData initialization without data."""
    data = PipelineData()
    assert data.data == {}
    assert isinstance(data.data, dict)


def test_pipeline_data_init_with_none():
    """Test PipelineData initialization with None."""
    data = PipelineData(None)
    assert data.data == {}
    assert isinstance(data.data, dict)

================
File: pipeline/tests/test_pipeline_logging.py
================
"""
Tests for pipeline logging functionality.

This file tests that the pipeline correctly uses the logging system.
"""

import logging

import pytest

from ..pipeline import Pipeline, PipelineError
from ..utils.logging import get_logger, set_log_level


def test_pipeline_initialization_logging(caplog):
    """Test that pipeline initialization is properly logged."""
    caplog.set_level(logging.INFO)
    test_config = {"test_key": "test_value"}
    pipeline = Pipeline(test_config)

    # Check initialization log
    assert any(
        record.levelname == "INFO"
        and "Pipeline initialized with config" in record.message
        and str(test_config) in record.message
        for record in caplog.records
    )


def test_pipeline_processing_logging(caplog, tmp_path):
    """Test that pipeline processing steps are properly logged."""
    caplog.set_level(logging.INFO)
    pipeline = Pipeline()

    # Create a test file
    test_file = tmp_path / "test.txt"
    test_file.write_text("test content")

    # Run pipeline and capture logs
    pipeline.run(str(test_file))

    # Expected log messages in order
    expected_messages = [
        "Starting pipeline processing for",
        "Detected document type",
        "Step 1: Analyzing document structure",
        "Step 2: Cleaning and normalizing content",
        "Step 3: Extracting structured data",
        "Step 4: Validating extracted data",
        "Step 5: Formatting output",
        "Pipeline processing completed successfully",
    ]

    # Check that all expected messages are present in order
    log_messages = [record.message for record in caplog.records]
    current_idx = 0
    for expected in expected_messages:
        matching_messages = [
            msg for msg in log_messages[current_idx:] if expected in msg
        ]
        assert matching_messages, f"Missing log message: {expected}"
        current_idx = log_messages.index(matching_messages[0]) + 1


def test_pipeline_error_logging(caplog, tmp_path):
    """Test that pipeline errors are properly logged."""
    caplog.set_level(logging.ERROR)
    pipeline = Pipeline()

    # Try to process a non-existent file
    non_existent_file = tmp_path / "does_not_exist.txt"

    with pytest.raises(PipelineError):
        pipeline.run(str(non_existent_file))

    # Check error log
    assert any(
        record.levelname == "ERROR" and "Pipeline processing failed" in record.message
        for record in caplog.records
    )


def test_strategy_selector_logging(caplog, tmp_path):
    """Test that strategy selection is properly logged."""
    caplog.set_level(logging.INFO)
    pipeline = Pipeline()

    # Create a test PDF file
    test_file = tmp_path / "test.pdf"
    test_file.write_text("test content")

    # Process a test document to trigger strategy selection
    result = pipeline.run(str(test_file))

    # Check strategy selection log
    assert any(
        record.levelname == "INFO"
        and "Selecting strategies for document type: pdf" in record.message
        for record in caplog.records
    )


def test_output_saving_logging(caplog, tmp_path):
    """Test that output saving is properly logged."""
    caplog.set_level(logging.INFO)
    pipeline = Pipeline()

    # Create some test output data
    output_data = {"test": "data"}
    output_file = tmp_path / "output.yaml"

    # Save output and check logs
    pipeline.save_output(output_data, str(output_file))

    assert any(
        record.levelname == "INFO"
        and "Saving output to:" in record.message
        and str(output_file) in record.message
        for record in caplog.records
    )


def test_log_level_propagation():
    """Test that log level changes are properly propagated to pipeline components."""
    # Create loggers for different components
    pipeline_logger = get_logger("pipeline")
    strategy_logger = get_logger("pipeline.strategy")
    processor_logger = get_logger("pipeline.processor")

    # Set different log levels
    levels_to_test = [logging.DEBUG, logging.INFO, logging.WARNING, logging.ERROR]

    for level in levels_to_test:
        # Use set_log_level to properly propagate levels
        set_log_level(level)
        assert pipeline_logger.level == level
        assert strategy_logger.level == level
        assert processor_logger.level == level

================
File: pipeline/tests/test_pipeline.py
================
"""
Tests for the pipeline module.

This file demonstrates TDD approach for the pipeline orchestrator.
"""

import os
from unittest.mock import MagicMock

import pytest

from pipeline import (
    MockStrategy,
    Pipeline,
    PipelineError,
    StrategySelector,
    StrategySet,
)


# Basic initialization tests
def test_pipeline_initialization(sample_config):
    """Test that the pipeline initializes correctly with a configuration."""
    pipeline = Pipeline(sample_config)
    assert pipeline.config == sample_config


def test_pipeline_default_config():
    """Test that the pipeline initializes with a default configuration if none is provided."""
    pipeline = Pipeline()
    assert isinstance(pipeline.config, dict)


# Document type detection tests
@pytest.mark.parametrize(
    "file_path,expected_type",
    [
        ("document.pdf", "pdf"),
        ("document.PDF", "pdf"),
        ("path/to/document.xlsx", "excel"),
        ("path/to/document.xls", "excel"),
        ("document.docx", "word"),
        ("document.doc", "word"),
        ("document.txt", "text"),
        ("document.unknown", "generic"),
    ],
)
def test_detect_document_type(file_path, expected_type):
    """Test that the pipeline correctly detects document types based on file extension."""
    pipeline = Pipeline()
    detected_type = pipeline._detect_document_type(file_path)
    assert detected_type == expected_type


# Pipeline flow tests
def test_pipeline_run_with_mocks(mock_strategy_set):
    """Test the pipeline run method with mocked strategy components."""
    pipeline = Pipeline()

    # Mock the strategy selector to return our mock strategy set
    pipeline.strategy_selector = MagicMock()
    pipeline.strategy_selector.get_strategies.return_value = mock_strategy_set

    # Run the pipeline with a dummy file path
    result = pipeline.run("dummy/path/to/document.pdf")

    # Verify that each strategy was called in the correct order
    mock_strategy_set.analyzer.analyze.assert_called_once()
    mock_strategy_set.cleaner.clean.assert_called_once()
    mock_strategy_set.extractor.extract.assert_called_once()
    mock_strategy_set.validator.validate.assert_called_once()
    mock_strategy_set.formatter.format.assert_called_once()

    # Verify that the result is the output from the formatter
    assert result == mock_strategy_set.formatter.format.return_value


def test_pipeline_error_handling():
    """Test that the pipeline handles errors correctly."""
    pipeline = Pipeline()

    # Mock the strategy selector to raise an exception
    pipeline.strategy_selector = MagicMock()
    pipeline.strategy_selector.get_strategies.side_effect = Exception("Test error")

    # Verify that the pipeline raises a PipelineError
    with pytest.raises(PipelineError, match="Test error"):
        pipeline.run("dummy/path/to/document.pdf")


# Integration test with file system
def test_pipeline_save_output_yaml(temp_dir):
    """Test that the pipeline can save output to a YAML file."""
    pipeline = Pipeline()

    # Create a sample output
    output_data = {
        "title": "Test Document",
        "content": "This is a test document.",
        "metadata": {
            "author": "Test Author",
            "date": "2025-03-14",
        },
    }

    # Test both .yaml and .yml extensions
    for ext in [".yaml", ".yml"]:
        output_path = os.path.join(temp_dir, f"output{ext}")
        pipeline.save_output(output_data, output_path)

        # Verify that the file was created
        assert os.path.exists(output_path)

        # Verify the content of the file
        import yaml

        with open(output_path, "r") as f:
            loaded_data = yaml.safe_load(f)

        assert loaded_data == output_data


def test_pipeline_save_output_json(temp_dir):
    """Test that the pipeline can save output to a JSON file."""
    pipeline = Pipeline()

    # Create a sample output
    output_data = {
        "title": "Test Document",
        "content": "This is a test document.",
        "metadata": {
            "author": "Test Author",
            "date": "2025-03-14",
        },
    }

    # Save the output to a JSON file
    output_path = os.path.join(temp_dir, "output.json")
    pipeline.save_output(output_data, output_path)

    # Verify that the file was created
    assert os.path.exists(output_path)

    # Verify the content of the file
    import json

    with open(output_path, "r") as f:
        loaded_data = json.load(f)

    assert loaded_data == output_data


def test_pipeline_save_output_default_yaml(temp_dir):
    """Test that the pipeline defaults to YAML for unknown extensions."""
    pipeline = Pipeline()

    # Create a sample output
    output_data = {
        "title": "Test Document",
        "content": "This is a test document.",
    }

    # Save with unknown extension
    output_path = os.path.join(temp_dir, "output.unknown")
    pipeline.save_output(output_data, output_path)

    # Verify that the file was created
    assert os.path.exists(output_path)

    # Verify the content is YAML
    import yaml

    with open(output_path, "r") as f:
        loaded_data = yaml.safe_load(f)

    assert loaded_data == output_data


def test_strategy_selector_import_paths():
    """Test strategy selector's import paths for different document types."""
    selector = StrategySelector({})

    # Test each document type
    for doc_type in ["pdf", "excel", "word", "generic"]:
        strategy_set = selector.get_strategies(doc_type)
        assert isinstance(strategy_set, StrategySet)
        assert hasattr(strategy_set, "analyzer")
        assert hasattr(strategy_set, "cleaner")
        assert hasattr(strategy_set, "extractor")
        assert hasattr(strategy_set, "validator")
        assert hasattr(strategy_set, "formatter")


def test_strategy_selector_import_error():
    """Test strategy selector's fallback to mock strategies on import error."""
    selector = StrategySelector({})

    # Test with a non-existent strategy type
    strategy_set = selector.get_strategies("nonexistent")

    # Verify that mock strategies are used
    assert isinstance(strategy_set.analyzer, MockStrategy)
    assert isinstance(strategy_set.cleaner, MockStrategy)
    assert isinstance(strategy_set.extractor, MockStrategy)
    assert isinstance(strategy_set.validator, MockStrategy)
    assert isinstance(strategy_set.formatter, MockStrategy)


def test_mock_strategy_methods(tmp_path):
    """Test all methods of the MockStrategy class."""
    strategy = MockStrategy()

    # Create a test file
    test_file = tmp_path / "test.txt"
    test_file.write_text("test content")

    # Test analyze method
    result = strategy.analyze(str(test_file))
    assert result == {"mock_analysis": True, "path": str(test_file)}

    # Test analyze with non-existent file
    with pytest.raises(FileNotFoundError):
        strategy.analyze("nonexistent/file.txt")

    # Test clean method
    data = {"test": "data"}
    result = strategy.clean(data)
    assert result == {"mock_cleaned": True, "data": data}

    # Test extract method
    result = strategy.extract(data)
    assert result == {"mock_extracted": True, "data": data}

    # Test validate method
    result = strategy.validate(data)
    assert result == {"mock_validated": True, "data": data}

    # Test format method
    result = strategy.format(data)
    assert result == {"mock_formatted": True, "data": data}


# Property-based testing for document type detection
@pytest.mark.parametrize(
    "extension",
    [
        "pdf",
        "xlsx",
        "docx",
        "txt",
        "csv",
        "json",
        "xml",
        "html",
        "md",
        "py",
        "js",
        "unknown",
    ],
)
def test_document_type_detection_property(extension, create_temp_file):
    """
    Property-based test for document type detection.

    For any file extension, the detected type should be consistent
    regardless of the file name or path.
    """
    pipeline = Pipeline()

    # Create multiple file paths with the same extension
    file_paths = [
        f"document.{extension}",
        f"path/to/document.{extension}",
        f"path/with spaces/to/document with spaces.{extension}",
        f"path/with-special-chars/to/document-with-special-chars.{extension}",
    ]

    # Get the expected type for the first file path
    expected_type = pipeline._detect_document_type(file_paths[0])

    # Verify that all file paths with the same extension have the same detected type
    for file_path in file_paths[1:]:
        detected_type = pipeline._detect_document_type(file_path)
        assert detected_type == expected_type, (
            f"Inconsistent type detection for {file_path}"
        )

================
File: pipeline/utils/logging.py
================
"""
Centralized logging configuration for the pipeline.

This module provides a consistent logging setup across all pipeline components.
"""

import logging
from pathlib import Path
from typing import Optional, Union

# Default log format
DEFAULT_FORMAT = "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

# Default log level
DEFAULT_LEVEL = logging.INFO


def setup_logger(
    name: str,
    level: Optional[Union[str, int]] = None,
    log_format: Optional[str] = None,
    log_file: Optional[str] = None,
) -> logging.Logger:
    """
    Set up a logger with consistent formatting and optional file output.

    Args:
        name: Name of the logger (usually __name__)
        level: Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
        log_format: Custom log format string
        log_file: Path to log file (if file logging is desired)

    Returns:
        Configured logger instance
    """
    logger = logging.getLogger(name)

    # Enable propagation to parent loggers
    logger.propagate = True

    # If this is a pipeline logger, inherit level from root pipeline logger
    if name.startswith("pipeline."):
        root_logger = logging.getLogger("pipeline")
        logger.setLevel(root_logger.level)
    else:
        # Set log level (default to INFO if not specified or invalid)
        if isinstance(level, str):
            level = getattr(logging, level.upper(), DEFAULT_LEVEL)
        logger.setLevel(level or DEFAULT_LEVEL)

    # Create formatter
    formatter = logging.Formatter(log_format or DEFAULT_FORMAT)

    # Always add console handler if none exists
    if not logger.handlers:
        console_handler = logging.StreamHandler()
        console_handler.setFormatter(formatter)
        logger.addHandler(console_handler)

    # Add file handler if specified
    if log_file:
        # Ensure log directory exists
        log_path = Path(log_file)
        log_path.parent.mkdir(parents=True, exist_ok=True)

        file_handler = logging.FileHandler(log_file)
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)

    return logger


def get_logger(name: str) -> logging.Logger:
    """
    Get a logger with default configuration.

    This is a convenience function for getting a logger with default settings.
    For custom configuration, use setup_logger directly.

    Args:
        name: Name of the logger (usually __name__)

    Returns:
        Configured logger instance
    """
    return setup_logger(name)


def set_log_level(level: Union[str, int]) -> None:
    """
    Set the log level for all pipeline loggers.

    Args:
        level: Log level (DEBUG, INFO, WARNING, ERROR, CRITICAL)
    """
    if isinstance(level, str):
        level = getattr(logging, level.upper(), DEFAULT_LEVEL)

    # Get the root pipeline logger
    root_logger = logging.getLogger("pipeline")
    root_logger.setLevel(level)

    # Update all child loggers
    for name, logger in logging.root.manager.loggerDict.items():
        if isinstance(logger, logging.Logger) and name.startswith("pipeline"):
            logger.setLevel(level)
            # Ensure child loggers inherit from parent
            logger.propagate = True


def enable_debug_logging() -> None:
    """Enable debug logging for all pipeline components."""
    set_log_level(logging.DEBUG)


def disable_logging() -> None:
    """Disable logging for all pipeline components."""
    set_log_level(logging.CRITICAL)

================
File: pipeline/utils/progress.py
================
"""
Progress tracking utilities using Rich.

This module provides rich terminal output for pipeline progress.
"""

from typing import Any, Dict, Optional

from rich.console import Console
from rich.panel import Panel
from rich.progress import (
    BarColumn,
    Progress,
    SpinnerColumn,
    TaskID,
    TaskProgressColumn,
    TextColumn,
    TimeRemainingColumn,
)
from rich.tree import Tree

console = Console()


class PipelineProgress:
    """Rich progress tracking for pipeline operations."""

    def __init__(self):
        self.progress = Progress(
            SpinnerColumn(),
            TextColumn("[progress.description]{task.description}"),
            BarColumn(),
            TaskProgressColumn(),
            TimeRemainingColumn(),
            console=console,
            transient=True,  # Hide completed tasks
            expand=True,
        )

    def __enter__(self):
        self.progress.__enter__()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.progress.__exit__(exc_type, exc_val, exc_tb)

    def start(self):
        """Start progress tracking."""
        self.progress.start()

    def stop(self):
        """Stop progress tracking."""
        self.progress.stop()

    def add_task(self, description: str, total: Optional[float] = None) -> TaskID:
        """Add a new task to track."""
        return self.progress.add_task(description, total=total)

    def update(self, task_id: TaskID, advance: float = 1):
        """Update task progress."""
        self.progress.update(task_id, advance=advance)

    def _create_tree_view(self, data: Dict[str, Any], title: str) -> Tree:
        """Create a tree view of nested data."""
        tree = Tree(f"[bold blue]{title}")

        def add_nodes(parent, content, depth=0, max_depth=2):
            if depth >= max_depth:
                return

            if isinstance(content, dict):
                for key, value in content.items():
                    # Skip content display
                    if key == "content":
                        parent.add(f"[cyan]{key}: [dim](content hidden)")
                        continue

                    if isinstance(value, (dict, list)):
                        branch = parent.add(f"[cyan]{key}")
                        add_nodes(branch, value, depth + 1, max_depth)
                    else:
                        # Truncate long values
                        str_value = str(value)
                        if len(str_value) > 30:
                            str_value = str_value[:27] + "..."
                        parent.add(f"[green]{key}: [yellow]{str_value}")
            elif isinstance(content, list):
                if not content:
                    parent.add("[dim]<empty>")
                else:
                    parent.add(f"[dim]{len(content)} items")

        add_nodes(tree, data)
        return tree

    def _update_display(self, content: Any) -> None:
        """Update display with new content."""
        console.print(content)

    def display_stage_output(
        self, stage_name: str, data: Dict[str, Any], show_details: bool = False
    ):
        """Display stage output in a concise tree view."""
        if show_details:
            self._update_display(
                Panel(
                    self._create_tree_view(data, stage_name),
                    title=f"[bold]{stage_name} Output",
                    border_style="blue",
                )
            )

    def display_summary(self, stages_data: Dict[str, Dict[str, Any]]):
        """Display final summary of all stages."""
        summary_tree = Tree("[bold blue]Pipeline Summary")
        for stage, data in stages_data.items():
            stage_branch = summary_tree.add(f"[cyan]{stage}")
            if isinstance(data, dict):
                # Show key statistics or counts
                stats = {
                    k: v
                    for k, v in data.items()
                    if isinstance(v, (int, float, str))
                    or (isinstance(v, (list, dict)) and len(v) > 0)
                }
                for key, value in stats.items():
                    if isinstance(value, (list, dict)):
                        stage_branch.add(f"[green]{key}: [yellow]{len(value)} items")
                    else:
                        stage_branch.add(f"[green]{key}: [yellow]{value}")

        self._update_display(
            Panel(
                summary_tree,
                title="[bold]Pipeline Execution Summary",
                border_style="green",
            )
        )

    def display_error(self, message: str):
        """Display error message."""
        self._update_display(
            Panel(f"[red]{message}", title="Error", border_style="red")
        )

    def display_warning(self, message: str):
        """Display warning message."""
        self._update_display(
            Panel(f"[yellow]{message}", title="Warning", border_style="yellow")
        )

    def display_success(self, message: str):
        """Display success message."""
        self._update_display(
            Panel(f"[green]{message}", title="Success", border_style="green")
        )

================
File: pipeline/uv.lock
================
version = 1
requires-python = ">=3.8"
resolution-markers = [
    "python_full_version < '3.9'",
    "python_full_version == '3.9.*'",
    "python_full_version == '3.10.*'",
    "python_full_version == '3.11.*'",
    "python_full_version >= '3.12'",
]

[[package]]
name = "annotated-types"
version = "0.7.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions", marker = "python_full_version < '3.9'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/ee/67/531ea369ba64dcff5ec9c3402f9f51bf748cec26dde048a2f973a4eea7f5/annotated_types-0.7.0.tar.gz", hash = "sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89", size = 16081 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl", hash = "sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53", size = 13643 },
]

[[package]]
name = "appscript"
version = "1.3.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "lxml" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a3/84/5c0aec149c6a002d46af17e3d2c5efbe5e8258ef7574cfc17cd1b26c726e/appscript-1.3.0.tar.gz", hash = "sha256:80943118bc97f9f78a8aa55f85565752ed4d82c7893427d7d9ebfdf401c12b2c", size = 295205 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/33/c1/27f71a14b212ff6b33a4ebcd55c5f89353220252be2226c4d660bce16c90/appscript-1.3.0-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:c39d9fdbe92dce3c731bce4b818d1e5776d03e8b18706ee25777b7446032a061", size = 99360 },
    { url = "https://files.pythonhosted.org/packages/24/e7/3487e33c2ad1fd26d683e4b80970b01a74696d9874c36841f5c207229cca/appscript-1.3.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:11a19fdf690e359af634c32d5bec96afd3f8f5229cd2f1c332137ebcbf8fbe90", size = 85400 },
    { url = "https://files.pythonhosted.org/packages/99/64/db8dddd3c561fe5085e5b3a60419bfb560f07e1ca0dc1c7027cbaa5fb582/appscript-1.3.0-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:76a3507b27c78bf79af83a5f6fac49664b53d530d75632c023e53df1bd350caf", size = 99353 },
    { url = "https://files.pythonhosted.org/packages/40/ee/4e0dee488d3dd35aab03c2f6ecb6dc0161fad200077cca68afe041079d2b/appscript-1.3.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:94ca097d672de5b8cfc82b4179b00cabd21588dbfd939347cf14a9e81955b2d5", size = 85401 },
    { url = "https://files.pythonhosted.org/packages/b8/e2/05fd221bea1d309211569130a1a8f0966eb56394e46df068a69df0f29d61/appscript-1.3.0-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:c0b5c160908de728072d4a0ae57f286608c5d7692bfccbc6eadde868aac2742b", size = 99575 },
    { url = "https://files.pythonhosted.org/packages/df/2f/3ee4190ce97b0b39df58184210d3baaa5fe59ae0972e63c2c85f122ca887/appscript-1.3.0-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:d2a287b81030c81017127d4fb1c24729623576c50d2ff41694476b9af3ce0a97", size = 85496 },
    { url = "https://files.pythonhosted.org/packages/92/5a/3b642e3e904fb37d45e40bb07b4362979160bdecb0d37aa74f2506b1a47e/appscript-1.3.0-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:13094640e2694b888827d4e133f33dad1e08c9d7102b447c3cc8a73246fdab40", size = 99574 },
    { url = "https://files.pythonhosted.org/packages/5c/bc/d8558bec737e02a9c404fb3b985b8636c313bb65a176375d551cb839e876/appscript-1.3.0-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:e7b4760105810e9b1ecd5b40aba7617e0a047346fb94ee4370e9d37e4383b78d", size = 85503 },
    { url = "https://files.pythonhosted.org/packages/b5/a1/45915ac267d0e192f638b56521bc9f2bbd8bb204689672fb9e1080009f1d/appscript-1.3.0-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:a48338f9aad0f26f6f1e1d3a90685df771966b2c4f93374f92d7d90d69f3f745", size = 99349 },
    { url = "https://files.pythonhosted.org/packages/d8/47/9c72ec7f16a610d8bd08ecc47b47cbe0517e86ae0efc67252659b9f86dcf/appscript-1.3.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:f40d8f82da4ac99ddacc7cf845df56c27a7fa190989fd0c1299eabfeef97add2", size = 85402 },
]

[[package]]
name = "beautifulsoup4"
version = "4.13.3"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "soupsieve" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/f0/3c/adaf39ce1fb4afdd21b611e3d530b183bb7759c9b673d60db0e347fd4439/beautifulsoup4-4.13.3.tar.gz", hash = "sha256:1bd32405dacc920b42b83ba01644747ed77456a65760e285fbc47633ceddaf8b", size = 619516 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f9/49/6abb616eb3cbab6a7cca303dc02fdf3836de2e0b834bf966a7f5271a34d8/beautifulsoup4-4.13.3-py3-none-any.whl", hash = "sha256:99045d7d3f08f91f0d656bc9b7efbae189426cd913d830294a15eefa0ea4df16", size = 186015 },
]

[[package]]
name = "blis"
version = "0.7.11"
source = { registry = "https://pypi.org/simple" }
resolution-markers = [
    "python_full_version < '3.9'",
]
dependencies = [
    { name = "numpy", marker = "python_full_version < '3.9'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/51/8c/60c85350f2e1c9647df580083a0f6acc686ef32d1a91f4ab0c624b3ff867/blis-0.7.11.tar.gz", hash = "sha256:cec6d48f75f7ac328ae1b6fbb372dde8c8a57c89559172277f66e01ff08d4d42", size = 2897107 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/41/8b/b61978aa36de134d1056c55c2efe818042df68aff211b91fa5b1b9ae3f85/blis-0.7.11-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:cd5fba34c5775e4c440d80e4dea8acb40e2d3855b546e07c4e21fad8f972404c", size = 6127109 },
    { url = "https://files.pythonhosted.org/packages/3d/95/f23fbbf3010bf057302ebbb8ad697fb9a0f8624e833025c4a58bfb8d3389/blis-0.7.11-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:31273d9086cab9c56986d478e3ed6da6752fa4cdd0f7b5e8e5db30827912d90d", size = 1110252 },
    { url = "https://files.pythonhosted.org/packages/fd/82/8d9576904833a8575ae6758dd8c1a2152fdec1705dd3ae65a10e99d8896a/blis-0.7.11-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d06883f83d4c8de8264154f7c4a420b4af323050ed07398c1ff201c34c25c0d2", size = 1711161 },
    { url = "https://files.pythonhosted.org/packages/9b/81/55092e1c016fe05ef7a57623920209012f05e8b897acbad355c9bf854181/blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ee493683e3043650d4413d531e79e580d28a3c7bdd184f1b9cfa565497bda1e7", size = 10171589 },
    { url = "https://files.pythonhosted.org/packages/ad/65/d9fd07e11499e0a3162c6d61ae430172125e5c340c89c40504189d5299b9/blis-0.7.11-cp310-cp310-win_amd64.whl", hash = "sha256:a73945a9d635eea528bccfdfcaa59dd35bd5f82a4a40d5ca31f08f507f3a6f81", size = 6620069 },
    { url = "https://files.pythonhosted.org/packages/c7/59/c8010f380a16709e6d3ef5534845d1ca1e689079914ec67ab60f57edfc37/blis-0.7.11-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:1b68df4d01d62f9adaef3dad6f96418787265a6878891fc4e0fabafd6d02afba", size = 6123547 },
    { url = "https://files.pythonhosted.org/packages/a8/73/0a9d4e7f6e78ef270e3a4532b17e060a02087590cf615ba9943fd1a283e9/blis-0.7.11-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:162e60d941a8151418d558a94ee5547cb1bbeed9f26b3b6f89ec9243f111a201", size = 1106895 },
    { url = "https://files.pythonhosted.org/packages/51/f7/a5d9a0be0729f4172248dbae74d7e02b139b3a32cc29650d3ade7ab91fea/blis-0.7.11-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:686a7d0111d5ba727cd62f374748952fd6eb74701b18177f525b16209a253c01", size = 1707389 },
    { url = "https://files.pythonhosted.org/packages/dc/23/eb01450dc284a7ea8ebc0e5296f1f8fdbe5299169f4c318f836b4284a119/blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0421d6e44cda202b113a34761f9a062b53f8c2ae8e4ec8325a76e709fca93b6e", size = 10172888 },
    { url = "https://files.pythonhosted.org/packages/2f/09/da0592c74560cc33396504698122f7a56747c82a5e072ca7d2c3397898e1/blis-0.7.11-cp311-cp311-win_amd64.whl", hash = "sha256:0dc9dcb3843045b6b8b00432409fd5ee96b8344a324e031bfec7303838c41a1a", size = 6602835 },
    { url = "https://files.pythonhosted.org/packages/e2/12/90897bc489626cb71e51ce8bb89e492fabe96a57811e53159c0f74ae90ec/blis-0.7.11-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:dadf8713ea51d91444d14ad4104a5493fa7ecc401bbb5f4a203ff6448fadb113", size = 6121528 },
    { url = "https://files.pythonhosted.org/packages/e2/5d/67a3f6b6108c39d3fd1cf55a7dca9267152190dad419c9de6d764b3708ca/blis-0.7.11-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:5bcdaf370f03adaf4171d6405a89fa66cb3c09399d75fc02e1230a78cd2759e4", size = 1105039 },
    { url = "https://files.pythonhosted.org/packages/03/62/0d214dde0703863ed2d3dabb3f10606f7f55ac4eb07a52c3906601331b63/blis-0.7.11-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:7de19264b1d49a178bf8035406d0ae77831f3bfaa3ce02942964a81a202abb03", size = 1701009 },
    { url = "https://files.pythonhosted.org/packages/66/aa/bcbd1c6b1c7dfd717ff5c899a1c8adcc6b3e391fb7a0b00fdc64e4e54235/blis-0.7.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8ea55c6a4a60fcbf6a0fdce40df6e254451ce636988323a34b9c94b583fc11e5", size = 10161187 },
    { url = "https://files.pythonhosted.org/packages/9a/91/4aea63dccee6491a54c630d9817656a886e086ab97222e2d8101d8cdf894/blis-0.7.11-cp312-cp312-win_amd64.whl", hash = "sha256:5a305dbfc96d202a20d0edd6edf74a406b7e1404f4fa4397d24c68454e60b1b4", size = 6624079 },
    { url = "https://files.pythonhosted.org/packages/6d/88/bd90a1c3f7dd3cab95d41404932a0926bf2dc54f6cc28cc27feb9480aa4e/blis-0.7.11-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:6df00c24128e323174cde5d80ebe3657df39615322098ce06613845433057614", size = 6121079 },
    { url = "https://files.pythonhosted.org/packages/71/b8/e90fd4c2c4e14335da99b33d3e022527e2b67e15194c2c678d04ad091b2d/blis-0.7.11-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:809d1da1331108935bf06e22f3cf07ef73a41a572ecd81575bdedb67defe3465", size = 1104565 },
    { url = "https://files.pythonhosted.org/packages/f6/d5/3b494bbdfcb5c361938b897225a3af24d03ba0ab11f1a45c18087b0cc3b2/blis-0.7.11-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bfabd5272bbbe504702b8dfe30093653d278057656126716ff500d9c184b35a6", size = 1712658 },
    { url = "https://files.pythonhosted.org/packages/9d/42/d233ec75bc8682e368e96073703f01dc095792019fcb541e741b28ce4074/blis-0.7.11-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ca684f5c2f05269f17aefe7812360286e9a1cee3afb96d416485efd825dbcf19", size = 10172191 },
    { url = "https://files.pythonhosted.org/packages/68/fe/a6e76b918206fb103c7ea511db1556b824d6c9bbbbd147b91ee8540253b1/blis-0.7.11-cp38-cp38-win_amd64.whl", hash = "sha256:688a8b21d2521c2124ee8dfcbaf2c385981ccc27e313e052113d5db113e27d3b", size = 6625814 },
    { url = "https://files.pythonhosted.org/packages/a5/95/25d8d197204624f2ea5f529c87446b16bf625d1377789af56d35648d0705/blis-0.7.11-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:2ff7abd784033836b284ff9f4d0d7cb0737b7684daebb01a4c9fe145ffa5a31e", size = 6127608 },
    { url = "https://files.pythonhosted.org/packages/b0/08/e3e77a51a458184996ac598ae3eef42dac61363e009125555ce659da5103/blis-0.7.11-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:f9caffcd14795bfe52add95a0dd8426d44e737b55fcb69e2b797816f4da0b1d2", size = 1109493 },
    { url = "https://files.pythonhosted.org/packages/c2/66/fd4a750cb01f5d62227f526e1803e2c2046cd627594023c850b160a6c9ac/blis-0.7.11-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:2fb36989ed61233cfd48915896802ee6d3d87882190000f8cfe0cf4a3819f9a8", size = 1711586 },
    { url = "https://files.pythonhosted.org/packages/00/45/9d371e2047ecefc423dcf22b6b351e9fbf34f6e82e7827b8567e880fbafe/blis-0.7.11-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7ea09f961871f880d5dc622dce6c370e4859559f0ead897ae9b20ddafd6b07a2", size = 10172486 },
    { url = "https://files.pythonhosted.org/packages/b6/fd/d2dcd4a3334ac69e91bc0e90ac522f78f5973919d25cf1f757a6517a11f2/blis-0.7.11-cp39-cp39-win_amd64.whl", hash = "sha256:5bb38adabbb22f69f22c74bad025a010ae3b14de711bf5c715353980869d491d", size = 6624422 },
]

[[package]]
name = "blis"
version = "1.2.0"
source = { registry = "https://pypi.org/simple" }
resolution-markers = [
    "python_full_version == '3.9.*'",
    "python_full_version == '3.10.*'",
    "python_full_version == '3.11.*'",
    "python_full_version >= '3.12'",
]
dependencies = [
    { name = "numpy", marker = "python_full_version >= '3.9'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/e5/69/d4829c5b5cd244e6140a0754a0f73cc725c6e138f609b4c5d1982e699906/blis-1.2.0.tar.gz", hash = "sha256:f25f99d7f3cad72c86a7499212ee833fb5062d80ad1763a935e0e498bc147c69", size = 2375955 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/54/ff/c55d9d42a622b95fca27f82d4674cd19ad86941dc893f0898ebcccdab105/blis-1.2.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:76998702acbb782e9bb298a5c446aaa1ed4652dbade853baa6a7a26f7b98105b", size = 6973751 },
    { url = "https://files.pythonhosted.org/packages/fd/bc/5993eb63fc8a2784fb3a82320bd65df958d7250047f77f467508da896296/blis-1.2.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:1c290c1ba6cb5b633abe59b2fb9ae2ea5dcd7508202f65658fe816bb7e129485", size = 1280762 },
    { url = "https://files.pythonhosted.org/packages/ff/65/3dae66f7aec4fe92726f33180cb8780d6a9bc49de25b3ee413275ff1aaf3/blis-1.2.0-cp310-cp310-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:cd81489e4b1a4a6bc51f5578795bc9150a2e8b9babead1074ca51398aff51852", size = 3186927 },
    { url = "https://files.pythonhosted.org/packages/4c/96/a420114cb430a790a038ca5a67171b5b124b2b1b0463be2e93bfa8c3378d/blis-1.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:4896cc4c10c9856c9faaf89401dcb87894da06a18b4b986064acd737a6ed3e60", size = 11526130 },
    { url = "https://files.pythonhosted.org/packages/a1/a3/a626f0e90683667a83cb735fe9638e4ffd0004a188287868a79771fb257f/blis-1.2.0-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:60a29dcb1bba49cae70088d480b95042d4fbbe6b380f2f7c9e70b2781dc126dd", size = 4225925 },
    { url = "https://files.pythonhosted.org/packages/c9/70/655b6017396074b1c05010d9127c18eb5f404b22e2b819f1e6da50f202fe/blis-1.2.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:fc1de26073302a3713e487ea85d1ecd0bce204f6b102da498c3cd08528a1d69e", size = 14694282 },
    { url = "https://files.pythonhosted.org/packages/af/e0/4ac06562b5dce221fbe20a1f0acd47f67454c377d00b1de0dd44de67116d/blis-1.2.0-cp310-cp310-win_amd64.whl", hash = "sha256:cc2aa5ce96f33162779e88add93b5051437f9c2701d24ee0d2dd89da9a9c23b1", size = 6247380 },
    { url = "https://files.pythonhosted.org/packages/3c/3f/62bc963d7cad6d5d4038ca0fed236559abd67c1afca33a2d5644412470f7/blis-1.2.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:debafb46ad8b5e2d18932770639aa1d22b61580a07ec718e9efcf50c76e180d6", size = 6976662 },
    { url = "https://files.pythonhosted.org/packages/70/4e/4d030d66d3de8dbe12217b4bb0fc67264df9befea07f6c164d33a23b0b09/blis-1.2.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:eb27e94b9dbd9c23595b95155607a57ad814bebd3cc1bf8551bee4af60e1b5d7", size = 1281766 },
    { url = "https://files.pythonhosted.org/packages/c8/32/9994aa6a2cc00f97a71cb6079364c3108da35e19203affcd9c541309728a/blis-1.2.0-cp311-cp311-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f8ed98669144fb8ee30052f7259d0cb78b7b3755d9589d98cbb7986d22473ab7", size = 3304018 },
    { url = "https://files.pythonhosted.org/packages/73/e7/95ae571ccfe5c43fb65fce5921e8a6213c4443a2e18a9ca5b6bad2fc8aab/blis-1.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:08f62b6f114370d8449b4836ebd157980a5718a5c39266af9cdff67a9602a421", size = 11659934 },
    { url = "https://files.pythonhosted.org/packages/21/09/e99e3575eb3609db01948a4bbc3abce03e47be53c18338aa7a657bc92f1b/blis-1.2.0-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:cc5c25fb12fd134812ea47e3fcbbd64d46d0717d307c5c2fb32a45ac8daf3226", size = 4360532 },
    { url = "https://files.pythonhosted.org/packages/fc/94/2575e8e7716f25265ea17a7272c4dc5b0d32b4d2c52aafbf5425cfbf998c/blis-1.2.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:78a6498c748a42494a2cf58be489616a42ba0b925bc92ab23c3721dc779a4739", size = 14827891 },
    { url = "https://files.pythonhosted.org/packages/c4/d9/b647ef53c33c82c1fa2ed217c5793de551a38fb1e5b2430f59c3ecba4c86/blis-1.2.0-cp311-cp311-win_amd64.whl", hash = "sha256:5ad68bc972f210a0227d9742bf6325600bb95c8188f97850634f6d97c3a08107", size = 6230482 },
    { url = "https://files.pythonhosted.org/packages/fb/98/79df1711d96b38a3cf72b2abad412191fe2ada986b6203a1237dcd7aac9a/blis-1.2.0-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:99df869b8998303cf78e9f408f0350b0c5cd12d733caa8df99682f046b83ea35", size = 6989668 },
    { url = "https://files.pythonhosted.org/packages/1e/bb/3f84de3303873783f6c2dee121d0a36fae641332db73b046cc93cb7b717e/blis-1.2.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:4001df564c43c8f2260b13c4f06327dee23831b178f65884c22b879062ebca14", size = 1282523 },
    { url = "https://files.pythonhosted.org/packages/91/4d/d0a599555fd97d3229d3c3fd8c7e5b531ca5863421370e99b46d70bce883/blis-1.2.0-cp312-cp312-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:6af5dec35acfc044e29b89bb9202e74edc747344f5a46fc27e8a8998f8229610", size = 3260765 },
    { url = "https://files.pythonhosted.org/packages/4d/59/b7571c5fa57b2198b5240f8cd790daf5749491cc17706e3a4b1528a75185/blis-1.2.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:986f125ad0215e975a0895505728644dff2669a739f6c2faf89436e3fcae21ac", size = 11616436 },
    { url = "https://files.pythonhosted.org/packages/fe/50/9c1311aa73d9812e3c78ebeec7c4fb0b15fdecfcc9a4866f1e3c06d0f331/blis-1.2.0-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:ea1f4ce1541cddbc9b0574a5969df2a518c5a6d4aa8787782dab5d82233a1458", size = 4309834 },
    { url = "https://files.pythonhosted.org/packages/d1/12/02f3afacf790a93e4d9f367cc5cdd95ed0348e5d2927bc4d9c7d1d70d1ae/blis-1.2.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:6358168c4218a36e49c244c714f50248a1ef981874ae7bc785d68e76d55c57b5", size = 14789989 },
    { url = "https://files.pythonhosted.org/packages/c0/3a/ce0a98664d6283276fa986685e308c1dc1feb634241b2d3828ceaaa5a128/blis-1.2.0-cp312-cp312-win_amd64.whl", hash = "sha256:067f4f99fb3dc0cf50bbbf0ee4b850f13e64fbb84fdaab0864fd97af0bee0ced", size = 6258036 },
    { url = "https://files.pythonhosted.org/packages/fe/50/6b964f1e5b0eb9c8d2503422aa0fedef693afc18d0af1d2b5d65048060c6/blis-1.2.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:f21d71f64aa32554d261d9c3308ac9276571d698546aa571bd393ff24b3df8f9", size = 6975317 },
    { url = "https://files.pythonhosted.org/packages/c2/6d/fade1d59a50f4fdd506e68fcc00e150e324479d361479403519bdffd109d/blis-1.2.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:3b372b6a92de9694baa94792767434b37d08bda7d4020bd7f970adf99ebf460d", size = 1282011 },
    { url = "https://files.pythonhosted.org/packages/1e/03/3857d8d99fd9b71c0bbf02a4d6b4b7f402a0a00e075bd0f394c6c110150e/blis-1.2.0-cp39-cp39-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:fbe2e0f772909f66a0eed26dfa5146b8a0758e65aa3a9b9791155fd1fd69a0f9", size = 3190732 },
    { url = "https://files.pythonhosted.org/packages/1a/d5/0023a8b63a4fb1b831aaff3a3d700ad352e1c02a452275f53efdd79a361c/blis-1.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7d94255f50f54c98727e57d12beeb3cb9d8879fd895d2e8c61d1b975ac87685f", size = 11537527 },
    { url = "https://files.pythonhosted.org/packages/3f/76/40f8a04a9af055ce14be19eda647a8e7c55839233f187ce89c6c3bc626e4/blis-1.2.0-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:6f2ce3b35a66dc7ffff3f68b60a4eb622dbcb0128617c79bf02c098077e2745c", size = 4230054 },
    { url = "https://files.pythonhosted.org/packages/6d/67/60979f43df41705584c75a2f50891c7f2210136169c6b904f96dfce66216/blis-1.2.0-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:f4bdcd436eb08c541c9d44315db2647a30492091cd98a9651a4fe58460a091a3", size = 14698839 },
    { url = "https://files.pythonhosted.org/packages/56/4c/cc3be3cb80a862799f5a13a2f6f660bc555b0f0aebfac75aee9f0b5dd9ea/blis-1.2.0-cp39-cp39-win_amd64.whl", hash = "sha256:613a343acad0a254ab87e1b5ec92a031aef73c0640df1e1d09f0f27293654859", size = 6247455 },
]

[[package]]
name = "camelot-py"
version = "0.11.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "chardet" },
    { name = "click" },
    { name = "numpy" },
    { name = "openpyxl" },
    { name = "pandas" },
    { name = "pdfminer-six" },
    { name = "pypdf" },
    { name = "tabulate" },
]
sdist = { url = "https://files.pythonhosted.org/packages/cc/7c/04337f3c81e1606cad2b966677c7f3016c2acc7ed254ac72f1dcec2acb9d/camelot-py-0.11.0.tar.gz", hash = "sha256:97a7d906d685e4059a4a549a63ae3a51f0ab72a3c826557f8443c65a1181dfe6", size = 40103 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/8c/6b/054432c9d7f9ebd6748873efda7fbb19580da7bc4d16505f6bfd848c8d90/camelot_py-0.11.0-py3-none-any.whl", hash = "sha256:96d0f0386c8993f8f6b0aaaddf5f14a4a6ec6e9d1e07b6128d1c3abfa9156683", size = 40978 },
]

[[package]]
name = "catalogue"
version = "2.0.10"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/38/b4/244d58127e1cdf04cf2dc7d9566f0d24ef01d5ce21811bab088ecc62b5ea/catalogue-2.0.10.tar.gz", hash = "sha256:4f56daa940913d3f09d589c191c74e5a6d51762b3a9e37dd53b7437afd6cda15", size = 19561 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl", hash = "sha256:58c2de0020aa90f4a2da7dfad161bf7b3b054c86a5f09fcedc0b2b740c109a9f", size = 17325 },
]

[[package]]
name = "certifi"
version = "2025.1.31"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/1c/ab/c9f1e32b7b1bf505bf26f0ef697775960db7932abeb7b516de930ba2705f/certifi-2025.1.31.tar.gz", hash = "sha256:3d5da6925056f6f18f119200434a4780a94263f10d1c21d032a6f6b2baa20651", size = 167577 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/38/fc/bce832fd4fd99766c04d1ee0eead6b0ec6486fb100ae5e74c1d91292b982/certifi-2025.1.31-py3-none-any.whl", hash = "sha256:ca78db4565a652026a4db2bcdf68f2fb589ea80d0be70e03929ed730746b84fe", size = 166393 },
]

[[package]]
name = "cffi"
version = "1.17.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "pycparser" },
]
sdist = { url = "https://files.pythonhosted.org/packages/fc/97/c783634659c2920c3fc70419e3af40972dbaf758daa229a7d6ea6135c90d/cffi-1.17.1.tar.gz", hash = "sha256:1c39c6016c32bc48dd54561950ebd6836e1670f2ae46128f67cf49e789c52824", size = 516621 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/90/07/f44ca684db4e4f08a3fdc6eeb9a0d15dc6883efc7b8c90357fdbf74e186c/cffi-1.17.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:df8b1c11f177bc2313ec4b2d46baec87a5f3e71fc8b45dab2ee7cae86d9aba14", size = 182191 },
    { url = "https://files.pythonhosted.org/packages/08/fd/cc2fedbd887223f9f5d170c96e57cbf655df9831a6546c1727ae13fa977a/cffi-1.17.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:8f2cdc858323644ab277e9bb925ad72ae0e67f69e804f4898c070998d50b1a67", size = 178592 },
    { url = "https://files.pythonhosted.org/packages/de/cc/4635c320081c78d6ffc2cab0a76025b691a91204f4aa317d568ff9280a2d/cffi-1.17.1-cp310-cp310-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:edae79245293e15384b51f88b00613ba9f7198016a5948b5dddf4917d4d26382", size = 426024 },
    { url = "https://files.pythonhosted.org/packages/b6/7b/3b2b250f3aab91abe5f8a51ada1b717935fdaec53f790ad4100fe2ec64d1/cffi-1.17.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:45398b671ac6d70e67da8e4224a065cec6a93541bb7aebe1b198a61b58c7b702", size = 448188 },
    { url = "https://files.pythonhosted.org/packages/d3/48/1b9283ebbf0ec065148d8de05d647a986c5f22586b18120020452fff8f5d/cffi-1.17.1-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ad9413ccdeda48c5afdae7e4fa2192157e991ff761e7ab8fdd8926f40b160cc3", size = 455571 },
    { url = "https://files.pythonhosted.org/packages/40/87/3b8452525437b40f39ca7ff70276679772ee7e8b394934ff60e63b7b090c/cffi-1.17.1-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5da5719280082ac6bd9aa7becb3938dc9f9cbd57fac7d2871717b1feb0902ab6", size = 436687 },
    { url = "https://files.pythonhosted.org/packages/8d/fb/4da72871d177d63649ac449aec2e8a29efe0274035880c7af59101ca2232/cffi-1.17.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2bb1a08b8008b281856e5971307cc386a8e9c5b625ac297e853d36da6efe9c17", size = 446211 },
    { url = "https://files.pythonhosted.org/packages/ab/a0/62f00bcb411332106c02b663b26f3545a9ef136f80d5df746c05878f8c4b/cffi-1.17.1-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:045d61c734659cc045141be4bae381a41d89b741f795af1dd018bfb532fd0df8", size = 461325 },
    { url = "https://files.pythonhosted.org/packages/36/83/76127035ed2e7e27b0787604d99da630ac3123bfb02d8e80c633f218a11d/cffi-1.17.1-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:6883e737d7d9e4899a8a695e00ec36bd4e5e4f18fabe0aca0efe0a4b44cdb13e", size = 438784 },
    { url = "https://files.pythonhosted.org/packages/21/81/a6cd025db2f08ac88b901b745c163d884641909641f9b826e8cb87645942/cffi-1.17.1-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:6b8b4a92e1c65048ff98cfe1f735ef8f1ceb72e3d5f0c25fdb12087a23da22be", size = 461564 },
    { url = "https://files.pythonhosted.org/packages/f8/fe/4d41c2f200c4a457933dbd98d3cf4e911870877bd94d9656cc0fcb390681/cffi-1.17.1-cp310-cp310-win32.whl", hash = "sha256:c9c3d058ebabb74db66e431095118094d06abf53284d9c81f27300d0e0d8bc7c", size = 171804 },
    { url = "https://files.pythonhosted.org/packages/d1/b6/0b0f5ab93b0df4acc49cae758c81fe4e5ef26c3ae2e10cc69249dfd8b3ab/cffi-1.17.1-cp310-cp310-win_amd64.whl", hash = "sha256:0f048dcf80db46f0098ccac01132761580d28e28bc0f78ae0d58048063317e15", size = 181299 },
    { url = "https://files.pythonhosted.org/packages/6b/f4/927e3a8899e52a27fa57a48607ff7dc91a9ebe97399b357b85a0c7892e00/cffi-1.17.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:a45e3c6913c5b87b3ff120dcdc03f6131fa0065027d0ed7ee6190736a74cd401", size = 182264 },
    { url = "https://files.pythonhosted.org/packages/6c/f5/6c3a8efe5f503175aaddcbea6ad0d2c96dad6f5abb205750d1b3df44ef29/cffi-1.17.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:30c5e0cb5ae493c04c8b42916e52ca38079f1b235c2f8ae5f4527b963c401caf", size = 178651 },
    { url = "https://files.pythonhosted.org/packages/94/dd/a3f0118e688d1b1a57553da23b16bdade96d2f9bcda4d32e7d2838047ff7/cffi-1.17.1-cp311-cp311-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f75c7ab1f9e4aca5414ed4d8e5c0e303a34f4421f8a0d47a4d019ceff0ab6af4", size = 445259 },
    { url = "https://files.pythonhosted.org/packages/2e/ea/70ce63780f096e16ce8588efe039d3c4f91deb1dc01e9c73a287939c79a6/cffi-1.17.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a1ed2dd2972641495a3ec98445e09766f077aee98a1c896dcb4ad0d303628e41", size = 469200 },
    { url = "https://files.pythonhosted.org/packages/1c/a0/a4fa9f4f781bda074c3ddd57a572b060fa0df7655d2a4247bbe277200146/cffi-1.17.1-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:46bf43160c1a35f7ec506d254e5c890f3c03648a4dbac12d624e4490a7046cd1", size = 477235 },
    { url = "https://files.pythonhosted.org/packages/62/12/ce8710b5b8affbcdd5c6e367217c242524ad17a02fe5beec3ee339f69f85/cffi-1.17.1-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a24ed04c8ffd54b0729c07cee15a81d964e6fee0e3d4d342a27b020d22959dc6", size = 459721 },
    { url = "https://files.pythonhosted.org/packages/ff/6b/d45873c5e0242196f042d555526f92aa9e0c32355a1be1ff8c27f077fd37/cffi-1.17.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:610faea79c43e44c71e1ec53a554553fa22321b65fae24889706c0a84d4ad86d", size = 467242 },
    { url = "https://files.pythonhosted.org/packages/1a/52/d9a0e523a572fbccf2955f5abe883cfa8bcc570d7faeee06336fbd50c9fc/cffi-1.17.1-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:a9b15d491f3ad5d692e11f6b71f7857e7835eb677955c00cc0aefcd0669adaf6", size = 477999 },
    { url = "https://files.pythonhosted.org/packages/44/74/f2a2460684a1a2d00ca799ad880d54652841a780c4c97b87754f660c7603/cffi-1.17.1-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:de2ea4b5833625383e464549fec1bc395c1bdeeb5f25c4a3a82b5a8c756ec22f", size = 454242 },
    { url = "https://files.pythonhosted.org/packages/f8/4a/34599cac7dfcd888ff54e801afe06a19c17787dfd94495ab0c8d35fe99fb/cffi-1.17.1-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:fc48c783f9c87e60831201f2cce7f3b2e4846bf4d8728eabe54d60700b318a0b", size = 478604 },
    { url = "https://files.pythonhosted.org/packages/34/33/e1b8a1ba29025adbdcda5fb3a36f94c03d771c1b7b12f726ff7fef2ebe36/cffi-1.17.1-cp311-cp311-win32.whl", hash = "sha256:85a950a4ac9c359340d5963966e3e0a94a676bd6245a4b55bc43949eee26a655", size = 171727 },
    { url = "https://files.pythonhosted.org/packages/3d/97/50228be003bb2802627d28ec0627837ac0bf35c90cf769812056f235b2d1/cffi-1.17.1-cp311-cp311-win_amd64.whl", hash = "sha256:caaf0640ef5f5517f49bc275eca1406b0ffa6aa184892812030f04c2abf589a0", size = 181400 },
    { url = "https://files.pythonhosted.org/packages/5a/84/e94227139ee5fb4d600a7a4927f322e1d4aea6fdc50bd3fca8493caba23f/cffi-1.17.1-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:805b4371bf7197c329fcb3ead37e710d1bca9da5d583f5073b799d5c5bd1eee4", size = 183178 },
    { url = "https://files.pythonhosted.org/packages/da/ee/fb72c2b48656111c4ef27f0f91da355e130a923473bf5ee75c5643d00cca/cffi-1.17.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:733e99bc2df47476e3848417c5a4540522f234dfd4ef3ab7fafdf555b082ec0c", size = 178840 },
    { url = "https://files.pythonhosted.org/packages/cc/b6/db007700f67d151abadf508cbfd6a1884f57eab90b1bb985c4c8c02b0f28/cffi-1.17.1-cp312-cp312-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1257bdabf294dceb59f5e70c64a3e2f462c30c7ad68092d01bbbfb1c16b1ba36", size = 454803 },
    { url = "https://files.pythonhosted.org/packages/1a/df/f8d151540d8c200eb1c6fba8cd0dfd40904f1b0682ea705c36e6c2e97ab3/cffi-1.17.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:da95af8214998d77a98cc14e3a3bd00aa191526343078b530ceb0bd710fb48a5", size = 478850 },
    { url = "https://files.pythonhosted.org/packages/28/c0/b31116332a547fd2677ae5b78a2ef662dfc8023d67f41b2a83f7c2aa78b1/cffi-1.17.1-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:d63afe322132c194cf832bfec0dc69a99fb9bb6bbd550f161a49e9e855cc78ff", size = 485729 },
    { url = "https://files.pythonhosted.org/packages/91/2b/9a1ddfa5c7f13cab007a2c9cc295b70fbbda7cb10a286aa6810338e60ea1/cffi-1.17.1-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f79fc4fc25f1c8698ff97788206bb3c2598949bfe0fef03d299eb1b5356ada99", size = 471256 },
    { url = "https://files.pythonhosted.org/packages/b2/d5/da47df7004cb17e4955df6a43d14b3b4ae77737dff8bf7f8f333196717bf/cffi-1.17.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b62ce867176a75d03a665bad002af8e6d54644fad99a3c70905c543130e39d93", size = 479424 },
    { url = "https://files.pythonhosted.org/packages/0b/ac/2a28bcf513e93a219c8a4e8e125534f4f6db03e3179ba1c45e949b76212c/cffi-1.17.1-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:386c8bf53c502fff58903061338ce4f4950cbdcb23e2902d86c0f722b786bbe3", size = 484568 },
    { url = "https://files.pythonhosted.org/packages/d4/38/ca8a4f639065f14ae0f1d9751e70447a261f1a30fa7547a828ae08142465/cffi-1.17.1-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:4ceb10419a9adf4460ea14cfd6bc43d08701f0835e979bf821052f1805850fe8", size = 488736 },
    { url = "https://files.pythonhosted.org/packages/86/c5/28b2d6f799ec0bdecf44dced2ec5ed43e0eb63097b0f58c293583b406582/cffi-1.17.1-cp312-cp312-win32.whl", hash = "sha256:a08d7e755f8ed21095a310a693525137cfe756ce62d066e53f502a83dc550f65", size = 172448 },
    { url = "https://files.pythonhosted.org/packages/50/b9/db34c4755a7bd1cb2d1603ac3863f22bcecbd1ba29e5ee841a4bc510b294/cffi-1.17.1-cp312-cp312-win_amd64.whl", hash = "sha256:51392eae71afec0d0c8fb1a53b204dbb3bcabcb3c9b807eedf3e1e6ccf2de903", size = 181976 },
    { url = "https://files.pythonhosted.org/packages/8d/f8/dd6c246b148639254dad4d6803eb6a54e8c85c6e11ec9df2cffa87571dbe/cffi-1.17.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:f3a2b4222ce6b60e2e8b337bb9596923045681d71e5a082783484d845390938e", size = 182989 },
    { url = "https://files.pythonhosted.org/packages/8b/f1/672d303ddf17c24fc83afd712316fda78dc6fce1cd53011b839483e1ecc8/cffi-1.17.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:0984a4925a435b1da406122d4d7968dd861c1385afe3b45ba82b750f229811e2", size = 178802 },
    { url = "https://files.pythonhosted.org/packages/0e/2d/eab2e858a91fdff70533cab61dcff4a1f55ec60425832ddfdc9cd36bc8af/cffi-1.17.1-cp313-cp313-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d01b12eeeb4427d3110de311e1774046ad344f5b1a7403101878976ecd7a10f3", size = 454792 },
    { url = "https://files.pythonhosted.org/packages/75/b2/fbaec7c4455c604e29388d55599b99ebcc250a60050610fadde58932b7ee/cffi-1.17.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:706510fe141c86a69c8ddc029c7910003a17353970cff3b904ff0686a5927683", size = 478893 },
    { url = "https://files.pythonhosted.org/packages/4f/b7/6e4a2162178bf1935c336d4da8a9352cccab4d3a5d7914065490f08c0690/cffi-1.17.1-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:de55b766c7aa2e2a3092c51e0483d700341182f08e67c63630d5b6f200bb28e5", size = 485810 },
    { url = "https://files.pythonhosted.org/packages/c7/8a/1d0e4a9c26e54746dc08c2c6c037889124d4f59dffd853a659fa545f1b40/cffi-1.17.1-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:c59d6e989d07460165cc5ad3c61f9fd8f1b4796eacbd81cee78957842b834af4", size = 471200 },
    { url = "https://files.pythonhosted.org/packages/26/9f/1aab65a6c0db35f43c4d1b4f580e8df53914310afc10ae0397d29d697af4/cffi-1.17.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:dd398dbc6773384a17fe0d3e7eeb8d1a21c2200473ee6806bb5e6a8e62bb73dd", size = 479447 },
    { url = "https://files.pythonhosted.org/packages/5f/e4/fb8b3dd8dc0e98edf1135ff067ae070bb32ef9d509d6cb0f538cd6f7483f/cffi-1.17.1-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:3edc8d958eb099c634dace3c7e16560ae474aa3803a5df240542b305d14e14ed", size = 484358 },
    { url = "https://files.pythonhosted.org/packages/f1/47/d7145bf2dc04684935d57d67dff9d6d795b2ba2796806bb109864be3a151/cffi-1.17.1-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:72e72408cad3d5419375fc87d289076ee319835bdfa2caad331e377589aebba9", size = 488469 },
    { url = "https://files.pythonhosted.org/packages/bf/ee/f94057fa6426481d663b88637a9a10e859e492c73d0384514a17d78ee205/cffi-1.17.1-cp313-cp313-win32.whl", hash = "sha256:e03eab0a8677fa80d646b5ddece1cbeaf556c313dcfac435ba11f107ba117b5d", size = 172475 },
    { url = "https://files.pythonhosted.org/packages/7c/fc/6a8cb64e5f0324877d503c854da15d76c1e50eb722e320b15345c4d0c6de/cffi-1.17.1-cp313-cp313-win_amd64.whl", hash = "sha256:f6a16c31041f09ead72d69f583767292f750d24913dadacf5756b966aacb3f1a", size = 182009 },
    { url = "https://files.pythonhosted.org/packages/48/08/15bf6b43ae9bd06f6b00ad8a91f5a8fe1069d4c9fab550a866755402724e/cffi-1.17.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:636062ea65bd0195bc012fea9321aca499c0504409f413dc88af450b57ffd03b", size = 182457 },
    { url = "https://files.pythonhosted.org/packages/c2/5b/f1523dd545f92f7df468e5f653ffa4df30ac222f3c884e51e139878f1cb5/cffi-1.17.1-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:c7eac2ef9b63c79431bc4b25f1cd649d7f061a28808cbc6c47b534bd789ef964", size = 425932 },
    { url = "https://files.pythonhosted.org/packages/53/93/7e547ab4105969cc8c93b38a667b82a835dd2cc78f3a7dad6130cfd41e1d/cffi-1.17.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e221cf152cff04059d011ee126477f0d9588303eb57e88923578ace7baad17f9", size = 448585 },
    { url = "https://files.pythonhosted.org/packages/56/c4/a308f2c332006206bb511de219efeff090e9d63529ba0a77aae72e82248b/cffi-1.17.1-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:31000ec67d4221a71bd3f67df918b1f88f676f1c3b535a7eb473255fdc0b83fc", size = 456268 },
    { url = "https://files.pythonhosted.org/packages/ca/5b/b63681518265f2f4060d2b60755c1c77ec89e5e045fc3773b72735ddaad5/cffi-1.17.1-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:6f17be4345073b0a7b8ea599688f692ac3ef23ce28e5df79c04de519dbc4912c", size = 436592 },
    { url = "https://files.pythonhosted.org/packages/bb/19/b51af9f4a4faa4a8ac5a0e5d5c2522dcd9703d07fac69da34a36c4d960d3/cffi-1.17.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0e2b1fac190ae3ebfe37b979cc1ce69c81f4e4fe5746bb401dca63a9062cdaf1", size = 446512 },
    { url = "https://files.pythonhosted.org/packages/e2/63/2bed8323890cb613bbecda807688a31ed11a7fe7afe31f8faaae0206a9a3/cffi-1.17.1-cp38-cp38-win32.whl", hash = "sha256:7596d6620d3fa590f677e9ee430df2958d2d6d6de2feeae5b20e82c00b76fbf8", size = 171576 },
    { url = "https://files.pythonhosted.org/packages/2f/70/80c33b044ebc79527447fd4fbc5455d514c3bb840dede4455de97da39b4d/cffi-1.17.1-cp38-cp38-win_amd64.whl", hash = "sha256:78122be759c3f8a014ce010908ae03364d00a1f81ab5c7f4a7a5120607ea56e1", size = 181229 },
    { url = "https://files.pythonhosted.org/packages/b9/ea/8bb50596b8ffbc49ddd7a1ad305035daa770202a6b782fc164647c2673ad/cffi-1.17.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:b2ab587605f4ba0bf81dc0cb08a41bd1c0a5906bd59243d56bad7668a6fc6c16", size = 182220 },
    { url = "https://files.pythonhosted.org/packages/ae/11/e77c8cd24f58285a82c23af484cf5b124a376b32644e445960d1a4654c3a/cffi-1.17.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:28b16024becceed8c6dfbc75629e27788d8a3f9030691a1dbf9821a128b22c36", size = 178605 },
    { url = "https://files.pythonhosted.org/packages/ed/65/25a8dc32c53bf5b7b6c2686b42ae2ad58743f7ff644844af7cdb29b49361/cffi-1.17.1-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1d599671f396c4723d016dbddb72fe8e0397082b0a77a4fab8028923bec050e8", size = 424910 },
    { url = "https://files.pythonhosted.org/packages/42/7a/9d086fab7c66bd7c4d0f27c57a1b6b068ced810afc498cc8c49e0088661c/cffi-1.17.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ca74b8dbe6e8e8263c0ffd60277de77dcee6c837a3d0881d8c1ead7268c9e576", size = 447200 },
    { url = "https://files.pythonhosted.org/packages/da/63/1785ced118ce92a993b0ec9e0d0ac8dc3e5dbfbcaa81135be56c69cabbb6/cffi-1.17.1-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:f7f5baafcc48261359e14bcd6d9bff6d4b28d9103847c9e136694cb0501aef87", size = 454565 },
    { url = "https://files.pythonhosted.org/packages/74/06/90b8a44abf3556599cdec107f7290277ae8901a58f75e6fe8f970cd72418/cffi-1.17.1-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:98e3969bcff97cae1b2def8ba499ea3d6f31ddfdb7635374834cf89a1a08ecf0", size = 435635 },
    { url = "https://files.pythonhosted.org/packages/bd/62/a1f468e5708a70b1d86ead5bab5520861d9c7eacce4a885ded9faa7729c3/cffi-1.17.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:cdf5ce3acdfd1661132f2a9c19cac174758dc2352bfe37d98aa7512c6b7178b3", size = 445218 },
    { url = "https://files.pythonhosted.org/packages/5b/95/b34462f3ccb09c2594aa782d90a90b045de4ff1f70148ee79c69d37a0a5a/cffi-1.17.1-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:9755e4345d1ec879e3849e62222a18c7174d65a6a92d5b346b1863912168b595", size = 460486 },
    { url = "https://files.pythonhosted.org/packages/fc/fc/a1e4bebd8d680febd29cf6c8a40067182b64f00c7d105f8f26b5bc54317b/cffi-1.17.1-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:f1e22e8c4419538cb197e4dd60acc919d7696e5ef98ee4da4e01d3f8cfa4cc5a", size = 437911 },
    { url = "https://files.pythonhosted.org/packages/e6/c3/21cab7a6154b6a5ea330ae80de386e7665254835b9e98ecc1340b3a7de9a/cffi-1.17.1-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:c03e868a0b3bc35839ba98e74211ed2b05d2119be4e8a0f224fba9384f1fe02e", size = 460632 },
    { url = "https://files.pythonhosted.org/packages/cb/b5/fd9f8b5a84010ca169ee49f4e4ad6f8c05f4e3545b72ee041dbbcb159882/cffi-1.17.1-cp39-cp39-win32.whl", hash = "sha256:e31ae45bc2e29f6b2abd0de1cc3b9d5205aa847cafaecb8af1476a609a2f6eb7", size = 171820 },
    { url = "https://files.pythonhosted.org/packages/8c/52/b08750ce0bce45c143e1b5d7357ee8c55341b52bdef4b0f081af1eb248c2/cffi-1.17.1-cp39-cp39-win_amd64.whl", hash = "sha256:d016c76bdd850f3c626af19b0542c9677ba156e4ee4fccfdd7848803533ef662", size = 181290 },
]

[[package]]
name = "chardet"
version = "5.2.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f3/0d/f7b6ab21ec75897ed80c17d79b15951a719226b9fababf1e40ea74d69079/chardet-5.2.0.tar.gz", hash = "sha256:1b3b6ff479a8c414bc3fa2c0852995695c4a026dcd6d0633b2dd092ca39c1cf7", size = 2069618 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/38/6f/f5fbc992a329ee4e0f288c1fe0e2ad9485ed064cac731ed2fe47dcc38cbf/chardet-5.2.0-py3-none-any.whl", hash = "sha256:e1cf59446890a00105fe7b7912492ea04b6e6f06d4b742b2c788469e34c82970", size = 199385 },
]

[[package]]
name = "charset-normalizer"
version = "3.4.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/16/b0/572805e227f01586461c80e0fd25d65a2115599cc9dad142fee4b747c357/charset_normalizer-3.4.1.tar.gz", hash = "sha256:44251f18cd68a75b56585dd00dae26183e102cd5e0f9f1466e6df5da2ed64ea3", size = 123188 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/0d/58/5580c1716040bc89206c77d8f74418caf82ce519aae06450393ca73475d1/charset_normalizer-3.4.1-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:91b36a978b5ae0ee86c394f5a54d6ef44db1de0815eb43de826d41d21e4af3de", size = 198013 },
    { url = "https://files.pythonhosted.org/packages/d0/11/00341177ae71c6f5159a08168bcb98c6e6d196d372c94511f9f6c9afe0c6/charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:7461baadb4dc00fd9e0acbe254e3d7d2112e7f92ced2adc96e54ef6501c5f176", size = 141285 },
    { url = "https://files.pythonhosted.org/packages/01/09/11d684ea5819e5a8f5100fb0b38cf8d02b514746607934134d31233e02c8/charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:e218488cd232553829be0664c2292d3af2eeeb94b32bea483cf79ac6a694e037", size = 151449 },
    { url = "https://files.pythonhosted.org/packages/08/06/9f5a12939db324d905dc1f70591ae7d7898d030d7662f0d426e2286f68c9/charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:80ed5e856eb7f30115aaf94e4a08114ccc8813e6ed1b5efa74f9f82e8509858f", size = 143892 },
    { url = "https://files.pythonhosted.org/packages/93/62/5e89cdfe04584cb7f4d36003ffa2936681b03ecc0754f8e969c2becb7e24/charset_normalizer-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b010a7a4fd316c3c484d482922d13044979e78d1861f0e0650423144c616a46a", size = 146123 },
    { url = "https://files.pythonhosted.org/packages/a9/ac/ab729a15c516da2ab70a05f8722ecfccc3f04ed7a18e45c75bbbaa347d61/charset_normalizer-3.4.1-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:4532bff1b8421fd0a320463030c7520f56a79c9024a4e88f01c537316019005a", size = 147943 },
    { url = "https://files.pythonhosted.org/packages/03/d2/3f392f23f042615689456e9a274640c1d2e5dd1d52de36ab8f7955f8f050/charset_normalizer-3.4.1-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:d973f03c0cb71c5ed99037b870f2be986c3c05e63622c017ea9816881d2dd247", size = 142063 },
    { url = "https://files.pythonhosted.org/packages/f2/e3/e20aae5e1039a2cd9b08d9205f52142329f887f8cf70da3650326670bddf/charset_normalizer-3.4.1-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:3a3bd0dcd373514dcec91c411ddb9632c0d7d92aed7093b8c3bbb6d69ca74408", size = 150578 },
    { url = "https://files.pythonhosted.org/packages/8d/af/779ad72a4da0aed925e1139d458adc486e61076d7ecdcc09e610ea8678db/charset_normalizer-3.4.1-cp310-cp310-musllinux_1_2_ppc64le.whl", hash = "sha256:d9c3cdf5390dcd29aa8056d13e8e99526cda0305acc038b96b30352aff5ff2bb", size = 153629 },
    { url = "https://files.pythonhosted.org/packages/c2/b6/7aa450b278e7aa92cf7732140bfd8be21f5f29d5bf334ae987c945276639/charset_normalizer-3.4.1-cp310-cp310-musllinux_1_2_s390x.whl", hash = "sha256:2bdfe3ac2e1bbe5b59a1a63721eb3b95fc9b6817ae4a46debbb4e11f6232428d", size = 150778 },
    { url = "https://files.pythonhosted.org/packages/39/f4/d9f4f712d0951dcbfd42920d3db81b00dd23b6ab520419626f4023334056/charset_normalizer-3.4.1-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:eab677309cdb30d047996b36d34caeda1dc91149e4fdca0b1a039b3f79d9a807", size = 146453 },
    { url = "https://files.pythonhosted.org/packages/49/2b/999d0314e4ee0cff3cb83e6bc9aeddd397eeed693edb4facb901eb8fbb69/charset_normalizer-3.4.1-cp310-cp310-win32.whl", hash = "sha256:c0429126cf75e16c4f0ad00ee0eae4242dc652290f940152ca8c75c3a4b6ee8f", size = 95479 },
    { url = "https://files.pythonhosted.org/packages/2d/ce/3cbed41cff67e455a386fb5e5dd8906cdda2ed92fbc6297921f2e4419309/charset_normalizer-3.4.1-cp310-cp310-win_amd64.whl", hash = "sha256:9f0b8b1c6d84c8034a44893aba5e767bf9c7a211e313a9605d9c617d7083829f", size = 102790 },
    { url = "https://files.pythonhosted.org/packages/72/80/41ef5d5a7935d2d3a773e3eaebf0a9350542f2cab4eac59a7a4741fbbbbe/charset_normalizer-3.4.1-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:8bfa33f4f2672964266e940dd22a195989ba31669bd84629f05fab3ef4e2d125", size = 194995 },
    { url = "https://files.pythonhosted.org/packages/7a/28/0b9fefa7b8b080ec492110af6d88aa3dea91c464b17d53474b6e9ba5d2c5/charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:28bf57629c75e810b6ae989f03c0828d64d6b26a5e205535585f96093e405ed1", size = 139471 },
    { url = "https://files.pythonhosted.org/packages/71/64/d24ab1a997efb06402e3fc07317e94da358e2585165930d9d59ad45fcae2/charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:f08ff5e948271dc7e18a35641d2f11a4cd8dfd5634f55228b691e62b37125eb3", size = 149831 },
    { url = "https://files.pythonhosted.org/packages/37/ed/be39e5258e198655240db5e19e0b11379163ad7070962d6b0c87ed2c4d39/charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:234ac59ea147c59ee4da87a0c0f098e9c8d169f4dc2a159ef720f1a61bbe27cd", size = 142335 },
    { url = "https://files.pythonhosted.org/packages/88/83/489e9504711fa05d8dde1574996408026bdbdbd938f23be67deebb5eca92/charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fd4ec41f914fa74ad1b8304bbc634b3de73d2a0889bd32076342a573e0779e00", size = 143862 },
    { url = "https://files.pythonhosted.org/packages/c6/c7/32da20821cf387b759ad24627a9aca289d2822de929b8a41b6241767b461/charset_normalizer-3.4.1-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:eea6ee1db730b3483adf394ea72f808b6e18cf3cb6454b4d86e04fa8c4327a12", size = 145673 },
    { url = "https://files.pythonhosted.org/packages/68/85/f4288e96039abdd5aeb5c546fa20a37b50da71b5cf01e75e87f16cd43304/charset_normalizer-3.4.1-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:c96836c97b1238e9c9e3fe90844c947d5afbf4f4c92762679acfe19927d81d77", size = 140211 },
    { url = "https://files.pythonhosted.org/packages/28/a3/a42e70d03cbdabc18997baf4f0227c73591a08041c149e710045c281f97b/charset_normalizer-3.4.1-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:4d86f7aff21ee58f26dcf5ae81a9addbd914115cdebcbb2217e4f0ed8982e146", size = 148039 },
    { url = "https://files.pythonhosted.org/packages/85/e4/65699e8ab3014ecbe6f5c71d1a55d810fb716bbfd74f6283d5c2aa87febf/charset_normalizer-3.4.1-cp311-cp311-musllinux_1_2_ppc64le.whl", hash = "sha256:09b5e6733cbd160dcc09589227187e242a30a49ca5cefa5a7edd3f9d19ed53fd", size = 151939 },
    { url = "https://files.pythonhosted.org/packages/b1/82/8e9fe624cc5374193de6860aba3ea8070f584c8565ee77c168ec13274bd2/charset_normalizer-3.4.1-cp311-cp311-musllinux_1_2_s390x.whl", hash = "sha256:5777ee0881f9499ed0f71cc82cf873d9a0ca8af166dfa0af8ec4e675b7df48e6", size = 149075 },
    { url = "https://files.pythonhosted.org/packages/3d/7b/82865ba54c765560c8433f65e8acb9217cb839a9e32b42af4aa8e945870f/charset_normalizer-3.4.1-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:237bdbe6159cff53b4f24f397d43c6336c6b0b42affbe857970cefbb620911c8", size = 144340 },
    { url = "https://files.pythonhosted.org/packages/b5/b6/9674a4b7d4d99a0d2df9b215da766ee682718f88055751e1e5e753c82db0/charset_normalizer-3.4.1-cp311-cp311-win32.whl", hash = "sha256:8417cb1f36cc0bc7eaba8ccb0e04d55f0ee52df06df3ad55259b9a323555fc8b", size = 95205 },
    { url = "https://files.pythonhosted.org/packages/1e/ab/45b180e175de4402dcf7547e4fb617283bae54ce35c27930a6f35b6bef15/charset_normalizer-3.4.1-cp311-cp311-win_amd64.whl", hash = "sha256:d7f50a1f8c450f3925cb367d011448c39239bb3eb4117c36a6d354794de4ce76", size = 102441 },
    { url = "https://files.pythonhosted.org/packages/0a/9a/dd1e1cdceb841925b7798369a09279bd1cf183cef0f9ddf15a3a6502ee45/charset_normalizer-3.4.1-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:73d94b58ec7fecbc7366247d3b0b10a21681004153238750bb67bd9012414545", size = 196105 },
    { url = "https://files.pythonhosted.org/packages/d3/8c/90bfabf8c4809ecb648f39794cf2a84ff2e7d2a6cf159fe68d9a26160467/charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:dad3e487649f498dd991eeb901125411559b22e8d7ab25d3aeb1af367df5efd7", size = 140404 },
    { url = "https://files.pythonhosted.org/packages/ad/8f/e410d57c721945ea3b4f1a04b74f70ce8fa800d393d72899f0a40526401f/charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:c30197aa96e8eed02200a83fba2657b4c3acd0f0aa4bdc9f6c1af8e8962e0757", size = 150423 },
    { url = "https://files.pythonhosted.org/packages/f0/b8/e6825e25deb691ff98cf5c9072ee0605dc2acfca98af70c2d1b1bc75190d/charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:2369eea1ee4a7610a860d88f268eb39b95cb588acd7235e02fd5a5601773d4fa", size = 143184 },
    { url = "https://files.pythonhosted.org/packages/3e/a2/513f6cbe752421f16d969e32f3583762bfd583848b763913ddab8d9bfd4f/charset_normalizer-3.4.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bc2722592d8998c870fa4e290c2eec2c1569b87fe58618e67d38b4665dfa680d", size = 145268 },
    { url = "https://files.pythonhosted.org/packages/74/94/8a5277664f27c3c438546f3eb53b33f5b19568eb7424736bdc440a88a31f/charset_normalizer-3.4.1-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ffc9202a29ab3920fa812879e95a9e78b2465fd10be7fcbd042899695d75e616", size = 147601 },
    { url = "https://files.pythonhosted.org/packages/7c/5f/6d352c51ee763623a98e31194823518e09bfa48be2a7e8383cf691bbb3d0/charset_normalizer-3.4.1-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:804a4d582ba6e5b747c625bf1255e6b1507465494a40a2130978bda7b932c90b", size = 141098 },
    { url = "https://files.pythonhosted.org/packages/78/d4/f5704cb629ba5ab16d1d3d741396aec6dc3ca2b67757c45b0599bb010478/charset_normalizer-3.4.1-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:0f55e69f030f7163dffe9fd0752b32f070566451afe180f99dbeeb81f511ad8d", size = 149520 },
    { url = "https://files.pythonhosted.org/packages/c5/96/64120b1d02b81785f222b976c0fb79a35875457fa9bb40827678e54d1bc8/charset_normalizer-3.4.1-cp312-cp312-musllinux_1_2_ppc64le.whl", hash = "sha256:c4c3e6da02df6fa1410a7680bd3f63d4f710232d3139089536310d027950696a", size = 152852 },
    { url = "https://files.pythonhosted.org/packages/84/c9/98e3732278a99f47d487fd3468bc60b882920cef29d1fa6ca460a1fdf4e6/charset_normalizer-3.4.1-cp312-cp312-musllinux_1_2_s390x.whl", hash = "sha256:5df196eb874dae23dcfb968c83d4f8fdccb333330fe1fc278ac5ceeb101003a9", size = 150488 },
    { url = "https://files.pythonhosted.org/packages/13/0e/9c8d4cb99c98c1007cc11eda969ebfe837bbbd0acdb4736d228ccaabcd22/charset_normalizer-3.4.1-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:e358e64305fe12299a08e08978f51fc21fac060dcfcddd95453eabe5b93ed0e1", size = 146192 },
    { url = "https://files.pythonhosted.org/packages/b2/21/2b6b5b860781a0b49427309cb8670785aa543fb2178de875b87b9cc97746/charset_normalizer-3.4.1-cp312-cp312-win32.whl", hash = "sha256:9b23ca7ef998bc739bf6ffc077c2116917eabcc901f88da1b9856b210ef63f35", size = 95550 },
    { url = "https://files.pythonhosted.org/packages/21/5b/1b390b03b1d16c7e382b561c5329f83cc06623916aab983e8ab9239c7d5c/charset_normalizer-3.4.1-cp312-cp312-win_amd64.whl", hash = "sha256:6ff8a4a60c227ad87030d76e99cd1698345d4491638dfa6673027c48b3cd395f", size = 102785 },
    { url = "https://files.pythonhosted.org/packages/38/94/ce8e6f63d18049672c76d07d119304e1e2d7c6098f0841b51c666e9f44a0/charset_normalizer-3.4.1-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:aabfa34badd18f1da5ec1bc2715cadc8dca465868a4e73a0173466b688f29dda", size = 195698 },
    { url = "https://files.pythonhosted.org/packages/24/2e/dfdd9770664aae179a96561cc6952ff08f9a8cd09a908f259a9dfa063568/charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:22e14b5d70560b8dd51ec22863f370d1e595ac3d024cb8ad7d308b4cd95f8313", size = 140162 },
    { url = "https://files.pythonhosted.org/packages/24/4e/f646b9093cff8fc86f2d60af2de4dc17c759de9d554f130b140ea4738ca6/charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:8436c508b408b82d87dc5f62496973a1805cd46727c34440b0d29d8a2f50a6c9", size = 150263 },
    { url = "https://files.pythonhosted.org/packages/5e/67/2937f8d548c3ef6e2f9aab0f6e21001056f692d43282b165e7c56023e6dd/charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:2d074908e1aecee37a7635990b2c6d504cd4766c7bc9fc86d63f9c09af3fa11b", size = 142966 },
    { url = "https://files.pythonhosted.org/packages/52/ed/b7f4f07de100bdb95c1756d3a4d17b90c1a3c53715c1a476f8738058e0fa/charset_normalizer-3.4.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:955f8851919303c92343d2f66165294848d57e9bba6cf6e3625485a70a038d11", size = 144992 },
    { url = "https://files.pythonhosted.org/packages/96/2c/d49710a6dbcd3776265f4c923bb73ebe83933dfbaa841c5da850fe0fd20b/charset_normalizer-3.4.1-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:44ecbf16649486d4aebafeaa7ec4c9fed8b88101f4dd612dcaf65d5e815f837f", size = 147162 },
    { url = "https://files.pythonhosted.org/packages/b4/41/35ff1f9a6bd380303dea55e44c4933b4cc3c4850988927d4082ada230273/charset_normalizer-3.4.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:0924e81d3d5e70f8126529951dac65c1010cdf117bb75eb02dd12339b57749dd", size = 140972 },
    { url = "https://files.pythonhosted.org/packages/fb/43/c6a0b685fe6910d08ba971f62cd9c3e862a85770395ba5d9cad4fede33ab/charset_normalizer-3.4.1-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:2967f74ad52c3b98de4c3b32e1a44e32975e008a9cd2a8cc8966d6a5218c5cb2", size = 149095 },
    { url = "https://files.pythonhosted.org/packages/4c/ff/a9a504662452e2d2878512115638966e75633519ec11f25fca3d2049a94a/charset_normalizer-3.4.1-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:c75cb2a3e389853835e84a2d8fb2b81a10645b503eca9bcb98df6b5a43eb8886", size = 152668 },
    { url = "https://files.pythonhosted.org/packages/6c/71/189996b6d9a4b932564701628af5cee6716733e9165af1d5e1b285c530ed/charset_normalizer-3.4.1-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:09b26ae6b1abf0d27570633b2b078a2a20419c99d66fb2823173d73f188ce601", size = 150073 },
    { url = "https://files.pythonhosted.org/packages/e4/93/946a86ce20790e11312c87c75ba68d5f6ad2208cfb52b2d6a2c32840d922/charset_normalizer-3.4.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:fa88b843d6e211393a37219e6a1c1df99d35e8fd90446f1118f4216e307e48cd", size = 145732 },
    { url = "https://files.pythonhosted.org/packages/cd/e5/131d2fb1b0dddafc37be4f3a2fa79aa4c037368be9423061dccadfd90091/charset_normalizer-3.4.1-cp313-cp313-win32.whl", hash = "sha256:eb8178fe3dba6450a3e024e95ac49ed3400e506fd4e9e5c32d30adda88cbd407", size = 95391 },
    { url = "https://files.pythonhosted.org/packages/27/f2/4f9a69cc7712b9b5ad8fdb87039fd89abba997ad5cbe690d1835d40405b0/charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl", hash = "sha256:b1ac5992a838106edb89654e0aebfc24f5848ae2547d22c2c3f66454daa11971", size = 102702 },
    { url = "https://files.pythonhosted.org/packages/10/bd/6517ea94f2672e801011d50b5d06be2a0deaf566aea27bcdcd47e5195357/charset_normalizer-3.4.1-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:ecddf25bee22fe4fe3737a399d0d177d72bc22be6913acfab364b40bce1ba83c", size = 195653 },
    { url = "https://files.pythonhosted.org/packages/e5/0d/815a2ba3f283b4eeaa5ece57acade365c5b4135f65a807a083c818716582/charset_normalizer-3.4.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8c60ca7339acd497a55b0ea5d506b2a2612afb2826560416f6894e8b5770d4a9", size = 140701 },
    { url = "https://files.pythonhosted.org/packages/aa/17/c94be7ee0d142687e047fe1de72060f6d6837f40eedc26e87e6e124a3fc6/charset_normalizer-3.4.1-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:b7b2d86dd06bfc2ade3312a83a5c364c7ec2e3498f8734282c6c3d4b07b346b8", size = 150495 },
    { url = "https://files.pythonhosted.org/packages/f7/33/557ac796c47165fc141e4fb71d7b0310f67e05cb420756f3a82e0a0068e0/charset_normalizer-3.4.1-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:dd78cfcda14a1ef52584dbb008f7ac81c1328c0f58184bf9a84c49c605002da6", size = 142946 },
    { url = "https://files.pythonhosted.org/packages/1e/0d/38ef4ae41e9248d63fc4998d933cae22473b1b2ac4122cf908d0f5eb32aa/charset_normalizer-3.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6e27f48bcd0957c6d4cb9d6fa6b61d192d0b13d5ef563e5f2ae35feafc0d179c", size = 144737 },
    { url = "https://files.pythonhosted.org/packages/43/01/754cdb29dd0560f58290aaaa284d43eea343ad0512e6ad3b8b5c11f08592/charset_normalizer-3.4.1-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:01ad647cdd609225c5350561d084b42ddf732f4eeefe6e678765636791e78b9a", size = 147471 },
    { url = "https://files.pythonhosted.org/packages/ba/cd/861883ba5160c7a9bd242c30b2c71074cda2aefcc0addc91118e0d4e0765/charset_normalizer-3.4.1-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:619a609aa74ae43d90ed2e89bdd784765de0a25ca761b93e196d938b8fd1dbbd", size = 140801 },
    { url = "https://files.pythonhosted.org/packages/6f/7f/0c0dad447819e90b93f8ed238cc8f11b91353c23c19e70fa80483a155bed/charset_normalizer-3.4.1-cp38-cp38-musllinux_1_2_i686.whl", hash = "sha256:89149166622f4db9b4b6a449256291dc87a99ee53151c74cbd82a53c8c2f6ccd", size = 149312 },
    { url = "https://files.pythonhosted.org/packages/8e/09/9f8abcc6fff60fb727268b63c376c8c79cc37b833c2dfe1f535dfb59523b/charset_normalizer-3.4.1-cp38-cp38-musllinux_1_2_ppc64le.whl", hash = "sha256:7709f51f5f7c853f0fb938bcd3bc59cdfdc5203635ffd18bf354f6967ea0f824", size = 152347 },
    { url = "https://files.pythonhosted.org/packages/be/e5/3f363dad2e24378f88ccf63ecc39e817c29f32e308ef21a7a6d9c1201165/charset_normalizer-3.4.1-cp38-cp38-musllinux_1_2_s390x.whl", hash = "sha256:345b0426edd4e18138d6528aed636de7a9ed169b4aaf9d61a8c19e39d26838ca", size = 149888 },
    { url = "https://files.pythonhosted.org/packages/e4/10/a78c0e91f487b4ad0ef7480ac765e15b774f83de2597f1b6ef0eaf7a2f99/charset_normalizer-3.4.1-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:0907f11d019260cdc3f94fbdb23ff9125f6b5d1039b76003b5b0ac9d6a6c9d5b", size = 145169 },
    { url = "https://files.pythonhosted.org/packages/d3/81/396e7d7f5d7420da8273c91175d2e9a3f569288e3611d521685e4b9ac9cc/charset_normalizer-3.4.1-cp38-cp38-win32.whl", hash = "sha256:ea0d8d539afa5eb2728aa1932a988a9a7af94f18582ffae4bc10b3fbdad0626e", size = 95094 },
    { url = "https://files.pythonhosted.org/packages/40/bb/20affbbd9ea29c71ea123769dc568a6d42052ff5089c5fe23e21e21084a6/charset_normalizer-3.4.1-cp38-cp38-win_amd64.whl", hash = "sha256:329ce159e82018d646c7ac45b01a430369d526569ec08516081727a20e9e4af4", size = 102139 },
    { url = "https://files.pythonhosted.org/packages/7f/c0/b913f8f02836ed9ab32ea643c6fe4d3325c3d8627cf6e78098671cafff86/charset_normalizer-3.4.1-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:b97e690a2118911e39b4042088092771b4ae3fc3aa86518f84b8cf6888dbdb41", size = 197867 },
    { url = "https://files.pythonhosted.org/packages/0f/6c/2bee440303d705b6fb1e2ec789543edec83d32d258299b16eed28aad48e0/charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:78baa6d91634dfb69ec52a463534bc0df05dbd546209b79a3880a34487f4b84f", size = 141385 },
    { url = "https://files.pythonhosted.org/packages/3d/04/cb42585f07f6f9fd3219ffb6f37d5a39b4fd2db2355b23683060029c35f7/charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:1a2bc9f351a75ef49d664206d51f8e5ede9da246602dc2d2726837620ea034b2", size = 151367 },
    { url = "https://files.pythonhosted.org/packages/54/54/2412a5b093acb17f0222de007cc129ec0e0df198b5ad2ce5699355269dfe/charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:75832c08354f595c760a804588b9357d34ec00ba1c940c15e31e96d902093770", size = 143928 },
    { url = "https://files.pythonhosted.org/packages/5a/6d/e2773862b043dcf8a221342954f375392bb2ce6487bcd9f2c1b34e1d6781/charset_normalizer-3.4.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0af291f4fe114be0280cdd29d533696a77b5b49cfde5467176ecab32353395c4", size = 146203 },
    { url = "https://files.pythonhosted.org/packages/b9/f8/ca440ef60d8f8916022859885f231abb07ada3c347c03d63f283bec32ef5/charset_normalizer-3.4.1-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:0167ddc8ab6508fe81860a57dd472b2ef4060e8d378f0cc555707126830f2537", size = 148082 },
    { url = "https://files.pythonhosted.org/packages/04/d2/42fd330901aaa4b805a1097856c2edf5095e260a597f65def493f4b8c833/charset_normalizer-3.4.1-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:2a75d49014d118e4198bcee5ee0a6f25856b29b12dbf7cd012791f8a6cc5c496", size = 142053 },
    { url = "https://files.pythonhosted.org/packages/9e/af/3a97a4fa3c53586f1910dadfc916e9c4f35eeada36de4108f5096cb7215f/charset_normalizer-3.4.1-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:363e2f92b0f0174b2f8238240a1a30142e3db7b957a5dd5689b0e75fb717cc78", size = 150625 },
    { url = "https://files.pythonhosted.org/packages/26/ae/23d6041322a3556e4da139663d02fb1b3c59a23ab2e2b56432bd2ad63ded/charset_normalizer-3.4.1-cp39-cp39-musllinux_1_2_ppc64le.whl", hash = "sha256:ab36c8eb7e454e34e60eb55ca5d241a5d18b2c6244f6827a30e451c42410b5f7", size = 153549 },
    { url = "https://files.pythonhosted.org/packages/94/22/b8f2081c6a77cb20d97e57e0b385b481887aa08019d2459dc2858ed64871/charset_normalizer-3.4.1-cp39-cp39-musllinux_1_2_s390x.whl", hash = "sha256:4c0907b1928a36d5a998d72d64d8eaa7244989f7aaaf947500d3a800c83a3fd6", size = 150945 },
    { url = "https://files.pythonhosted.org/packages/c7/0b/c5ec5092747f801b8b093cdf5610e732b809d6cb11f4c51e35fc28d1d389/charset_normalizer-3.4.1-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:04432ad9479fa40ec0f387795ddad4437a2b50417c69fa275e212933519ff294", size = 146595 },
    { url = "https://files.pythonhosted.org/packages/0c/5a/0b59704c38470df6768aa154cc87b1ac7c9bb687990a1559dc8765e8627e/charset_normalizer-3.4.1-cp39-cp39-win32.whl", hash = "sha256:3bed14e9c89dcb10e8f3a29f9ccac4955aebe93c71ae803af79265c9ca5644c5", size = 95453 },
    { url = "https://files.pythonhosted.org/packages/85/2d/a9790237cb4d01a6d57afadc8573c8b73c609ade20b80f4cda30802009ee/charset_normalizer-3.4.1-cp39-cp39-win_amd64.whl", hash = "sha256:49402233c892a461407c512a19435d1ce275543138294f7ef013f0b63d5d3765", size = 102811 },
    { url = "https://files.pythonhosted.org/packages/0e/f6/65ecc6878a89bb1c23a086ea335ad4bf21a588990c3f535a227b9eea9108/charset_normalizer-3.4.1-py3-none-any.whl", hash = "sha256:d98b1668f06378c6dbefec3b92299716b931cd4e6061f3c875a71ced1780ab85", size = 49767 },
]

[[package]]
name = "click"
version = "8.1.8"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "colorama", marker = "platform_system == 'Windows'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b9/2e/0090cbf739cee7d23781ad4b89a9894a41538e4fcf4c31dcdd705b78eb8b/click-8.1.8.tar.gz", hash = "sha256:ed53c9d8990d83c2a27deae68e4ee337473f6330c040a31d4225c9574d16096a", size = 226593 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7e/d4/7ebdbd03970677812aac39c869717059dbb71a4cfc033ca6e5221787892c/click-8.1.8-py3-none-any.whl", hash = "sha256:63c132bbbed01578a06712a2d1f497bb62d9c1c0d329b7903a866228027263b2", size = 98188 },
]

[[package]]
name = "cloudpathlib"
version = "0.20.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions", marker = "python_full_version < '3.11'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/71/0b/a47d78ed2816db100543b504fdbfc2070f422aac858e6bcf775713e37b8a/cloudpathlib-0.20.0.tar.gz", hash = "sha256:f6ef7ca409a510f7ba4639ba50ab3fc5b6dee82d6dff0d7f5715fd0c9ab35891", size = 45149 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/1f/6e/b64600156934dab14cc8b403095a9ea8bd722aad2e775673c68346b76220/cloudpathlib-0.20.0-py3-none-any.whl", hash = "sha256:7af3bcefbf73392ae7f31c08b3660ec31607f8c01b7f6262d4d73469a845f641", size = 52547 },
]

[[package]]
name = "cobble"
version = "0.1.4"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/54/7a/a507c709be2c96e1bb6102eb7b7f4026c5e5e223ef7d745a17d239e9d844/cobble-0.1.4.tar.gz", hash = "sha256:de38be1539992c8a06e569630717c485a5f91be2192c461ea2b220607dfa78aa", size = 3805 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d5/e1/3714a2f371985215c219c2a70953d38e3eed81ef165aed061d21de0e998b/cobble-0.1.4-py3-none-any.whl", hash = "sha256:36c91b1655e599fd428e2b95fdd5f0da1ca2e9f1abb0bc871dec21a0e78a2b44", size = 3984 },
]

[[package]]
name = "colorama"
version = "0.4.6"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d8/53/6f443c9a4a8358a93a6792e2acffb9d9d5cb0a5cfd8802644b7b1c9a02e4/colorama-0.4.6.tar.gz", hash = "sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44", size = 27697 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl", hash = "sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6", size = 25335 },
]

[[package]]
name = "confection"
version = "0.1.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "pydantic" },
    { name = "srsly" },
]
sdist = { url = "https://files.pythonhosted.org/packages/51/d3/57c6631159a1b48d273b40865c315cf51f89df7a9d1101094ef12e3a37c2/confection-0.1.5.tar.gz", hash = "sha256:8e72dd3ca6bd4f48913cd220f10b8275978e740411654b6e8ca6d7008c590f0e", size = 38924 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/0c/00/3106b1854b45bd0474ced037dfe6b73b90fe68a68968cef47c23de3d43d2/confection-0.1.5-py3-none-any.whl", hash = "sha256:e29d3c3f8eac06b3f77eb9dfb4bf2fc6bcc9622a98ca00a698e3d019c6430b14", size = 35451 },
]

[[package]]
name = "contourpy"
version = "1.1.1"
source = { registry = "https://pypi.org/simple" }
resolution-markers = [
    "python_full_version < '3.9'",
    "python_full_version == '3.9.*'",
    "python_full_version == '3.10.*'",
    "python_full_version == '3.11.*'",
]
dependencies = [
    { name = "numpy", marker = "python_full_version < '3.12'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b1/7d/087ee4295e7580d3f7eb8a8a4e0ec8c7847e60f34135248ccf831cf5bbfc/contourpy-1.1.1.tar.gz", hash = "sha256:96ba37c2e24b7212a77da85004c38e7c4d155d3e72a45eeaf22c1f03f607e8ab", size = 13433167 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/fb/7f/c44a51a83a093bf5c84e07dd1e3cfe9f68c47b6499bd05a9de0c6dbdc2bc/contourpy-1.1.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:46e24f5412c948d81736509377e255f6040e94216bf1a9b5ea1eaa9d29f6ec1b", size = 247207 },
    { url = "https://files.pythonhosted.org/packages/a9/65/544d66da0716b20084874297ff7596704e435cf011512f8e576638e83db2/contourpy-1.1.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:0e48694d6a9c5a26ee85b10130c77a011a4fedf50a7279fa0bdaf44bafb4299d", size = 232428 },
    { url = "https://files.pythonhosted.org/packages/5b/e6/697085cc34a294bd399548fd99562537a75408f113e3a815807e206246f0/contourpy-1.1.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a66045af6cf00e19d02191ab578a50cb93b2028c3eefed999793698e9ea768ae", size = 285304 },
    { url = "https://files.pythonhosted.org/packages/69/4b/52d0d2e85c59f00f6ddbd6fea819f267008c58ee7708da96d112a293e91c/contourpy-1.1.1-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:4ebf42695f75ee1a952f98ce9775c873e4971732a87334b099dde90b6af6a916", size = 322655 },
    { url = "https://files.pythonhosted.org/packages/82/fc/3decc656a547a6d5d5b4249f81c72668a1f3259a62b2def2504120d38746/contourpy-1.1.1-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f6aec19457617ef468ff091669cca01fa7ea557b12b59a7908b9474bb9674cf0", size = 296430 },
    { url = "https://files.pythonhosted.org/packages/f1/6b/e4b0f8708f22dd7c321f87eadbb98708975e115ac6582eb46d1f32197ce6/contourpy-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:462c59914dc6d81e0b11f37e560b8a7c2dbab6aca4f38be31519d442d6cde1a1", size = 301672 },
    { url = "https://files.pythonhosted.org/packages/c3/87/201410522a756e605069078833d806147cad8532fdc164a96689d05c5afc/contourpy-1.1.1-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:6d0a8efc258659edc5299f9ef32d8d81de8b53b45d67bf4bfa3067f31366764d", size = 820145 },
    { url = "https://files.pythonhosted.org/packages/b4/d9/42680a17d43edda04ab2b3f11125cf97b61bce5d3b52721a42960bf748bd/contourpy-1.1.1-cp310-cp310-win32.whl", hash = "sha256:d6ab42f223e58b7dac1bb0af32194a7b9311065583cc75ff59dcf301afd8a431", size = 399542 },
    { url = "https://files.pythonhosted.org/packages/55/14/0dc1884e3c04f9b073a47283f5d424926644250891db392a07c56f05e5c5/contourpy-1.1.1-cp310-cp310-win_amd64.whl", hash = "sha256:549174b0713d49871c6dee90a4b499d3f12f5e5f69641cd23c50a4542e2ca1eb", size = 477974 },
    { url = "https://files.pythonhosted.org/packages/8b/4f/be28a39cd5e988b8d3c2cc642c2c7ffeeb28fe80a86df71b6d1e473c5038/contourpy-1.1.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:407d864db716a067cc696d61fa1ef6637fedf03606e8417fe2aeed20a061e6b2", size = 248613 },
    { url = "https://files.pythonhosted.org/packages/2c/8e/656f8e7cd316aa68d9824744773e90dbd71f847429d10c82001e927480a2/contourpy-1.1.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:dfe80c017973e6a4c367e037cb31601044dd55e6bfacd57370674867d15a899b", size = 233603 },
    { url = "https://files.pythonhosted.org/packages/60/2a/4d4bd4541212ab98f3411f21bf58b0b246f333ae996e9f57e1acf12bcc45/contourpy-1.1.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e30aaf2b8a2bac57eb7e1650df1b3a4130e8d0c66fc2f861039d507a11760e1b", size = 287037 },
    { url = "https://files.pythonhosted.org/packages/24/67/8abf919443381585a4eee74069e311c736350549dae02d3d014fef93d50a/contourpy-1.1.1-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:3de23ca4f381c3770dee6d10ead6fff524d540c0f662e763ad1530bde5112532", size = 323274 },
    { url = "https://files.pythonhosted.org/packages/2a/e5/6da11329dd35a2f2e404a95e5374b5702de6ac52e776e8b87dd6ea4b29d0/contourpy-1.1.1-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:566f0e41df06dfef2431defcfaa155f0acfa1ca4acbf8fd80895b1e7e2ada40e", size = 297801 },
    { url = "https://files.pythonhosted.org/packages/b7/f6/78f60fa0b6ae64971178e2542e8b3ad3ba5f4f379b918ab7b18038a3f897/contourpy-1.1.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b04c2f0adaf255bf756cf08ebef1be132d3c7a06fe6f9877d55640c5e60c72c5", size = 302821 },
    { url = "https://files.pythonhosted.org/packages/da/25/6062395a1c6a06f46a577da821318886b8b939453a098b9cd61671bb497b/contourpy-1.1.1-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:d0c188ae66b772d9d61d43c6030500344c13e3f73a00d1dc241da896f379bb62", size = 820121 },
    { url = "https://files.pythonhosted.org/packages/41/5e/64e78b1e8682cbab10c13fc1a2c070d30acedb805ab2f42afbd3d88f7225/contourpy-1.1.1-cp311-cp311-win32.whl", hash = "sha256:0683e1ae20dc038075d92e0e0148f09ffcefab120e57f6b4c9c0f477ec171f33", size = 401590 },
    { url = "https://files.pythonhosted.org/packages/e5/76/94bc17eb868f8c7397f8fdfdeae7661c1b9a35f3a7219da308596e8c252a/contourpy-1.1.1-cp311-cp311-win_amd64.whl", hash = "sha256:8636cd2fc5da0fb102a2504fa2c4bea3cbc149533b345d72cdf0e7a924decc45", size = 480534 },
    { url = "https://files.pythonhosted.org/packages/94/0f/07a5e26fec7176658f6aecffc615900ff1d303baa2b67bc37fd98ce67c87/contourpy-1.1.1-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:560f1d68a33e89c62da5da4077ba98137a5e4d3a271b29f2f195d0fba2adcb6a", size = 249799 },
    { url = "https://files.pythonhosted.org/packages/32/0b/d7baca3f60d3b3a77c9ba1307c7792befd3c1c775a26c649dca1bfa9b6ba/contourpy-1.1.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:24216552104ae8f3b34120ef84825400b16eb6133af2e27a190fdc13529f023e", size = 232739 },
    { url = "https://files.pythonhosted.org/packages/6d/62/a385b4d4b5718e3a933de5791528f45f1f5b364d3c79172ad0309c832041/contourpy-1.1.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:56de98a2fb23025882a18b60c7f0ea2d2d70bbbcfcf878f9067234b1c4818442", size = 282171 },
    { url = "https://files.pythonhosted.org/packages/91/21/8c6819747fea53557f3963ca936035b3e8bed87d591f5278ad62516a059d/contourpy-1.1.1-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:07d6f11dfaf80a84c97f1a5ba50d129d9303c5b4206f776e94037332e298dda8", size = 321182 },
    { url = "https://files.pythonhosted.org/packages/22/29/d75da9002f9df09c755b12cf0357eb91b081c858e604f4e92b4b8bfc3c15/contourpy-1.1.1-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f1eaac5257a8f8a047248d60e8f9315c6cff58f7803971170d952555ef6344a7", size = 295869 },
    { url = "https://files.pythonhosted.org/packages/a7/47/4e7e66159f881c131e3b97d1cc5c0ea72be62bdd292c7f63fd13937d07f4/contourpy-1.1.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:19557fa407e70f20bfaba7d55b4d97b14f9480856c4fb65812e8a05fe1c6f9bf", size = 298756 },
    { url = "https://files.pythonhosted.org/packages/d3/bb/bffc99bc3172942b5eda8027ca0cb80ddd336fcdd634d68adce957d37231/contourpy-1.1.1-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:081f3c0880712e40effc5f4c3b08feca6d064cb8cfbb372ca548105b86fd6c3d", size = 818441 },
    { url = "https://files.pythonhosted.org/packages/da/1b/904baf0aaaf6c6e2247801dcd1ff0d7bf84352839927d356b28ae804cbb0/contourpy-1.1.1-cp312-cp312-win32.whl", hash = "sha256:059c3d2a94b930f4dafe8105bcdc1b21de99b30b51b5bce74c753686de858cb6", size = 410294 },
    { url = "https://files.pythonhosted.org/packages/75/d4/c3b7a9a0d1f99b528e5a46266b0b9f13aad5a0dd1156d071418df314c427/contourpy-1.1.1-cp312-cp312-win_amd64.whl", hash = "sha256:f44d78b61740e4e8c71db1cf1fd56d9050a4747681c59ec1094750a658ceb970", size = 486678 },
    { url = "https://files.pythonhosted.org/packages/02/7e/ffaba1bf3719088be3ad6983a5e85e1fc9edccd7b406b98e433436ecef74/contourpy-1.1.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:70e5a10f8093d228bb2b552beeb318b8928b8a94763ef03b858ef3612b29395d", size = 247023 },
    { url = "https://files.pythonhosted.org/packages/a6/82/29f5ff4ae074c3230e266bc9efef449ebde43721a727b989dd8ef8f97d73/contourpy-1.1.1-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:8394e652925a18ef0091115e3cc191fef350ab6dc3cc417f06da66bf98071ae9", size = 232380 },
    { url = "https://files.pythonhosted.org/packages/9b/cb/08f884c4c2efd433a38876b1b8069bfecef3f2d21ff0ce635d455962f70f/contourpy-1.1.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c5bd5680f844c3ff0008523a71949a3ff5e4953eb7701b28760805bc9bcff217", size = 285830 },
    { url = "https://files.pythonhosted.org/packages/8e/57/cd4d4c99d999a25e9d518f628b4793e64b1ecb8ad3147f8469d8d4a80678/contourpy-1.1.1-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:66544f853bfa85c0d07a68f6c648b2ec81dafd30f272565c37ab47a33b220684", size = 322038 },
    { url = "https://files.pythonhosted.org/packages/32/b6/c57ed305a6f86731107fc183e97c7e6a6005d145f5c5228a44718082ad12/contourpy-1.1.1-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:e0c02b75acfea5cab07585d25069207e478d12309557f90a61b5a3b4f77f46ce", size = 295797 },
    { url = "https://files.pythonhosted.org/packages/8e/71/7f20855592cc929bc206810432b991ec4c702dc26b0567b132e52c85536f/contourpy-1.1.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:41339b24471c58dc1499e56783fedc1afa4bb018bcd035cfb0ee2ad2a7501ef8", size = 301124 },
    { url = "https://files.pythonhosted.org/packages/86/6d/52c2fc80f433e7cdc8624d82e1422ad83ad461463cf16a1953bbc7d10eb1/contourpy-1.1.1-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:f29fb0b3f1217dfe9362ec55440d0743fe868497359f2cf93293f4b2701b8251", size = 819787 },
    { url = "https://files.pythonhosted.org/packages/d0/b0/f8d4548e89f929d6c5ca329df9afad6190af60079ec77d8c31eb48cf6f82/contourpy-1.1.1-cp38-cp38-win32.whl", hash = "sha256:f9dc7f933975367251c1b34da882c4f0e0b2e24bb35dc906d2f598a40b72bfc7", size = 400031 },
    { url = "https://files.pythonhosted.org/packages/96/1b/b05cd42c8d21767a0488b883b38658fb9a45f86c293b7b42521a8113dc5d/contourpy-1.1.1-cp38-cp38-win_amd64.whl", hash = "sha256:498e53573e8b94b1caeb9e62d7c2d053c263ebb6aa259c81050766beb50ff8d9", size = 477949 },
    { url = "https://files.pythonhosted.org/packages/16/d9/8a15ff67fc27c65939e454512955e1b240ec75cd201d82e115b3b63ef76d/contourpy-1.1.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:ba42e3810999a0ddd0439e6e5dbf6d034055cdc72b7c5c839f37a7c274cb4eba", size = 247396 },
    { url = "https://files.pythonhosted.org/packages/09/fe/086e6847ee53da10ddf0b6c5e5f877ab43e68e355d2f4c85f67561ee8a57/contourpy-1.1.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:6c06e4c6e234fcc65435223c7b2a90f286b7f1b2733058bdf1345d218cc59e34", size = 232598 },
    { url = "https://files.pythonhosted.org/packages/a3/9c/662925239e1185c6cf1da8c334e4c61bddcfa8e528f4b51083b613003170/contourpy-1.1.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ca6fab080484e419528e98624fb5c4282148b847e3602dc8dbe0cb0669469887", size = 286436 },
    { url = "https://files.pythonhosted.org/packages/d3/7e/417cdf65da7140981079eda6a81ecd593ae0239bf8c738f2e2b3f6df8920/contourpy-1.1.1-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:93df44ab351119d14cd1e6b52a5063d3336f0754b72736cc63db59307dabb718", size = 322629 },
    { url = "https://files.pythonhosted.org/packages/a8/22/ffd88aef74cc045698c5e5c400e8b7cd62311199c109245ac7827290df2c/contourpy-1.1.1-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:eafbef886566dc1047d7b3d4b14db0d5b7deb99638d8e1be4e23a7c7ac59ff0f", size = 297117 },
    { url = "https://files.pythonhosted.org/packages/2b/c0/24c34c41a180f875419b536125799c61e2330b997d77a5a818a3bc3e08cd/contourpy-1.1.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:efe0fab26d598e1ec07d72cf03eaeeba8e42b4ecf6b9ccb5a356fde60ff08b85", size = 301855 },
    { url = "https://files.pythonhosted.org/packages/bf/ec/f9877f6378a580cd683bd76c8a781dcd972e82965e0da951a739d3364677/contourpy-1.1.1-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:f08e469821a5e4751c97fcd34bcb586bc243c39c2e39321822060ba902eac49e", size = 820597 },
    { url = "https://files.pythonhosted.org/packages/e1/3a/c41f4bc7122d3a06388acae1bed6f50a665c1031863ca42bd701094dcb1f/contourpy-1.1.1-cp39-cp39-win32.whl", hash = "sha256:bfc8a5e9238232a45ebc5cb3bfee71f1167064c8d382cadd6076f0d51cff1da0", size = 400031 },
    { url = "https://files.pythonhosted.org/packages/87/2b/9b49451f7412cc1a79198e94a771a4e52d65c479aae610b1161c0290ef2c/contourpy-1.1.1-cp39-cp39-win_amd64.whl", hash = "sha256:c84fdf3da00c2827d634de4fcf17e3e067490c4aea82833625c4c8e6cdea0887", size = 435965 },
    { url = "https://files.pythonhosted.org/packages/e6/3c/fc36884b6793e2066a6ff25c86e21b8bd62553456b07e964c260bcf22711/contourpy-1.1.1-pp38-pypy38_pp73-macosx_10_9_x86_64.whl", hash = "sha256:229a25f68046c5cf8067d6d6351c8b99e40da11b04d8416bf8d2b1d75922521e", size = 246493 },
    { url = "https://files.pythonhosted.org/packages/3d/85/f4c5b09ce79828ed4553a8ae2ebdf937794f57b45848b1f5c95d9744ecc2/contourpy-1.1.1-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a10dab5ea1bd4401c9483450b5b0ba5416be799bbd50fc7a6cc5e2a15e03e8a3", size = 289240 },
    { url = "https://files.pythonhosted.org/packages/18/d3/9d7c0a372baf5130c1417a4b8275079d5379c11355436cb9fc78af7d7559/contourpy-1.1.1-pp38-pypy38_pp73-win_amd64.whl", hash = "sha256:4f9147051cb8fdb29a51dc2482d792b3b23e50f8f57e3720ca2e3d438b7adf23", size = 476043 },
    { url = "https://files.pythonhosted.org/packages/e7/12/643242c3d9b031ca19f9a440f63e568dd883a04711056ca5d607f9bda888/contourpy-1.1.1-pp39-pypy39_pp73-macosx_10_9_x86_64.whl", hash = "sha256:a75cc163a5f4531a256f2c523bd80db509a49fc23721b36dd1ef2f60ff41c3cb", size = 246247 },
    { url = "https://files.pythonhosted.org/packages/e1/37/95716fe235bf441422059e4afcd4b9b7c5821851c2aee992a06d1e9f831a/contourpy-1.1.1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3b53d5769aa1f2d4ea407c65f2d1d08002952fac1d9e9d307aa2e1023554a163", size = 289029 },
    { url = "https://files.pythonhosted.org/packages/e5/fd/14852c4a688031e0d8a20d9a1b60078d45507186ef17042093835be2f01a/contourpy-1.1.1-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:11b836b7dbfb74e049c302bbf74b4b8f6cb9d0b6ca1bf86cfa8ba144aedadd9c", size = 476043 },
]

[[package]]
name = "contourpy"
version = "1.3.1"
source = { registry = "https://pypi.org/simple" }
resolution-markers = [
    "python_full_version >= '3.12'",
]
dependencies = [
    { name = "numpy", marker = "python_full_version >= '3.12'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/25/c2/fc7193cc5383637ff390a712e88e4ded0452c9fbcf84abe3de5ea3df1866/contourpy-1.3.1.tar.gz", hash = "sha256:dfd97abd83335045a913e3bcc4a09c0ceadbe66580cf573fe961f4a825efa699", size = 13465753 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b2/a3/80937fe3efe0edacf67c9a20b955139a1a622730042c1ea991956f2704ad/contourpy-1.3.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:a045f341a77b77e1c5de31e74e966537bba9f3c4099b35bf4c2e3939dd54cdab", size = 268466 },
    { url = "https://files.pythonhosted.org/packages/82/1d/e3eaebb4aa2d7311528c048350ca8e99cdacfafd99da87bc0a5f8d81f2c2/contourpy-1.3.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:500360b77259914f7805af7462e41f9cb7ca92ad38e9f94d6c8641b089338124", size = 253314 },
    { url = "https://files.pythonhosted.org/packages/de/f3/d796b22d1a2b587acc8100ba8c07fb7b5e17fde265a7bb05ab967f4c935a/contourpy-1.3.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b2f926efda994cdf3c8d3fdb40b9962f86edbc4457e739277b961eced3d0b4c1", size = 312003 },
    { url = "https://files.pythonhosted.org/packages/bf/f5/0e67902bc4394daee8daa39c81d4f00b50e063ee1a46cb3938cc65585d36/contourpy-1.3.1-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:adce39d67c0edf383647a3a007de0a45fd1b08dedaa5318404f1a73059c2512b", size = 351896 },
    { url = "https://files.pythonhosted.org/packages/1f/d6/e766395723f6256d45d6e67c13bb638dd1fa9dc10ef912dc7dd3dcfc19de/contourpy-1.3.1-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:abbb49fb7dac584e5abc6636b7b2a7227111c4f771005853e7d25176daaf8453", size = 320814 },
    { url = "https://files.pythonhosted.org/packages/a9/57/86c500d63b3e26e5b73a28b8291a67c5608d4aa87ebd17bd15bb33c178bc/contourpy-1.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a0cffcbede75c059f535725c1680dfb17b6ba8753f0c74b14e6a9c68c29d7ea3", size = 324969 },
    { url = "https://files.pythonhosted.org/packages/b8/62/bb146d1289d6b3450bccc4642e7f4413b92ebffd9bf2e91b0404323704a7/contourpy-1.3.1-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:ab29962927945d89d9b293eabd0d59aea28d887d4f3be6c22deaefbb938a7277", size = 1265162 },
    { url = "https://files.pythonhosted.org/packages/18/04/9f7d132ce49a212c8e767042cc80ae390f728060d2eea47058f55b9eff1c/contourpy-1.3.1-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:974d8145f8ca354498005b5b981165b74a195abfae9a8129df3e56771961d595", size = 1324328 },
    { url = "https://files.pythonhosted.org/packages/46/23/196813901be3f97c83ababdab1382e13e0edc0bb4e7b49a7bff15fcf754e/contourpy-1.3.1-cp310-cp310-win32.whl", hash = "sha256:ac4578ac281983f63b400f7fe6c101bedc10651650eef012be1ccffcbacf3697", size = 173861 },
    { url = "https://files.pythonhosted.org/packages/e0/82/c372be3fc000a3b2005061ca623a0d1ecd2eaafb10d9e883a2fc8566e951/contourpy-1.3.1-cp310-cp310-win_amd64.whl", hash = "sha256:174e758c66bbc1c8576992cec9599ce8b6672b741b5d336b5c74e35ac382b18e", size = 218566 },
    { url = "https://files.pythonhosted.org/packages/12/bb/11250d2906ee2e8b466b5f93e6b19d525f3e0254ac8b445b56e618527718/contourpy-1.3.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:3e8b974d8db2c5610fb4e76307e265de0edb655ae8169e8b21f41807ccbeec4b", size = 269555 },
    { url = "https://files.pythonhosted.org/packages/67/71/1e6e95aee21a500415f5d2dbf037bf4567529b6a4e986594d7026ec5ae90/contourpy-1.3.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:20914c8c973f41456337652a6eeca26d2148aa96dd7ac323b74516988bea89fc", size = 254549 },
    { url = "https://files.pythonhosted.org/packages/31/2c/b88986e8d79ac45efe9d8801ae341525f38e087449b6c2f2e6050468a42c/contourpy-1.3.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:19d40d37c1c3a4961b4619dd9d77b12124a453cc3d02bb31a07d58ef684d3d86", size = 313000 },
    { url = "https://files.pythonhosted.org/packages/c4/18/65280989b151fcf33a8352f992eff71e61b968bef7432fbfde3a364f0730/contourpy-1.3.1-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:113231fe3825ebf6f15eaa8bc1f5b0ddc19d42b733345eae0934cb291beb88b6", size = 352925 },
    { url = "https://files.pythonhosted.org/packages/f5/c7/5fd0146c93220dbfe1a2e0f98969293b86ca9bc041d6c90c0e065f4619ad/contourpy-1.3.1-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:4dbbc03a40f916a8420e420d63e96a1258d3d1b58cbdfd8d1f07b49fcbd38e85", size = 323693 },
    { url = "https://files.pythonhosted.org/packages/85/fc/7fa5d17daf77306840a4e84668a48ddff09e6bc09ba4e37e85ffc8e4faa3/contourpy-1.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3a04ecd68acbd77fa2d39723ceca4c3197cb2969633836ced1bea14e219d077c", size = 326184 },
    { url = "https://files.pythonhosted.org/packages/ef/e7/104065c8270c7397c9571620d3ab880558957216f2b5ebb7e040f85eeb22/contourpy-1.3.1-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:c414fc1ed8ee1dbd5da626cf3710c6013d3d27456651d156711fa24f24bd1291", size = 1268031 },
    { url = "https://files.pythonhosted.org/packages/e2/4a/c788d0bdbf32c8113c2354493ed291f924d4793c4a2e85b69e737a21a658/contourpy-1.3.1-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:31c1b55c1f34f80557d3830d3dd93ba722ce7e33a0b472cba0ec3b6535684d8f", size = 1325995 },
    { url = "https://files.pythonhosted.org/packages/a6/e6/a2f351a90d955f8b0564caf1ebe4b1451a3f01f83e5e3a414055a5b8bccb/contourpy-1.3.1-cp311-cp311-win32.whl", hash = "sha256:f611e628ef06670df83fce17805c344710ca5cde01edfdc72751311da8585375", size = 174396 },
    { url = "https://files.pythonhosted.org/packages/a8/7e/cd93cab453720a5d6cb75588cc17dcdc08fc3484b9de98b885924ff61900/contourpy-1.3.1-cp311-cp311-win_amd64.whl", hash = "sha256:b2bdca22a27e35f16794cf585832e542123296b4687f9fd96822db6bae17bfc9", size = 219787 },
    { url = "https://files.pythonhosted.org/packages/37/6b/175f60227d3e7f5f1549fcb374592be311293132207e451c3d7c654c25fb/contourpy-1.3.1-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:0ffa84be8e0bd33410b17189f7164c3589c229ce5db85798076a3fa136d0e509", size = 271494 },
    { url = "https://files.pythonhosted.org/packages/6b/6a/7833cfae2c1e63d1d8875a50fd23371394f540ce809d7383550681a1fa64/contourpy-1.3.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:805617228ba7e2cbbfb6c503858e626ab528ac2a32a04a2fe88ffaf6b02c32bc", size = 255444 },
    { url = "https://files.pythonhosted.org/packages/7f/b3/7859efce66eaca5c14ba7619791b084ed02d868d76b928ff56890d2d059d/contourpy-1.3.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ade08d343436a94e633db932e7e8407fe7de8083967962b46bdfc1b0ced39454", size = 307628 },
    { url = "https://files.pythonhosted.org/packages/48/b2/011415f5e3f0a50b1e285a0bf78eb5d92a4df000553570f0851b6e309076/contourpy-1.3.1-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:47734d7073fb4590b4a40122b35917cd77be5722d80683b249dac1de266aac80", size = 347271 },
    { url = "https://files.pythonhosted.org/packages/84/7d/ef19b1db0f45b151ac78c65127235239a8cf21a59d1ce8507ce03e89a30b/contourpy-1.3.1-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:2ba94a401342fc0f8b948e57d977557fbf4d515f03c67682dd5c6191cb2d16ec", size = 318906 },
    { url = "https://files.pythonhosted.org/packages/ba/99/6794142b90b853a9155316c8f470d2e4821fe6f086b03e372aca848227dd/contourpy-1.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:efa874e87e4a647fd2e4f514d5e91c7d493697127beb95e77d2f7561f6905bd9", size = 323622 },
    { url = "https://files.pythonhosted.org/packages/3c/0f/37d2c84a900cd8eb54e105f4fa9aebd275e14e266736778bb5dccbf3bbbb/contourpy-1.3.1-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:1bf98051f1045b15c87868dbaea84f92408337d4f81d0e449ee41920ea121d3b", size = 1266699 },
    { url = "https://files.pythonhosted.org/packages/3a/8a/deb5e11dc7d9cc8f0f9c8b29d4f062203f3af230ba83c30a6b161a6effc9/contourpy-1.3.1-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:61332c87493b00091423e747ea78200659dc09bdf7fd69edd5e98cef5d3e9a8d", size = 1326395 },
    { url = "https://files.pythonhosted.org/packages/1a/35/7e267ae7c13aaf12322ccc493531f1e7f2eb8fba2927b9d7a05ff615df7a/contourpy-1.3.1-cp312-cp312-win32.whl", hash = "sha256:e914a8cb05ce5c809dd0fe350cfbb4e881bde5e2a38dc04e3afe1b3e58bd158e", size = 175354 },
    { url = "https://files.pythonhosted.org/packages/a1/35/c2de8823211d07e8a79ab018ef03960716c5dff6f4d5bff5af87fd682992/contourpy-1.3.1-cp312-cp312-win_amd64.whl", hash = "sha256:08d9d449a61cf53033612cb368f3a1b26cd7835d9b8cd326647efe43bca7568d", size = 220971 },
    { url = "https://files.pythonhosted.org/packages/9a/e7/de62050dce687c5e96f946a93546910bc67e483fe05324439e329ff36105/contourpy-1.3.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:a761d9ccfc5e2ecd1bf05534eda382aa14c3e4f9205ba5b1684ecfe400716ef2", size = 271548 },
    { url = "https://files.pythonhosted.org/packages/78/4d/c2a09ae014ae984c6bdd29c11e74d3121b25eaa117eca0bb76340efd7e1c/contourpy-1.3.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:523a8ee12edfa36f6d2a49407f705a6ef4c5098de4f498619787e272de93f2d5", size = 255576 },
    { url = "https://files.pythonhosted.org/packages/ab/8a/915380ee96a5638bda80cd061ccb8e666bfdccea38d5741cb69e6dbd61fc/contourpy-1.3.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ece6df05e2c41bd46776fbc712e0996f7c94e0d0543af1656956d150c4ca7c81", size = 306635 },
    { url = "https://files.pythonhosted.org/packages/29/5c/c83ce09375428298acd4e6582aeb68b1e0d1447f877fa993d9bf6cd3b0a0/contourpy-1.3.1-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:573abb30e0e05bf31ed067d2f82500ecfdaec15627a59d63ea2d95714790f5c2", size = 345925 },
    { url = "https://files.pythonhosted.org/packages/29/63/5b52f4a15e80c66c8078a641a3bfacd6e07106835682454647aca1afc852/contourpy-1.3.1-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a9fa36448e6a3a1a9a2ba23c02012c43ed88905ec80163f2ffe2421c7192a5d7", size = 318000 },
    { url = "https://files.pythonhosted.org/packages/9a/e2/30ca086c692691129849198659bf0556d72a757fe2769eb9620a27169296/contourpy-1.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3ea9924d28fc5586bf0b42d15f590b10c224117e74409dd7a0be3b62b74a501c", size = 322689 },
    { url = "https://files.pythonhosted.org/packages/6b/77/f37812ef700f1f185d348394debf33f22d531e714cf6a35d13d68a7003c7/contourpy-1.3.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:5b75aa69cb4d6f137b36f7eb2ace9280cfb60c55dc5f61c731fdf6f037f958a3", size = 1268413 },
    { url = "https://files.pythonhosted.org/packages/3f/6d/ce84e79cdd128542ebeb268f84abb4b093af78e7f8ec504676673d2675bc/contourpy-1.3.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:041b640d4ec01922083645a94bb3b2e777e6b626788f4095cf21abbe266413c1", size = 1326530 },
    { url = "https://files.pythonhosted.org/packages/72/22/8282f4eae20c73c89bee7a82a19c4e27af9b57bb602ecaa00713d5bdb54d/contourpy-1.3.1-cp313-cp313-win32.whl", hash = "sha256:36987a15e8ace5f58d4d5da9dca82d498c2bbb28dff6e5d04fbfcc35a9cb3a82", size = 175315 },
    { url = "https://files.pythonhosted.org/packages/e3/d5/28bca491f65312b438fbf076589dcde7f6f966b196d900777f5811b9c4e2/contourpy-1.3.1-cp313-cp313-win_amd64.whl", hash = "sha256:a7895f46d47671fa7ceec40f31fae721da51ad34bdca0bee83e38870b1f47ffd", size = 220987 },
    { url = "https://files.pythonhosted.org/packages/2f/24/a4b285d6adaaf9746e4700932f579f1a7b6f9681109f694cfa233ae75c4e/contourpy-1.3.1-cp313-cp313t-macosx_10_13_x86_64.whl", hash = "sha256:9ddeb796389dadcd884c7eb07bd14ef12408aaae358f0e2ae24114d797eede30", size = 285001 },
    { url = "https://files.pythonhosted.org/packages/48/1d/fb49a401b5ca4f06ccf467cd6c4f1fd65767e63c21322b29b04ec40b40b9/contourpy-1.3.1-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:19c1555a6801c2f084c7ddc1c6e11f02eb6a6016ca1318dd5452ba3f613a1751", size = 268553 },
    { url = "https://files.pythonhosted.org/packages/79/1e/4aef9470d13fd029087388fae750dccb49a50c012a6c8d1d634295caa644/contourpy-1.3.1-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:841ad858cff65c2c04bf93875e384ccb82b654574a6d7f30453a04f04af71342", size = 310386 },
    { url = "https://files.pythonhosted.org/packages/b0/34/910dc706ed70153b60392b5305c708c9810d425bde12499c9184a1100888/contourpy-1.3.1-cp313-cp313t-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:4318af1c925fb9a4fb190559ef3eec206845f63e80fb603d47f2d6d67683901c", size = 349806 },
    { url = "https://files.pythonhosted.org/packages/31/3c/faee6a40d66d7f2a87f7102236bf4780c57990dd7f98e5ff29881b1b1344/contourpy-1.3.1-cp313-cp313t-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:14c102b0eab282427b662cb590f2e9340a9d91a1c297f48729431f2dcd16e14f", size = 321108 },
    { url = "https://files.pythonhosted.org/packages/17/69/390dc9b20dd4bb20585651d7316cc3054b7d4a7b4f8b710b2b698e08968d/contourpy-1.3.1-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:05e806338bfeaa006acbdeba0ad681a10be63b26e1b17317bfac3c5d98f36cda", size = 327291 },
    { url = "https://files.pythonhosted.org/packages/ef/74/7030b67c4e941fe1e5424a3d988080e83568030ce0355f7c9fc556455b01/contourpy-1.3.1-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:4d76d5993a34ef3df5181ba3c92fabb93f1eaa5729504fb03423fcd9f3177242", size = 1263752 },
    { url = "https://files.pythonhosted.org/packages/f0/ed/92d86f183a8615f13f6b9cbfc5d4298a509d6ce433432e21da838b4b63f4/contourpy-1.3.1-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:89785bb2a1980c1bd87f0cb1517a71cde374776a5f150936b82580ae6ead44a1", size = 1318403 },
    { url = "https://files.pythonhosted.org/packages/b3/0e/c8e4950c77dcfc897c71d61e56690a0a9df39543d2164040301b5df8e67b/contourpy-1.3.1-cp313-cp313t-win32.whl", hash = "sha256:8eb96e79b9f3dcadbad2a3891672f81cdcab7f95b27f28f1c67d75f045b6b4f1", size = 185117 },
    { url = "https://files.pythonhosted.org/packages/c1/31/1ae946f11dfbd229222e6d6ad8e7bd1891d3d48bde5fbf7a0beb9491f8e3/contourpy-1.3.1-cp313-cp313t-win_amd64.whl", hash = "sha256:287ccc248c9e0d0566934e7d606201abd74761b5703d804ff3df8935f523d546", size = 236668 },
    { url = "https://files.pythonhosted.org/packages/3e/4f/e56862e64b52b55b5ddcff4090085521fc228ceb09a88390a2b103dccd1b/contourpy-1.3.1-pp310-pypy310_pp73-macosx_10_15_x86_64.whl", hash = "sha256:b457d6430833cee8e4b8e9b6f07aa1c161e5e0d52e118dc102c8f9bd7dd060d6", size = 265605 },
    { url = "https://files.pythonhosted.org/packages/b0/2e/52bfeeaa4541889f23d8eadc6386b442ee2470bd3cff9baa67deb2dd5c57/contourpy-1.3.1-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:cb76c1a154b83991a3cbbf0dfeb26ec2833ad56f95540b442c73950af2013750", size = 315040 },
    { url = "https://files.pythonhosted.org/packages/52/94/86bfae441707205634d80392e873295652fc313dfd93c233c52c4dc07874/contourpy-1.3.1-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:44a29502ca9c7b5ba389e620d44f2fbe792b1fb5734e8b931ad307071ec58c53", size = 218221 },
]

[[package]]
name = "coverage"
version = "7.6.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f7/08/7e37f82e4d1aead42a7443ff06a1e406aabf7302c4f00a546e4b320b994c/coverage-7.6.1.tar.gz", hash = "sha256:953510dfb7b12ab69d20135a0662397f077c59b1e6379a768e97c59d852ee51d", size = 798791 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7e/61/eb7ce5ed62bacf21beca4937a90fe32545c91a3c8a42a30c6616d48fc70d/coverage-7.6.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:b06079abebbc0e89e6163b8e8f0e16270124c154dc6e4a47b413dd538859af16", size = 206690 },
    { url = "https://files.pythonhosted.org/packages/7d/73/041928e434442bd3afde5584bdc3f932fb4562b1597629f537387cec6f3d/coverage-7.6.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:cf4b19715bccd7ee27b6b120e7e9dd56037b9c0681dcc1adc9ba9db3d417fa36", size = 207127 },
    { url = "https://files.pythonhosted.org/packages/c7/c8/6ca52b5147828e45ad0242388477fdb90df2c6cbb9a441701a12b3c71bc8/coverage-7.6.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e61c0abb4c85b095a784ef23fdd4aede7a2628478e7baba7c5e3deba61070a02", size = 235654 },
    { url = "https://files.pythonhosted.org/packages/d5/da/9ac2b62557f4340270942011d6efeab9833648380109e897d48ab7c1035d/coverage-7.6.1-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:fd21f6ae3f08b41004dfb433fa895d858f3f5979e7762d052b12aef444e29afc", size = 233598 },
    { url = "https://files.pythonhosted.org/packages/53/23/9e2c114d0178abc42b6d8d5281f651a8e6519abfa0ef460a00a91f80879d/coverage-7.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8f59d57baca39b32db42b83b2a7ba6f47ad9c394ec2076b084c3f029b7afca23", size = 234732 },
    { url = "https://files.pythonhosted.org/packages/0f/7e/a0230756fb133343a52716e8b855045f13342b70e48e8ad41d8a0d60ab98/coverage-7.6.1-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:a1ac0ae2b8bd743b88ed0502544847c3053d7171a3cff9228af618a068ed9c34", size = 233816 },
    { url = "https://files.pythonhosted.org/packages/28/7c/3753c8b40d232b1e5eeaed798c875537cf3cb183fb5041017c1fdb7ec14e/coverage-7.6.1-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:e6a08c0be454c3b3beb105c0596ebdc2371fab6bb90c0c0297f4e58fd7e1012c", size = 232325 },
    { url = "https://files.pythonhosted.org/packages/57/e3/818a2b2af5b7573b4b82cf3e9f137ab158c90ea750a8f053716a32f20f06/coverage-7.6.1-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:f5796e664fe802da4f57a168c85359a8fbf3eab5e55cd4e4569fbacecc903959", size = 233418 },
    { url = "https://files.pythonhosted.org/packages/c8/fb/4532b0b0cefb3f06d201648715e03b0feb822907edab3935112b61b885e2/coverage-7.6.1-cp310-cp310-win32.whl", hash = "sha256:7bb65125fcbef8d989fa1dd0e8a060999497629ca5b0efbca209588a73356232", size = 209343 },
    { url = "https://files.pythonhosted.org/packages/5a/25/af337cc7421eca1c187cc9c315f0a755d48e755d2853715bfe8c418a45fa/coverage-7.6.1-cp310-cp310-win_amd64.whl", hash = "sha256:3115a95daa9bdba70aea750db7b96b37259a81a709223c8448fa97727d546fe0", size = 210136 },
    { url = "https://files.pythonhosted.org/packages/ad/5f/67af7d60d7e8ce61a4e2ddcd1bd5fb787180c8d0ae0fbd073f903b3dd95d/coverage-7.6.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:7dea0889685db8550f839fa202744652e87c60015029ce3f60e006f8c4462c93", size = 206796 },
    { url = "https://files.pythonhosted.org/packages/e1/0e/e52332389e057daa2e03be1fbfef25bb4d626b37d12ed42ae6281d0a274c/coverage-7.6.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:ed37bd3c3b063412f7620464a9ac1314d33100329f39799255fb8d3027da50d3", size = 207244 },
    { url = "https://files.pythonhosted.org/packages/aa/cd/766b45fb6e090f20f8927d9c7cb34237d41c73a939358bc881883fd3a40d/coverage-7.6.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d85f5e9a5f8b73e2350097c3756ef7e785f55bd71205defa0bfdaf96c31616ff", size = 239279 },
    { url = "https://files.pythonhosted.org/packages/70/6c/a9ccd6fe50ddaf13442a1e2dd519ca805cbe0f1fcd377fba6d8339b98ccb/coverage-7.6.1-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:9bc572be474cafb617672c43fe989d6e48d3c83af02ce8de73fff1c6bb3c198d", size = 236859 },
    { url = "https://files.pythonhosted.org/packages/14/6f/8351b465febb4dbc1ca9929505202db909c5a635c6fdf33e089bbc3d7d85/coverage-7.6.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0c0420b573964c760df9e9e86d1a9a622d0d27f417e1a949a8a66dd7bcee7bc6", size = 238549 },
    { url = "https://files.pythonhosted.org/packages/68/3c/289b81fa18ad72138e6d78c4c11a82b5378a312c0e467e2f6b495c260907/coverage-7.6.1-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:1f4aa8219db826ce6be7099d559f8ec311549bfc4046f7f9fe9b5cea5c581c56", size = 237477 },
    { url = "https://files.pythonhosted.org/packages/ed/1c/aa1efa6459d822bd72c4abc0b9418cf268de3f60eeccd65dc4988553bd8d/coverage-7.6.1-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:fc5a77d0c516700ebad189b587de289a20a78324bc54baee03dd486f0855d234", size = 236134 },
    { url = "https://files.pythonhosted.org/packages/fb/c8/521c698f2d2796565fe9c789c2ee1ccdae610b3aa20b9b2ef980cc253640/coverage-7.6.1-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:b48f312cca9621272ae49008c7f613337c53fadca647d6384cc129d2996d1133", size = 236910 },
    { url = "https://files.pythonhosted.org/packages/7d/30/033e663399ff17dca90d793ee8a2ea2890e7fdf085da58d82468b4220bf7/coverage-7.6.1-cp311-cp311-win32.whl", hash = "sha256:1125ca0e5fd475cbbba3bb67ae20bd2c23a98fac4e32412883f9bcbaa81c314c", size = 209348 },
    { url = "https://files.pythonhosted.org/packages/20/05/0d1ccbb52727ccdadaa3ff37e4d2dc1cd4d47f0c3df9eb58d9ec8508ca88/coverage-7.6.1-cp311-cp311-win_amd64.whl", hash = "sha256:8ae539519c4c040c5ffd0632784e21b2f03fc1340752af711f33e5be83a9d6c6", size = 210230 },
    { url = "https://files.pythonhosted.org/packages/7e/d4/300fc921dff243cd518c7db3a4c614b7e4b2431b0d1145c1e274fd99bd70/coverage-7.6.1-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:95cae0efeb032af8458fc27d191f85d1717b1d4e49f7cb226cf526ff28179778", size = 206983 },
    { url = "https://files.pythonhosted.org/packages/e1/ab/6bf00de5327ecb8db205f9ae596885417a31535eeda6e7b99463108782e1/coverage-7.6.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:5621a9175cf9d0b0c84c2ef2b12e9f5f5071357c4d2ea6ca1cf01814f45d2391", size = 207221 },
    { url = "https://files.pythonhosted.org/packages/92/8f/2ead05e735022d1a7f3a0a683ac7f737de14850395a826192f0288703472/coverage-7.6.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:260933720fdcd75340e7dbe9060655aff3af1f0c5d20f46b57f262ab6c86a5e8", size = 240342 },
    { url = "https://files.pythonhosted.org/packages/0f/ef/94043e478201ffa85b8ae2d2c79b4081e5a1b73438aafafccf3e9bafb6b5/coverage-7.6.1-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:07e2ca0ad381b91350c0ed49d52699b625aab2b44b65e1b4e02fa9df0e92ad2d", size = 237371 },
    { url = "https://files.pythonhosted.org/packages/1f/0f/c890339dd605f3ebc269543247bdd43b703cce6825b5ed42ff5f2d6122c7/coverage-7.6.1-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:c44fee9975f04b33331cb8eb272827111efc8930cfd582e0320613263ca849ca", size = 239455 },
    { url = "https://files.pythonhosted.org/packages/d1/04/7fd7b39ec7372a04efb0f70c70e35857a99b6a9188b5205efb4c77d6a57a/coverage-7.6.1-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:877abb17e6339d96bf08e7a622d05095e72b71f8afd8a9fefc82cf30ed944163", size = 238924 },
    { url = "https://files.pythonhosted.org/packages/ed/bf/73ce346a9d32a09cf369f14d2a06651329c984e106f5992c89579d25b27e/coverage-7.6.1-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:3e0cadcf6733c09154b461f1ca72d5416635e5e4ec4e536192180d34ec160f8a", size = 237252 },
    { url = "https://files.pythonhosted.org/packages/86/74/1dc7a20969725e917b1e07fe71a955eb34bc606b938316bcc799f228374b/coverage-7.6.1-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:c3c02d12f837d9683e5ab2f3d9844dc57655b92c74e286c262e0fc54213c216d", size = 238897 },
    { url = "https://files.pythonhosted.org/packages/b6/e9/d9cc3deceb361c491b81005c668578b0dfa51eed02cd081620e9a62f24ec/coverage-7.6.1-cp312-cp312-win32.whl", hash = "sha256:e05882b70b87a18d937ca6768ff33cc3f72847cbc4de4491c8e73880766718e5", size = 209606 },
    { url = "https://files.pythonhosted.org/packages/47/c8/5a2e41922ea6740f77d555c4d47544acd7dc3f251fe14199c09c0f5958d3/coverage-7.6.1-cp312-cp312-win_amd64.whl", hash = "sha256:b5d7b556859dd85f3a541db6a4e0167b86e7273e1cdc973e5b175166bb634fdb", size = 210373 },
    { url = "https://files.pythonhosted.org/packages/8c/f9/9aa4dfb751cb01c949c990d136a0f92027fbcc5781c6e921df1cb1563f20/coverage-7.6.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:a4acd025ecc06185ba2b801f2de85546e0b8ac787cf9d3b06e7e2a69f925b106", size = 207007 },
    { url = "https://files.pythonhosted.org/packages/b9/67/e1413d5a8591622a46dd04ff80873b04c849268831ed5c304c16433e7e30/coverage-7.6.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:a6d3adcf24b624a7b778533480e32434a39ad8fa30c315208f6d3e5542aeb6e9", size = 207269 },
    { url = "https://files.pythonhosted.org/packages/14/5b/9dec847b305e44a5634d0fb8498d135ab1d88330482b74065fcec0622224/coverage-7.6.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d0c212c49b6c10e6951362f7c6df3329f04c2b1c28499563d4035d964ab8e08c", size = 239886 },
    { url = "https://files.pythonhosted.org/packages/7b/b7/35760a67c168e29f454928f51f970342d23cf75a2bb0323e0f07334c85f3/coverage-7.6.1-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:6e81d7a3e58882450ec4186ca59a3f20a5d4440f25b1cff6f0902ad890e6748a", size = 237037 },
    { url = "https://files.pythonhosted.org/packages/f7/95/d2fd31f1d638df806cae59d7daea5abf2b15b5234016a5ebb502c2f3f7ee/coverage-7.6.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:78b260de9790fd81e69401c2dc8b17da47c8038176a79092a89cb2b7d945d060", size = 239038 },
    { url = "https://files.pythonhosted.org/packages/6e/bd/110689ff5752b67924efd5e2aedf5190cbbe245fc81b8dec1abaffba619d/coverage-7.6.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:a78d169acd38300060b28d600344a803628c3fd585c912cacc9ea8790fe96862", size = 238690 },
    { url = "https://files.pythonhosted.org/packages/d3/a8/08d7b38e6ff8df52331c83130d0ab92d9c9a8b5462f9e99c9f051a4ae206/coverage-7.6.1-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:2c09f4ce52cb99dd7505cd0fc8e0e37c77b87f46bc9c1eb03fe3bc9991085388", size = 236765 },
    { url = "https://files.pythonhosted.org/packages/d6/6a/9cf96839d3147d55ae713eb2d877f4d777e7dc5ba2bce227167d0118dfe8/coverage-7.6.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:6878ef48d4227aace338d88c48738a4258213cd7b74fd9a3d4d7582bb1d8a155", size = 238611 },
    { url = "https://files.pythonhosted.org/packages/74/e4/7ff20d6a0b59eeaab40b3140a71e38cf52547ba21dbcf1d79c5a32bba61b/coverage-7.6.1-cp313-cp313-win32.whl", hash = "sha256:44df346d5215a8c0e360307d46ffaabe0f5d3502c8a1cefd700b34baf31d411a", size = 209671 },
    { url = "https://files.pythonhosted.org/packages/35/59/1812f08a85b57c9fdb6d0b383d779e47b6f643bc278ed682859512517e83/coverage-7.6.1-cp313-cp313-win_amd64.whl", hash = "sha256:8284cf8c0dd272a247bc154eb6c95548722dce90d098c17a883ed36e67cdb129", size = 210368 },
    { url = "https://files.pythonhosted.org/packages/9c/15/08913be1c59d7562a3e39fce20661a98c0a3f59d5754312899acc6cb8a2d/coverage-7.6.1-cp313-cp313t-macosx_10_13_x86_64.whl", hash = "sha256:d3296782ca4eab572a1a4eca686d8bfb00226300dcefdf43faa25b5242ab8a3e", size = 207758 },
    { url = "https://files.pythonhosted.org/packages/c4/ae/b5d58dff26cade02ada6ca612a76447acd69dccdbb3a478e9e088eb3d4b9/coverage-7.6.1-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:502753043567491d3ff6d08629270127e0c31d4184c4c8d98f92c26f65019962", size = 208035 },
    { url = "https://files.pythonhosted.org/packages/b8/d7/62095e355ec0613b08dfb19206ce3033a0eedb6f4a67af5ed267a8800642/coverage-7.6.1-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6a89ecca80709d4076b95f89f308544ec8f7b4727e8a547913a35f16717856cb", size = 250839 },
    { url = "https://files.pythonhosted.org/packages/7c/1e/c2967cb7991b112ba3766df0d9c21de46b476d103e32bb401b1b2adf3380/coverage-7.6.1-cp313-cp313t-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:a318d68e92e80af8b00fa99609796fdbcdfef3629c77c6283566c6f02c6d6704", size = 246569 },
    { url = "https://files.pythonhosted.org/packages/8b/61/a7a6a55dd266007ed3b1df7a3386a0d760d014542d72f7c2c6938483b7bd/coverage-7.6.1-cp313-cp313t-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:13b0a73a0896988f053e4fbb7de6d93388e6dd292b0d87ee51d106f2c11b465b", size = 248927 },
    { url = "https://files.pythonhosted.org/packages/c8/fa/13a6f56d72b429f56ef612eb3bc5ce1b75b7ee12864b3bd12526ab794847/coverage-7.6.1-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:4421712dbfc5562150f7554f13dde997a2e932a6b5f352edcce948a815efee6f", size = 248401 },
    { url = "https://files.pythonhosted.org/packages/75/06/0429c652aa0fb761fc60e8c6b291338c9173c6aa0f4e40e1902345b42830/coverage-7.6.1-cp313-cp313t-musllinux_1_2_i686.whl", hash = "sha256:166811d20dfea725e2e4baa71fffd6c968a958577848d2131f39b60043400223", size = 246301 },
    { url = "https://files.pythonhosted.org/packages/52/76/1766bb8b803a88f93c3a2d07e30ffa359467810e5cbc68e375ebe6906efb/coverage-7.6.1-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:225667980479a17db1048cb2bf8bfb39b8e5be8f164b8f6628b64f78a72cf9d3", size = 247598 },
    { url = "https://files.pythonhosted.org/packages/66/8b/f54f8db2ae17188be9566e8166ac6df105c1c611e25da755738025708d54/coverage-7.6.1-cp313-cp313t-win32.whl", hash = "sha256:170d444ab405852903b7d04ea9ae9b98f98ab6d7e63e1115e82620807519797f", size = 210307 },
    { url = "https://files.pythonhosted.org/packages/9f/b0/e0dca6da9170aefc07515cce067b97178cefafb512d00a87a1c717d2efd5/coverage-7.6.1-cp313-cp313t-win_amd64.whl", hash = "sha256:b9f222de8cded79c49bf184bdbc06630d4c58eec9459b939b4a690c82ed05657", size = 211453 },
    { url = "https://files.pythonhosted.org/packages/81/d0/d9e3d554e38beea5a2e22178ddb16587dbcbe9a1ef3211f55733924bf7fa/coverage-7.6.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:6db04803b6c7291985a761004e9060b2bca08da6d04f26a7f2294b8623a0c1a0", size = 206674 },
    { url = "https://files.pythonhosted.org/packages/38/ea/cab2dc248d9f45b2b7f9f1f596a4d75a435cb364437c61b51d2eb33ceb0e/coverage-7.6.1-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:f1adfc8ac319e1a348af294106bc6a8458a0f1633cc62a1446aebc30c5fa186a", size = 207101 },
    { url = "https://files.pythonhosted.org/packages/ca/6f/f82f9a500c7c5722368978a5390c418d2a4d083ef955309a8748ecaa8920/coverage-7.6.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a95324a9de9650a729239daea117df21f4b9868ce32e63f8b650ebe6cef5595b", size = 236554 },
    { url = "https://files.pythonhosted.org/packages/a6/94/d3055aa33d4e7e733d8fa309d9adf147b4b06a82c1346366fc15a2b1d5fa/coverage-7.6.1-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:b43c03669dc4618ec25270b06ecd3ee4fa94c7f9b3c14bae6571ca00ef98b0d3", size = 234440 },
    { url = "https://files.pythonhosted.org/packages/e4/6e/885bcd787d9dd674de4a7d8ec83faf729534c63d05d51d45d4fa168f7102/coverage-7.6.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8929543a7192c13d177b770008bc4e8119f2e1f881d563fc6b6305d2d0ebe9de", size = 235889 },
    { url = "https://files.pythonhosted.org/packages/f4/63/df50120a7744492710854860783d6819ff23e482dee15462c9a833cc428a/coverage-7.6.1-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:a09ece4a69cf399510c8ab25e0950d9cf2b42f7b3cb0374f95d2e2ff594478a6", size = 235142 },
    { url = "https://files.pythonhosted.org/packages/3a/5d/9d0acfcded2b3e9ce1c7923ca52ccc00c78a74e112fc2aee661125b7843b/coverage-7.6.1-cp38-cp38-musllinux_1_2_i686.whl", hash = "sha256:9054a0754de38d9dbd01a46621636689124d666bad1936d76c0341f7d71bf569", size = 233805 },
    { url = "https://files.pythonhosted.org/packages/c4/56/50abf070cb3cd9b1dd32f2c88f083aab561ecbffbcd783275cb51c17f11d/coverage-7.6.1-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:0dbde0f4aa9a16fa4d754356a8f2e36296ff4d83994b2c9d8398aa32f222f989", size = 234655 },
    { url = "https://files.pythonhosted.org/packages/25/ee/b4c246048b8485f85a2426ef4abab88e48c6e80c74e964bea5cd4cd4b115/coverage-7.6.1-cp38-cp38-win32.whl", hash = "sha256:da511e6ad4f7323ee5702e6633085fb76c2f893aaf8ce4c51a0ba4fc07580ea7", size = 209296 },
    { url = "https://files.pythonhosted.org/packages/5c/1c/96cf86b70b69ea2b12924cdf7cabb8ad10e6130eab8d767a1099fbd2a44f/coverage-7.6.1-cp38-cp38-win_amd64.whl", hash = "sha256:3f1156e3e8f2872197af3840d8ad307a9dd18e615dc64d9ee41696f287c57ad8", size = 210137 },
    { url = "https://files.pythonhosted.org/packages/19/d3/d54c5aa83268779d54c86deb39c1c4566e5d45c155369ca152765f8db413/coverage-7.6.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:abd5fd0db5f4dc9289408aaf34908072f805ff7792632250dcb36dc591d24255", size = 206688 },
    { url = "https://files.pythonhosted.org/packages/a5/fe/137d5dca72e4a258b1bc17bb04f2e0196898fe495843402ce826a7419fe3/coverage-7.6.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:547f45fa1a93154bd82050a7f3cddbc1a7a4dd2a9bf5cb7d06f4ae29fe94eaf8", size = 207120 },
    { url = "https://files.pythonhosted.org/packages/78/5b/a0a796983f3201ff5485323b225d7c8b74ce30c11f456017e23d8e8d1945/coverage-7.6.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:645786266c8f18a931b65bfcefdbf6952dd0dea98feee39bd188607a9d307ed2", size = 235249 },
    { url = "https://files.pythonhosted.org/packages/4e/e1/76089d6a5ef9d68f018f65411fcdaaeb0141b504587b901d74e8587606ad/coverage-7.6.1-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:9e0b2df163b8ed01d515807af24f63de04bebcecbd6c3bfeff88385789fdf75a", size = 233237 },
    { url = "https://files.pythonhosted.org/packages/9a/6f/eef79b779a540326fee9520e5542a8b428cc3bfa8b7c8f1022c1ee4fc66c/coverage-7.6.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:609b06f178fe8e9f89ef676532760ec0b4deea15e9969bf754b37f7c40326dbc", size = 234311 },
    { url = "https://files.pythonhosted.org/packages/75/e1/656d65fb126c29a494ef964005702b012f3498db1a30dd562958e85a4049/coverage-7.6.1-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:702855feff378050ae4f741045e19a32d57d19f3e0676d589df0575008ea5004", size = 233453 },
    { url = "https://files.pythonhosted.org/packages/68/6a/45f108f137941a4a1238c85f28fd9d048cc46b5466d6b8dda3aba1bb9d4f/coverage-7.6.1-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:2bdb062ea438f22d99cba0d7829c2ef0af1d768d1e4a4f528087224c90b132cb", size = 231958 },
    { url = "https://files.pythonhosted.org/packages/9b/e7/47b809099168b8b8c72ae311efc3e88c8d8a1162b3ba4b8da3cfcdb85743/coverage-7.6.1-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:9c56863d44bd1c4fe2abb8a4d6f5371d197f1ac0ebdee542f07f35895fc07f36", size = 232938 },
    { url = "https://files.pythonhosted.org/packages/52/80/052222ba7058071f905435bad0ba392cc12006380731c37afaf3fe749b88/coverage-7.6.1-cp39-cp39-win32.whl", hash = "sha256:6e2cd258d7d927d09493c8df1ce9174ad01b381d4729a9d8d4e38670ca24774c", size = 209352 },
    { url = "https://files.pythonhosted.org/packages/b8/d8/1b92e0b3adcf384e98770a00ca095da1b5f7b483e6563ae4eb5e935d24a1/coverage-7.6.1-cp39-cp39-win_amd64.whl", hash = "sha256:06a737c882bd26d0d6ee7269b20b12f14a8704807a01056c80bb881a4b2ce6ca", size = 210153 },
    { url = "https://files.pythonhosted.org/packages/a5/2b/0354ed096bca64dc8e32a7cbcae28b34cb5ad0b1fe2125d6d99583313ac0/coverage-7.6.1-pp38.pp39.pp310-none-any.whl", hash = "sha256:e9a6e0eb86070e8ccaedfbd9d38fec54864f3125ab95419970575b42af7541df", size = 198926 },
]

[package.optional-dependencies]
toml = [
    { name = "tomli", marker = "python_full_version <= '3.11'" },
]

[[package]]
name = "cryptography"
version = "44.0.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "cffi", marker = "platform_python_implementation != 'PyPy'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/cd/25/4ce80c78963834b8a9fd1cc1266be5ed8d1840785c0f2e1b73b8d128d505/cryptography-44.0.2.tar.gz", hash = "sha256:c63454aa261a0cf0c5b4718349629793e9e634993538db841165b3df74f37ec0", size = 710807 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/92/ef/83e632cfa801b221570c5f58c0369db6fa6cef7d9ff859feab1aae1a8a0f/cryptography-44.0.2-cp37-abi3-macosx_10_9_universal2.whl", hash = "sha256:efcfe97d1b3c79e486554efddeb8f6f53a4cdd4cf6086642784fa31fc384e1d7", size = 6676361 },
    { url = "https://files.pythonhosted.org/packages/30/ec/7ea7c1e4c8fc8329506b46c6c4a52e2f20318425d48e0fe597977c71dbce/cryptography-44.0.2-cp37-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:29ecec49f3ba3f3849362854b7253a9f59799e3763b0c9d0826259a88efa02f1", size = 3952350 },
    { url = "https://files.pythonhosted.org/packages/27/61/72e3afdb3c5ac510330feba4fc1faa0fe62e070592d6ad00c40bb69165e5/cryptography-44.0.2-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bc821e161ae88bfe8088d11bb39caf2916562e0a2dc7b6d56714a48b784ef0bb", size = 4166572 },
    { url = "https://files.pythonhosted.org/packages/26/e4/ba680f0b35ed4a07d87f9e98f3ebccb05091f3bf6b5a478b943253b3bbd5/cryptography-44.0.2-cp37-abi3-manylinux_2_28_aarch64.whl", hash = "sha256:3c00b6b757b32ce0f62c574b78b939afab9eecaf597c4d624caca4f9e71e7843", size = 3958124 },
    { url = "https://files.pythonhosted.org/packages/9c/e8/44ae3e68c8b6d1cbc59040288056df2ad7f7f03bbcaca6b503c737ab8e73/cryptography-44.0.2-cp37-abi3-manylinux_2_28_armv7l.manylinux_2_31_armv7l.whl", hash = "sha256:7bdcd82189759aba3816d1f729ce42ffded1ac304c151d0a8e89b9996ab863d5", size = 3678122 },
    { url = "https://files.pythonhosted.org/packages/27/7b/664ea5e0d1eab511a10e480baf1c5d3e681c7d91718f60e149cec09edf01/cryptography-44.0.2-cp37-abi3-manylinux_2_28_x86_64.whl", hash = "sha256:4973da6ca3db4405c54cd0b26d328be54c7747e89e284fcff166132eb7bccc9c", size = 4191831 },
    { url = "https://files.pythonhosted.org/packages/2a/07/79554a9c40eb11345e1861f46f845fa71c9e25bf66d132e123d9feb8e7f9/cryptography-44.0.2-cp37-abi3-manylinux_2_34_aarch64.whl", hash = "sha256:4e389622b6927d8133f314949a9812972711a111d577a5d1f4bee5e58736b80a", size = 3960583 },
    { url = "https://files.pythonhosted.org/packages/bb/6d/858e356a49a4f0b591bd6789d821427de18432212e137290b6d8a817e9bf/cryptography-44.0.2-cp37-abi3-manylinux_2_34_x86_64.whl", hash = "sha256:f514ef4cd14bb6fb484b4a60203e912cfcb64f2ab139e88c2274511514bf7308", size = 4191753 },
    { url = "https://files.pythonhosted.org/packages/b2/80/62df41ba4916067fa6b125aa8c14d7e9181773f0d5d0bd4dcef580d8b7c6/cryptography-44.0.2-cp37-abi3-musllinux_1_2_aarch64.whl", hash = "sha256:1bc312dfb7a6e5d66082c87c34c8a62176e684b6fe3d90fcfe1568de675e6688", size = 4079550 },
    { url = "https://files.pythonhosted.org/packages/f3/cd/2558cc08f7b1bb40683f99ff4327f8dcfc7de3affc669e9065e14824511b/cryptography-44.0.2-cp37-abi3-musllinux_1_2_x86_64.whl", hash = "sha256:3b721b8b4d948b218c88cb8c45a01793483821e709afe5f622861fc6182b20a7", size = 4298367 },
    { url = "https://files.pythonhosted.org/packages/71/59/94ccc74788945bc3bd4cf355d19867e8057ff5fdbcac781b1ff95b700fb1/cryptography-44.0.2-cp37-abi3-win32.whl", hash = "sha256:51e4de3af4ec3899d6d178a8c005226491c27c4ba84101bfb59c901e10ca9f79", size = 2772843 },
    { url = "https://files.pythonhosted.org/packages/ca/2c/0d0bbaf61ba05acb32f0841853cfa33ebb7a9ab3d9ed8bb004bd39f2da6a/cryptography-44.0.2-cp37-abi3-win_amd64.whl", hash = "sha256:c505d61b6176aaf982c5717ce04e87da5abc9a36a5b39ac03905c4aafe8de7aa", size = 3209057 },
    { url = "https://files.pythonhosted.org/packages/9e/be/7a26142e6d0f7683d8a382dd963745e65db895a79a280a30525ec92be890/cryptography-44.0.2-cp39-abi3-macosx_10_9_universal2.whl", hash = "sha256:8e0ddd63e6bf1161800592c71ac794d3fb8001f2caebe0966e77c5234fa9efc3", size = 6677789 },
    { url = "https://files.pythonhosted.org/packages/06/88/638865be7198a84a7713950b1db7343391c6066a20e614f8fa286eb178ed/cryptography-44.0.2-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:81276f0ea79a208d961c433a947029e1a15948966658cf6710bbabb60fcc2639", size = 3951919 },
    { url = "https://files.pythonhosted.org/packages/d7/fc/99fe639bcdf58561dfad1faa8a7369d1dc13f20acd78371bb97a01613585/cryptography-44.0.2-cp39-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9a1e657c0f4ea2a23304ee3f964db058c9e9e635cc7019c4aa21c330755ef6fd", size = 4167812 },
    { url = "https://files.pythonhosted.org/packages/53/7b/aafe60210ec93d5d7f552592a28192e51d3c6b6be449e7fd0a91399b5d07/cryptography-44.0.2-cp39-abi3-manylinux_2_28_aarch64.whl", hash = "sha256:6210c05941994290f3f7f175a4a57dbbb2afd9273657614c506d5976db061181", size = 3958571 },
    { url = "https://files.pythonhosted.org/packages/16/32/051f7ce79ad5a6ef5e26a92b37f172ee2d6e1cce09931646eef8de1e9827/cryptography-44.0.2-cp39-abi3-manylinux_2_28_armv7l.manylinux_2_31_armv7l.whl", hash = "sha256:d1c3572526997b36f245a96a2b1713bf79ce99b271bbcf084beb6b9b075f29ea", size = 3679832 },
    { url = "https://files.pythonhosted.org/packages/78/2b/999b2a1e1ba2206f2d3bca267d68f350beb2b048a41ea827e08ce7260098/cryptography-44.0.2-cp39-abi3-manylinux_2_28_x86_64.whl", hash = "sha256:b042d2a275c8cee83a4b7ae30c45a15e6a4baa65a179a0ec2d78ebb90e4f6699", size = 4193719 },
    { url = "https://files.pythonhosted.org/packages/72/97/430e56e39a1356e8e8f10f723211a0e256e11895ef1a135f30d7d40f2540/cryptography-44.0.2-cp39-abi3-manylinux_2_34_aarch64.whl", hash = "sha256:d03806036b4f89e3b13b6218fefea8d5312e450935b1a2d55f0524e2ed7c59d9", size = 3960852 },
    { url = "https://files.pythonhosted.org/packages/89/33/c1cf182c152e1d262cac56850939530c05ca6c8d149aa0dcee490b417e99/cryptography-44.0.2-cp39-abi3-manylinux_2_34_x86_64.whl", hash = "sha256:c7362add18b416b69d58c910caa217f980c5ef39b23a38a0880dfd87bdf8cd23", size = 4193906 },
    { url = "https://files.pythonhosted.org/packages/e1/99/87cf26d4f125380dc674233971069bc28d19b07f7755b29861570e513650/cryptography-44.0.2-cp39-abi3-musllinux_1_2_aarch64.whl", hash = "sha256:8cadc6e3b5a1f144a039ea08a0bdb03a2a92e19c46be3285123d32029f40a922", size = 4081572 },
    { url = "https://files.pythonhosted.org/packages/b3/9f/6a3e0391957cc0c5f84aef9fbdd763035f2b52e998a53f99345e3ac69312/cryptography-44.0.2-cp39-abi3-musllinux_1_2_x86_64.whl", hash = "sha256:6f101b1f780f7fc613d040ca4bdf835c6ef3b00e9bd7125a4255ec574c7916e4", size = 4298631 },
    { url = "https://files.pythonhosted.org/packages/e2/a5/5bc097adb4b6d22a24dea53c51f37e480aaec3465285c253098642696423/cryptography-44.0.2-cp39-abi3-win32.whl", hash = "sha256:3dc62975e31617badc19a906481deacdeb80b4bb454394b4098e3f2525a488c5", size = 2773792 },
    { url = "https://files.pythonhosted.org/packages/33/cf/1f7649b8b9a3543e042d3f348e398a061923ac05b507f3f4d95f11938aa9/cryptography-44.0.2-cp39-abi3-win_amd64.whl", hash = "sha256:5f6f90b72d8ccadb9c6e311c775c8305381db88374c65fa1a68250aa8a9cb3a6", size = 3210957 },
    { url = "https://files.pythonhosted.org/packages/99/10/173be140714d2ebaea8b641ff801cbcb3ef23101a2981cbf08057876f89e/cryptography-44.0.2-pp310-pypy310_pp73-macosx_10_9_x86_64.whl", hash = "sha256:af4ff3e388f2fa7bff9f7f2b31b87d5651c45731d3e8cfa0944be43dff5cfbdb", size = 3396886 },
    { url = "https://files.pythonhosted.org/packages/2f/b4/424ea2d0fce08c24ede307cead3409ecbfc2f566725d4701b9754c0a1174/cryptography-44.0.2-pp310-pypy310_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:0529b1d5a0105dd3731fa65680b45ce49da4d8115ea76e9da77a875396727b41", size = 3892387 },
    { url = "https://files.pythonhosted.org/packages/28/20/8eaa1a4f7c68a1cb15019dbaad59c812d4df4fac6fd5f7b0b9c5177f1edd/cryptography-44.0.2-pp310-pypy310_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:7ca25849404be2f8e4b3c59483d9d3c51298a22c1c61a0e84415104dacaf5562", size = 4109922 },
    { url = "https://files.pythonhosted.org/packages/11/25/5ed9a17d532c32b3bc81cc294d21a36c772d053981c22bd678396bc4ae30/cryptography-44.0.2-pp310-pypy310_pp73-manylinux_2_34_aarch64.whl", hash = "sha256:268e4e9b177c76d569e8a145a6939eca9a5fec658c932348598818acf31ae9a5", size = 3895715 },
    { url = "https://files.pythonhosted.org/packages/63/31/2aac03b19c6329b62c45ba4e091f9de0b8f687e1b0cd84f101401bece343/cryptography-44.0.2-pp310-pypy310_pp73-manylinux_2_34_x86_64.whl", hash = "sha256:9eb9d22b0a5d8fd9925a7764a054dca914000607dff201a24c791ff5c799e1fa", size = 4109876 },
    { url = "https://files.pythonhosted.org/packages/99/ec/6e560908349843718db1a782673f36852952d52a55ab14e46c42c8a7690a/cryptography-44.0.2-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:2bf7bf75f7df9715f810d1b038870309342bff3069c5bd8c6b96128cb158668d", size = 3131719 },
    { url = "https://files.pythonhosted.org/packages/d6/d7/f30e75a6aa7d0f65031886fa4a1485c2fbfe25a1896953920f6a9cfe2d3b/cryptography-44.0.2-pp311-pypy311_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:909c97ab43a9c0c0b0ada7a1281430e4e5ec0458e6d9244c0e821bbf152f061d", size = 3887513 },
    { url = "https://files.pythonhosted.org/packages/9c/b4/7a494ce1032323ca9db9a3661894c66e0d7142ad2079a4249303402d8c71/cryptography-44.0.2-pp311-pypy311_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:96e7a5e9d6e71f9f4fca8eebfd603f8e86c5225bb18eb621b2c1e50b290a9471", size = 4107432 },
    { url = "https://files.pythonhosted.org/packages/45/f8/6b3ec0bc56123b344a8d2b3264a325646d2dcdbdd9848b5e6f3d37db90b3/cryptography-44.0.2-pp311-pypy311_pp73-manylinux_2_34_aarch64.whl", hash = "sha256:d1b3031093a366ac767b3feb8bcddb596671b3aaff82d4050f984da0c248b615", size = 3891421 },
    { url = "https://files.pythonhosted.org/packages/57/ff/f3b4b2d007c2a646b0f69440ab06224f9cf37a977a72cdb7b50632174e8a/cryptography-44.0.2-pp311-pypy311_pp73-manylinux_2_34_x86_64.whl", hash = "sha256:04abd71114848aa25edb28e225ab5f268096f44cf0127f3d36975bdf1bdf3390", size = 4107081 },
]

[[package]]
name = "cssselect"
version = "1.2.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d1/91/d51202cc41fbfca7fa332f43a5adac4b253962588c7cc5a54824b019081c/cssselect-1.2.0.tar.gz", hash = "sha256:666b19839cfaddb9ce9d36bfe4c969132c647b92fc9088c4e23f786b30f1b3dc", size = 41423 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/06/a9/2da08717a6862c48f1d61ef957a7bba171e7eefa6c0aa0ceb96a140c2a6b/cssselect-1.2.0-py2.py3-none-any.whl", hash = "sha256:da1885f0c10b60c03ed5eccbb6b68d6eff248d91976fcde348f395d54c9fd35e", size = 18687 },
]

[[package]]
name = "cycler"
version = "0.12.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/a9/95/a3dbbb5028f35eafb79008e7522a75244477d2838f38cbb722248dabc2a8/cycler-0.12.1.tar.gz", hash = "sha256:88bb128f02ba341da8ef447245a9e138fae777f6a23943da4540077d3601eb1c", size = 7615 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e7/05/c19819d5e3d95294a6f5947fb9b9629efb316b96de511b418c53d245aae6/cycler-0.12.1-py3-none-any.whl", hash = "sha256:85cef7cff222d8644161529808465972e51340599459b8ac3ccbac5a854e0d30", size = 8321 },
]

[[package]]
name = "cymem"
version = "2.0.11"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f2/4a/1acd761fb6ac4c560e823ce40536a62f886f2d59b2763b5c3fc7e9d92101/cymem-2.0.11.tar.gz", hash = "sha256:efe49a349d4a518be6b6c6b255d4a80f740a341544bde1a807707c058b88d0bd", size = 10346 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/6d/55/f453f2b2f560e057f20eb2acdaafbf6488d72a6e8a36a4aef30f6053a51c/cymem-2.0.11-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:1b4dd8f8c2475c7c9948eefa89c790d83134600858d8d43b90276efd8df3882e", size = 41886 },
    { url = "https://files.pythonhosted.org/packages/a6/9d/03299eff35bd4fd80db33e4fd516661b82bb7b898cb677829acf22391ede/cymem-2.0.11-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:d46ba0d2e0f749195297d16f2286b55af7d7c084db2b853fdfccece2c000c5dc", size = 41696 },
    { url = "https://files.pythonhosted.org/packages/d3/0c/90aa41f258a67ea210886c5c73f88dc9f120b7a20e6b5d92c5ce73a68276/cymem-2.0.11-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:739c4336b9d04ce9761851e9260ef77508d4a86ee3060e41302bfb6fa82c37de", size = 203719 },
    { url = "https://files.pythonhosted.org/packages/52/d1/dc4a72aa2049c34a53a220290b1a59fadae61929dff3a6e1a830a22971fe/cymem-2.0.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a69c470c2fb118161f49761f9137384f46723c77078b659bba33858e19e46b49", size = 204763 },
    { url = "https://files.pythonhosted.org/packages/69/51/86ed323585530558bcdda1324c570abe032db2c1d5afd1c5e8e3e8fde63a/cymem-2.0.11-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:40159f6c92627438de970fd761916e745d70dfd84a7dcc28c1627eb49cee00d8", size = 193964 },
    { url = "https://files.pythonhosted.org/packages/ed/0c/aee4ad2996a4e24342228ccf44d7835c7784042f0ee0c47ad33be1443f18/cymem-2.0.11-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:f503f98e6aa333fffbe657a6854f13a9c3de68860795ae21171284213b9c5c09", size = 195002 },
    { url = "https://files.pythonhosted.org/packages/eb/d5/eda823d639258d2ed1db83403c991a9a57d5a4ddea3bf08e59060809a9aa/cymem-2.0.11-cp310-cp310-win_amd64.whl", hash = "sha256:7f05ed5920cc92d6b958ec5da55bd820d326fe9332b90660e6fa67e3b476ceb1", size = 39079 },
    { url = "https://files.pythonhosted.org/packages/03/e3/d98e3976f4ffa99cddebc1ce379d4d62e3eb1da22285267f902c99cc3395/cymem-2.0.11-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:3ee54039aad3ef65de82d66c40516bf54586287b46d32c91ea0530c34e8a2745", size = 42005 },
    { url = "https://files.pythonhosted.org/packages/41/b4/7546faf2ab63e59befc95972316d62276cec153f7d4d60e7b0d5e08f0602/cymem-2.0.11-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:4c05ef75b5db217be820604e43a47ccbbafea98ab6659d07cea92fa3c864ea58", size = 41747 },
    { url = "https://files.pythonhosted.org/packages/7d/4e/042f372e5b3eb7f5f3dd7677161771d301de2b6fa3f7c74e1cebcd502552/cymem-2.0.11-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a8d5381e5793ce531bac0dbc00829c8381f18605bb67e4b61d34f8850463da40", size = 217647 },
    { url = "https://files.pythonhosted.org/packages/48/cb/2207679e4b92701f78cf141e1ab4f81f55247dbe154eb426b842a0a993de/cymem-2.0.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f2b9d3f42d7249ac81802135cad51d707def058001a32f73fc7fbf3de7045ac7", size = 218857 },
    { url = "https://files.pythonhosted.org/packages/31/7a/76ae3b7a39ab2531029d281e43fcfcaad728c2341b150a81a3a1f5587cf3/cymem-2.0.11-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:39b78f2195d20b75c2d465732f6b8e8721c5d4eb012777c2cb89bdb45a043185", size = 206148 },
    { url = "https://files.pythonhosted.org/packages/25/f9/d0fc0191ac79f15638ddb59237aa76f234691374d7d7950e10f384bd8a25/cymem-2.0.11-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:2203bd6525a80d8fd0c94654a263af21c0387ae1d5062cceaebb652bf9bad7bc", size = 207112 },
    { url = "https://files.pythonhosted.org/packages/56/c8/75f75889401b20f4c3a7c5965dda09df42913e904ddc2ffe7ef3bdf25061/cymem-2.0.11-cp311-cp311-win_amd64.whl", hash = "sha256:aa54af7314de400634448da1f935b61323da80a49484074688d344fb2036681b", size = 39360 },
    { url = "https://files.pythonhosted.org/packages/71/67/0d74f7e9d79f934368a78fb1d1466b94bebdbff14f8ae94dd3e4ea8738bb/cymem-2.0.11-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:a0fbe19ce653cd688842d81e5819dc63f911a26e192ef30b0b89f0ab2b192ff2", size = 42621 },
    { url = "https://files.pythonhosted.org/packages/4a/d6/f7a19c63b48efc3f00a3ee8d69070ac90202e1e378f6cf81b8671f0cf762/cymem-2.0.11-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:de72101dc0e6326f6a2f73e05a438d1f3c6110d41044236d0fbe62925091267d", size = 42249 },
    { url = "https://files.pythonhosted.org/packages/d7/60/cdc434239813eef547fb99b6d0bafe31178501702df9b77c4108c9a216f6/cymem-2.0.11-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bee4395917f6588b8ac1699499128842768b391fe8896e8626950b4da5f9a406", size = 224758 },
    { url = "https://files.pythonhosted.org/packages/1d/68/8fa6efae17cd3b2ba9a2f83b824867c5b65b06f7aec3f8a0d0cabdeffb9b/cymem-2.0.11-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:5b02f2b17d760dc3fe5812737b1ce4f684641cdd751d67761d333a3b5ea97b83", size = 227995 },
    { url = "https://files.pythonhosted.org/packages/e4/f3/ceda70bf6447880140602285b7c6fa171cb7c78b623d35345cc32505cd06/cymem-2.0.11-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:04ee6b4041ddec24512d6e969ed6445e57917f01e73b9dabbe17b7e6b27fef05", size = 215325 },
    { url = "https://files.pythonhosted.org/packages/d3/47/6915eaa521e1ce7a0ba480eecb6870cb4f681bcd64ced88c2f0ed7a744b4/cymem-2.0.11-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:e1048dae7e627ee25f22c87bb670b13e06bc0aecc114b89b959a798d487d1bf4", size = 216447 },
    { url = "https://files.pythonhosted.org/packages/7b/be/8e02bdd31e557f642741a06c8e886782ef78f0b00daffd681922dc9bbc88/cymem-2.0.11-cp312-cp312-win_amd64.whl", hash = "sha256:0c269c7a867d74adeb9db65fa1d226342aacf44d64b7931282f0b0eb22eb6275", size = 39283 },
    { url = "https://files.pythonhosted.org/packages/bd/90/b064e2677e27a35cf3605146abc3285d4f599cc1b6c18fc445ae876dd1e3/cymem-2.0.11-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:f4a311c82f743275c84f708df89ac5bf60ddefe4713d532000c887931e22941f", size = 42389 },
    { url = "https://files.pythonhosted.org/packages/fd/60/7aa0561a6c1f0d42643b02c4fdeb2a16181b0ff4e85d73d2d80c6689e92a/cymem-2.0.11-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:02ed92bead896cca36abad00502b14fa651bdf5d8319461126a2d5ac8c9674c5", size = 41948 },
    { url = "https://files.pythonhosted.org/packages/5f/4e/88a29cc5575374982e527b4ebcab3781bdc826ce693c6418a0f836544246/cymem-2.0.11-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:44ddd3588379f8f376116384af99e3fb5f90091d90f520c341942618bf22f05e", size = 219382 },
    { url = "https://files.pythonhosted.org/packages/9b/3a/8f96e167e93b7f7ec105ed7b25c77bbf215d15bcbf4a24082cdc12234cd6/cymem-2.0.11-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:87ec985623624bbd298762d8163fc194a096cb13282731a017e09ff8a60bb8b1", size = 222974 },
    { url = "https://files.pythonhosted.org/packages/6a/fc/ce016bb0c66a4776345fac7508fddec3b739b9dd4363094ac89cce048832/cymem-2.0.11-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:e3385a47285435848e0ed66cfd29b35f3ed8703218e2b17bd7a0c053822f26bf", size = 213426 },
    { url = "https://files.pythonhosted.org/packages/5c/c8/accf7cc768f751447a5050b14a195af46798bc22767ac25f49b02861b1eb/cymem-2.0.11-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:5461e65340d6572eb64deadce79242a446a1d39cb7bf70fe7b7e007eb0d799b0", size = 219195 },
    { url = "https://files.pythonhosted.org/packages/74/65/c162fbac63e867a055240b6600b92ef96c0eb7a1895312ac53c4be93d056/cymem-2.0.11-cp313-cp313-win_amd64.whl", hash = "sha256:25da111adf425c29af0cfd9fecfec1c71c8d82e2244a85166830a0817a66ada7", size = 39090 },
    { url = "https://files.pythonhosted.org/packages/f1/13/b51db4b79e4e50bdb2f230d69ba26af0f6da3c522c4a2b334cdf538ba939/cymem-2.0.11-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:1450498623d9f176d48578779c4e9d133c7f252f73c5a93b762f35d059a09398", size = 42479 },
    { url = "https://files.pythonhosted.org/packages/12/35/d176ca37dfc746cf5125d3fe682fd0949b23dde78b23e13e010b1bcffdf1/cymem-2.0.11-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:0a407fd8766e1f666c48cb232f760267cecf0acb04cc717d8ec4de6adc6ab8e0", size = 42230 },
    { url = "https://files.pythonhosted.org/packages/59/f4/906e3c7c48d2a5c15b008e9fac33732435860634642bbefb18815868faf8/cymem-2.0.11-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6347aed08442679a57bcce5ad1e338f6b717e46654549c5d65c798552d910591", size = 206680 },
    { url = "https://files.pythonhosted.org/packages/20/91/ca365ed2c4da383a1b4fd698960b9ab72f6fd1b61f7bfcebda4150224327/cymem-2.0.11-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9d8f11149b1a154de0e93f5eda0a13ad9948a739b58a2aace996ca41bbb6d0f5", size = 208224 },
    { url = "https://files.pythonhosted.org/packages/a9/a0/4d664bec2eadf5d27a121d54a62bf4ef5805a5eedf1005afc2788edfcc72/cymem-2.0.11-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:7a2b4d1a9b1674d6ac0e4c5136b70b805535dc8d1060aa7c4ded3e52fb74e615", size = 198436 },
    { url = "https://files.pythonhosted.org/packages/87/7f/e48a20534b121fb84c526743f8cae878a4f0c097b48af6b7c027f1dda944/cymem-2.0.11-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:dec13c1a84612815365939f59e128a0031cae5f6b5a86e4b8fd7c4efa3fad262", size = 199766 },
    { url = "https://files.pythonhosted.org/packages/11/f6/16044e000072ae452e006930ca8eb7d21bad1b45d1a5978f82944482a9c8/cymem-2.0.11-cp39-cp39-win_amd64.whl", hash = "sha256:332ea5bc1c13c9a186532a06846881288eb846425898b70f047a0820714097bf", size = 39590 },
]

[[package]]
name = "distro"
version = "1.9.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/fc/f8/98eea607f65de6527f8a2e8885fc8015d3e6f5775df186e443e0964a11c3/distro-1.9.0.tar.gz", hash = "sha256:2fa77c6fd8940f116ee1d6b94a2f90b13b5ea8d019b98bc8bafdcabcdd9bdbed", size = 60722 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/12/b3/231ffd4ab1fc9d679809f356cebee130ac7daa00d6d6f3206dd4fd137e9e/distro-1.9.0-py3-none-any.whl", hash = "sha256:7bffd925d65168f85027d8da9af6bddab658135b840670a223589bc0c8ef02b2", size = 20277 },
]

[[package]]
name = "docx2python"
version = "3.4.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "lxml" },
    { name = "paragraphs" },
    { name = "types-lxml" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a6/cd/21aa86166b135c5d63949db5c5bec65c9acbfa8776a5fddbde795d96ff05/docx2python-3.4.1.tar.gz", hash = "sha256:373b3de82c57fcf21bff3a01f6f137923fbe9dd53e6abe0fdf2bf942879e0816", size = 10084206 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/bb/b3/aa39ec8267c5c02ea20f9378024a762797cf73e9807208475b289e5b360d/docx2python-3.4.1-py3-none-any.whl", hash = "sha256:f39ae9539298ba90ea9938f9b6e2f5887783dac2ba19eec8a41c8a7c4c39a4e9", size = 50304 },
]

[[package]]
name = "docx2txt"
version = "0.8"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/7d/7d/60ee3f2b16d9bfdfa72e8599470a2c1a5b759cb113c6fe1006be28359327/docx2txt-0.8.tar.gz", hash = "sha256:2c06d98d7cfe2d3947e5760a57d924e3ff07745b379c8737723922e7009236e5", size = 2814 }

[[package]]
name = "et-xmlfile"
version = "2.0.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d3/38/af70d7ab1ae9d4da450eeec1fa3918940a5fafb9055e934af8d6eb0c2313/et_xmlfile-2.0.0.tar.gz", hash = "sha256:dab3f4764309081ce75662649be815c4c9081e88f0837825f90fd28317d4da54", size = 17234 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c1/8b/5fe2cc11fee489817272089c4203e679c63b570a5aaeb18d852ae3cbba6a/et_xmlfile-2.0.0-py3-none-any.whl", hash = "sha256:7a91720bc756843502c3b7504c77b8fe44217c85c537d85037f0f536151b2caa", size = 18059 },
]

[[package]]
name = "exceptiongroup"
version = "1.2.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/09/35/2495c4ac46b980e4ca1f6ad6db102322ef3ad2410b79fdde159a4b0f3b92/exceptiongroup-1.2.2.tar.gz", hash = "sha256:47c2edf7c6738fafb49fd34290706d1a1a2f4d1c6df275526b62cbb4aa5393cc", size = 28883 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/02/cc/b7e31358aac6ed1ef2bb790a9746ac2c69bcb3c8588b41616914eb106eaf/exceptiongroup-1.2.2-py3-none-any.whl", hash = "sha256:3111b9d131c238bec2f8f516e123e14ba243563fb135d3fe885990585aa7795b", size = 16453 },
]

[[package]]
name = "execnet"
version = "2.1.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/bb/ff/b4c0dc78fbe20c3e59c0c7334de0c27eb4001a2b2017999af398bf730817/execnet-2.1.1.tar.gz", hash = "sha256:5189b52c6121c24feae288166ab41b32549c7e2348652736540b9e6e7d4e72e3", size = 166524 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/43/09/2aea36ff60d16dd8879bdb2f5b3ee0ba8d08cbbdcdfe870e695ce3784385/execnet-2.1.1-py3-none-any.whl", hash = "sha256:26dee51f1b80cebd6d0ca8e74dd8745419761d3bef34163928cbebbdc4749fdc", size = 40612 },
]

[[package]]
name = "fonttools"
version = "4.56.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/1c/8c/9ffa2a555af0e5e5d0e2ed7fdd8c9bef474ed676995bb4c57c9cd0014248/fonttools-4.56.0.tar.gz", hash = "sha256:a114d1567e1a1586b7e9e7fc2ff686ca542a82769a296cef131e4c4af51e58f4", size = 3462892 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/1e/5e/6ac30c2cc6a29454260f13c9c6422fc509b7982c13cd4597041260d8f482/fonttools-4.56.0-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:331954d002dbf5e704c7f3756028e21db07097c19722569983ba4d74df014000", size = 2752190 },
    { url = "https://files.pythonhosted.org/packages/92/3a/ac382a8396d1b420ee45eeb0f65b614a9ca7abbb23a1b17524054f0f2200/fonttools-4.56.0-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:8d1613abd5af2f93c05867b3a3759a56e8bf97eb79b1da76b2bc10892f96ff16", size = 2280624 },
    { url = "https://files.pythonhosted.org/packages/8a/ae/00b58bfe20e9ff7fbc3dda38f5d127913942b5e252288ea9583099a31bf5/fonttools-4.56.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:705837eae384fe21cee5e5746fd4f4b2f06f87544fa60f60740007e0aa600311", size = 4562074 },
    { url = "https://files.pythonhosted.org/packages/46/d0/0004ca8f6a200252e5bd6982ed99b5fe58c4c59efaf5f516621c4cd8f703/fonttools-4.56.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bc871904a53a9d4d908673c6faa15689874af1c7c5ac403a8e12d967ebd0c0dc", size = 4604747 },
    { url = "https://files.pythonhosted.org/packages/45/ea/c8862bd3e09d143ef8ed8268ec8a7d477828f960954889e65288ac050b08/fonttools-4.56.0-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:38b947de71748bab150259ee05a775e8a0635891568e9fdb3cdd7d0e0004e62f", size = 4559025 },
    { url = "https://files.pythonhosted.org/packages/8f/75/bb88a9552ec1de31a414066257bfd9f40f4ada00074f7a3799ea39b5741f/fonttools-4.56.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:86b2a1013ef7a64d2e94606632683f07712045ed86d937c11ef4dde97319c086", size = 4728482 },
    { url = "https://files.pythonhosted.org/packages/2a/5f/80a2b640df1e1bb7d459d62c8b3f37fe83fd413897e549106d4ebe6371f5/fonttools-4.56.0-cp310-cp310-win32.whl", hash = "sha256:133bedb9a5c6376ad43e6518b7e2cd2f866a05b1998f14842631d5feb36b5786", size = 2155557 },
    { url = "https://files.pythonhosted.org/packages/8f/85/0904f9dbe51ac70d878d3242a8583b9453a09105c3ed19c6301247fd0d3a/fonttools-4.56.0-cp310-cp310-win_amd64.whl", hash = "sha256:17f39313b649037f6c800209984a11fc256a6137cbe5487091c6c7187cae4685", size = 2200017 },
    { url = "https://files.pythonhosted.org/packages/35/56/a2f3e777d48fcae7ecd29de4d96352d84e5ea9871e5f3fc88241521572cf/fonttools-4.56.0-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:7ef04bc7827adb7532be3d14462390dd71287644516af3f1e67f1e6ff9c6d6df", size = 2753325 },
    { url = "https://files.pythonhosted.org/packages/71/85/d483e9c4e5ed586b183bf037a353e8d766366b54fd15519b30e6178a6a6e/fonttools-4.56.0-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:ffda9b8cd9cb8b301cae2602ec62375b59e2e2108a117746f12215145e3f786c", size = 2281554 },
    { url = "https://files.pythonhosted.org/packages/09/67/060473b832b2fade03c127019794df6dc02d9bc66fa4210b8e0d8a99d1e5/fonttools-4.56.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e2e993e8db36306cc3f1734edc8ea67906c55f98683d6fd34c3fc5593fdbba4c", size = 4869260 },
    { url = "https://files.pythonhosted.org/packages/28/e9/47c02d5a7027e8ed841ab6a10ca00c93dadd5f16742f1af1fa3f9978adf4/fonttools-4.56.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:003548eadd674175510773f73fb2060bb46adb77c94854af3e0cc5bc70260049", size = 4898508 },
    { url = "https://files.pythonhosted.org/packages/bf/8a/221d456d1afb8ca043cfd078f59f187ee5d0a580f4b49351b9ce95121f57/fonttools-4.56.0-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:bd9825822e7bb243f285013e653f6741954d8147427aaa0324a862cdbf4cbf62", size = 4877700 },
    { url = "https://files.pythonhosted.org/packages/a4/8c/e503863adf7a6aeff7b960e2f66fa44dd0c29a7a8b79765b2821950d7b05/fonttools-4.56.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:b23d30a2c0b992fb1c4f8ac9bfde44b5586d23457759b6cf9a787f1a35179ee0", size = 5045817 },
    { url = "https://files.pythonhosted.org/packages/2b/50/79ba3b7e42f4eaa70b82b9e79155f0f6797858dc8a97862428b6852c6aee/fonttools-4.56.0-cp311-cp311-win32.whl", hash = "sha256:47b5e4680002ae1756d3ae3b6114e20aaee6cc5c69d1e5911f5ffffd3ee46c6b", size = 2154426 },
    { url = "https://files.pythonhosted.org/packages/3b/90/4926e653041c4116ecd43e50e3c79f5daae6dcafc58ceb64bc4f71dd4924/fonttools-4.56.0-cp311-cp311-win_amd64.whl", hash = "sha256:14a3e3e6b211660db54ca1ef7006401e4a694e53ffd4553ab9bc87ead01d0f05", size = 2200937 },
    { url = "https://files.pythonhosted.org/packages/39/32/71cfd6877999576a11824a7fe7bc0bb57c5c72b1f4536fa56a3e39552643/fonttools-4.56.0-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:d6f195c14c01bd057bc9b4f70756b510e009c83c5ea67b25ced3e2c38e6ee6e9", size = 2747757 },
    { url = "https://files.pythonhosted.org/packages/15/52/d9f716b072c5061a0b915dd4c387f74bef44c68c069e2195c753905bd9b7/fonttools-4.56.0-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:fa760e5fe8b50cbc2d71884a1eff2ed2b95a005f02dda2fa431560db0ddd927f", size = 2279007 },
    { url = "https://files.pythonhosted.org/packages/d1/97/f1b3a8afa9a0d814a092a25cd42f59ccb98a0bb7a295e6e02fc9ba744214/fonttools-4.56.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d54a45d30251f1d729e69e5b675f9a08b7da413391a1227781e2a297fa37f6d2", size = 4783991 },
    { url = "https://files.pythonhosted.org/packages/95/70/2a781bedc1c45a0c61d29c56425609b22ed7f971da5d7e5df2679488741b/fonttools-4.56.0-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:661a8995d11e6e4914a44ca7d52d1286e2d9b154f685a4d1f69add8418961563", size = 4855109 },
    { url = "https://files.pythonhosted.org/packages/0c/02/a2597858e61a5e3fb6a14d5f6be9e6eb4eaf090da56ad70cedcbdd201685/fonttools-4.56.0-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:9d94449ad0a5f2a8bf5d2f8d71d65088aee48adbe45f3c5f8e00e3ad861ed81a", size = 4762496 },
    { url = "https://files.pythonhosted.org/packages/f2/00/aaf00100d6078fdc73f7352b44589804af9dc12b182a2540b16002152ba4/fonttools-4.56.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:f59746f7953f69cc3290ce2f971ab01056e55ddd0fb8b792c31a8acd7fee2d28", size = 4990094 },
    { url = "https://files.pythonhosted.org/packages/bf/dc/3ff1db522460db60cf3adaf1b64e0c72b43406717d139786d3fa1eb20709/fonttools-4.56.0-cp312-cp312-win32.whl", hash = "sha256:bce60f9a977c9d3d51de475af3f3581d9b36952e1f8fc19a1f2254f1dda7ce9c", size = 2142888 },
    { url = "https://files.pythonhosted.org/packages/6f/e3/5a181a85777f7809076e51f7422e0dc77eb04676c40ec8bf6a49d390d1ff/fonttools-4.56.0-cp312-cp312-win_amd64.whl", hash = "sha256:300c310bb725b2bdb4f5fc7e148e190bd69f01925c7ab437b9c0ca3e1c7cd9ba", size = 2189734 },
    { url = "https://files.pythonhosted.org/packages/a5/55/f06b48d48e0b4ec3a3489efafe9bd4d81b6e0802ac51026e3ee4634e89ba/fonttools-4.56.0-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:f20e2c0dfab82983a90f3d00703ac0960412036153e5023eed2b4641d7d5e692", size = 2735127 },
    { url = "https://files.pythonhosted.org/packages/59/db/d2c7c9b6dd5cbd46f183e650a47403ffb88fca17484eb7c4b1cd88f9e513/fonttools-4.56.0-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:f36a0868f47b7566237640c026c65a86d09a3d9ca5df1cd039e30a1da73098a0", size = 2272519 },
    { url = "https://files.pythonhosted.org/packages/4d/a2/da62d779c34a0e0c06415f02eab7fa3466de5d46df459c0275a255cefc65/fonttools-4.56.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:62b4c6802fa28e14dba010e75190e0e6228513573f1eeae57b11aa1a39b7e5b1", size = 4762423 },
    { url = "https://files.pythonhosted.org/packages/be/6a/fd4018e0448c8a5e12138906411282c5eab51a598493f080a9f0960e658f/fonttools-4.56.0-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a05d1f07eb0a7d755fbe01fee1fd255c3a4d3730130cf1bfefb682d18fd2fcea", size = 4834442 },
    { url = "https://files.pythonhosted.org/packages/6d/63/fa1dec8efb35bc11ef9c39b2d74754b45d48a3ccb2cf78c0109c0af639e8/fonttools-4.56.0-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:0073b62c3438cf0058488c002ea90489e8801d3a7af5ce5f7c05c105bee815c3", size = 4742800 },
    { url = "https://files.pythonhosted.org/packages/dd/f4/963247ae8c73ccc4cf2929e7162f595c81dbe17997d1d0ea77da24a217c9/fonttools-4.56.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:e2cad98c94833465bcf28f51c248aaf07ca022efc6a3eba750ad9c1e0256d278", size = 4963746 },
    { url = "https://files.pythonhosted.org/packages/ea/e0/46f9600c39c644b54e4420f941f75fa200d9288c9ae171e5d80918b8cbb9/fonttools-4.56.0-cp313-cp313-win32.whl", hash = "sha256:d0cb73ccf7f6d7ca8d0bc7ea8ac0a5b84969a41c56ac3ac3422a24df2680546f", size = 2140927 },
    { url = "https://files.pythonhosted.org/packages/27/6d/3edda54f98a550a0473f032d8050315fbc8f1b76a0d9f3879b72ebb2cdd6/fonttools-4.56.0-cp313-cp313-win_amd64.whl", hash = "sha256:62cc1253827d1e500fde9dbe981219fea4eb000fd63402283472d38e7d8aa1c6", size = 2186709 },
    { url = "https://files.pythonhosted.org/packages/72/2d/762488c56a2bba2fa4d459233d971c2122bf1ed1ec5d9edfee7d58963ef5/fonttools-4.56.0-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:3fd3fccb7b9adaaecfa79ad51b759f2123e1aba97f857936ce044d4f029abd71", size = 2749891 },
    { url = "https://files.pythonhosted.org/packages/5a/64/4d4a46959e4bfd62210eee4c5c3259ec62c6eca437fa2e3e795ac0bde94f/fonttools-4.56.0-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:193b86e9f769320bc98ffdb42accafb5d0c8c49bd62884f1c0702bc598b3f0a2", size = 2279311 },
    { url = "https://files.pythonhosted.org/packages/5e/cd/0531711a900bb89cc757259c21fd67cc3cb4de260b3c4c1390dbfa463b01/fonttools-4.56.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6e81c1cc80c1d8bf071356cc3e0e25071fbba1c75afc48d41b26048980b3c771", size = 4643308 },
    { url = "https://files.pythonhosted.org/packages/e0/c1/a3b9221b623eead07a4f2fd105b9183a2f70461deae14fac0f4c65872d04/fonttools-4.56.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e9270505a19361e81eecdbc2c251ad1e1a9a9c2ad75fa022ccdee533f55535dc", size = 4687400 },
    { url = "https://files.pythonhosted.org/packages/67/14/67f5c0b695e4043b566e04b1f78e4f749cdd1bab6370f8056791e1c57314/fonttools-4.56.0-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:53f5e9767978a4daf46f28e09dbeb7d010319924ae622f7b56174b777258e5ba", size = 4665170 },
    { url = "https://files.pythonhosted.org/packages/3c/fe/c8bfbe682def287eca26052e5232ca293ea0f9a6a3051dab2cb65e4ef401/fonttools-4.56.0-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:9da650cb29bc098b8cfd15ef09009c914b35c7986c8fa9f08b51108b7bc393b4", size = 4844223 },
    { url = "https://files.pythonhosted.org/packages/9c/c1/2133e0a2558c94fefb3d655b3ca782f4310aa86ee8da0e12274cf6dc91c2/fonttools-4.56.0-cp38-cp38-win32.whl", hash = "sha256:965d0209e6dbdb9416100123b6709cb13f5232e2d52d17ed37f9df0cc31e2b35", size = 1480341 },
    { url = "https://files.pythonhosted.org/packages/e9/73/e0285a1cd25da20f1403a6dea54c116a6ccae6063f209a39793977dad03a/fonttools-4.56.0-cp38-cp38-win_amd64.whl", hash = "sha256:654ac4583e2d7c62aebc6fc6a4c6736f078f50300e18aa105d87ce8925cfac31", size = 1525378 },
    { url = "https://files.pythonhosted.org/packages/c2/a0/c62b7f219f74f0e9c4b7662c269b360f5c380cf7dfabaff06e114acc5576/fonttools-4.56.0-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:ca7962e8e5fc047cc4e59389959843aafbf7445b6c08c20d883e60ced46370a5", size = 2754871 },
    { url = "https://files.pythonhosted.org/packages/22/aa/2ce61705c48c4dc7953bec95f7cfa29e528294a06e7d38f2c674343425ca/fonttools-4.56.0-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:a1af375734018951c31c0737d04a9d5fd0a353a0253db5fbed2ccd44eac62d8c", size = 2281885 },
    { url = "https://files.pythonhosted.org/packages/81/68/508c1e84050b950918b1345ee22def98291b2e58890b0f3c2d0cfc4fee6b/fonttools-4.56.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:442ad4122468d0e47d83bc59d0e91b474593a8c813839e1872e47c7a0cb53b10", size = 4567663 },
    { url = "https://files.pythonhosted.org/packages/56/af/78b2c901949ca37c02ba4eec88020479e929b7d1126af30ee9d7e44b4c4c/fonttools-4.56.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3cf4f8d2a30b454ac682e12c61831dcb174950c406011418e739de592bbf8f76", size = 4612654 },
    { url = "https://files.pythonhosted.org/packages/cb/fb/156bd9760b6d42be3d821f0ac3edccf8daf97b0e4fe539c569b6593f4b6a/fonttools-4.56.0-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:96a4271f63a615bcb902b9f56de00ea225d6896052c49f20d0c91e9f43529a29", size = 4561135 },
    { url = "https://files.pythonhosted.org/packages/c4/e9/c6c433b8ea306ba402aa1d53349237d78c1d21ec11bb69cc6d8442533d5b/fonttools-4.56.0-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:6c1d38642ca2dddc7ae992ef5d026e5061a84f10ff2b906be5680ab089f55bb8", size = 4731430 },
    { url = "https://files.pythonhosted.org/packages/00/41/4c199ca2c6d25edced1cdd6a3d32b2471c1e85dc7fbb2145e73805cf2a38/fonttools-4.56.0-cp39-cp39-win32.whl", hash = "sha256:2d351275f73ebdd81dd5b09a8b8dac7a30f29a279d41e1c1192aedf1b6dced40", size = 2156113 },
    { url = "https://files.pythonhosted.org/packages/00/8f/430abf16726cd627e176df92c452f239fcc488fac1e23c9ab57bb7ad6976/fonttools-4.56.0-cp39-cp39-win_amd64.whl", hash = "sha256:d6ca96d1b61a707ba01a43318c9c40aaf11a5a568d1e61146fafa6ab20890793", size = 2200538 },
    { url = "https://files.pythonhosted.org/packages/bf/ff/44934a031ce5a39125415eb405b9efb76fe7f9586b75291d66ae5cbfc4e6/fonttools-4.56.0-py3-none-any.whl", hash = "sha256:1088182f68c303b50ca4dc0c82d42083d176cba37af1937e1a976a31149d4d14", size = 1089800 },
]

[[package]]
name = "idna"
version = "3.10"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f1/70/7703c29685631f5a7590aa73f1f1d3fa9a380e654b86af429e0934a32f7d/idna-3.10.tar.gz", hash = "sha256:12f65c9b470abda6dc35cf8e63cc574b1c52b11df2c86030af0ac09b01b13ea9", size = 190490 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl", hash = "sha256:946d195a0d259cbba61165e88e65941f16e9b36ea6ddb97f00452bae8b1287d3", size = 70442 },
]

[[package]]
name = "importlib-resources"
version = "6.4.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "zipp", marker = "python_full_version < '3.10'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/98/be/f3e8c6081b684f176b761e6a2fef02a0be939740ed6f54109a2951d806f3/importlib_resources-6.4.5.tar.gz", hash = "sha256:980862a1d16c9e147a59603677fa2aa5fd82b87f223b6cb870695bcfce830065", size = 43372 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e1/6a/4604f9ae2fa62ef47b9de2fa5ad599589d28c9fd1d335f32759813dfa91e/importlib_resources-6.4.5-py3-none-any.whl", hash = "sha256:ac29d5f956f01d5e4bb63102a5a19957f1b9175e45649977264a1416783bb717", size = 36115 },
]

[[package]]
name = "iniconfig"
version = "2.0.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d7/4b/cbd8e699e64a6f16ca3a8220661b5f83792b3017d0f79807cb8708d33913/iniconfig-2.0.0.tar.gz", hash = "sha256:2d91e135bf72d31a410b17c16da610a82cb55f6b0477d1a902134b24a455b8b3", size = 4646 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/ef/a6/62565a6e1cf69e10f5727360368e451d4b7f58beeac6173dc9db836a5b46/iniconfig-2.0.0-py3-none-any.whl", hash = "sha256:b6a85871a79d2e3b22d2d1b94ac2824226a63c6b741c88f7ae975f18b6778374", size = 5892 },
]

[[package]]
name = "jinja2"
version = "3.1.6"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "markupsafe" },
]
sdist = { url = "https://files.pythonhosted.org/packages/df/bf/f7da0350254c0ed7c72f3e33cef02e048281fec7ecec5f032d4aac52226b/jinja2-3.1.6.tar.gz", hash = "sha256:0137fb05990d35f1275a587e9aee6d56da821fc83491a0fb838183be43f66d6d", size = 245115 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/62/a1/3d680cbfd5f4b8f15abc1d571870c5fc3e594bb582bc3b64ea099db13e56/jinja2-3.1.6-py3-none-any.whl", hash = "sha256:85ece4451f492d0c13c5dd7c13a64681a86afae63a5f347908daf103ce6d2f67", size = 134899 },
]

[[package]]
name = "joblib"
version = "1.4.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/64/33/60135848598c076ce4b231e1b1895170f45fbcaeaa2c9d5e38b04db70c35/joblib-1.4.2.tar.gz", hash = "sha256:2382c5816b2636fbd20a09e0f4e9dad4736765fdfb7dca582943b9c1366b3f0e", size = 2116621 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/91/29/df4b9b42f2be0b623cbd5e2140cafcaa2bef0759a00b7b70104dcfe2fb51/joblib-1.4.2-py3-none-any.whl", hash = "sha256:06d478d5674cbc267e7496a410ee875abd68e4340feff4490bcb7afb88060ae6", size = 301817 },
]

[[package]]
name = "kiwisolver"
version = "1.4.7"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/85/4d/2255e1c76304cbd60b48cee302b66d1dde4468dc5b1160e4b7cb43778f2a/kiwisolver-1.4.7.tar.gz", hash = "sha256:9893ff81bd7107f7b685d3017cc6583daadb4fc26e4a888350df530e41980a60", size = 97286 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/97/14/fc943dd65268a96347472b4fbe5dcc2f6f55034516f80576cd0dd3a8930f/kiwisolver-1.4.7-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:8a9c83f75223d5e48b0bc9cb1bf2776cf01563e00ade8775ffe13b0b6e1af3a6", size = 122440 },
    { url = "https://files.pythonhosted.org/packages/1e/46/e68fed66236b69dd02fcdb506218c05ac0e39745d696d22709498896875d/kiwisolver-1.4.7-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:58370b1ffbd35407444d57057b57da5d6549d2d854fa30249771775c63b5fe17", size = 65758 },
    { url = "https://files.pythonhosted.org/packages/ef/fa/65de49c85838681fc9cb05de2a68067a683717321e01ddafb5b8024286f0/kiwisolver-1.4.7-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:aa0abdf853e09aff551db11fce173e2177d00786c688203f52c87ad7fcd91ef9", size = 64311 },
    { url = "https://files.pythonhosted.org/packages/42/9c/cc8d90f6ef550f65443bad5872ffa68f3dee36de4974768628bea7c14979/kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_i686.manylinux2010_i686.whl", hash = "sha256:8d53103597a252fb3ab8b5845af04c7a26d5e7ea8122303dd7a021176a87e8b9", size = 1637109 },
    { url = "https://files.pythonhosted.org/packages/55/91/0a57ce324caf2ff5403edab71c508dd8f648094b18cfbb4c8cc0fde4a6ac/kiwisolver-1.4.7-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:88f17c5ffa8e9462fb79f62746428dd57b46eb931698e42e990ad63103f35e6c", size = 1617814 },
    { url = "https://files.pythonhosted.org/packages/12/5d/c36140313f2510e20207708adf36ae4919416d697ee0236b0ddfb6fd1050/kiwisolver-1.4.7-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:88a9ca9c710d598fd75ee5de59d5bda2684d9db36a9f50b6125eaea3969c2599", size = 1400881 },
    { url = "https://files.pythonhosted.org/packages/56/d0/786e524f9ed648324a466ca8df86298780ef2b29c25313d9a4f16992d3cf/kiwisolver-1.4.7-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:f4d742cb7af1c28303a51b7a27aaee540e71bb8e24f68c736f6f2ffc82f2bf05", size = 1512972 },
    { url = "https://files.pythonhosted.org/packages/67/5a/77851f2f201e6141d63c10a0708e996a1363efaf9e1609ad0441b343763b/kiwisolver-1.4.7-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:e28c7fea2196bf4c2f8d46a0415c77a1c480cc0724722f23d7410ffe9842c407", size = 1444787 },
    { url = "https://files.pythonhosted.org/packages/06/5f/1f5eaab84355885e224a6fc8d73089e8713dc7e91c121f00b9a1c58a2195/kiwisolver-1.4.7-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:e968b84db54f9d42046cf154e02911e39c0435c9801681e3fc9ce8a3c4130278", size = 2199212 },
    { url = "https://files.pythonhosted.org/packages/b5/28/9152a3bfe976a0ae21d445415defc9d1cd8614b2910b7614b30b27a47270/kiwisolver-1.4.7-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:0c18ec74c0472de033e1bebb2911c3c310eef5649133dd0bedf2a169a1b269e5", size = 2346399 },
    { url = "https://files.pythonhosted.org/packages/26/f6/453d1904c52ac3b400f4d5e240ac5fec25263716723e44be65f4d7149d13/kiwisolver-1.4.7-cp310-cp310-musllinux_1_2_ppc64le.whl", hash = "sha256:8f0ea6da6d393d8b2e187e6a5e3fb81f5862010a40c3945e2c6d12ae45cfb2ad", size = 2308688 },
    { url = "https://files.pythonhosted.org/packages/5a/9a/d4968499441b9ae187e81745e3277a8b4d7c60840a52dc9d535a7909fac3/kiwisolver-1.4.7-cp310-cp310-musllinux_1_2_s390x.whl", hash = "sha256:f106407dda69ae456dd1227966bf445b157ccc80ba0dff3802bb63f30b74e895", size = 2445493 },
    { url = "https://files.pythonhosted.org/packages/07/c9/032267192e7828520dacb64dfdb1d74f292765f179e467c1cba97687f17d/kiwisolver-1.4.7-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:84ec80df401cfee1457063732d90022f93951944b5b58975d34ab56bb150dfb3", size = 2262191 },
    { url = "https://files.pythonhosted.org/packages/6c/ad/db0aedb638a58b2951da46ddaeecf204be8b4f5454df020d850c7fa8dca8/kiwisolver-1.4.7-cp310-cp310-win32.whl", hash = "sha256:71bb308552200fb2c195e35ef05de12f0c878c07fc91c270eb3d6e41698c3bcc", size = 46644 },
    { url = "https://files.pythonhosted.org/packages/12/ca/d0f7b7ffbb0be1e7c2258b53554efec1fd652921f10d7d85045aff93ab61/kiwisolver-1.4.7-cp310-cp310-win_amd64.whl", hash = "sha256:44756f9fd339de0fb6ee4f8c1696cfd19b2422e0d70b4cefc1cc7f1f64045a8c", size = 55877 },
    { url = "https://files.pythonhosted.org/packages/97/6c/cfcc128672f47a3e3c0d918ecb67830600078b025bfc32d858f2e2d5c6a4/kiwisolver-1.4.7-cp310-cp310-win_arm64.whl", hash = "sha256:78a42513018c41c2ffd262eb676442315cbfe3c44eed82385c2ed043bc63210a", size = 48347 },
    { url = "https://files.pythonhosted.org/packages/e9/44/77429fa0a58f941d6e1c58da9efe08597d2e86bf2b2cce6626834f49d07b/kiwisolver-1.4.7-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:d2b0e12a42fb4e72d509fc994713d099cbb15ebf1103545e8a45f14da2dfca54", size = 122442 },
    { url = "https://files.pythonhosted.org/packages/e5/20/8c75caed8f2462d63c7fd65e16c832b8f76cda331ac9e615e914ee80bac9/kiwisolver-1.4.7-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:2a8781ac3edc42ea4b90bc23e7d37b665d89423818e26eb6df90698aa2287c95", size = 65762 },
    { url = "https://files.pythonhosted.org/packages/f4/98/fe010f15dc7230f45bc4cf367b012d651367fd203caaa992fd1f5963560e/kiwisolver-1.4.7-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:46707a10836894b559e04b0fd143e343945c97fd170d69a2d26d640b4e297935", size = 64319 },
    { url = "https://files.pythonhosted.org/packages/8b/1b/b5d618f4e58c0675654c1e5051bcf42c776703edb21c02b8c74135541f60/kiwisolver-1.4.7-cp311-cp311-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ef97b8df011141c9b0f6caf23b29379f87dd13183c978a30a3c546d2c47314cb", size = 1334260 },
    { url = "https://files.pythonhosted.org/packages/b8/01/946852b13057a162a8c32c4c8d2e9ed79f0bb5d86569a40c0b5fb103e373/kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:3ab58c12a2cd0fc769089e6d38466c46d7f76aced0a1f54c77652446733d2d02", size = 1426589 },
    { url = "https://files.pythonhosted.org/packages/70/d1/c9f96df26b459e15cf8a965304e6e6f4eb291e0f7a9460b4ad97b047561e/kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:803b8e1459341c1bb56d1c5c010406d5edec8a0713a0945851290a7930679b51", size = 1541080 },
    { url = "https://files.pythonhosted.org/packages/d3/73/2686990eb8b02d05f3de759d6a23a4ee7d491e659007dd4c075fede4b5d0/kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f9a9e8a507420fe35992ee9ecb302dab68550dedc0da9e2880dd88071c5fb052", size = 1470049 },
    { url = "https://files.pythonhosted.org/packages/a7/4b/2db7af3ed3af7c35f388d5f53c28e155cd402a55432d800c543dc6deb731/kiwisolver-1.4.7-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:18077b53dc3bb490e330669a99920c5e6a496889ae8c63b58fbc57c3d7f33a18", size = 1426376 },
    { url = "https://files.pythonhosted.org/packages/05/83/2857317d04ea46dc5d115f0df7e676997bbd968ced8e2bd6f7f19cfc8d7f/kiwisolver-1.4.7-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:6af936f79086a89b3680a280c47ea90b4df7047b5bdf3aa5c524bbedddb9e545", size = 2222231 },
    { url = "https://files.pythonhosted.org/packages/0d/b5/866f86f5897cd4ab6d25d22e403404766a123f138bd6a02ecb2cdde52c18/kiwisolver-1.4.7-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:3abc5b19d24af4b77d1598a585b8a719beb8569a71568b66f4ebe1fb0449460b", size = 2368634 },
    { url = "https://files.pythonhosted.org/packages/c1/ee/73de8385403faba55f782a41260210528fe3273d0cddcf6d51648202d6d0/kiwisolver-1.4.7-cp311-cp311-musllinux_1_2_ppc64le.whl", hash = "sha256:933d4de052939d90afbe6e9d5273ae05fb836cc86c15b686edd4b3560cc0ee36", size = 2329024 },
    { url = "https://files.pythonhosted.org/packages/a1/e7/cd101d8cd2cdfaa42dc06c433df17c8303d31129c9fdd16c0ea37672af91/kiwisolver-1.4.7-cp311-cp311-musllinux_1_2_s390x.whl", hash = "sha256:65e720d2ab2b53f1f72fb5da5fb477455905ce2c88aaa671ff0a447c2c80e8e3", size = 2468484 },
    { url = "https://files.pythonhosted.org/packages/e1/72/84f09d45a10bc57a40bb58b81b99d8f22b58b2040c912b7eb97ebf625bf2/kiwisolver-1.4.7-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:3bf1ed55088f214ba6427484c59553123fdd9b218a42bbc8c6496d6754b1e523", size = 2284078 },
    { url = "https://files.pythonhosted.org/packages/d2/d4/71828f32b956612dc36efd7be1788980cb1e66bfb3706e6dec9acad9b4f9/kiwisolver-1.4.7-cp311-cp311-win32.whl", hash = "sha256:4c00336b9dd5ad96d0a558fd18a8b6f711b7449acce4c157e7343ba92dd0cf3d", size = 46645 },
    { url = "https://files.pythonhosted.org/packages/a1/65/d43e9a20aabcf2e798ad1aff6c143ae3a42cf506754bcb6a7ed8259c8425/kiwisolver-1.4.7-cp311-cp311-win_amd64.whl", hash = "sha256:929e294c1ac1e9f615c62a4e4313ca1823ba37326c164ec720a803287c4c499b", size = 56022 },
    { url = "https://files.pythonhosted.org/packages/35/b3/9f75a2e06f1b4ca00b2b192bc2b739334127d27f1d0625627ff8479302ba/kiwisolver-1.4.7-cp311-cp311-win_arm64.whl", hash = "sha256:e33e8fbd440c917106b237ef1a2f1449dfbb9b6f6e1ce17c94cd6a1e0d438376", size = 48536 },
    { url = "https://files.pythonhosted.org/packages/97/9c/0a11c714cf8b6ef91001c8212c4ef207f772dd84540104952c45c1f0a249/kiwisolver-1.4.7-cp312-cp312-macosx_10_9_universal2.whl", hash = "sha256:5360cc32706dab3931f738d3079652d20982511f7c0ac5711483e6eab08efff2", size = 121808 },
    { url = "https://files.pythonhosted.org/packages/f2/d8/0fe8c5f5d35878ddd135f44f2af0e4e1d379e1c7b0716f97cdcb88d4fd27/kiwisolver-1.4.7-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:942216596dc64ddb25adb215c3c783215b23626f8d84e8eff8d6d45c3f29f75a", size = 65531 },
    { url = "https://files.pythonhosted.org/packages/80/c5/57fa58276dfdfa612241d640a64ca2f76adc6ffcebdbd135b4ef60095098/kiwisolver-1.4.7-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:48b571ecd8bae15702e4f22d3ff6a0f13e54d3d00cd25216d5e7f658242065ee", size = 63894 },
    { url = "https://files.pythonhosted.org/packages/8b/e9/26d3edd4c4ad1c5b891d8747a4f81b1b0aba9fb9721de6600a4adc09773b/kiwisolver-1.4.7-cp312-cp312-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ad42ba922c67c5f219097b28fae965e10045ddf145d2928bfac2eb2e17673640", size = 1369296 },
    { url = "https://files.pythonhosted.org/packages/b6/67/3f4850b5e6cffb75ec40577ddf54f7b82b15269cc5097ff2e968ee32ea7d/kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:612a10bdae23404a72941a0fc8fa2660c6ea1217c4ce0dbcab8a8f6543ea9e7f", size = 1461450 },
    { url = "https://files.pythonhosted.org/packages/52/be/86cbb9c9a315e98a8dc6b1d23c43cffd91d97d49318854f9c37b0e41cd68/kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:9e838bba3a3bac0fe06d849d29772eb1afb9745a59710762e4ba3f4cb8424483", size = 1579168 },
    { url = "https://files.pythonhosted.org/packages/0f/00/65061acf64bd5fd34c1f4ae53f20b43b0a017a541f242a60b135b9d1e301/kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:22f499f6157236c19f4bbbd472fa55b063db77a16cd74d49afe28992dff8c258", size = 1507308 },
    { url = "https://files.pythonhosted.org/packages/21/e4/c0b6746fd2eb62fe702118b3ca0cb384ce95e1261cfada58ff693aeec08a/kiwisolver-1.4.7-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:693902d433cf585133699972b6d7c42a8b9f8f826ebcaf0132ff55200afc599e", size = 1464186 },
    { url = "https://files.pythonhosted.org/packages/0a/0f/529d0a9fffb4d514f2782c829b0b4b371f7f441d61aa55f1de1c614c4ef3/kiwisolver-1.4.7-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:4e77f2126c3e0b0d055f44513ed349038ac180371ed9b52fe96a32aa071a5107", size = 2247877 },
    { url = "https://files.pythonhosted.org/packages/d1/e1/66603ad779258843036d45adcbe1af0d1a889a07af4635f8b4ec7dccda35/kiwisolver-1.4.7-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:657a05857bda581c3656bfc3b20e353c232e9193eb167766ad2dc58b56504948", size = 2404204 },
    { url = "https://files.pythonhosted.org/packages/8d/61/de5fb1ca7ad1f9ab7970e340a5b833d735df24689047de6ae71ab9d8d0e7/kiwisolver-1.4.7-cp312-cp312-musllinux_1_2_ppc64le.whl", hash = "sha256:4bfa75a048c056a411f9705856abfc872558e33c055d80af6a380e3658766038", size = 2352461 },
    { url = "https://files.pythonhosted.org/packages/ba/d2/0edc00a852e369827f7e05fd008275f550353f1f9bcd55db9363d779fc63/kiwisolver-1.4.7-cp312-cp312-musllinux_1_2_s390x.whl", hash = "sha256:34ea1de54beef1c104422d210c47c7d2a4999bdecf42c7b5718fbe59a4cac383", size = 2501358 },
    { url = "https://files.pythonhosted.org/packages/84/15/adc15a483506aec6986c01fb7f237c3aec4d9ed4ac10b756e98a76835933/kiwisolver-1.4.7-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:90da3b5f694b85231cf93586dad5e90e2d71b9428f9aad96952c99055582f520", size = 2314119 },
    { url = "https://files.pythonhosted.org/packages/36/08/3a5bb2c53c89660863a5aa1ee236912269f2af8762af04a2e11df851d7b2/kiwisolver-1.4.7-cp312-cp312-win32.whl", hash = "sha256:18e0cca3e008e17fe9b164b55735a325140a5a35faad8de92dd80265cd5eb80b", size = 46367 },
    { url = "https://files.pythonhosted.org/packages/19/93/c05f0a6d825c643779fc3c70876bff1ac221f0e31e6f701f0e9578690d70/kiwisolver-1.4.7-cp312-cp312-win_amd64.whl", hash = "sha256:58cb20602b18f86f83a5c87d3ee1c766a79c0d452f8def86d925e6c60fbf7bfb", size = 55884 },
    { url = "https://files.pythonhosted.org/packages/d2/f9/3828d8f21b6de4279f0667fb50a9f5215e6fe57d5ec0d61905914f5b6099/kiwisolver-1.4.7-cp312-cp312-win_arm64.whl", hash = "sha256:f5a8b53bdc0b3961f8b6125e198617c40aeed638b387913bf1ce78afb1b0be2a", size = 48528 },
    { url = "https://files.pythonhosted.org/packages/c4/06/7da99b04259b0f18b557a4effd1b9c901a747f7fdd84cf834ccf520cb0b2/kiwisolver-1.4.7-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:2e6039dcbe79a8e0f044f1c39db1986a1b8071051efba3ee4d74f5b365f5226e", size = 121913 },
    { url = "https://files.pythonhosted.org/packages/97/f5/b8a370d1aa593c17882af0a6f6755aaecd643640c0ed72dcfd2eafc388b9/kiwisolver-1.4.7-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:a1ecf0ac1c518487d9d23b1cd7139a6a65bc460cd101ab01f1be82ecf09794b6", size = 65627 },
    { url = "https://files.pythonhosted.org/packages/2a/fc/6c0374f7503522539e2d4d1b497f5ebad3f8ed07ab51aed2af988dd0fb65/kiwisolver-1.4.7-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:7ab9ccab2b5bd5702ab0803676a580fffa2aa178c2badc5557a84cc943fcf750", size = 63888 },
    { url = "https://files.pythonhosted.org/packages/bf/3e/0b7172793d0f41cae5c923492da89a2ffcd1adf764c16159ca047463ebd3/kiwisolver-1.4.7-cp313-cp313-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f816dd2277f8d63d79f9c8473a79fe54047bc0467754962840782c575522224d", size = 1369145 },
    { url = "https://files.pythonhosted.org/packages/77/92/47d050d6f6aced2d634258123f2688fbfef8ded3c5baf2c79d94d91f1f58/kiwisolver-1.4.7-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:cf8bcc23ceb5a1b624572a1623b9f79d2c3b337c8c455405ef231933a10da379", size = 1461448 },
    { url = "https://files.pythonhosted.org/packages/9c/1b/8f80b18e20b3b294546a1adb41701e79ae21915f4175f311a90d042301cf/kiwisolver-1.4.7-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:dea0bf229319828467d7fca8c7c189780aa9ff679c94539eed7532ebe33ed37c", size = 1578750 },
    { url = "https://files.pythonhosted.org/packages/a4/fe/fe8e72f3be0a844f257cadd72689c0848c6d5c51bc1d60429e2d14ad776e/kiwisolver-1.4.7-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:7c06a4c7cf15ec739ce0e5971b26c93638730090add60e183530d70848ebdd34", size = 1507175 },
    { url = "https://files.pythonhosted.org/packages/39/fa/cdc0b6105d90eadc3bee525fecc9179e2b41e1ce0293caaf49cb631a6aaf/kiwisolver-1.4.7-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:913983ad2deb14e66d83c28b632fd35ba2b825031f2fa4ca29675e665dfecbe1", size = 1463963 },
    { url = "https://files.pythonhosted.org/packages/6e/5c/0c03c4e542720c6177d4f408e56d1c8315899db72d46261a4e15b8b33a41/kiwisolver-1.4.7-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:5337ec7809bcd0f424c6b705ecf97941c46279cf5ed92311782c7c9c2026f07f", size = 2248220 },
    { url = "https://files.pythonhosted.org/packages/3d/ee/55ef86d5a574f4e767df7da3a3a7ff4954c996e12d4fbe9c408170cd7dcc/kiwisolver-1.4.7-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:4c26ed10c4f6fa6ddb329a5120ba3b6db349ca192ae211e882970bfc9d91420b", size = 2404463 },
    { url = "https://files.pythonhosted.org/packages/0f/6d/73ad36170b4bff4825dc588acf4f3e6319cb97cd1fb3eb04d9faa6b6f212/kiwisolver-1.4.7-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:c619b101e6de2222c1fcb0531e1b17bbffbe54294bfba43ea0d411d428618c27", size = 2352842 },
    { url = "https://files.pythonhosted.org/packages/0b/16/fa531ff9199d3b6473bb4d0f47416cdb08d556c03b8bc1cccf04e756b56d/kiwisolver-1.4.7-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:073a36c8273647592ea332e816e75ef8da5c303236ec0167196793eb1e34657a", size = 2501635 },
    { url = "https://files.pythonhosted.org/packages/78/7e/aa9422e78419db0cbe75fb86d8e72b433818f2e62e2e394992d23d23a583/kiwisolver-1.4.7-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:3ce6b2b0231bda412463e152fc18335ba32faf4e8c23a754ad50ffa70e4091ee", size = 2314556 },
    { url = "https://files.pythonhosted.org/packages/a8/b2/15f7f556df0a6e5b3772a1e076a9d9f6c538ce5f05bd590eca8106508e06/kiwisolver-1.4.7-cp313-cp313-win32.whl", hash = "sha256:f4c9aee212bc89d4e13f58be11a56cc8036cabad119259d12ace14b34476fd07", size = 46364 },
    { url = "https://files.pythonhosted.org/packages/0b/db/32e897e43a330eee8e4770bfd2737a9584b23e33587a0812b8e20aac38f7/kiwisolver-1.4.7-cp313-cp313-win_amd64.whl", hash = "sha256:8a3ec5aa8e38fc4c8af308917ce12c536f1c88452ce554027e55b22cbbfbff76", size = 55887 },
    { url = "https://files.pythonhosted.org/packages/c8/a4/df2bdca5270ca85fd25253049eb6708d4127be2ed0e5c2650217450b59e9/kiwisolver-1.4.7-cp313-cp313-win_arm64.whl", hash = "sha256:76c8094ac20ec259471ac53e774623eb62e6e1f56cd8690c67ce6ce4fcb05650", size = 48530 },
    { url = "https://files.pythonhosted.org/packages/57/d6/620247574d9e26fe24384087879e8399e309f0051782f95238090afa6ccc/kiwisolver-1.4.7-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:5d5abf8f8ec1f4e22882273c423e16cae834c36856cac348cfbfa68e01c40f3a", size = 122325 },
    { url = "https://files.pythonhosted.org/packages/bd/c6/572ad7d73dbd898cffa9050ffd7ff7e78a055a1d9b7accd6b4d1f50ec858/kiwisolver-1.4.7-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:aeb3531b196ef6f11776c21674dba836aeea9d5bd1cf630f869e3d90b16cfade", size = 65679 },
    { url = "https://files.pythonhosted.org/packages/14/a7/bb8ab10e12cc8764f4da0245d72dee4731cc720bdec0f085d5e9c6005b98/kiwisolver-1.4.7-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:b7d755065e4e866a8086c9bdada157133ff466476a2ad7861828e17b6026e22c", size = 64267 },
    { url = "https://files.pythonhosted.org/packages/54/a4/3b5a2542429e182a4df0528214e76803f79d016110f5e67c414a0357cd7d/kiwisolver-1.4.7-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:08471d4d86cbaec61f86b217dd938a83d85e03785f51121e791a6e6689a3be95", size = 1387236 },
    { url = "https://files.pythonhosted.org/packages/a6/d7/bc3005e906c1673953a3e31ee4f828157d5e07a62778d835dd937d624ea0/kiwisolver-1.4.7-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:7bbfcb7165ce3d54a3dfbe731e470f65739c4c1f85bb1018ee912bae139e263b", size = 1500555 },
    { url = "https://files.pythonhosted.org/packages/09/a7/87cb30741f13b7af08446795dca6003491755805edc9c321fe996c1320b8/kiwisolver-1.4.7-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5d34eb8494bea691a1a450141ebb5385e4b69d38bb8403b5146ad279f4b30fa3", size = 1431684 },
    { url = "https://files.pythonhosted.org/packages/37/a4/1e4e2d8cdaa42c73d523413498445247e615334e39401ae49dae74885429/kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:9242795d174daa40105c1d86aba618e8eab7bf96ba8c3ee614da8302a9f95503", size = 1125811 },
    { url = "https://files.pythonhosted.org/packages/76/36/ae40d7a3171e06f55ac77fe5536079e7be1d8be2a8210e08975c7f9b4d54/kiwisolver-1.4.7-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl", hash = "sha256:a0f64a48bb81af7450e641e3fe0b0394d7381e342805479178b3d335d60ca7cf", size = 1179987 },
    { url = "https://files.pythonhosted.org/packages/d8/5d/6e4894b9fdf836d8bd095729dff123bbbe6ad0346289287b45c800fae656/kiwisolver-1.4.7-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:8e045731a5416357638d1700927529e2b8ab304811671f665b225f8bf8d8f933", size = 2186817 },
    { url = "https://files.pythonhosted.org/packages/f0/2d/603079b2c2fd62890be0b0ebfc8bb6dda8a5253ca0758885596565b0dfc1/kiwisolver-1.4.7-cp38-cp38-musllinux_1_2_i686.whl", hash = "sha256:4322872d5772cae7369f8351da1edf255a604ea7087fe295411397d0cfd9655e", size = 2332538 },
    { url = "https://files.pythonhosted.org/packages/bb/2a/9a28279c865c38a27960db38b07179143aafc94877945c209bfc553d9dd3/kiwisolver-1.4.7-cp38-cp38-musllinux_1_2_ppc64le.whl", hash = "sha256:e1631290ee9271dffe3062d2634c3ecac02c83890ada077d225e081aca8aab89", size = 2293890 },
    { url = "https://files.pythonhosted.org/packages/1a/4d/4da8967f3bf13c764984b8fbae330683ee5fbd555b4a5624ad2b9decc0ab/kiwisolver-1.4.7-cp38-cp38-musllinux_1_2_s390x.whl", hash = "sha256:edcfc407e4eb17e037bca59be0e85a2031a2ac87e4fed26d3e9df88b4165f92d", size = 2434677 },
    { url = "https://files.pythonhosted.org/packages/08/e9/a97a2b6b74dd850fa5974309367e025c06093a143befe9b962d0baebb4f0/kiwisolver-1.4.7-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:4d05d81ecb47d11e7f8932bd8b61b720bf0b41199358f3f5e36d38e28f0532c5", size = 2250339 },
    { url = "https://files.pythonhosted.org/packages/8a/e7/55507a387ba1766e69f5e13a79e1aefabdafe0532bee5d1972dfc42b3d16/kiwisolver-1.4.7-cp38-cp38-win32.whl", hash = "sha256:b38ac83d5f04b15e515fd86f312479d950d05ce2368d5413d46c088dda7de90a", size = 46932 },
    { url = "https://files.pythonhosted.org/packages/52/77/7e04cca2ff1dc6ee6b7654cebe233de72b7a3ec5616501b6f3144fb70740/kiwisolver-1.4.7-cp38-cp38-win_amd64.whl", hash = "sha256:d83db7cde68459fc803052a55ace60bea2bae361fc3b7a6d5da07e11954e4b09", size = 55836 },
    { url = "https://files.pythonhosted.org/packages/11/88/37ea0ea64512997b13d69772db8dcdc3bfca5442cda3a5e4bb943652ee3e/kiwisolver-1.4.7-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:3f9362ecfca44c863569d3d3c033dbe8ba452ff8eed6f6b5806382741a1334bd", size = 122449 },
    { url = "https://files.pythonhosted.org/packages/4e/45/5a5c46078362cb3882dcacad687c503089263c017ca1241e0483857791eb/kiwisolver-1.4.7-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:e8df2eb9b2bac43ef8b082e06f750350fbbaf2887534a5be97f6cf07b19d9583", size = 65757 },
    { url = "https://files.pythonhosted.org/packages/8a/be/a6ae58978772f685d48dd2e84460937761c53c4bbd84e42b0336473d9775/kiwisolver-1.4.7-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:f32d6edbc638cde7652bd690c3e728b25332acbadd7cad670cc4a02558d9c417", size = 64312 },
    { url = "https://files.pythonhosted.org/packages/f4/04/18ef6f452d311e1e1eb180c9bf5589187fa1f042db877e6fe443ef10099c/kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.whl", hash = "sha256:e2e6c39bd7b9372b0be21456caab138e8e69cc0fc1190a9dfa92bd45a1e6e904", size = 1626966 },
    { url = "https://files.pythonhosted.org/packages/21/b1/40655f6c3fa11ce740e8a964fa8e4c0479c87d6a7944b95af799c7a55dfe/kiwisolver-1.4.7-cp39-cp39-manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:dda56c24d869b1193fcc763f1284b9126550eaf84b88bbc7256e15028f19188a", size = 1607044 },
    { url = "https://files.pythonhosted.org/packages/fd/93/af67dbcfb9b3323bbd2c2db1385a7139d8f77630e4a37bb945b57188eb2d/kiwisolver-1.4.7-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:79849239c39b5e1fd906556c474d9b0439ea6792b637511f3fe3a41158d89ca8", size = 1391879 },
    { url = "https://files.pythonhosted.org/packages/40/6f/d60770ef98e77b365d96061d090c0cd9e23418121c55fff188fa4bdf0b54/kiwisolver-1.4.7-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:5e3bc157fed2a4c02ec468de4ecd12a6e22818d4f09cde2c31ee3226ffbefab2", size = 1504751 },
    { url = "https://files.pythonhosted.org/packages/fa/3a/5f38667d313e983c432f3fcd86932177519ed8790c724e07d77d1de0188a/kiwisolver-1.4.7-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:3da53da805b71e41053dc670f9a820d1157aae77b6b944e08024d17bcd51ef88", size = 1436990 },
    { url = "https://files.pythonhosted.org/packages/cb/3b/1520301a47326e6a6043b502647e42892be33b3f051e9791cc8bb43f1a32/kiwisolver-1.4.7-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:8705f17dfeb43139a692298cb6637ee2e59c0194538153e83e9ee0c75c2eddde", size = 2191122 },
    { url = "https://files.pythonhosted.org/packages/cf/c4/eb52da300c166239a2233f1f9c4a1b767dfab98fae27681bfb7ea4873cb6/kiwisolver-1.4.7-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:82a5c2f4b87c26bb1a0ef3d16b5c4753434633b83d365cc0ddf2770c93829e3c", size = 2338126 },
    { url = "https://files.pythonhosted.org/packages/1a/cb/42b92fd5eadd708dd9107c089e817945500685f3437ce1fd387efebc6d6e/kiwisolver-1.4.7-cp39-cp39-musllinux_1_2_ppc64le.whl", hash = "sha256:ce8be0466f4c0d585cdb6c1e2ed07232221df101a4c6f28821d2aa754ca2d9e2", size = 2298313 },
    { url = "https://files.pythonhosted.org/packages/4f/eb/be25aa791fe5fc75a8b1e0c965e00f942496bc04635c9aae8035f6b76dcd/kiwisolver-1.4.7-cp39-cp39-musllinux_1_2_s390x.whl", hash = "sha256:409afdfe1e2e90e6ee7fc896f3df9a7fec8e793e58bfa0d052c8a82f99c37abb", size = 2437784 },
    { url = "https://files.pythonhosted.org/packages/c5/22/30a66be7f3368d76ff95689e1c2e28d382383952964ab15330a15d8bfd03/kiwisolver-1.4.7-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:5b9c3f4ee0b9a439d2415012bd1b1cc2df59e4d6a9939f4d669241d30b414327", size = 2253988 },
    { url = "https://files.pythonhosted.org/packages/35/d3/5f2ecb94b5211c8a04f218a76133cc8d6d153b0f9cd0b45fad79907f0689/kiwisolver-1.4.7-cp39-cp39-win32.whl", hash = "sha256:a79ae34384df2b615eefca647a2873842ac3b596418032bef9a7283675962644", size = 46980 },
    { url = "https://files.pythonhosted.org/packages/ef/17/cd10d020578764ea91740204edc6b3236ed8106228a46f568d716b11feb2/kiwisolver-1.4.7-cp39-cp39-win_amd64.whl", hash = "sha256:cf0438b42121a66a3a667de17e779330fc0f20b0d97d59d2f2121e182b0505e4", size = 55847 },
    { url = "https://files.pythonhosted.org/packages/91/84/32232502020bd78d1d12be7afde15811c64a95ed1f606c10456db4e4c3ac/kiwisolver-1.4.7-cp39-cp39-win_arm64.whl", hash = "sha256:764202cc7e70f767dab49e8df52c7455e8de0df5d858fa801a11aa0d882ccf3f", size = 48494 },
    { url = "https://files.pythonhosted.org/packages/ac/59/741b79775d67ab67ced9bb38552da688c0305c16e7ee24bba7a2be253fb7/kiwisolver-1.4.7-pp310-pypy310_pp73-macosx_10_15_x86_64.whl", hash = "sha256:94252291e3fe68001b1dd747b4c0b3be12582839b95ad4d1b641924d68fd4643", size = 59491 },
    { url = "https://files.pythonhosted.org/packages/58/cc/fb239294c29a5656e99e3527f7369b174dd9cc7c3ef2dea7cb3c54a8737b/kiwisolver-1.4.7-pp310-pypy310_pp73-macosx_11_0_arm64.whl", hash = "sha256:5b7dfa3b546da08a9f622bb6becdb14b3e24aaa30adba66749d38f3cc7ea9706", size = 57648 },
    { url = "https://files.pythonhosted.org/packages/3b/ef/2f009ac1f7aab9f81efb2d837301d255279d618d27b6015780115ac64bdd/kiwisolver-1.4.7-pp310-pypy310_pp73-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:bd3de6481f4ed8b734da5df134cd5a6a64fe32124fe83dde1e5b5f29fe30b1e6", size = 84257 },
    { url = "https://files.pythonhosted.org/packages/81/e1/c64f50987f85b68b1c52b464bb5bf73e71570c0f7782d626d1eb283ad620/kiwisolver-1.4.7-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a91b5f9f1205845d488c928e8570dcb62b893372f63b8b6e98b863ebd2368ff2", size = 80906 },
    { url = "https://files.pythonhosted.org/packages/fd/71/1687c5c0a0be2cee39a5c9c389e546f9c6e215e46b691d00d9f646892083/kiwisolver-1.4.7-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:40fa14dbd66b8b8f470d5fc79c089a66185619d31645f9b0773b88b19f7223c4", size = 79951 },
    { url = "https://files.pythonhosted.org/packages/ea/8b/d7497df4a1cae9367adf21665dd1f896c2a7aeb8769ad77b662c5e2bcce7/kiwisolver-1.4.7-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:eb542fe7933aa09d8d8f9d9097ef37532a7df6497819d16efe4359890a2f417a", size = 55715 },
    { url = "https://files.pythonhosted.org/packages/64/f3/2403d90821fffe496df16f6996cb328b90b0d80c06d2938a930a7732b4f1/kiwisolver-1.4.7-pp38-pypy38_pp73-macosx_10_9_x86_64.whl", hash = "sha256:bfa1acfa0c54932d5607e19a2c24646fb4c1ae2694437789129cf099789a3b00", size = 59662 },
    { url = "https://files.pythonhosted.org/packages/fa/7d/8f409736a4a6ac04354fa530ebf46682ddb1539b0bae15f4731ff2c575bc/kiwisolver-1.4.7-pp38-pypy38_pp73-macosx_11_0_arm64.whl", hash = "sha256:eee3ea935c3d227d49b4eb85660ff631556841f6e567f0f7bda972df6c2c9935", size = 57753 },
    { url = "https://files.pythonhosted.org/packages/4c/a5/3937c9abe8eedb1356071739ad437a0b486cbad27d54f4ec4733d24882ac/kiwisolver-1.4.7-pp38-pypy38_pp73-manylinux_2_12_i686.manylinux2010_i686.whl", hash = "sha256:f3160309af4396e0ed04db259c3ccbfdc3621b5559b5453075e5de555e1f3a1b", size = 103564 },
    { url = "https://files.pythonhosted.org/packages/b2/18/a5ae23888f010b90d5eb8d196fed30e268056b2ded54d25b38a193bb70e9/kiwisolver-1.4.7-pp38-pypy38_pp73-manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:a17f6a29cf8935e587cc8a4dbfc8368c55edc645283db0ce9801016f83526c2d", size = 95264 },
    { url = "https://files.pythonhosted.org/packages/f9/d0/c4240ae86306d4395e9701f1d7e6ddcc6d60c28cb0127139176cfcfc9ebe/kiwisolver-1.4.7-pp38-pypy38_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:10849fb2c1ecbfae45a693c070e0320a91b35dd4bcf58172c023b994283a124d", size = 78197 },
    { url = "https://files.pythonhosted.org/packages/62/db/62423f0ab66813376a35c1e7da488ebdb4e808fcb54b7cec33959717bda1/kiwisolver-1.4.7-pp38-pypy38_pp73-win_amd64.whl", hash = "sha256:ac542bf38a8a4be2dc6b15248d36315ccc65f0743f7b1a76688ffb6b5129a5c2", size = 56080 },
    { url = "https://files.pythonhosted.org/packages/d5/df/ce37d9b26f07ab90880923c94d12a6ff4d27447096b4c849bfc4339ccfdf/kiwisolver-1.4.7-pp39-pypy39_pp73-macosx_10_15_x86_64.whl", hash = "sha256:8b01aac285f91ca889c800042c35ad3b239e704b150cfd3382adfc9dcc780e39", size = 58666 },
    { url = "https://files.pythonhosted.org/packages/b0/d3/e4b04f43bc629ac8e186b77b2b1a251cdfa5b7610fa189dc0db622672ce6/kiwisolver-1.4.7-pp39-pypy39_pp73-macosx_11_0_arm64.whl", hash = "sha256:48be928f59a1f5c8207154f935334d374e79f2b5d212826307d072595ad76a2e", size = 57088 },
    { url = "https://files.pythonhosted.org/packages/30/1c/752df58e2d339e670a535514d2db4fe8c842ce459776b8080fbe08ebb98e/kiwisolver-1.4.7-pp39-pypy39_pp73-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f37cfe618a117e50d8c240555331160d73d0411422b59b5ee217843d7b693608", size = 84321 },
    { url = "https://files.pythonhosted.org/packages/f0/f8/fe6484e847bc6e238ec9f9828089fb2c0bb53f2f5f3a79351fde5b565e4f/kiwisolver-1.4.7-pp39-pypy39_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:599b5c873c63a1f6ed7eead644a8a380cfbdf5db91dcb6f85707aaab213b1674", size = 80776 },
    { url = "https://files.pythonhosted.org/packages/9b/57/d7163c0379f250ef763aba85330a19feefb5ce6cb541ade853aaba881524/kiwisolver-1.4.7-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:801fa7802e5cfabe3ab0c81a34c323a319b097dfb5004be950482d882f3d7225", size = 79984 },
    { url = "https://files.pythonhosted.org/packages/8c/95/4a103776c265d13b3d2cd24fb0494d4e04ea435a8ef97e1b2c026d43250b/kiwisolver-1.4.7-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:0c6c43471bc764fad4bc99c5c2d6d16a676b1abf844ca7c8702bdae92df01ee0", size = 55811 },
]

[[package]]
name = "langcodes"
version = "3.4.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "language-data" },
]
sdist = { url = "https://files.pythonhosted.org/packages/f4/79/adb488d97c8bad22fe69a1966c3fb47eb38b22598324d8ffbc5e88bc475d/langcodes-3.4.1.tar.gz", hash = "sha256:a24879fed238013ac3af2424b9d1124e38b4a38b2044fd297c8ff38e5912e718", size = 190832 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e8/fc/79a44f4bc84b8e669dad3ca5652263477c7ecfc830d09777a214317915f9/langcodes-3.4.1-py3-none-any.whl", hash = "sha256:68f686fc3d358f222674ecf697ddcee3ace3c2fe325083ecad2543fd28a20e77", size = 182392 },
]

[[package]]
name = "language-data"
version = "1.3.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "marisa-trie" },
]
sdist = { url = "https://files.pythonhosted.org/packages/dd/ce/3f144716a9f2cbf42aa86ebc8b085a184be25c80aa453eea17c294d239c1/language_data-1.3.0.tar.gz", hash = "sha256:7600ef8aa39555145d06c89f0c324bf7dab834ea0b0a439d8243762e3ebad7ec", size = 5129310 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/5d/e9/5a5ffd9b286db82be70d677d0a91e4d58f7912bb8dd026ddeeb4abe70679/language_data-1.3.0-py3-none-any.whl", hash = "sha256:e2ee943551b5ae5f89cd0e801d1fc3835bb0ef5b7e9c3a4e8e17b2b214548fbf", size = 5385760 },
]

[[package]]
name = "lxml"
version = "5.3.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/ef/f6/c15ca8e5646e937c148e147244817672cf920b56ac0bf2cc1512ae674be8/lxml-5.3.1.tar.gz", hash = "sha256:106b7b5d2977b339f1e97efe2778e2ab20e99994cbb0ec5e55771ed0795920c8", size = 3678591 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/80/4b/73426192004a643c11a644ed2346dbe72da164c8e775ea2e70f60e63e516/lxml-5.3.1-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:a4058f16cee694577f7e4dd410263cd0ef75644b43802a689c2b3c2a7e69453b", size = 8142766 },
    { url = "https://files.pythonhosted.org/packages/30/c2/3b28f642b43fdf9580d936e8fdd3ec43c01a97ecfe17fd67f76ce9099752/lxml-5.3.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:364de8f57d6eda0c16dcfb999af902da31396949efa0e583e12675d09709881b", size = 4422744 },
    { url = "https://files.pythonhosted.org/packages/1f/a5/45279e464174b99d72d25bc018b097f9211c0925a174ca582a415609f036/lxml-5.3.1-cp310-cp310-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:528f3a0498a8edc69af0559bdcf8a9f5a8bf7c00051a6ef3141fdcf27017bbf5", size = 5229609 },
    { url = "https://files.pythonhosted.org/packages/f0/e7/10cd8b9e27ffb6b3465b76604725b67b7c70d4e399750ff88de1b38ab9eb/lxml-5.3.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:db4743e30d6f5f92b6d2b7c86b3ad250e0bad8dee4b7ad8a0c44bfb276af89a3", size = 4943509 },
    { url = "https://files.pythonhosted.org/packages/ce/54/2d6f634924920b17122445136345d44c6d69178c9c49e161aa8f206739d6/lxml-5.3.1-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:17b5d7f8acf809465086d498d62a981fa6a56d2718135bb0e4aa48c502055f5c", size = 5561495 },
    { url = "https://files.pythonhosted.org/packages/a2/fe/7f5ae8fd1f357fcb21b0d4e20416fae870d654380b6487adbcaaf0df9b31/lxml-5.3.1-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:928e75a7200a4c09e6efc7482a1337919cc61fe1ba289f297827a5b76d8969c2", size = 4998970 },
    { url = "https://files.pythonhosted.org/packages/af/70/22fecb6f2ca8dc77d14ab6be3cef767ff8340040bc95dca384b5b1cb333a/lxml-5.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:5a997b784a639e05b9d4053ef3b20c7e447ea80814a762f25b8ed5a89d261eac", size = 5114205 },
    { url = "https://files.pythonhosted.org/packages/63/91/21619cc14f7fd1de3f1bdf86cc8106edacf4d685b540d658d84247a3a32a/lxml-5.3.1-cp310-cp310-manylinux_2_28_aarch64.whl", hash = "sha256:7b82e67c5feb682dbb559c3e6b78355f234943053af61606af126df2183b9ef9", size = 4940823 },
    { url = "https://files.pythonhosted.org/packages/50/0f/27183248fa3cdd2040047ceccd320ff1ed1344167f38a4ac26aed092268b/lxml-5.3.1-cp310-cp310-manylinux_2_28_ppc64le.whl", hash = "sha256:f1de541a9893cf8a1b1db9bf0bf670a2decab42e3e82233d36a74eda7822b4c9", size = 5585725 },
    { url = "https://files.pythonhosted.org/packages/c6/8d/9b7388d5b23ed2f239a992a478cbd0ce313aaa2d008dd73c4042b190b6a9/lxml-5.3.1-cp310-cp310-manylinux_2_28_s390x.whl", hash = "sha256:de1fc314c3ad6bc2f6bd5b5a5b9357b8c6896333d27fdbb7049aea8bd5af2d79", size = 5082641 },
    { url = "https://files.pythonhosted.org/packages/65/8e/590e20833220eac55b6abcde71d3ae629d38ac1c3543bcc2bfe1f3c2f5d1/lxml-5.3.1-cp310-cp310-manylinux_2_28_x86_64.whl", hash = "sha256:7c0536bd9178f754b277a3e53f90f9c9454a3bd108b1531ffff720e082d824f2", size = 5161219 },
    { url = "https://files.pythonhosted.org/packages/4e/77/cabdf5569fd0415a88ebd1d62d7f2814e71422439b8564aaa03e7eefc069/lxml-5.3.1-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:68018c4c67d7e89951a91fbd371e2e34cd8cfc71f0bb43b5332db38497025d51", size = 5019293 },
    { url = "https://files.pythonhosted.org/packages/49/bd/f0b6d50ea7b8b54aaa5df4410cb1d5ae6ffa016b8e0503cae08b86c24674/lxml-5.3.1-cp310-cp310-musllinux_1_2_ppc64le.whl", hash = "sha256:aa826340a609d0c954ba52fd831f0fba2a4165659ab0ee1a15e4aac21f302406", size = 5651232 },
    { url = "https://files.pythonhosted.org/packages/fa/69/1793d00a4e3da7f27349edb5a6f3da947ed921263cd9a243fab11c6cbc07/lxml-5.3.1-cp310-cp310-musllinux_1_2_s390x.whl", hash = "sha256:796520afa499732191e39fc95b56a3b07f95256f2d22b1c26e217fb69a9db5b5", size = 5489527 },
    { url = "https://files.pythonhosted.org/packages/d3/c9/e2449129b6cb2054c898df8d850ea4dadd75b4c33695a6c4b0f35082f1e7/lxml-5.3.1-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:3effe081b3135237da6e4c4530ff2a868d3f80be0bda027e118a5971285d42d0", size = 5227050 },
    { url = "https://files.pythonhosted.org/packages/ed/63/e5da540eba6ab9a0d4188eeaa5c85767b77cafa8efeb70da0593d6cd3b81/lxml-5.3.1-cp310-cp310-win32.whl", hash = "sha256:a22f66270bd6d0804b02cd49dae2b33d4341015545d17f8426f2c4e22f557a23", size = 3475345 },
    { url = "https://files.pythonhosted.org/packages/08/71/853a3ad812cd24c35b7776977cb0ae40c2b64ff79ad6d6c36c987daffc49/lxml-5.3.1-cp310-cp310-win_amd64.whl", hash = "sha256:0bcfadea3cdc68e678d2b20cb16a16716887dd00a881e16f7d806c2138b8ff0c", size = 3805093 },
    { url = "https://files.pythonhosted.org/packages/57/bb/2faea15df82114fa27f2a86eec220506c532ee8ce211dff22f48881b353a/lxml-5.3.1-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:e220f7b3e8656ab063d2eb0cd536fafef396829cafe04cb314e734f87649058f", size = 8161781 },
    { url = "https://files.pythonhosted.org/packages/9f/d3/374114084abb1f96026eccb6cd48b070f85de82fdabae6c2f1e198fa64e5/lxml-5.3.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:0f2cfae0688fd01f7056a17367e3b84f37c545fb447d7282cf2c242b16262607", size = 4432571 },
    { url = "https://files.pythonhosted.org/packages/0f/fb/44a46efdc235c2dd763c1e929611d8ff3b920c32b8fcd9051d38f4d04633/lxml-5.3.1-cp311-cp311-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:67d2f8ad9dcc3a9e826bdc7802ed541a44e124c29b7d95a679eeb58c1c14ade8", size = 5028919 },
    { url = "https://files.pythonhosted.org/packages/3b/e5/168ddf9f16a90b590df509858ae97a8219d6999d5a132ad9f72427454bed/lxml-5.3.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:db0c742aad702fd5d0c6611a73f9602f20aec2007c102630c06d7633d9c8f09a", size = 4769599 },
    { url = "https://files.pythonhosted.org/packages/f9/0e/3e2742c6f4854b202eb8587c1f7ed760179f6a9fcb34a460497c8c8f3078/lxml-5.3.1-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:198bb4b4dd888e8390afa4f170d4fa28467a7eaf857f1952589f16cfbb67af27", size = 5369260 },
    { url = "https://files.pythonhosted.org/packages/b8/03/b2f2ab9e33c47609c80665e75efed258b030717e06693835413b34e797cb/lxml-5.3.1-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:d2a3e412ce1849be34b45922bfef03df32d1410a06d1cdeb793a343c2f1fd666", size = 4842798 },
    { url = "https://files.pythonhosted.org/packages/93/ad/0ecfb082b842358c8a9e3115ec944b7240f89821baa8cd7c0cb8a38e05cb/lxml-5.3.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2b8969dbc8d09d9cd2ae06362c3bad27d03f433252601ef658a49bd9f2b22d79", size = 4917531 },
    { url = "https://files.pythonhosted.org/packages/64/5b/3e93d8ebd2b7eb984c2ad74dfff75493ce96e7b954b12e4f5fc34a700414/lxml-5.3.1-cp311-cp311-manylinux_2_28_aarch64.whl", hash = "sha256:5be8f5e4044146a69c96077c7e08f0709c13a314aa5315981185c1f00235fe65", size = 4791500 },
    { url = "https://files.pythonhosted.org/packages/91/83/7dc412362ee7a0259c7f64349393262525061fad551a1340ef92c59d9732/lxml-5.3.1-cp311-cp311-manylinux_2_28_ppc64le.whl", hash = "sha256:133f3493253a00db2c870d3740bc458ebb7d937bd0a6a4f9328373e0db305709", size = 5404557 },
    { url = "https://files.pythonhosted.org/packages/1e/41/c337f121d9dca148431f246825e021fa1a3f66a6b975deab1950530fdb04/lxml-5.3.1-cp311-cp311-manylinux_2_28_s390x.whl", hash = "sha256:52d82b0d436edd6a1d22d94a344b9a58abd6c68c357ed44f22d4ba8179b37629", size = 4931386 },
    { url = "https://files.pythonhosted.org/packages/a5/73/762c319c4906b3db67e4abc7cfe7d66c34996edb6d0e8cb60f462954d662/lxml-5.3.1-cp311-cp311-manylinux_2_28_x86_64.whl", hash = "sha256:1b6f92e35e2658a5ed51c6634ceb5ddae32053182851d8cad2a5bc102a359b33", size = 4982124 },
    { url = "https://files.pythonhosted.org/packages/c1/e7/d1e296cb3b3b46371220a31350730948d7bea41cc9123c5fd219dea33c29/lxml-5.3.1-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:203b1d3eaebd34277be06a3eb880050f18a4e4d60861efba4fb946e31071a295", size = 4852742 },
    { url = "https://files.pythonhosted.org/packages/df/90/4adc854475105b93ead6c0c736f762d29371751340dcf5588cfcf8191b8a/lxml-5.3.1-cp311-cp311-musllinux_1_2_ppc64le.whl", hash = "sha256:155e1a5693cf4b55af652f5c0f78ef36596c7f680ff3ec6eb4d7d85367259b2c", size = 5457004 },
    { url = "https://files.pythonhosted.org/packages/f0/0d/39864efbd231c13eb53edee2ab91c742c24d2f93efe2af7d3fe4343e42c1/lxml-5.3.1-cp311-cp311-musllinux_1_2_s390x.whl", hash = "sha256:22ec2b3c191f43ed21f9545e9df94c37c6b49a5af0a874008ddc9132d49a2d9c", size = 5298185 },
    { url = "https://files.pythonhosted.org/packages/8d/7a/630a64ceb1088196de182e2e33b5899691c3e1ae21af688e394208bd6810/lxml-5.3.1-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:7eda194dd46e40ec745bf76795a7cccb02a6a41f445ad49d3cf66518b0bd9cff", size = 5032707 },
    { url = "https://files.pythonhosted.org/packages/b2/3d/091bc7b592333754cb346c1507ca948ab39bc89d83577ac8f1da3be4dece/lxml-5.3.1-cp311-cp311-win32.whl", hash = "sha256:fb7c61d4be18e930f75948705e9718618862e6fc2ed0d7159b2262be73f167a2", size = 3474288 },
    { url = "https://files.pythonhosted.org/packages/12/8c/7d47cfc0d04fd4e3639ec7e1c96c2561d5e890eb900de8f76eea75e0964a/lxml-5.3.1-cp311-cp311-win_amd64.whl", hash = "sha256:c809eef167bf4a57af4b03007004896f5c60bd38dc3852fcd97a26eae3d4c9e6", size = 3815031 },
    { url = "https://files.pythonhosted.org/packages/3b/f4/5121aa9ee8e09b8b8a28cf3709552efe3d206ca51a20d6fa471b60bb3447/lxml-5.3.1-cp312-cp312-macosx_10_9_universal2.whl", hash = "sha256:e69add9b6b7b08c60d7ff0152c7c9a6c45b4a71a919be5abde6f98f1ea16421c", size = 8191889 },
    { url = "https://files.pythonhosted.org/packages/0a/ca/8e9aa01edddc74878f4aea85aa9ab64372f46aa804d1c36dda861bf9eabf/lxml-5.3.1-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:4e52e1b148867b01c05e21837586ee307a01e793b94072d7c7b91d2c2da02ffe", size = 4450685 },
    { url = "https://files.pythonhosted.org/packages/b2/b3/ea40a5c98619fbd7e9349df7007994506d396b97620ced34e4e5053d3734/lxml-5.3.1-cp312-cp312-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:a4b382e0e636ed54cd278791d93fe2c4f370772743f02bcbe431a160089025c9", size = 5051722 },
    { url = "https://files.pythonhosted.org/packages/3a/5e/375418be35f8a695cadfe7e7412f16520e62e24952ed93c64c9554755464/lxml-5.3.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c2e49dc23a10a1296b04ca9db200c44d3eb32c8d8ec532e8c1fd24792276522a", size = 4786661 },
    { url = "https://files.pythonhosted.org/packages/79/7c/d258eaaa9560f6664f9b426a5165103015bee6512d8931e17342278bad0a/lxml-5.3.1-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:4399b4226c4785575fb20998dc571bc48125dc92c367ce2602d0d70e0c455eb0", size = 5311766 },
    { url = "https://files.pythonhosted.org/packages/03/bc/a041415be4135a1b3fdf017a5d873244cc16689456166fbdec4b27fba153/lxml-5.3.1-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5412500e0dc5481b1ee9cf6b38bb3b473f6e411eb62b83dc9b62699c3b7b79f7", size = 4836014 },
    { url = "https://files.pythonhosted.org/packages/32/88/047f24967d5e3fc97848ea2c207eeef0f16239cdc47368c8b95a8dc93a33/lxml-5.3.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1c93ed3c998ea8472be98fb55aed65b5198740bfceaec07b2eba551e55b7b9ae", size = 4961064 },
    { url = "https://files.pythonhosted.org/packages/3d/b5/ecf5a20937ecd21af02c5374020f4e3a3538e10a32379a7553fca3d77094/lxml-5.3.1-cp312-cp312-manylinux_2_28_aarch64.whl", hash = "sha256:63d57fc94eb0bbb4735e45517afc21ef262991d8758a8f2f05dd6e4174944519", size = 4778341 },
    { url = "https://files.pythonhosted.org/packages/a4/05/56c359e07275911ed5f35ab1d63c8cd3360d395fb91e43927a2ae90b0322/lxml-5.3.1-cp312-cp312-manylinux_2_28_ppc64le.whl", hash = "sha256:b450d7cabcd49aa7ab46a3c6aa3ac7e1593600a1a0605ba536ec0f1b99a04322", size = 5345450 },
    { url = "https://files.pythonhosted.org/packages/b7/f4/f95e3ae12e9f32fbcde00f9affa6b0df07f495117f62dbb796a9a31c84d6/lxml-5.3.1-cp312-cp312-manylinux_2_28_s390x.whl", hash = "sha256:4df0ec814b50275ad6a99bc82a38b59f90e10e47714ac9871e1b223895825468", size = 4908336 },
    { url = "https://files.pythonhosted.org/packages/c5/f8/309546aec092434166a6e11c7dcecb5c2d0a787c18c072d61e18da9eba57/lxml-5.3.1-cp312-cp312-manylinux_2_28_x86_64.whl", hash = "sha256:d184f85ad2bb1f261eac55cddfcf62a70dee89982c978e92b9a74a1bfef2e367", size = 4986049 },
    { url = "https://files.pythonhosted.org/packages/71/1c/b951817cb5058ca7c332d012dfe8bc59dabd0f0a8911ddd7b7ea8e41cfbd/lxml-5.3.1-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:b725e70d15906d24615201e650d5b0388b08a5187a55f119f25874d0103f90dd", size = 4860351 },
    { url = "https://files.pythonhosted.org/packages/31/23/45feba8dae1d35fcca1e51b051f59dc4223cbd23e071a31e25f3f73938a8/lxml-5.3.1-cp312-cp312-musllinux_1_2_ppc64le.whl", hash = "sha256:a31fa7536ec1fb7155a0cd3a4e3d956c835ad0a43e3610ca32384d01f079ea1c", size = 5421580 },
    { url = "https://files.pythonhosted.org/packages/61/69/be245d7b2dbef81c542af59c97fcd641fbf45accf2dc1c325bae7d0d014c/lxml-5.3.1-cp312-cp312-musllinux_1_2_s390x.whl", hash = "sha256:3c3c8b55c7fc7b7e8877b9366568cc73d68b82da7fe33d8b98527b73857a225f", size = 5285778 },
    { url = "https://files.pythonhosted.org/packages/69/06/128af2ed04bac99b8f83becfb74c480f1aa18407b5c329fad457e08a1bf4/lxml-5.3.1-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:d61ec60945d694df806a9aec88e8f29a27293c6e424f8ff91c80416e3c617645", size = 5054455 },
    { url = "https://files.pythonhosted.org/packages/8a/2d/f03a21cf6cc75cdd083563e509c7b6b159d761115c4142abb5481094ed8c/lxml-5.3.1-cp312-cp312-win32.whl", hash = "sha256:f4eac0584cdc3285ef2e74eee1513a6001681fd9753b259e8159421ed28a72e5", size = 3486315 },
    { url = "https://files.pythonhosted.org/packages/2b/9c/8abe21585d20ef70ad9cec7562da4332b764ed69ec29b7389d23dfabcea0/lxml-5.3.1-cp312-cp312-win_amd64.whl", hash = "sha256:29bfc8d3d88e56ea0a27e7c4897b642706840247f59f4377d81be8f32aa0cfbf", size = 3816925 },
    { url = "https://files.pythonhosted.org/packages/94/1c/724931daa1ace168e0237b929e44062545bf1551974102a5762c349c668d/lxml-5.3.1-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:c093c7088b40d8266f57ed71d93112bd64c6724d31f0794c1e52cc4857c28e0e", size = 8171881 },
    { url = "https://files.pythonhosted.org/packages/67/0c/857b8fb6010c4246e66abeebb8639eaabba60a6d9b7c606554ecc5cbf1ee/lxml-5.3.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:b0884e3f22d87c30694e625b1e62e6f30d39782c806287450d9dc2fdf07692fd", size = 4440394 },
    { url = "https://files.pythonhosted.org/packages/61/72/c9e81de6a000f9682ccdd13503db26e973b24c68ac45a7029173237e3eed/lxml-5.3.1-cp313-cp313-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:1637fa31ec682cd5760092adfabe86d9b718a75d43e65e211d5931809bc111e7", size = 5037860 },
    { url = "https://files.pythonhosted.org/packages/24/26/942048c4b14835711b583b48cd7209bd2b5f0b6939ceed2381a494138b14/lxml-5.3.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a364e8e944d92dcbf33b6b494d4e0fb3499dcc3bd9485beb701aa4b4201fa414", size = 4782513 },
    { url = "https://files.pythonhosted.org/packages/e2/65/27792339caf00f610cc5be32b940ba1e3009b7054feb0c4527cebac228d4/lxml-5.3.1-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:779e851fd0e19795ccc8a9bb4d705d6baa0ef475329fe44a13cf1e962f18ff1e", size = 5305227 },
    { url = "https://files.pythonhosted.org/packages/18/e1/25f7aa434a4d0d8e8420580af05ea49c3e12db6d297cf5435ac0a054df56/lxml-5.3.1-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:c4393600915c308e546dc7003d74371744234e8444a28622d76fe19b98fa59d1", size = 4829846 },
    { url = "https://files.pythonhosted.org/packages/fe/ed/faf235e0792547d24f61ee1448159325448a7e4f2ab706503049d8e5df19/lxml-5.3.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:673b9d8e780f455091200bba8534d5f4f465944cbdd61f31dc832d70e29064a5", size = 4949495 },
    { url = "https://files.pythonhosted.org/packages/e5/e1/8f572ad9ed6039ba30f26dd4c2c58fb90f79362d2ee35ca3820284767672/lxml-5.3.1-cp313-cp313-manylinux_2_28_aarch64.whl", hash = "sha256:2e4a570f6a99e96c457f7bec5ad459c9c420ee80b99eb04cbfcfe3fc18ec6423", size = 4773415 },
    { url = "https://files.pythonhosted.org/packages/a3/75/6b57166b9d1983dac8f28f354e38bff8d6bcab013a241989c4d54c72701b/lxml-5.3.1-cp313-cp313-manylinux_2_28_ppc64le.whl", hash = "sha256:71f31eda4e370f46af42fc9f264fafa1b09f46ba07bdbee98f25689a04b81c20", size = 5337710 },
    { url = "https://files.pythonhosted.org/packages/cc/71/4aa56e2daa83bbcc66ca27b5155be2f900d996f5d0c51078eaaac8df9547/lxml-5.3.1-cp313-cp313-manylinux_2_28_s390x.whl", hash = "sha256:42978a68d3825eaac55399eb37a4d52012a205c0c6262199b8b44fcc6fd686e8", size = 4897362 },
    { url = "https://files.pythonhosted.org/packages/65/10/3fa2da152cd9b49332fd23356ed7643c9b74cad636ddd5b2400a9730d12b/lxml-5.3.1-cp313-cp313-manylinux_2_28_x86_64.whl", hash = "sha256:8b1942b3e4ed9ed551ed3083a2e6e0772de1e5e3aca872d955e2e86385fb7ff9", size = 4977795 },
    { url = "https://files.pythonhosted.org/packages/de/d2/e1da0f7b20827e7b0ce934963cb6334c1b02cf1bb4aecd218c4496880cb3/lxml-5.3.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:85c4f11be9cf08917ac2a5a8b6e1ef63b2f8e3799cec194417e76826e5f1de9c", size = 4858104 },
    { url = "https://files.pythonhosted.org/packages/a5/35/063420e1b33d3308f5aa7fcbdd19ef6c036f741c9a7a4bd5dc8032486b27/lxml-5.3.1-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:231cf4d140b22a923b1d0a0a4e0b4f972e5893efcdec188934cc65888fd0227b", size = 5416531 },
    { url = "https://files.pythonhosted.org/packages/c3/83/93a6457d291d1e37adfb54df23498101a4701834258c840381dd2f6a030e/lxml-5.3.1-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:5865b270b420eda7b68928d70bb517ccbe045e53b1a428129bb44372bf3d7dd5", size = 5273040 },
    { url = "https://files.pythonhosted.org/packages/39/25/ad4ac8fac488505a2702656550e63c2a8db3a4fd63db82a20dad5689cecb/lxml-5.3.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:dbf7bebc2275016cddf3c997bf8a0f7044160714c64a9b83975670a04e6d2252", size = 5050951 },
    { url = "https://files.pythonhosted.org/packages/82/74/f7d223c704c87e44b3d27b5e0dde173a2fcf2e89c0524c8015c2b3554876/lxml-5.3.1-cp313-cp313-win32.whl", hash = "sha256:d0751528b97d2b19a388b302be2a0ee05817097bab46ff0ed76feeec24951f78", size = 3485357 },
    { url = "https://files.pythonhosted.org/packages/80/83/8c54533b3576f4391eebea88454738978669a6cad0d8e23266224007939d/lxml-5.3.1-cp313-cp313-win_amd64.whl", hash = "sha256:91fb6a43d72b4f8863d21f347a9163eecbf36e76e2f51068d59cd004c506f332", size = 3814484 },
    { url = "https://files.pythonhosted.org/packages/3d/99/bd6bf91fa6e2daf544aeb99f0a7a942e3cf40564c9f745bcbbc7bda5a5e8/lxml-5.3.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:b2aca14c235c7a08558fe0a4786a1a05873a01e86b474dfa8f6df49101853a4e", size = 4465413 },
    { url = "https://files.pythonhosted.org/packages/00/7e/46f3167919cab2b81e105afdd86784516689f4e6e02d04fcc039d1381da0/lxml-5.3.1-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ae82fce1d964f065c32c9517309f0c7be588772352d2f40b1574a214bd6e6098", size = 5147664 },
    { url = "https://files.pythonhosted.org/packages/5f/75/72c3f1cd08d93ccfa3a9343959bf4ea99ff41b16a21365dea730bbf97abf/lxml-5.3.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:7aae7a3d63b935babfdc6864b31196afd5145878ddd22f5200729006366bc4d5", size = 4856772 },
    { url = "https://files.pythonhosted.org/packages/b1/c4/4334eecacbbbe4e7ac07c3ea676973d50cb8dd5d7d3f78d9e50dc2991a64/lxml-5.3.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e8e0d177b1fe251c3b1b914ab64135475c5273c8cfd2857964b2e3bb0fe196a7", size = 5027050 },
    { url = "https://files.pythonhosted.org/packages/dc/68/60694897b523b5186540e468f166b06a054856b471bca73ebee60b6c8330/lxml-5.3.1-cp38-cp38-manylinux_2_28_aarch64.whl", hash = "sha256:6c4dd3bfd0c82400060896717dd261137398edb7e524527438c54a8c34f736bf", size = 4848872 },
    { url = "https://files.pythonhosted.org/packages/a1/77/cca85be1418f45d793d006f5641562cb08d6b0ae283b2a41c5d61e8f8d56/lxml-5.3.1-cp38-cp38-manylinux_2_28_x86_64.whl", hash = "sha256:f1208c1c67ec9e151d78aa3435aa9b08a488b53d9cfac9b699f15255a3461ef2", size = 5069839 },
    { url = "https://files.pythonhosted.org/packages/bb/88/0c37d238d5988dd025433d62afa876ac9462b5086e79f006e1b6fc31f183/lxml-5.3.1-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:c6aacf00d05b38a5069826e50ae72751cb5bc27bdc4d5746203988e429b385bb", size = 4920768 },
    { url = "https://files.pythonhosted.org/packages/77/e4/3f5c5faa8fab14455a0287aae88a5f13bd6ee67c1103a3ea49d8d1b299a9/lxml-5.3.1-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:5881aaa4bf3a2d086c5f20371d3a5856199a0d8ac72dd8d0dbd7a2ecfc26ab73", size = 5120806 },
    { url = "https://files.pythonhosted.org/packages/11/be/1249ee83ce2586c1d6f4e6ac5940cce94a07d9cfd75092aba02a94df0e89/lxml-5.3.1-cp38-cp38-win32.whl", hash = "sha256:45fbb70ccbc8683f2fb58bea89498a7274af1d9ec7995e9f4af5604e028233fc", size = 3484412 },
    { url = "https://files.pythonhosted.org/packages/82/08/6807a53e97c1058efe242e75732814496f2281aee2577f9bf0089c68730c/lxml-5.3.1-cp38-cp38-win_amd64.whl", hash = "sha256:7512b4d0fc5339d5abbb14d1843f70499cab90d0b864f790e73f780f041615d7", size = 3814682 },
    { url = "https://files.pythonhosted.org/packages/e6/ed/b27f5dd676e66aa8d7a5cef895c056fc5594b861aa7899d6445dcaa174e6/lxml-5.3.1-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:5885bc586f1edb48e5d68e7a4b4757b5feb2a496b64f462b4d65950f5af3364f", size = 8147771 },
    { url = "https://files.pythonhosted.org/packages/3d/aa/7cf5d1b9301b061aa6ecd956d32ff01a1b3eadfd40e7634adb98f8909302/lxml-5.3.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:1b92fe86e04f680b848fff594a908edfa72b31bfc3499ef7433790c11d4c8cd8", size = 4425579 },
    { url = "https://files.pythonhosted.org/packages/e7/c8/e2f993dec05cd33108e547a65d786bd5a72fe45797d481db409f2102837c/lxml-5.3.1-cp39-cp39-manylinux_2_12_i686.manylinux2010_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:a091026c3bf7519ab1e64655a3f52a59ad4a4e019a6f830c24d6430695b1cf6a", size = 5233161 },
    { url = "https://files.pythonhosted.org/packages/4a/98/561bd6a513a72f018ea951ddd0245afd2f4312d27346a8b719f8306827f0/lxml-5.3.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8ffb141361108e864ab5f1813f66e4e1164181227f9b1f105b042729b6c15125", size = 4945449 },
    { url = "https://files.pythonhosted.org/packages/16/4a/36f84f0e5c40f58a2744e8eb92308e32884411e2fdadbf235168e4991678/lxml-5.3.1-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:3715cdf0dd31b836433af9ee9197af10e3df41d273c19bb249230043667a5dfd", size = 5564649 },
    { url = "https://files.pythonhosted.org/packages/cc/fc/a7c5a1c79d9cbdcb4c73b3b10fa5b73326b04e5324e5856e15a5a276c49c/lxml-5.3.1-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:88b72eb7222d918c967202024812c2bfb4048deeb69ca328363fb8e15254c549", size = 5002027 },
    { url = "https://files.pythonhosted.org/packages/63/f5/981828897caf3790c6c3d73f300a69b9d9bdc074a990a54b881c58386b88/lxml-5.3.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:aa59974880ab5ad8ef3afaa26f9bda148c5f39e06b11a8ada4660ecc9fb2feb3", size = 5115962 },
    { url = "https://files.pythonhosted.org/packages/e7/a1/aec02b84113733fa642e4ad0a5a6fa42126bbb6b3c8c8cac2cd3186f5ebe/lxml-5.3.1-cp39-cp39-manylinux_2_28_aarch64.whl", hash = "sha256:3bb8149840daf2c3f97cebf00e4ed4a65a0baff888bf2605a8d0135ff5cf764e", size = 4941318 },
    { url = "https://files.pythonhosted.org/packages/2d/a7/7d2426b9799651c5e48bc752744dbddc5c13b12b99296b0bb09cb0b4dfdb/lxml-5.3.1-cp39-cp39-manylinux_2_28_ppc64le.whl", hash = "sha256:0d6b2fa86becfa81f0a0271ccb9eb127ad45fb597733a77b92e8a35e53414914", size = 5587564 },
    { url = "https://files.pythonhosted.org/packages/62/b2/2df1030c2da9df240fedb05ea0a993fa6019385d8971ee23054ccb03b8db/lxml-5.3.1-cp39-cp39-manylinux_2_28_s390x.whl", hash = "sha256:136bf638d92848a939fd8f0e06fcf92d9f2e4b57969d94faae27c55f3d85c05b", size = 5081939 },
    { url = "https://files.pythonhosted.org/packages/45/f9/36ffd0cad187c22ed8db618cf68d89df5b2df75c467fc05f8c68d299f16b/lxml-5.3.1-cp39-cp39-manylinux_2_28_x86_64.whl", hash = "sha256:89934f9f791566e54c1d92cdc8f8fd0009447a5ecdb1ec6b810d5f8c4955f6be", size = 5161881 },
    { url = "https://files.pythonhosted.org/packages/29/6d/9f85ac6d67936c3b89daecb8e350e56e8b31d8350a2fe67b348b750eb85b/lxml-5.3.1-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:a8ade0363f776f87f982572c2860cc43c65ace208db49c76df0a21dde4ddd16e", size = 5019764 },
    { url = "https://files.pythonhosted.org/packages/39/77/61438fc6094909f3c570c5f14518e1b01d6361985b1d0895840d5813cf70/lxml-5.3.1-cp39-cp39-musllinux_1_2_ppc64le.whl", hash = "sha256:bfbbab9316330cf81656fed435311386610f78b6c93cc5db4bebbce8dd146675", size = 5650195 },
    { url = "https://files.pythonhosted.org/packages/c4/bf/37a89992b8d1cba68a8bd1623b6c41d9f45f8044c6063a7082ab77790d54/lxml-5.3.1-cp39-cp39-musllinux_1_2_s390x.whl", hash = "sha256:172d65f7c72a35a6879217bcdb4bb11bc88d55fb4879e7569f55616062d387c2", size = 5491896 },
    { url = "https://files.pythonhosted.org/packages/33/12/d7a26ea1308d7bf7c23f8f6be197665ff84cfab94f6bf81098b5059daddb/lxml-5.3.1-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:e3c623923967f3e5961d272718655946e5322b8d058e094764180cdee7bab1af", size = 5227538 },
    { url = "https://files.pythonhosted.org/packages/c7/04/cfd39f2fb0e33c0b91c8718197bf5e6a84d8c488b6706702eb39a11315c2/lxml-5.3.1-cp39-cp39-win32.whl", hash = "sha256:ce0930a963ff593e8bb6fda49a503911accc67dee7e5445eec972668e672a0f0", size = 3478331 },
    { url = "https://files.pythonhosted.org/packages/c2/6f/adc7985a81d3ad6f9898db2c8d4446546cf3c554510ab2451d370b02e99c/lxml-5.3.1-cp39-cp39-win_amd64.whl", hash = "sha256:f7b64fcd670bca8800bc10ced36620c6bbb321e7bc1214b9c0c0df269c1dddc2", size = 3806157 },
    { url = "https://files.pythonhosted.org/packages/d2/b4/89a68d05f267f05cc1b8b2f289a8242955705b1b0a9d246198227817ee46/lxml-5.3.1-pp310-pypy310_pp73-macosx_10_15_x86_64.whl", hash = "sha256:afa578b6524ff85fb365f454cf61683771d0170470c48ad9d170c48075f86725", size = 3936118 },
    { url = "https://files.pythonhosted.org/packages/7f/0d/c034a541e7a1153527d7880c62493a74f2277f38e64de2480cadd0d4cf96/lxml-5.3.1-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:67f5e80adf0aafc7b5454f2c1cb0cde920c9b1f2cbd0485f07cc1d0497c35c5d", size = 4233690 },
    { url = "https://files.pythonhosted.org/packages/35/5c/38e183c2802f14fbdaa75c3266e11d0ca05c64d78e8cdab2ee84e954a565/lxml-5.3.1-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2dd0b80ac2d8f13ffc906123a6f20b459cb50a99222d0da492360512f3e50f84", size = 4349569 },
    { url = "https://files.pythonhosted.org/packages/18/5b/14f93b359b3c29673d5d282bc3a6edb3a629879854a77541841aba37607f/lxml-5.3.1-pp310-pypy310_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:422c179022ecdedbe58b0e242607198580804253da220e9454ffe848daa1cfd2", size = 4236731 },
    { url = "https://files.pythonhosted.org/packages/f6/08/8471de65f3dee70a3a50e7082fd7409f0ac7a1ace777c13fca4aea1a5759/lxml-5.3.1-pp310-pypy310_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:524ccfded8989a6595dbdda80d779fb977dbc9a7bc458864fc9a0c2fc15dc877", size = 4373119 },
    { url = "https://files.pythonhosted.org/packages/83/29/00b9b0322a473aee6cda87473401c9abb19506cd650cc69a8aa38277ea74/lxml-5.3.1-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:48fd46bf7155def2e15287c6f2b133a2f78e2d22cdf55647269977b873c65499", size = 3487718 },
    { url = "https://files.pythonhosted.org/packages/0d/f4/91d56adc29c3c8100ce0a86ca09fe11b627f1fb1e305bb8fc87825bf81ec/lxml-5.3.1-pp38-pypy38_pp73-macosx_10_9_x86_64.whl", hash = "sha256:2f23cf50eccb3255b6e913188291af0150d89dab44137a69e14e4dcb7be981f1", size = 3939193 },
    { url = "https://files.pythonhosted.org/packages/1f/d6/469fc4d9126a03c1aa8bf81e8f02cb37f91c6650e8a20bdac8a0790e1e43/lxml-5.3.1-pp38-pypy38_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:df7e5edac4778127f2bf452e0721a58a1cfa4d1d9eac63bdd650535eb8543615", size = 4240865 },
    { url = "https://files.pythonhosted.org/packages/7f/3a/df07295c793fb14f1f6d2c21dc23ac45512ef8b648de1a8cc9185c3c2018/lxml-5.3.1-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:094b28ed8a8a072b9e9e2113a81fda668d2053f2ca9f2d202c2c8c7c2d6516b1", size = 4353941 },
    { url = "https://files.pythonhosted.org/packages/8c/f8/bc167e3d0a39068b51f47b9d383b21e1d0e2d8b7bf52dd1b8bfc39b14dc3/lxml-5.3.1-pp38-pypy38_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:514fe78fc4b87e7a7601c92492210b20a1b0c6ab20e71e81307d9c2e377c64de", size = 4241488 },
    { url = "https://files.pythonhosted.org/packages/b6/b8/b733fe2330a24e0b9489afd6bcf6546981be53a39ef2cb11c182af91486a/lxml-5.3.1-pp38-pypy38_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:8fffc08de02071c37865a155e5ea5fce0282e1546fd5bde7f6149fcaa32558ac", size = 4374769 },
    { url = "https://files.pythonhosted.org/packages/8b/f6/bb4983b4a210ea5f8b1334715a33626e1ce8e7c37a0610b6cf0a715da520/lxml-5.3.1-pp38-pypy38_pp73-win_amd64.whl", hash = "sha256:4b0d5cdba1b655d5b18042ac9c9ff50bda33568eb80feaaca4fc237b9c4fbfde", size = 3489861 },
    { url = "https://files.pythonhosted.org/packages/6e/cc/3613e2190c0b4ff7ad1b758542daa27d29f66218ea13e33eb49f034e5798/lxml-5.3.1-pp39-pypy39_pp73-macosx_10_15_x86_64.whl", hash = "sha256:3031e4c16b59424e8d78522c69b062d301d951dc55ad8685736c3335a97fc270", size = 3933176 },
    { url = "https://files.pythonhosted.org/packages/23/ab/8149b34aafa61d1deef24f3ec4e56a2cde08ff20b4ea95f5125f61ee8cd1/lxml-5.3.1-pp39-pypy39_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:cb659702a45136c743bc130760c6f137870d4df3a9e14386478b8a0511abcfca", size = 4231180 },
    { url = "https://files.pythonhosted.org/packages/cf/03/1727efdb98eb905ef4f5bd9aadfa0b243b6023101d87aaaa008d8119d4e9/lxml-5.3.1-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:5a11b16a33656ffc43c92a5343a28dc71eefe460bcc2a4923a96f292692709f6", size = 4346504 },
    { url = "https://files.pythonhosted.org/packages/00/1a/1fb699abda7f55e450b851d44f36d8c7c1525cbdbbda5ed095ae0e9ab3fc/lxml-5.3.1-pp39-pypy39_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:c5ae125276f254b01daa73e2c103363d3e99e3e10505686ac7d9d2442dd4627a", size = 4231437 },
    { url = "https://files.pythonhosted.org/packages/6c/f7/7978045dac9457bd952ea97fead4afbf5a98cae786c7a1a7309519c0b509/lxml-5.3.1-pp39-pypy39_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:c76722b5ed4a31ba103e0dc77ab869222ec36efe1a614e42e9bcea88a36186fe", size = 4369959 },
    { url = "https://files.pythonhosted.org/packages/54/9d/33dab9178adfa81d3062bb01eb41da65278e9c367bf31fbeab8803acbe1b/lxml-5.3.1-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:33e06717c00c788ab4e79bc4726ecc50c54b9bfb55355eae21473c145d83c2d2", size = 3486361 },
]

[[package]]
name = "mammoth"
version = "1.9.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "cobble" },
]
sdist = { url = "https://files.pythonhosted.org/packages/d6/a6/27a13ba068cf3ff764d631b8dd71dee1b33040aa8c143f66ce902b7d1da0/mammoth-1.9.0.tar.gz", hash = "sha256:74f5dae10ca240fd9b7a0e1a6deaebe0aad23bc590633ef6f5e868aa9b7042a6", size = 50906 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d0/ab/f8e63fcabc127c6efd68b03633c189ee799a5304fa96c036a325a2894bcb/mammoth-1.9.0-py2.py3-none-any.whl", hash = "sha256:0eea277316586f0ca65d86834aec4de5a0572c83ec54b4991f9bb520a891150f", size = 52901 },
]

[[package]]
name = "marisa-trie"
version = "1.2.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "setuptools" },
]
sdist = { url = "https://files.pythonhosted.org/packages/31/15/9d9743897e4450b2de199ee673b50cb018980c4ced477d41cf91304a85e3/marisa_trie-1.2.1.tar.gz", hash = "sha256:3a27c408e2aefc03e0f1d25b2ff2afb85aac3568f6fa2ae2a53b57a2e87ce29d", size = 416124 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e4/83/ccf5b33f2123f3110705c608f8e0caa82002626511aafafc58f82e50d322/marisa_trie-1.2.1-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:a2eb41d2f9114d8b7bd66772c237111e00d2bae2260824560eaa0a1e291ce9e8", size = 362200 },
    { url = "https://files.pythonhosted.org/packages/9d/74/f7ce1fc2ee480c7f8ceadd9b992caceaba442a97e5e99d6aea00d3635a0b/marisa_trie-1.2.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:9e956e6a46f604b17d570901e66f5214fb6f658c21e5e7665deace236793cef6", size = 192309 },
    { url = "https://files.pythonhosted.org/packages/e4/52/5dbbc13e57ce54c2ef0d04962d7d8f66edc69ed34310c734a2913199a581/marisa_trie-1.2.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:bd45142501300e7538b2e544905580918b67b1c82abed1275fe4c682c95635fa", size = 174713 },
    { url = "https://files.pythonhosted.org/packages/57/49/2580372f3f980aea95c23d05b2c1d3bbb9ee1ab8cfd441545153e44f1be7/marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a8443d116c612cfd1961fbf76769faf0561a46d8e317315dd13f9d9639ad500c", size = 1314808 },
    { url = "https://files.pythonhosted.org/packages/5a/ba/e12a4d450f265414cc68df6a116a78beece72b95f774f04d29cd48e08d19/marisa_trie-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:875a6248e60fbb48d947b574ffa4170f34981f9e579bde960d0f9a49ea393ecc", size = 1346678 },
    { url = "https://files.pythonhosted.org/packages/b2/81/8e130cb1eea741fd17694d821096f7ec9841f0e3d3c69b740257f5eeafa8/marisa_trie-1.2.1-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:746a7c60a17fccd3cfcfd4326926f02ea4fcdfc25d513411a0c4fc8e4a1ca51f", size = 1307254 },
    { url = "https://files.pythonhosted.org/packages/d7/d0/3deb5ea2bf7e4d845339875dbb31f3c3f66c8d6568723db1d137fb08a91c/marisa_trie-1.2.1-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:e70869737cc0e5bd903f620667da6c330d6737048d1f44db792a6af68a1d35be", size = 2194712 },
    { url = "https://files.pythonhosted.org/packages/9c/5f/b38d728dd30954816497b53425cfaddaf7b93ac0912db5911888f191b07a/marisa_trie-1.2.1-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:06b099dd743676dbcd8abd8465ceac8f6d97d8bfaabe2c83b965495523b4cef2", size = 2355625 },
    { url = "https://files.pythonhosted.org/packages/7e/4f/61c0faa9ae9e53600a1b7a0c367bc9db1a4fdc625402ec232c755a05e094/marisa_trie-1.2.1-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:d2a82eb21afdaf22b50d9b996472305c05ca67fc4ff5a026a220320c9c961db6", size = 2290290 },
    { url = "https://files.pythonhosted.org/packages/7c/7d/713b970fb3043248881ed776dbf4d54918398aa5dde843a38711d0d62c8f/marisa_trie-1.2.1-cp310-cp310-win32.whl", hash = "sha256:8951e7ce5d3167fbd085703b4cbb3f47948ed66826bef9a2173c379508776cf5", size = 130743 },
    { url = "https://files.pythonhosted.org/packages/cc/94/3d619cc82c30daeacd18a88674f4e6540ebfb7b4b7752ca0552793be80cf/marisa_trie-1.2.1-cp310-cp310-win_amd64.whl", hash = "sha256:5685a14b3099b1422c4f59fa38b0bf4b5342ee6cc38ae57df9666a0b28eeaad3", size = 151891 },
    { url = "https://files.pythonhosted.org/packages/4a/93/ffb01dfa22b6eee918e798e0bc3487427036c608aa4c065725f31aaf4104/marisa_trie-1.2.1-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:ed3fb4ed7f2084597e862bcd56c56c5529e773729a426c083238682dba540e98", size = 362823 },
    { url = "https://files.pythonhosted.org/packages/6d/1d/5c36500ac350c278c9bdfd88e17fa846fa4136d75597c167141ed973cdf2/marisa_trie-1.2.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:0fe69fb9ffb2767746181f7b3b29bbd3454d1d24717b5958e030494f3d3cddf3", size = 192741 },
    { url = "https://files.pythonhosted.org/packages/e8/04/87dd0840f3f720e511eba56193c02bf64d7d96df1ca9f6d19994f55154be/marisa_trie-1.2.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:4728ed3ae372d1ea2cdbd5eaa27b8f20a10e415d1f9d153314831e67d963f281", size = 174995 },
    { url = "https://files.pythonhosted.org/packages/c9/51/9e903a7e13b7593e2e675d0ec4c390ca076dc5df1c1a0d5e85a513b886a3/marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8cf4f25cf895692b232f49aa5397af6aba78bb679fb917a05fce8d3cb1ee446d", size = 1384728 },
    { url = "https://files.pythonhosted.org/packages/e8/3f/7362a5ac60c2b0aad0f52cd57e7bd0c708f20d2660d8df85360f3d8f1c4b/marisa_trie-1.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7cca7f96236ffdbf49be4b2e42c132e3df05968ac424544034767650913524de", size = 1412620 },
    { url = "https://files.pythonhosted.org/packages/1f/bc/aaa3eaf6875f78a204a8da9692d56e3a36f89997dad2c388628385614576/marisa_trie-1.2.1-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d7eb20bf0e8b55a58d2a9b518aabc4c18278787bdba476c551dd1c1ed109e509", size = 1361555 },
    { url = "https://files.pythonhosted.org/packages/18/98/e11b5a6206c5d110f32adab37fa84a85410d684e9c731acdd5c9250e2ce4/marisa_trie-1.2.1-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:b1ec93f0d1ee6d7ab680a6d8ea1a08bf264636358e92692072170032dda652ba", size = 2257717 },
    { url = "https://files.pythonhosted.org/packages/d2/9d/6b4a40867875e738a67c5b29f83e2e490a66bd9067ace3dd9a5c497e2b7f/marisa_trie-1.2.1-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:e2699255d7ac610dee26d4ae7bda5951d05c7d9123a22e1f7c6a6f1964e0a4e4", size = 2417044 },
    { url = "https://files.pythonhosted.org/packages/fe/61/e25613c72f2931757334b8bcf6b501569ef713f5ee9c6c7688ec460bd720/marisa_trie-1.2.1-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:c484410911182457a8a1a0249d0c09c01e2071b78a0a8538cd5f7fa45589b13a", size = 2351960 },
    { url = "https://files.pythonhosted.org/packages/19/0a/a90ccaf3eb476d13ec261f80c6c52defaf10ebc7f35eb2bcd7dfb533aef7/marisa_trie-1.2.1-cp311-cp311-win32.whl", hash = "sha256:ad548117744b2bcf0e3d97374608be0a92d18c2af13d98b728d37cd06248e571", size = 130446 },
    { url = "https://files.pythonhosted.org/packages/fc/98/574b4e143e0a2f5f71af8716b6c4a8a46220f75a6e0847ce7d11ee0ba4aa/marisa_trie-1.2.1-cp311-cp311-win_amd64.whl", hash = "sha256:436f62d27714970b9cdd3b3c41bdad046f260e62ebb0daa38125ef70536fc73b", size = 152037 },
    { url = "https://files.pythonhosted.org/packages/4e/bf/8bd4ac8436b33fd46c9e1ffe3c2a131cd9744cc1649dbbe13308f744ef2b/marisa_trie-1.2.1-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:638506eacf20ca503fff72221a7e66a6eadbf28d6a4a6f949fcf5b1701bb05ec", size = 360041 },
    { url = "https://files.pythonhosted.org/packages/ab/dd/4d3151e302e66ae387885f6ec265bd189e096b0c43c1379bfd9a3b9d2543/marisa_trie-1.2.1-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:de1665eaafefa48a308e4753786519888021740501a15461c77bdfd57638e6b4", size = 190520 },
    { url = "https://files.pythonhosted.org/packages/00/28/ae5991c74fb90b173167a366a634c83445f948ad044d37287b478d6b457e/marisa_trie-1.2.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:f713af9b8aa66a34cd3a78c7d150a560a75734713abe818a69021fd269e927fa", size = 174175 },
    { url = "https://files.pythonhosted.org/packages/5a/6a/fbfa89a8680eaabc6847a6c421e65427c43182db0c4bdb60e1516c81c822/marisa_trie-1.2.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b2a7d00f53f4945320b551bccb826b3fb26948bde1a10d50bb9802fabb611b10", size = 1354995 },
    { url = "https://files.pythonhosted.org/packages/9e/4c/2ba0b385e5f64ca4ddb0c10ec52ddf881bc4521f135948786fc339d1d6c8/marisa_trie-1.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:98042040d1d6085792e8d0f74004fc0f5f9ca6091c298f593dd81a22a4643854", size = 1390989 },
    { url = "https://files.pythonhosted.org/packages/6b/22/0791ed3045c91d0938345a86be472fc7c188b894f16c5dfad2ef31e7f882/marisa_trie-1.2.1-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:6532615111eec2c79e711965ece0bc95adac1ff547a7fff5ffca525463116deb", size = 1328810 },
    { url = "https://files.pythonhosted.org/packages/9d/7d/3f566e563abae6efce7fc311c63282a447c611739b3cd66c0e36077c86f8/marisa_trie-1.2.1-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:20948e40ab2038e62b7000ca6b4a913bc16c91a2c2e6da501bd1f917eeb28d51", size = 2230222 },
    { url = "https://files.pythonhosted.org/packages/a5/0b/38fbb4611b5d1030242ddc2aa62e524438c8076e26f87395dbbf222dc62d/marisa_trie-1.2.1-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:66b23e5b35dd547f85bf98db7c749bc0ffc57916ade2534a6bbc32db9a4abc44", size = 2383620 },
    { url = "https://files.pythonhosted.org/packages/ae/17/4553c63de29904d5d2521a24cad817bc7883cfa90506ab702ec4dae59a7b/marisa_trie-1.2.1-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:6704adf0247d2dda42e876b793be40775dff46624309ad99bc7537098bee106d", size = 2329202 },
    { url = "https://files.pythonhosted.org/packages/45/08/6307a630e63cd763fe77ac56516faa67fa9cd342060691e40fabc84be6b0/marisa_trie-1.2.1-cp312-cp312-win32.whl", hash = "sha256:3ad356442c2fea4c2a6f514738ddf213d23930f942299a2b2c05df464a00848a", size = 129652 },
    { url = "https://files.pythonhosted.org/packages/a1/fe/67c357bfd92710d95a16b86e1453c663d565415d7f7838781c79ff7e1a7e/marisa_trie-1.2.1-cp312-cp312-win_amd64.whl", hash = "sha256:f2806f75817392cedcacb24ac5d80b0350dde8d3861d67d045c1d9b109764114", size = 150845 },
    { url = "https://files.pythonhosted.org/packages/2a/a4/a110cd9952f0e72da7bafea1f0084b18b9e03952110d9083bfda52279f5c/marisa_trie-1.2.1-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:b5ea16e69bfda0ac028c921b58de1a4aaf83d43934892977368579cd3c0a2554", size = 354439 },
    { url = "https://files.pythonhosted.org/packages/3c/a5/a6099eb1c3fd8d7e93408c45501e1d08536ac57dfef02ec331f78e1ace18/marisa_trie-1.2.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:9f627f4e41be710b6cb6ed54b0128b229ac9d50e2054d9cde3af0fef277c23cf", size = 188187 },
    { url = "https://files.pythonhosted.org/packages/7c/cc/f637127e2beffa920d21f7fc45b4029575bcd1b28a90c0d90cb2b08c2205/marisa_trie-1.2.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:5e649f3dc8ab5476732094f2828cc90cac3be7c79bc0c8318b6fda0c1d248db4", size = 171484 },
    { url = "https://files.pythonhosted.org/packages/6d/0f/29f2ad7260b956570f69f25a542efa51ba76eb76ecd53c63ee9d21987c3d/marisa_trie-1.2.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:46e528ee71808c961baf8c3ce1c46a8337ec7a96cc55389d11baafe5b632f8e9", size = 1319770 },
    { url = "https://files.pythonhosted.org/packages/f2/12/0b69ed61fba59551a5f3d569af367afae614db7214ce1da12946ba9a433a/marisa_trie-1.2.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:36aa4401a1180615f74d575571a6550081d84fc6461e9aefc0bb7b2427af098e", size = 1356488 },
    { url = "https://files.pythonhosted.org/packages/33/23/483b110db7ffe8729d6ebea2bf74258aef51f10fef5775f99e4bac7aef69/marisa_trie-1.2.1-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ce59bcd2cda9bb52b0e90cc7f36413cd86c3d0ce7224143447424aafb9f4aa48", size = 1302334 },
    { url = "https://files.pythonhosted.org/packages/1c/6f/46c2be99ce925985127fdf78900f1673bce8cb72debfebee6dccd11032c6/marisa_trie-1.2.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:f4cd800704a5fc57e53c39c3a6b0c9b1519ebdbcb644ede3ee67a06eb542697d", size = 2202624 },
    { url = "https://files.pythonhosted.org/packages/fd/b6/ef642327dbd4ec35be55d5682520b8f70fca98a54024f441ef2732f6b305/marisa_trie-1.2.1-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:2428b495003c189695fb91ceeb499f9fcced3a2dce853e17fa475519433c67ff", size = 2364206 },
    { url = "https://files.pythonhosted.org/packages/69/04/ef8197a79d0ab5043b781cc9b457bd11b81d4204fe78adf7625a67f48c21/marisa_trie-1.2.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:735c363d9aaac82eaf516a28f7c6b95084c2e176d8231c87328dc80e112a9afa", size = 2304801 },
    { url = "https://files.pythonhosted.org/packages/03/72/f87564d653daf31d8f33d9bf0121e99ccc21f18f5c485fb404ba06abc10e/marisa_trie-1.2.1-cp313-cp313-win32.whl", hash = "sha256:eba6ca45500ca1a042466a0684aacc9838e7f20fe2605521ee19f2853062798f", size = 128799 },
    { url = "https://files.pythonhosted.org/packages/27/40/5f9eb8b73030cc4b0d6817176e66079a62a2ddd9d5530da54f8011473428/marisa_trie-1.2.1-cp313-cp313-win_amd64.whl", hash = "sha256:aa7cd17e1c690ce96c538b2f4aae003d9a498e65067dd433c52dd069009951d4", size = 149035 },
    { url = "https://files.pythonhosted.org/packages/ae/ec/abe083a948e688829f9411f1e174134b02d29c2fb050d249470f1d32a459/marisa_trie-1.2.1-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:952af3a5859c3b20b15a00748c36e9eb8316eb2c70bd353ae1646da216322908", size = 361940 },
    { url = "https://files.pythonhosted.org/packages/6b/1a/dd927cdbbda4cf9c81ba7c413489172a06dab12d8ff2de742936926b5ff8/marisa_trie-1.2.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:24a81aa7566e4ec96fc4d934581fe26d62eac47fc02b35fa443a0bb718b471e8", size = 192033 },
    { url = "https://files.pythonhosted.org/packages/f9/11/aaa6f88d5f9b6338f88da874fa5641ce1929440f047094e9559213ba8a9b/marisa_trie-1.2.1-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:9c9b32b14651a6dcf9e8857d2df5d29d322a1ea8c0be5c8ffb88f9841c4ec62b", size = 174689 },
    { url = "https://files.pythonhosted.org/packages/a3/dd/6c2abd4516aa39ef23a709dd821bd3a5091f9e6973bc92f1039e4bb0bcd4/marisa_trie-1.2.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:7ac170d20b97beb75059ba65d1ccad6b434d777c8992ab41ffabdade3b06dd74", size = 1326712 },
    { url = "https://files.pythonhosted.org/packages/63/2c/4b73dbd82ad767a2f28c7689fbac65c6cfb7f4327ace4b4c12200ad7593a/marisa_trie-1.2.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:da4e4facb79614cc4653cfd859f398e4db4ca9ab26270ff12610e50ed7f1f6c6", size = 1360633 },
    { url = "https://files.pythonhosted.org/packages/fa/8d/d0e01ab9c217d0baa4a4a7f21fad50a2fd0f1aaa3a80e5d09c1538862701/marisa_trie-1.2.1-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:25688f34cac3bec01b4f655ffdd6c599a01f0bd596b4a79cf56c6f01a7df3560", size = 1316781 },
    { url = "https://files.pythonhosted.org/packages/ff/2d/a0f54731a56d57a75bc497f1458294c0029d77ed642ce92bf41dc3282178/marisa_trie-1.2.1-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:1db3213b451bf058d558f6e619bceff09d1d130214448a207c55e1526e2773a1", size = 2209204 },
    { url = "https://files.pythonhosted.org/packages/01/6e/65e0e18b47d633567f6c7fec2afc92a508fdbf07a06cc0357c0c09ff477f/marisa_trie-1.2.1-cp38-cp38-musllinux_1_2_i686.whl", hash = "sha256:d5648c6dcc5dc9200297fb779b1663b8a4467bda034a3c69bd9c32d8afb33b1d", size = 2374103 },
    { url = "https://files.pythonhosted.org/packages/bb/82/c6af2d08cd1b48cc240cd22b0289ce3d7f16e7b0a319529815acfdb4c5c6/marisa_trie-1.2.1-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:5bd39a4e1cc839a88acca2889d17ebc3f202a5039cd6059a13148ce75c8a6244", size = 2305324 },
    { url = "https://files.pythonhosted.org/packages/fc/c3/e6f1728533eb3089b3dcc97cd6c3bf4e7f4e22c2e2ae3c27d8e4b56f115f/marisa_trie-1.2.1-cp38-cp38-win32.whl", hash = "sha256:594f98491a96c7f1ffe13ce292cef1b4e63c028f0707effdea0f113364c1ae6c", size = 131039 },
    { url = "https://files.pythonhosted.org/packages/79/f0/132676c9d5b2493581b175f34d24954763064bd0fff514ce10d9616e3829/marisa_trie-1.2.1-cp38-cp38-win_amd64.whl", hash = "sha256:5fe5a286f997848a410eebe1c28657506adaeb405220ee1e16cfcfd10deb37f2", size = 152246 },
    { url = "https://files.pythonhosted.org/packages/13/f5/00a62364e970c6ebdfbc24b3ded362b27b57ba8bc67109b828f64156f8e9/marisa_trie-1.2.1-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:c0fe2ace0cb1806badbd1c551a8ec2f8d4cf97bf044313c082ef1acfe631ddca", size = 363043 },
    { url = "https://files.pythonhosted.org/packages/a3/89/f9794a0e0e9f888ba1f18830337d6b50ed93f652157112ea12ab9035071c/marisa_trie-1.2.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:67f0c2ec82c20a02c16fc9ba81dee2586ef20270127c470cb1054767aa8ba310", size = 192769 },
    { url = "https://files.pythonhosted.org/packages/0d/3d/1981088acb417aa22d08ccff6bc8a2040f5dcd72b316004cf03857158996/marisa_trie-1.2.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:a3c98613180cf1730e221933ff74b454008161b1a82597e41054127719964188", size = 175138 },
    { url = "https://files.pythonhosted.org/packages/2a/6d/bcad5529d4b5050cba3d1dca0147a907d140be15fc1be5dbea94521b8a38/marisa_trie-1.2.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:429858a0452a7bedcf67bc7bb34383d00f666c980cb75a31bcd31285fbdd4403", size = 1317106 },
    { url = "https://files.pythonhosted.org/packages/09/66/d66b1300e5ea11ffa972659da71affd23f581c8a3861647248af0150303a/marisa_trie-1.2.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b2eacb84446543082ec50f2fb563f1a94c96804d4057b7da8ed815958d0cdfbe", size = 1345392 },
    { url = "https://files.pythonhosted.org/packages/5c/91/777a6b2f620fe41816869dad2d5bf4a8e8a34215158a8e38da2db301db18/marisa_trie-1.2.1-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:852d7bcf14b0c63404de26e7c4c8d5d65ecaeca935e93794331bc4e2f213660b", size = 1305127 },
    { url = "https://files.pythonhosted.org/packages/26/89/6f715d6a52f04a93b40369d1846dbb8425776f1ed34765dcf9655d8bb5f9/marisa_trie-1.2.1-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:e58788004adda24c401d1751331618ed20c507ffc23bfd28d7c0661a1cf0ad16", size = 2195490 },
    { url = "https://files.pythonhosted.org/packages/9d/f1/9a8eb122e0122445ce959af4a5e24e50877984348c3bdceebcba9783c4be/marisa_trie-1.2.1-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:aefe0973cc4698e0907289dc0517ab0c7cdb13d588201932ff567d08a50b0e2e", size = 2356807 },
    { url = "https://files.pythonhosted.org/packages/a6/60/50a5c2b8dc4ef9c33b9a13d8ca5eb6c0c39111507c955a25869d846126d5/marisa_trie-1.2.1-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:6c50c861faad0a5c091bd763e0729f958c316e678dfa065d3984fbb9e4eacbcd", size = 2289526 },
    { url = "https://files.pythonhosted.org/packages/57/71/cee2540c7d77359cad8a1cb28b7063798eb8648fefb25fc3f06d4028e27b/marisa_trie-1.2.1-cp39-cp39-win32.whl", hash = "sha256:b1ce340da608530500ab4f963f12d6bfc8d8680900919a60dbdc9b78c02060a4", size = 130793 },
    { url = "https://files.pythonhosted.org/packages/fb/3d/4eaad05fcbfd6a3357e2e2504becaa9c1720beeb75dc86753a301098efd9/marisa_trie-1.2.1-cp39-cp39-win_amd64.whl", hash = "sha256:ce37d8ca462bb64cc13f529b9ed92f7b21fe8d1f1679b62e29f9cb7d0e888b49", size = 152103 },
]

[[package]]
name = "markdown-it-py"
version = "3.0.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "mdurl" },
]
sdist = { url = "https://files.pythonhosted.org/packages/38/71/3b932df36c1a044d397a1f92d1cf91ee0a503d91e470cbd670aa66b07ed0/markdown-it-py-3.0.0.tar.gz", hash = "sha256:e3f60a94fa066dc52ec76661e37c851cb232d92f9886b15cb560aaada2df8feb", size = 74596 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl", hash = "sha256:355216845c60bd96232cd8d8c40e8f9765cc86f46880e43a8fd22dc1a1a8cab1", size = 87528 },
]

[[package]]
name = "markupsafe"
version = "2.1.5"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/87/5b/aae44c6655f3801e81aa3eef09dbbf012431987ba564d7231722f68df02d/MarkupSafe-2.1.5.tar.gz", hash = "sha256:d283d37a890ba4c1ae73ffadf8046435c76e7bc2247bbb63c00bd1a709c6544b", size = 19384 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e4/54/ad5eb37bf9d51800010a74e4665425831a9db4e7c4e0fde4352e391e808e/MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:a17a92de5231666cfbe003f0e4b9b3a7ae3afb1ec2845aadc2bacc93ff85febc", size = 18206 },
    { url = "https://files.pythonhosted.org/packages/6a/4a/a4d49415e600bacae038c67f9fecc1d5433b9d3c71a4de6f33537b89654c/MarkupSafe-2.1.5-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:72b6be590cc35924b02c78ef34b467da4ba07e4e0f0454a2c5907f473fc50ce5", size = 14079 },
    { url = "https://files.pythonhosted.org/packages/0a/7b/85681ae3c33c385b10ac0f8dd025c30af83c78cec1c37a6aa3b55e67f5ec/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e61659ba32cf2cf1481e575d0462554625196a1f2fc06a1c777d3f48e8865d46", size = 26620 },
    { url = "https://files.pythonhosted.org/packages/7c/52/2b1b570f6b8b803cef5ac28fdf78c0da318916c7d2fe9402a84d591b394c/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2174c595a0d73a3080ca3257b40096db99799265e1c27cc5a610743acd86d62f", size = 25818 },
    { url = "https://files.pythonhosted.org/packages/29/fe/a36ba8c7ca55621620b2d7c585313efd10729e63ef81e4e61f52330da781/MarkupSafe-2.1.5-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ae2ad8ae6ebee9d2d94b17fb62763125f3f374c25618198f40cbb8b525411900", size = 25493 },
    { url = "https://files.pythonhosted.org/packages/60/ae/9c60231cdfda003434e8bd27282b1f4e197ad5a710c14bee8bea8a9ca4f0/MarkupSafe-2.1.5-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:075202fa5b72c86ad32dc7d0b56024ebdbcf2048c0ba09f1cde31bfdd57bcfff", size = 30630 },
    { url = "https://files.pythonhosted.org/packages/65/dc/1510be4d179869f5dafe071aecb3f1f41b45d37c02329dfba01ff59e5ac5/MarkupSafe-2.1.5-cp310-cp310-musllinux_1_1_i686.whl", hash = "sha256:598e3276b64aff0e7b3451b72e94fa3c238d452e7ddcd893c3ab324717456bad", size = 29745 },
    { url = "https://files.pythonhosted.org/packages/30/39/8d845dd7d0b0613d86e0ef89549bfb5f61ed781f59af45fc96496e897f3a/MarkupSafe-2.1.5-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:fce659a462a1be54d2ffcacea5e3ba2d74daa74f30f5f143fe0c58636e355fdd", size = 30021 },
    { url = "https://files.pythonhosted.org/packages/c7/5c/356a6f62e4f3c5fbf2602b4771376af22a3b16efa74eb8716fb4e328e01e/MarkupSafe-2.1.5-cp310-cp310-win32.whl", hash = "sha256:d9fad5155d72433c921b782e58892377c44bd6252b5af2f67f16b194987338a4", size = 16659 },
    { url = "https://files.pythonhosted.org/packages/69/48/acbf292615c65f0604a0c6fc402ce6d8c991276e16c80c46a8f758fbd30c/MarkupSafe-2.1.5-cp310-cp310-win_amd64.whl", hash = "sha256:bf50cd79a75d181c9181df03572cdce0fbb75cc353bc350712073108cba98de5", size = 17213 },
    { url = "https://files.pythonhosted.org/packages/11/e7/291e55127bb2ae67c64d66cef01432b5933859dfb7d6949daa721b89d0b3/MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:629ddd2ca402ae6dbedfceeba9c46d5f7b2a61d9749597d4307f943ef198fc1f", size = 18219 },
    { url = "https://files.pythonhosted.org/packages/6b/cb/aed7a284c00dfa7c0682d14df85ad4955a350a21d2e3b06d8240497359bf/MarkupSafe-2.1.5-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:5b7b716f97b52c5a14bffdf688f971b2d5ef4029127f1ad7a513973cfd818df2", size = 14098 },
    { url = "https://files.pythonhosted.org/packages/1c/cf/35fe557e53709e93feb65575c93927942087e9b97213eabc3fe9d5b25a55/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6ec585f69cec0aa07d945b20805be741395e28ac1627333b1c5b0105962ffced", size = 29014 },
    { url = "https://files.pythonhosted.org/packages/97/18/c30da5e7a0e7f4603abfc6780574131221d9148f323752c2755d48abad30/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b91c037585eba9095565a3556f611e3cbfaa42ca1e865f7b8015fe5c7336d5a5", size = 28220 },
    { url = "https://files.pythonhosted.org/packages/0c/40/2e73e7d532d030b1e41180807a80d564eda53babaf04d65e15c1cf897e40/MarkupSafe-2.1.5-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:7502934a33b54030eaf1194c21c692a534196063db72176b0c4028e140f8f32c", size = 27756 },
    { url = "https://files.pythonhosted.org/packages/18/46/5dca760547e8c59c5311b332f70605d24c99d1303dd9a6e1fc3ed0d73561/MarkupSafe-2.1.5-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:0e397ac966fdf721b2c528cf028494e86172b4feba51d65f81ffd65c63798f3f", size = 33988 },
    { url = "https://files.pythonhosted.org/packages/6d/c5/27febe918ac36397919cd4a67d5579cbbfa8da027fa1238af6285bb368ea/MarkupSafe-2.1.5-cp311-cp311-musllinux_1_1_i686.whl", hash = "sha256:c061bb86a71b42465156a3ee7bd58c8c2ceacdbeb95d05a99893e08b8467359a", size = 32718 },
    { url = "https://files.pythonhosted.org/packages/f8/81/56e567126a2c2bc2684d6391332e357589a96a76cb9f8e5052d85cb0ead8/MarkupSafe-2.1.5-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:3a57fdd7ce31c7ff06cdfbf31dafa96cc533c21e443d57f5b1ecc6cdc668ec7f", size = 33317 },
    { url = "https://files.pythonhosted.org/packages/00/0b/23f4b2470accb53285c613a3ab9ec19dc944eaf53592cb6d9e2af8aa24cc/MarkupSafe-2.1.5-cp311-cp311-win32.whl", hash = "sha256:397081c1a0bfb5124355710fe79478cdbeb39626492b15d399526ae53422b906", size = 16670 },
    { url = "https://files.pythonhosted.org/packages/b7/a2/c78a06a9ec6d04b3445a949615c4c7ed86a0b2eb68e44e7541b9d57067cc/MarkupSafe-2.1.5-cp311-cp311-win_amd64.whl", hash = "sha256:2b7c57a4dfc4f16f7142221afe5ba4e093e09e728ca65c51f5620c9aaeb9a617", size = 17224 },
    { url = "https://files.pythonhosted.org/packages/53/bd/583bf3e4c8d6a321938c13f49d44024dbe5ed63e0a7ba127e454a66da974/MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_universal2.whl", hash = "sha256:8dec4936e9c3100156f8a2dc89c4b88d5c435175ff03413b443469c7c8c5f4d1", size = 18215 },
    { url = "https://files.pythonhosted.org/packages/48/d6/e7cd795fc710292c3af3a06d80868ce4b02bfbbf370b7cee11d282815a2a/MarkupSafe-2.1.5-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:3c6b973f22eb18a789b1460b4b91bf04ae3f0c4234a0a6aa6b0a92f6f7b951d4", size = 14069 },
    { url = "https://files.pythonhosted.org/packages/51/b5/5d8ec796e2a08fc814a2c7d2584b55f889a55cf17dd1a90f2beb70744e5c/MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ac07bad82163452a6884fe8fa0963fb98c2346ba78d779ec06bd7a6262132aee", size = 29452 },
    { url = "https://files.pythonhosted.org/packages/0a/0d/2454f072fae3b5a137c119abf15465d1771319dfe9e4acbb31722a0fff91/MarkupSafe-2.1.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f5dfb42c4604dddc8e4305050aa6deb084540643ed5804d7455b5df8fe16f5e5", size = 28462 },
    { url = "https://files.pythonhosted.org/packages/2d/75/fd6cb2e68780f72d47e6671840ca517bda5ef663d30ada7616b0462ad1e3/MarkupSafe-2.1.5-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ea3d8a3d18833cf4304cd2fc9cbb1efe188ca9b5efef2bdac7adc20594a0e46b", size = 27869 },
    { url = "https://files.pythonhosted.org/packages/b0/81/147c477391c2750e8fc7705829f7351cf1cd3be64406edcf900dc633feb2/MarkupSafe-2.1.5-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:d050b3361367a06d752db6ead6e7edeb0009be66bc3bae0ee9d97fb326badc2a", size = 33906 },
    { url = "https://files.pythonhosted.org/packages/8b/ff/9a52b71839d7a256b563e85d11050e307121000dcebc97df120176b3ad93/MarkupSafe-2.1.5-cp312-cp312-musllinux_1_1_i686.whl", hash = "sha256:bec0a414d016ac1a18862a519e54b2fd0fc8bbfd6890376898a6c0891dd82e9f", size = 32296 },
    { url = "https://files.pythonhosted.org/packages/88/07/2dc76aa51b481eb96a4c3198894f38b480490e834479611a4053fbf08623/MarkupSafe-2.1.5-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:58c98fee265677f63a4385256a6d7683ab1832f3ddd1e66fe948d5880c21a169", size = 33038 },
    { url = "https://files.pythonhosted.org/packages/96/0c/620c1fb3661858c0e37eb3cbffd8c6f732a67cd97296f725789679801b31/MarkupSafe-2.1.5-cp312-cp312-win32.whl", hash = "sha256:8590b4ae07a35970728874632fed7bd57b26b0102df2d2b233b6d9d82f6c62ad", size = 16572 },
    { url = "https://files.pythonhosted.org/packages/3f/14/c3554d512d5f9100a95e737502f4a2323a1959f6d0d01e0d0997b35f7b10/MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl", hash = "sha256:823b65d8706e32ad2df51ed89496147a42a2a6e01c13cfb6ffb8b1e92bc910bb", size = 17127 },
    { url = "https://files.pythonhosted.org/packages/f8/ff/2c942a82c35a49df5de3a630ce0a8456ac2969691b230e530ac12314364c/MarkupSafe-2.1.5-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:656f7526c69fac7f600bd1f400991cc282b417d17539a1b228617081106feb4a", size = 18192 },
    { url = "https://files.pythonhosted.org/packages/4f/14/6f294b9c4f969d0c801a4615e221c1e084722ea6114ab2114189c5b8cbe0/MarkupSafe-2.1.5-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:97cafb1f3cbcd3fd2b6fbfb99ae11cdb14deea0736fc2b0952ee177f2b813a46", size = 14072 },
    { url = "https://files.pythonhosted.org/packages/81/d4/fd74714ed30a1dedd0b82427c02fa4deec64f173831ec716da11c51a50aa/MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1f3fbcb7ef1f16e48246f704ab79d79da8a46891e2da03f8783a5b6fa41a9532", size = 26928 },
    { url = "https://files.pythonhosted.org/packages/c7/bd/50319665ce81bb10e90d1cf76f9e1aa269ea6f7fa30ab4521f14d122a3df/MarkupSafe-2.1.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fa9db3f79de01457b03d4f01b34cf91bc0048eb2c3846ff26f66687c2f6d16ab", size = 26106 },
    { url = "https://files.pythonhosted.org/packages/4c/6f/f2b0f675635b05f6afd5ea03c094557bdb8622fa8e673387444fe8d8e787/MarkupSafe-2.1.5-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:ffee1f21e5ef0d712f9033568f8344d5da8cc2869dbd08d87c84656e6a2d2f68", size = 25781 },
    { url = "https://files.pythonhosted.org/packages/51/e0/393467cf899b34a9d3678e78961c2c8cdf49fb902a959ba54ece01273fb1/MarkupSafe-2.1.5-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:5dedb4db619ba5a2787a94d877bc8ffc0566f92a01c0ef214865e54ecc9ee5e0", size = 30518 },
    { url = "https://files.pythonhosted.org/packages/f6/02/5437e2ad33047290dafced9df741d9efc3e716b75583bbd73a9984f1b6f7/MarkupSafe-2.1.5-cp38-cp38-musllinux_1_1_i686.whl", hash = "sha256:30b600cf0a7ac9234b2638fbc0fb6158ba5bdcdf46aeb631ead21248b9affbc4", size = 29669 },
    { url = "https://files.pythonhosted.org/packages/0e/7d/968284145ffd9d726183ed6237c77938c021abacde4e073020f920e060b2/MarkupSafe-2.1.5-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:8dd717634f5a044f860435c1d8c16a270ddf0ef8588d4887037c5028b859b0c3", size = 29933 },
    { url = "https://files.pythonhosted.org/packages/bf/f3/ecb00fc8ab02b7beae8699f34db9357ae49d9f21d4d3de6f305f34fa949e/MarkupSafe-2.1.5-cp38-cp38-win32.whl", hash = "sha256:daa4ee5a243f0f20d528d939d06670a298dd39b1ad5f8a72a4275124a7819eff", size = 16656 },
    { url = "https://files.pythonhosted.org/packages/92/21/357205f03514a49b293e214ac39de01fadd0970a6e05e4bf1ddd0ffd0881/MarkupSafe-2.1.5-cp38-cp38-win_amd64.whl", hash = "sha256:619bc166c4f2de5caa5a633b8b7326fbe98e0ccbfacabd87268a2b15ff73a029", size = 17206 },
    { url = "https://files.pythonhosted.org/packages/0f/31/780bb297db036ba7b7bbede5e1d7f1e14d704ad4beb3ce53fb495d22bc62/MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:7a68b554d356a91cce1236aa7682dc01df0edba8d043fd1ce607c49dd3c1edcf", size = 18193 },
    { url = "https://files.pythonhosted.org/packages/6c/77/d77701bbef72892affe060cdacb7a2ed7fd68dae3b477a8642f15ad3b132/MarkupSafe-2.1.5-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:db0b55e0f3cc0be60c1f19efdde9a637c32740486004f20d1cff53c3c0ece4d2", size = 14073 },
    { url = "https://files.pythonhosted.org/packages/d9/a7/1e558b4f78454c8a3a0199292d96159eb4d091f983bc35ef258314fe7269/MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:3e53af139f8579a6d5f7b76549125f0d94d7e630761a2111bc431fd820e163b8", size = 26486 },
    { url = "https://files.pythonhosted.org/packages/5f/5a/360da85076688755ea0cceb92472923086993e86b5613bbae9fbc14136b0/MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:17b950fccb810b3293638215058e432159d2b71005c74371d784862b7e4683f3", size = 25685 },
    { url = "https://files.pythonhosted.org/packages/6a/18/ae5a258e3401f9b8312f92b028c54d7026a97ec3ab20bfaddbdfa7d8cce8/MarkupSafe-2.1.5-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:4c31f53cdae6ecfa91a77820e8b151dba54ab528ba65dfd235c80b086d68a465", size = 25338 },
    { url = "https://files.pythonhosted.org/packages/0b/cc/48206bd61c5b9d0129f4d75243b156929b04c94c09041321456fd06a876d/MarkupSafe-2.1.5-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:bff1b4290a66b490a2f4719358c0cdcd9bafb6b8f061e45c7a2460866bf50c2e", size = 30439 },
    { url = "https://files.pythonhosted.org/packages/d1/06/a41c112ab9ffdeeb5f77bc3e331fdadf97fa65e52e44ba31880f4e7f983c/MarkupSafe-2.1.5-cp39-cp39-musllinux_1_1_i686.whl", hash = "sha256:bc1667f8b83f48511b94671e0e441401371dfd0f0a795c7daa4a3cd1dde55bea", size = 29531 },
    { url = "https://files.pythonhosted.org/packages/02/8c/ab9a463301a50dab04d5472e998acbd4080597abc048166ded5c7aa768c8/MarkupSafe-2.1.5-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:5049256f536511ee3f7e1b3f87d1d1209d327e818e6ae1365e8653d7e3abb6a6", size = 29823 },
    { url = "https://files.pythonhosted.org/packages/bc/29/9bc18da763496b055d8e98ce476c8e718dcfd78157e17f555ce6dd7d0895/MarkupSafe-2.1.5-cp39-cp39-win32.whl", hash = "sha256:00e046b6dd71aa03a41079792f8473dc494d564611a8f89bbbd7cb93295ebdcf", size = 16658 },
    { url = "https://files.pythonhosted.org/packages/f6/f8/4da07de16f10551ca1f640c92b5f316f9394088b183c6a57183df6de5ae4/MarkupSafe-2.1.5-cp39-cp39-win_amd64.whl", hash = "sha256:fa173ec60341d6bb97a89f5ea19c85c5643c1e7dedebc22f5181eb73573142c5", size = 17211 },
]

[[package]]
name = "matplotlib"
version = "3.7.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "contourpy", version = "1.1.1", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.12'" },
    { name = "contourpy", version = "1.3.1", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.12'" },
    { name = "cycler" },
    { name = "fonttools" },
    { name = "importlib-resources", marker = "python_full_version < '3.10'" },
    { name = "kiwisolver" },
    { name = "numpy" },
    { name = "packaging" },
    { name = "pillow" },
    { name = "pyparsing" },
    { name = "python-dateutil" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b6/f0/3836719cc3982fbba3b840d18a59db1d0ee9ac7986f24e8c0a092851b67b/matplotlib-3.7.5.tar.gz", hash = "sha256:1e5c971558ebc811aa07f54c7b7c677d78aa518ef4c390e14673a09e0860184a", size = 38098611 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f5/b0/3808e86c41e5d97822d77e89d7f3cb0890725845c050d87ec53732a8b150/matplotlib-3.7.5-cp310-cp310-macosx_10_12_universal2.whl", hash = "sha256:4a87b69cb1cb20943010f63feb0b2901c17a3b435f75349fd9865713bfa63925", size = 8322924 },
    { url = "https://files.pythonhosted.org/packages/5b/05/726623be56391ba1740331ad9f1cd30e1adec61c179ddac134957a6dc2e7/matplotlib-3.7.5-cp310-cp310-macosx_10_12_x86_64.whl", hash = "sha256:d3ce45010fefb028359accebb852ca0c21bd77ec0f281952831d235228f15810", size = 7438436 },
    { url = "https://files.pythonhosted.org/packages/15/83/89cdef49ef1e320060ec951ba33c132df211561d866c3ed144c81fd110b2/matplotlib-3.7.5-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:fbea1e762b28400393d71be1a02144aa16692a3c4c676ba0178ce83fc2928fdd", size = 7341849 },
    { url = "https://files.pythonhosted.org/packages/94/29/39fc4acdc296dd86e09cecb65c14966e1cf18e0f091b9cbd9bd3f0c19ee4/matplotlib-3.7.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ec0e1adc0ad70ba8227e957551e25a9d2995e319c29f94a97575bb90fa1d4469", size = 11354141 },
    { url = "https://files.pythonhosted.org/packages/54/36/44c5eeb0d83ae1e3ed34d264d7adee947c4fd56c4a9464ce822de094995a/matplotlib-3.7.5-cp310-cp310-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:6738c89a635ced486c8a20e20111d33f6398a9cbebce1ced59c211e12cd61455", size = 11457668 },
    { url = "https://files.pythonhosted.org/packages/b7/e2/f68aeaedf0ef57cbb793637ee82e62e64ea26cee908db0fe4f8e24d502c0/matplotlib-3.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1210b7919b4ed94b5573870f316bca26de3e3b07ffdb563e79327dc0e6bba515", size = 11580088 },
    { url = "https://files.pythonhosted.org/packages/d9/f7/7c88d34afc38943aa5e4e04d27fc9da5289a48c264c0d794f60c9cda0949/matplotlib-3.7.5-cp310-cp310-win32.whl", hash = "sha256:068ebcc59c072781d9dcdb82f0d3f1458271c2de7ca9c78f5bd672141091e9e1", size = 7339332 },
    { url = "https://files.pythonhosted.org/packages/91/99/e5f6f7c9438279581c4a2308d264fe24dc98bb80e3b2719f797227e54ddc/matplotlib-3.7.5-cp310-cp310-win_amd64.whl", hash = "sha256:f098ffbaab9df1e3ef04e5a5586a1e6b1791380698e84938d8640961c79b1fc0", size = 7506405 },
    { url = "https://files.pythonhosted.org/packages/5e/c6/45d0485e59d70b7a6a81eade5d0aed548b42cc65658c0ce0f813b9249165/matplotlib-3.7.5-cp311-cp311-macosx_10_12_universal2.whl", hash = "sha256:f65342c147572673f02a4abec2d5a23ad9c3898167df9b47c149f32ce61ca078", size = 8325506 },
    { url = "https://files.pythonhosted.org/packages/0e/0a/83bd8589f3597745f624fbcc7da1140088b2f4160ca51c71553c561d0df5/matplotlib-3.7.5-cp311-cp311-macosx_10_12_x86_64.whl", hash = "sha256:4ddf7fc0e0dc553891a117aa083039088d8a07686d4c93fb8a810adca68810af", size = 7439905 },
    { url = "https://files.pythonhosted.org/packages/84/c1/a7705b24f8f9b4d7ceea0002c13bae50cf9423f299f56d8c47a5cd2627d2/matplotlib-3.7.5-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:0ccb830fc29442360d91be48527809f23a5dcaee8da5f4d9b2d5b867c1b087b8", size = 7342895 },
    { url = "https://files.pythonhosted.org/packages/94/6e/55d7d8310c96a7459c883aa4be3f5a9338a108278484cbd5c95d480d1cef/matplotlib-3.7.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:efc6bb28178e844d1f408dd4d6341ee8a2e906fc9e0fa3dae497da4e0cab775d", size = 11358830 },
    { url = "https://files.pythonhosted.org/packages/55/57/3b36afe104216db1cf2f3889c394b403ea87eda77c4815227c9524462ba8/matplotlib-3.7.5-cp311-cp311-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:3b15c4c2d374f249f324f46e883340d494c01768dd5287f8bc00b65b625ab56c", size = 11462575 },
    { url = "https://files.pythonhosted.org/packages/f3/0b/fabcf5f66b12fab5c4110d06a6c0fed875c7e63bc446403f58f9dadc9999/matplotlib-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3d028555421912307845e59e3de328260b26d055c5dac9b182cc9783854e98fb", size = 11584280 },
    { url = "https://files.pythonhosted.org/packages/47/a9/1ad7df27a9da70b62109584632f83fe6ef45774701199c44d5777107c240/matplotlib-3.7.5-cp311-cp311-win32.whl", hash = "sha256:fe184b4625b4052fa88ef350b815559dd90cc6cc8e97b62f966e1ca84074aafa", size = 7340429 },
    { url = "https://files.pythonhosted.org/packages/e3/b1/1b6c34b89173d6c206dc5a4028e8518b4dfee3569c13bdc0c88d0486cae7/matplotlib-3.7.5-cp311-cp311-win_amd64.whl", hash = "sha256:084f1f0f2f1010868c6f1f50b4e1c6f2fb201c58475494f1e5b66fed66093647", size = 7507112 },
    { url = "https://files.pythonhosted.org/packages/75/dc/4e341a3ef36f3e7321aec0741317f12c7a23264be708a97972bf018c34af/matplotlib-3.7.5-cp312-cp312-macosx_10_12_universal2.whl", hash = "sha256:34bceb9d8ddb142055ff27cd7135f539f2f01be2ce0bafbace4117abe58f8fe4", size = 8323797 },
    { url = "https://files.pythonhosted.org/packages/af/83/bbb482d678362ceb68cc59ec4fc705dde636025969361dac77be868541ef/matplotlib-3.7.5-cp312-cp312-macosx_10_12_x86_64.whl", hash = "sha256:c5a2134162273eb8cdfd320ae907bf84d171de948e62180fa372a3ca7cf0f433", size = 7439549 },
    { url = "https://files.pythonhosted.org/packages/1a/ee/e49a92d9e369b2b9e4373894171cb4e641771cd7f81bde1d8b6fb8c60842/matplotlib-3.7.5-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:039ad54683a814002ff37bf7981aa1faa40b91f4ff84149beb53d1eb64617980", size = 7341788 },
    { url = "https://files.pythonhosted.org/packages/48/79/89cb2fc5ddcfc3d440a739df04dbe6e4e72b1153d1ebd32b45d42eb71d27/matplotlib-3.7.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4d742ccd1b09e863b4ca58291728db645b51dab343eebb08d5d4b31b308296ce", size = 11356329 },
    { url = "https://files.pythonhosted.org/packages/ff/25/84f181cdae5c9eba6fd1c2c35642aec47233425fe3b0d6fccdb323fb36e0/matplotlib-3.7.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:743b1c488ca6a2bc7f56079d282e44d236bf375968bfd1b7ba701fd4d0fa32d6", size = 11577813 },
    { url = "https://files.pythonhosted.org/packages/9f/24/b2db065d40e58033b3350222fb8bbb0ffcb834029df9c1f9349dd9c7dd45/matplotlib-3.7.5-cp312-cp312-win_amd64.whl", hash = "sha256:fbf730fca3e1f23713bc1fae0a57db386e39dc81ea57dc305c67f628c1d7a342", size = 7507667 },
    { url = "https://files.pythonhosted.org/packages/e3/72/50a38c8fd5dc845b06f8e71c9da802db44b81baabf4af8be78bb8a5622ea/matplotlib-3.7.5-cp38-cp38-macosx_10_12_universal2.whl", hash = "sha256:cfff9b838531698ee40e40ea1a8a9dc2c01edb400b27d38de6ba44c1f9a8e3d2", size = 8322659 },
    { url = "https://files.pythonhosted.org/packages/b1/ea/129163dcd21db6da5d559a8160c4a74c1dc5f96ac246a3d4248b43c7648d/matplotlib-3.7.5-cp38-cp38-macosx_10_12_x86_64.whl", hash = "sha256:1dbcca4508bca7847fe2d64a05b237a3dcaec1f959aedb756d5b1c67b770c5ee", size = 7438408 },
    { url = "https://files.pythonhosted.org/packages/aa/59/4d13e5b6298b1ca5525eea8c68d3806ae93ab6d0bb17ca9846aa3156b92b/matplotlib-3.7.5-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:4cdf4ef46c2a1609a50411b66940b31778db1e4b73d4ecc2eaa40bd588979b13", size = 7341782 },
    { url = "https://files.pythonhosted.org/packages/9e/c4/f562df04b08487731743511ff274ae5d31dce2ff3e5621f8b070d20ab54a/matplotlib-3.7.5-cp38-cp38-manylinux_2_12_i686.manylinux2010_i686.whl", hash = "sha256:167200ccfefd1674b60e957186dfd9baf58b324562ad1a28e5d0a6b3bea77905", size = 9196487 },
    { url = "https://files.pythonhosted.org/packages/30/33/cc27211d2ffeee4fd7402dca137b6e8a83f6dcae3d4be8d0ad5068555561/matplotlib-3.7.5-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:53e64522934df6e1818b25fd48cf3b645b11740d78e6ef765fbb5fa5ce080d02", size = 9213051 },
    { url = "https://files.pythonhosted.org/packages/9b/9d/8bd37c86b79312c9dbcfa379dec32303f9b38e8456e0829d7e666a0e0a05/matplotlib-3.7.5-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d3e3bc79b2d7d615067bd010caff9243ead1fc95cf735c16e4b2583173f717eb", size = 11370807 },
    { url = "https://files.pythonhosted.org/packages/c0/1e/b24a07a849c8d458f1b3724f49029f0dedf748bdedb4d5f69491314838b6/matplotlib-3.7.5-cp38-cp38-win32.whl", hash = "sha256:6b641b48c6819726ed47c55835cdd330e53747d4efff574109fd79b2d8a13748", size = 7340461 },
    { url = "https://files.pythonhosted.org/packages/16/51/58b0b9de42fe1e665736d9286f88b5f1556a0e22bed8a71f468231761083/matplotlib-3.7.5-cp38-cp38-win_amd64.whl", hash = "sha256:f0b60993ed3488b4532ec6b697059897891927cbfc2b8d458a891b60ec03d9d7", size = 7507471 },
    { url = "https://files.pythonhosted.org/packages/0d/00/17487e9e8949ca623af87f6c8767408efe7530b7e1f4d6897fa7fa940834/matplotlib-3.7.5-cp39-cp39-macosx_10_12_universal2.whl", hash = "sha256:090964d0afaff9c90e4d8de7836757e72ecfb252fb02884016d809239f715651", size = 8323175 },
    { url = "https://files.pythonhosted.org/packages/6a/84/be0acd521fa9d6697657cf35878153f8009a42b4b75237aebc302559a8a9/matplotlib-3.7.5-cp39-cp39-macosx_10_12_x86_64.whl", hash = "sha256:9fc6fcfbc55cd719bc0bfa60bde248eb68cf43876d4c22864603bdd23962ba25", size = 7438737 },
    { url = "https://files.pythonhosted.org/packages/17/39/175f36a6d68d0cf47a4fecbae9728048355df23c9feca8688f1476b198e6/matplotlib-3.7.5-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:5e7cc3078b019bb863752b8b60e8b269423000f1603cb2299608231996bd9d54", size = 7341916 },
    { url = "https://files.pythonhosted.org/packages/36/c0/9a1c2a79f85c15d41b60877cbc333694ed80605e5c97a33880c4ecfd5bf1/matplotlib-3.7.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1e4e9a868e8163abaaa8259842d85f949a919e1ead17644fb77a60427c90473c", size = 11352264 },
    { url = "https://files.pythonhosted.org/packages/a6/39/b0204e0e7a899b0676733366a55ccafa723799b719bc7f2e85e5ecde26a0/matplotlib-3.7.5-cp39-cp39-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:fa7ebc995a7d747dacf0a717d0eb3aa0f0c6a0e9ea88b0194d3a3cd241a1500f", size = 11454722 },
    { url = "https://files.pythonhosted.org/packages/d8/39/64dd1d36c79e72e614977db338d180cf204cf658927c05a8ef2d47feb4c0/matplotlib-3.7.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3785bfd83b05fc0e0c2ae4c4a90034fe693ef96c679634756c50fe6efcc09856", size = 11576343 },
    { url = "https://files.pythonhosted.org/packages/31/b4/e77bc11394d858bdf15e356980fceb4ac9604b0fa8212ef3ca4f1dc166b8/matplotlib-3.7.5-cp39-cp39-win32.whl", hash = "sha256:29b058738c104d0ca8806395f1c9089dfe4d4f0f78ea765c6c704469f3fffc81", size = 7340455 },
    { url = "https://files.pythonhosted.org/packages/4a/84/081820c596b9555ecffc6819ee71f847f2fbb0d7c70a42c1eeaa54edf3e0/matplotlib-3.7.5-cp39-cp39-win_amd64.whl", hash = "sha256:fd4028d570fa4b31b7b165d4a685942ae9cdc669f33741e388c01857d9723eab", size = 7507711 },
    { url = "https://files.pythonhosted.org/packages/27/6c/1bb10f3d6f337b9faa2e96a251bd87ba5fed85a608df95eb4d69acc109f0/matplotlib-3.7.5-pp38-pypy38_pp73-macosx_10_12_x86_64.whl", hash = "sha256:2a9a3f4d6a7f88a62a6a18c7e6a84aedcaf4faf0708b4ca46d87b19f1b526f88", size = 7397285 },
    { url = "https://files.pythonhosted.org/packages/b2/36/66cfea213e9ba91cda9e257542c249ed235d49021af71c2e8007107d7d4c/matplotlib-3.7.5-pp38-pypy38_pp73-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:b9b3fd853d4a7f008a938df909b96db0b454225f935d3917520305b90680579c", size = 7552612 },
    { url = "https://files.pythonhosted.org/packages/77/df/16655199bf984c37c6a816b854bc032b56aef521aadc04f27928422f3c91/matplotlib-3.7.5-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f0ad550da9f160737d7890217c5eeed4337d07e83ca1b2ca6535078f354e7675", size = 7515564 },
    { url = "https://files.pythonhosted.org/packages/5b/c8/3534c3705a677b71abb6be33609ba129fdeae2ea4e76b2fd3ab62c86fab3/matplotlib-3.7.5-pp38-pypy38_pp73-win_amd64.whl", hash = "sha256:20da7924a08306a861b3f2d1da0d1aa9a6678e480cf8eacffe18b565af2813e7", size = 7521336 },
    { url = "https://files.pythonhosted.org/packages/20/a0/c5c0d410798b387ed3a177a5a7eba21055dd9c41d4b15bd0861241a5a60e/matplotlib-3.7.5-pp39-pypy39_pp73-macosx_10_12_x86_64.whl", hash = "sha256:b45c9798ea6bb920cb77eb7306409756a7fab9db9b463e462618e0559aecb30e", size = 7397931 },
    { url = "https://files.pythonhosted.org/packages/c3/2f/9e9509727d4c7d1b8e2c88e9330a97d54a1dd20bd316a0c8d2f8b38c4513/matplotlib-3.7.5-pp39-pypy39_pp73-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:a99866267da1e561c7776fe12bf4442174b79aac1a47bd7e627c7e4d077ebd83", size = 7553224 },
    { url = "https://files.pythonhosted.org/packages/89/0c/5f3e403dcf5c23799c92b0139dd00e41caf23983e9281f5bfeba3065e7d2/matplotlib-3.7.5-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2b6aa62adb6c268fc87d80f963aca39c64615c31830b02697743c95590ce3fbb", size = 7513250 },
    { url = "https://files.pythonhosted.org/packages/87/e0/03eba0a8c3775ef910dbb3a287114a64c47abbcaeab2543c59957f155a86/matplotlib-3.7.5-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:e530ab6a0afd082d2e9c17eb1eb064a63c5b09bb607b2b74fa41adbe3e162286", size = 7521729 },
]

[[package]]
name = "mdurl"
version = "0.1.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d6/54/cfe61301667036ec958cb99bd3efefba235e65cdeb9c84d24a8293ba1d90/mdurl-0.1.2.tar.gz", hash = "sha256:bb413d29f5eea38f31dd4754dd7377d4465116fb207585f97bf925588687c1ba", size = 8729 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl", hash = "sha256:84008a41e51615a49fc9966191ff91509e3c40b939176e643fd50a5c2196b8f8", size = 9979 },
]

[[package]]
name = "murmurhash"
version = "1.0.12"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/64/d9/e7c6a7d4e9b5320c17e54af6f9edd2f521c6f86bbbb72aba571f641a9793/murmurhash-1.0.12.tar.gz", hash = "sha256:467b7ee31c1f79f46d00436a1957fc52a0e5801369dd2f30eb7655f380735b5f", size = 13233 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/74/4c/bc0a79c7b0ebec63256ac547e2cecbae73badcd26e874231ff901665e8fc/murmurhash-1.0.12-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:a3f492bbf6f879b6eaf9da4be7471f4b68a3e3ae525aac0f35c2ae27ec91265c", size = 26857 },
    { url = "https://files.pythonhosted.org/packages/2c/dc/824bd5cf239d6b6997f83dd94c4a99a48f5f2a6267174cf191ddb844f997/murmurhash-1.0.12-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:3493e0c10a64fa72026af2ea2271d8b3511a438de3c6a771b7a57771611b9c08", size = 26974 },
    { url = "https://files.pythonhosted.org/packages/51/b2/67f4e99f9b577187ec1376ff37478da87b88f2f8092c1f1351b18cb29fc6/murmurhash-1.0.12-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:95989ddbb187b9934e5b0e7f450793a445814b6c293a7bf92df56913c3a87c1e", size = 126364 },
    { url = "https://files.pythonhosted.org/packages/4e/10/c7efbc91842ec6d519296129071cc55ba50d5e120e796dac536e4c299dc3/murmurhash-1.0.12-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2efef9f9aad98ec915a830f0c53d14ce6807ccc6e14fd2966565ef0b71cfa086", size = 124315 },
    { url = "https://files.pythonhosted.org/packages/92/87/dc7dbca647909721006405b8f956628dfbd2fd4f7701f6dfcd5e40f29b4f/murmurhash-1.0.12-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:b3147d171a5e5d2953b5eead21d15ea59b424844b4504a692c4b9629191148ed", size = 120355 },
    { url = "https://files.pythonhosted.org/packages/ff/36/cf13614b4bb62a956c62a3d8cd81fb4e0dd35e982dd7d7d028522ba4d9d9/murmurhash-1.0.12-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:736c869bef5023540dde52a9338085ac823eda3f09591ba1b4ed2c09c8b378db", size = 119979 },
    { url = "https://files.pythonhosted.org/packages/05/b9/06bfba06b9fb4855db2cbbeb72eac7a879209c2b989b3de5d3383c49ca04/murmurhash-1.0.12-cp310-cp310-win_amd64.whl", hash = "sha256:b81feb5bfd13bce638ccf910c685b04ad0537635918d04c83b291ce0441776da", size = 25373 },
    { url = "https://files.pythonhosted.org/packages/d3/f4/0208624de330224f3a8981c030007fc4a3583ca6b4d4dd3275364c1d06e6/murmurhash-1.0.12-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:8b236b76a256690e745b63b679892878ec4f01deeeda8d311482a9b183d2d452", size = 26793 },
    { url = "https://files.pythonhosted.org/packages/2f/a4/a387486e79bcc04f3d3b123195fd4cca74a7ba439d6c45b35c5366c66586/murmurhash-1.0.12-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:8bc3756dd657ed90c1354705e66513c11516929fe726e7bc91c79734d190f394", size = 26884 },
    { url = "https://files.pythonhosted.org/packages/9f/38/ec45a33c519feb802cdf0fe9dd1b1e6c15897c43d29c738eaae61da8ae5d/murmurhash-1.0.12-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:fd41e4c3d7936b69010d76e5edff363bf40fd918d86287a14e924363d7828522", size = 136101 },
    { url = "https://files.pythonhosted.org/packages/0b/d5/6f1b561d8b14ef01d28d9cec278870bec01d8a569cfbc694e68ac05a5615/murmurhash-1.0.12-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:36be2831df750163495e471d24aeef6aca1b2a3c4dfb05f40114859db47ff3f2", size = 134309 },
    { url = "https://files.pythonhosted.org/packages/e8/78/2df6cdce439f6b8509d7947b8c47e7fe2589671899eb6399f4e2f602fe1f/murmurhash-1.0.12-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:b078c10f9c82cbd144b1200061fbfa7f99af9d5d8d7f7d8a324370169e3da7c2", size = 131134 },
    { url = "https://files.pythonhosted.org/packages/43/0b/f0a5a622c505786d3d1dc1ad3e7f6b6fbfcae2665b205e07b3882185c39f/murmurhash-1.0.12-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:307ca8da5f038635ded9de722fe11f07f06a2b76442ae272dcccbff6086de487", size = 128630 },
    { url = "https://files.pythonhosted.org/packages/de/30/ceb9217cdba72bc0bf8466e373e12e5a42945cc85eda0a7c479e319e07ae/murmurhash-1.0.12-cp311-cp311-win_amd64.whl", hash = "sha256:1b4ab5ba5ba909959659989f3bf57903f31f49906fe40f00aec81e32eea69a88", size = 25417 },
    { url = "https://files.pythonhosted.org/packages/38/c7/0dc2914c24adb9466b69606dfdee7bbfed13476f4dda3753e0185cfbbe1f/murmurhash-1.0.12-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:1a4c97c8ffbedb62b760c3c2f77b5b8cb0e0ac0ec83a74d2f289e113e3e92ed5", size = 27120 },
    { url = "https://files.pythonhosted.org/packages/ae/d7/aea56101f225eb021cfd47245d55680605665b556aba95eecee937b4d4d6/murmurhash-1.0.12-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:9574f0b634f059158bb89734a811e435ac9ad2335c02a7abb59f1875dcce244c", size = 27081 },
    { url = "https://files.pythonhosted.org/packages/f4/68/4b723e0f318e92b0b4779f41ff5d9446e1dc0e68aca2f0043e1fab3fc1be/murmurhash-1.0.12-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:701cc0ce91809b4d7c2e0518be759635205e1e181325792044f5a8118019f716", size = 138552 },
    { url = "https://files.pythonhosted.org/packages/13/40/eed53da76a428f404ec9db6d0983691c61d2744fea7070c6b31caca31ac4/murmurhash-1.0.12-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7e1c9de2167a9d408d121ebc918bcb20b2718ec956f3aae0ded53d9bb224bb8e", size = 138589 },
    { url = "https://files.pythonhosted.org/packages/12/e8/1b9164e62f75bf23d6af5262421985f45bce9bd5c4970a62b83ea7cb62df/murmurhash-1.0.12-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:94a52972835bdae8af18147c67c398ff3ea1d875f5b8dca1e1aa0fadb892f546", size = 129244 },
    { url = "https://files.pythonhosted.org/packages/a7/20/c91f06d3692705bc7ec16c219143cc56062afd8080756d55e0678a7b704c/murmurhash-1.0.12-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:cc88004c8615dcabe31d21142689f719fdf549ba782850bef389cf227a1df575", size = 128944 },
    { url = "https://files.pythonhosted.org/packages/b2/66/7d74a9f547dd719e86245e2a3d126140335861b8e362bdd22c7f9842a2b8/murmurhash-1.0.12-cp312-cp312-win_amd64.whl", hash = "sha256:8c5b8804c07a76f779e67f83aad37bc2189a0e65ebdd3f2b305242d489d31e03", size = 25554 },
    { url = "https://files.pythonhosted.org/packages/12/77/bec7e3f00b0e23bfa027704d4023fea808d8cc0e593dd4247f4579de6776/murmurhash-1.0.12-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:63f10c6d6ef9ee85073dd896d2c4e0ab161bc6b8e7e9201c69f8061f9f1b6468", size = 26474 },
    { url = "https://files.pythonhosted.org/packages/57/46/8dd3631cfb58435004678179a70352d3258b159c3f110e4f11fb23b1f776/murmurhash-1.0.12-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:66356f6308fd2a44a8ab056f020acd5bc22302f23ef5cce3705f2493e0fe9c3c", size = 26418 },
    { url = "https://files.pythonhosted.org/packages/50/8f/ae8ee91c1b9ecdc4d849382af64b10e5d3c79ee7fcf8af13400d32092ae7/murmurhash-1.0.12-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bdb2104aa3471324724abf5a3a76fc94bcbeaf023bb6a6dd94da567b8633d8a6", size = 133342 },
    { url = "https://files.pythonhosted.org/packages/cd/19/3ce034b0c068e8f88ea0ac28e196359aacf3c52718fbce1f7dbcf088261f/murmurhash-1.0.12-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7a7ef5fb37e72536458ac4a6f486fb374c60ac4c4862d9195d3d4b58239a91de", size = 133062 },
    { url = "https://files.pythonhosted.org/packages/a0/0c/f9a868eb39751b9dceb9e35d91e8cf321dad8ce9e3e965d067b0fff0547a/murmurhash-1.0.12-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:8bd5524de195991ce3551b14286ec0b730cc9dd2e10565dad2ae470eec082028", size = 124858 },
    { url = "https://files.pythonhosted.org/packages/b6/fc/52bcb3afc95733f30ec76e07cae4b5d0081fa049ade418303faeee619766/murmurhash-1.0.12-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:19de30edaaa2217cd0c41b6cf6bbfa418be5d7fdf267ca92e5e3710d4daac593", size = 124686 },
    { url = "https://files.pythonhosted.org/packages/cf/99/9cdea62dec8ea26a35a8231ee09c83b16f9dedf16280a7a15f41d2061706/murmurhash-1.0.12-cp313-cp313-win_amd64.whl", hash = "sha256:7dc4ebdfed7ef8ed70519962ac9b704e91978ee14e049f1ff37bca2f579ce84d", size = 24702 },
    { url = "https://files.pythonhosted.org/packages/8a/1d/4abc869cb939888dee758529094f708b95eb96d1d8b823b09753de451366/murmurhash-1.0.12-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:c9bb5652a3444d5a5bf5d164e6b5e6c8f5715d031627ff79d58caac0e510e8d8", size = 26853 },
    { url = "https://files.pythonhosted.org/packages/e5/1f/5822bd821b418340a368b82b54b5eca71c25c42c244881db00e4a79b641e/murmurhash-1.0.12-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:ef56fdee81e2b4191c5b7416b5428cb920260a91f028a82a1680b14137eaf32c", size = 26976 },
    { url = "https://files.pythonhosted.org/packages/9f/f4/b3bc4319227654efc973ba5283f3685a3885f0c6bc25a6980ee4909dbace/murmurhash-1.0.12-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:91042b85d3214ebaba505d7349f0bcd745b07e7163459909d622ea10a04c2dea", size = 126124 },
    { url = "https://files.pythonhosted.org/packages/53/64/ed2a4c2ccce4f6fc81618bbdef07493a4c96585d4655806d2f5ab07cd861/murmurhash-1.0.12-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7de1552326f4f8c0b63d26f823fa66a4dcf9c01164e252374d84bcf86a6af2fe", size = 124094 },
    { url = "https://files.pythonhosted.org/packages/61/e5/eecb6dac784b62f7baf3b63dba42f49a8c1bd075735832e5203a2e4b2125/murmurhash-1.0.12-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:16de7dee9e082159b7ad4cffd62b0c03bbc385b84dcff448ce27bb14c505d12d", size = 120120 },
    { url = "https://files.pythonhosted.org/packages/48/6d/34284c02a8f45f0278662c092c08ea7da33aeb1af7e919c55f21a5461342/murmurhash-1.0.12-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:8b5de26a7235d8794403353423cd65720d8496363ab75248120107559b12a8c6", size = 119774 },
    { url = "https://files.pythonhosted.org/packages/e0/04/5e66a4ed25155251263d8b3e9a954934ab97ad91565cf5133dfa1dfb49fc/murmurhash-1.0.12-cp39-cp39-win_amd64.whl", hash = "sha256:d1ad46f78de3ce3f3a8e8c2f87af32bcede893f047c87389c7325bb1f3f46b47", size = 25373 },
]

[[package]]
name = "mypy"
version = "1.14.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "mypy-extensions" },
    { name = "tomli", marker = "python_full_version < '3.11'" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b9/eb/2c92d8ea1e684440f54fa49ac5d9a5f19967b7b472a281f419e69a8d228e/mypy-1.14.1.tar.gz", hash = "sha256:7ec88144fe9b510e8475ec2f5f251992690fcf89ccb4500b214b4226abcd32d6", size = 3216051 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/9b/7a/87ae2adb31d68402da6da1e5f30c07ea6063e9f09b5e7cfc9dfa44075e74/mypy-1.14.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:52686e37cf13d559f668aa398dd7ddf1f92c5d613e4f8cb262be2fb4fedb0fcb", size = 11211002 },
    { url = "https://files.pythonhosted.org/packages/e1/23/eada4c38608b444618a132be0d199b280049ded278b24cbb9d3fc59658e4/mypy-1.14.1-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:1fb545ca340537d4b45d3eecdb3def05e913299ca72c290326be19b3804b39c0", size = 10358400 },
    { url = "https://files.pythonhosted.org/packages/43/c9/d6785c6f66241c62fd2992b05057f404237deaad1566545e9f144ced07f5/mypy-1.14.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:90716d8b2d1f4cd503309788e51366f07c56635a3309b0f6a32547eaaa36a64d", size = 12095172 },
    { url = "https://files.pythonhosted.org/packages/c3/62/daa7e787770c83c52ce2aaf1a111eae5893de9e004743f51bfcad9e487ec/mypy-1.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:2ae753f5c9fef278bcf12e1a564351764f2a6da579d4a81347e1d5a15819997b", size = 12828732 },
    { url = "https://files.pythonhosted.org/packages/1b/a2/5fb18318a3637f29f16f4e41340b795da14f4751ef4f51c99ff39ab62e52/mypy-1.14.1-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:e0fe0f5feaafcb04505bcf439e991c6d8f1bf8b15f12b05feeed96e9e7bf1427", size = 13012197 },
    { url = "https://files.pythonhosted.org/packages/28/99/e153ce39105d164b5f02c06c35c7ba958aaff50a2babba7d080988b03fe7/mypy-1.14.1-cp310-cp310-win_amd64.whl", hash = "sha256:7d54bd85b925e501c555a3227f3ec0cfc54ee8b6930bd6141ec872d1c572f81f", size = 9780836 },
    { url = "https://files.pythonhosted.org/packages/da/11/a9422850fd506edbcdc7f6090682ecceaf1f87b9dd847f9df79942da8506/mypy-1.14.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:f995e511de847791c3b11ed90084a7a0aafdc074ab88c5a9711622fe4751138c", size = 11120432 },
    { url = "https://files.pythonhosted.org/packages/b6/9e/47e450fd39078d9c02d620545b2cb37993a8a8bdf7db3652ace2f80521ca/mypy-1.14.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:d64169ec3b8461311f8ce2fd2eb5d33e2d0f2c7b49116259c51d0d96edee48d1", size = 10279515 },
    { url = "https://files.pythonhosted.org/packages/01/b5/6c8d33bd0f851a7692a8bfe4ee75eb82b6983a3cf39e5e32a5d2a723f0c1/mypy-1.14.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:ba24549de7b89b6381b91fbc068d798192b1b5201987070319889e93038967a8", size = 12025791 },
    { url = "https://files.pythonhosted.org/packages/f0/4c/e10e2c46ea37cab5c471d0ddaaa9a434dc1d28650078ac1b56c2d7b9b2e4/mypy-1.14.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:183cf0a45457d28ff9d758730cd0210419ac27d4d3f285beda038c9083363b1f", size = 12749203 },
    { url = "https://files.pythonhosted.org/packages/88/55/beacb0c69beab2153a0f57671ec07861d27d735a0faff135a494cd4f5020/mypy-1.14.1-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:f2a0ecc86378f45347f586e4163d1769dd81c5a223d577fe351f26b179e148b1", size = 12885900 },
    { url = "https://files.pythonhosted.org/packages/a2/75/8c93ff7f315c4d086a2dfcde02f713004357d70a163eddb6c56a6a5eff40/mypy-1.14.1-cp311-cp311-win_amd64.whl", hash = "sha256:ad3301ebebec9e8ee7135d8e3109ca76c23752bac1e717bc84cd3836b4bf3eae", size = 9777869 },
    { url = "https://files.pythonhosted.org/packages/43/1b/b38c079609bb4627905b74fc6a49849835acf68547ac33d8ceb707de5f52/mypy-1.14.1-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:30ff5ef8519bbc2e18b3b54521ec319513a26f1bba19a7582e7b1f58a6e69f14", size = 11266668 },
    { url = "https://files.pythonhosted.org/packages/6b/75/2ed0d2964c1ffc9971c729f7a544e9cd34b2cdabbe2d11afd148d7838aa2/mypy-1.14.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:cb9f255c18052343c70234907e2e532bc7e55a62565d64536dbc7706a20b78b9", size = 10254060 },
    { url = "https://files.pythonhosted.org/packages/a1/5f/7b8051552d4da3c51bbe8fcafffd76a6823779101a2b198d80886cd8f08e/mypy-1.14.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:8b4e3413e0bddea671012b063e27591b953d653209e7a4fa5e48759cda77ca11", size = 11933167 },
    { url = "https://files.pythonhosted.org/packages/04/90/f53971d3ac39d8b68bbaab9a4c6c58c8caa4d5fd3d587d16f5927eeeabe1/mypy-1.14.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:553c293b1fbdebb6c3c4030589dab9fafb6dfa768995a453d8a5d3b23784af2e", size = 12864341 },
    { url = "https://files.pythonhosted.org/packages/03/d2/8bc0aeaaf2e88c977db41583559319f1821c069e943ada2701e86d0430b7/mypy-1.14.1-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:fad79bfe3b65fe6a1efaed97b445c3d37f7be9fdc348bdb2d7cac75579607c89", size = 12972991 },
    { url = "https://files.pythonhosted.org/packages/6f/17/07815114b903b49b0f2cf7499f1c130e5aa459411596668267535fe9243c/mypy-1.14.1-cp312-cp312-win_amd64.whl", hash = "sha256:8fa2220e54d2946e94ab6dbb3ba0a992795bd68b16dc852db33028df2b00191b", size = 9879016 },
    { url = "https://files.pythonhosted.org/packages/9e/15/bb6a686901f59222275ab228453de741185f9d54fecbaacec041679496c6/mypy-1.14.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:92c3ed5afb06c3a8e188cb5da4984cab9ec9a77ba956ee419c68a388b4595255", size = 11252097 },
    { url = "https://files.pythonhosted.org/packages/f8/b3/8b0f74dfd072c802b7fa368829defdf3ee1566ba74c32a2cb2403f68024c/mypy-1.14.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:dbec574648b3e25f43d23577309b16534431db4ddc09fda50841f1e34e64ed34", size = 10239728 },
    { url = "https://files.pythonhosted.org/packages/c5/9b/4fd95ab20c52bb5b8c03cc49169be5905d931de17edfe4d9d2986800b52e/mypy-1.14.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:8c6d94b16d62eb3e947281aa7347d78236688e21081f11de976376cf010eb31a", size = 11924965 },
    { url = "https://files.pythonhosted.org/packages/56/9d/4a236b9c57f5d8f08ed346914b3f091a62dd7e19336b2b2a0d85485f82ff/mypy-1.14.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:d4b19b03fdf54f3c5b2fa474c56b4c13c9dbfb9a2db4370ede7ec11a2c5927d9", size = 12867660 },
    { url = "https://files.pythonhosted.org/packages/40/88/a61a5497e2f68d9027de2bb139c7bb9abaeb1be1584649fa9d807f80a338/mypy-1.14.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:0c911fde686394753fff899c409fd4e16e9b294c24bfd5e1ea4675deae1ac6fd", size = 12969198 },
    { url = "https://files.pythonhosted.org/packages/54/da/3d6fc5d92d324701b0c23fb413c853892bfe0e1dbe06c9138037d459756b/mypy-1.14.1-cp313-cp313-win_amd64.whl", hash = "sha256:8b21525cb51671219f5307be85f7e646a153e5acc656e5cebf64bfa076c50107", size = 9885276 },
    { url = "https://files.pythonhosted.org/packages/39/02/1817328c1372be57c16148ce7d2bfcfa4a796bedaed897381b1aad9b267c/mypy-1.14.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:7084fb8f1128c76cd9cf68fe5971b37072598e7c31b2f9f95586b65c741a9d31", size = 11143050 },
    { url = "https://files.pythonhosted.org/packages/b9/07/99db9a95ece5e58eee1dd87ca456a7e7b5ced6798fd78182c59c35a7587b/mypy-1.14.1-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:8f845a00b4f420f693f870eaee5f3e2692fa84cc8514496114649cfa8fd5e2c6", size = 10321087 },
    { url = "https://files.pythonhosted.org/packages/9a/eb/85ea6086227b84bce79b3baf7f465b4732e0785830726ce4a51528173b71/mypy-1.14.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:44bf464499f0e3a2d14d58b54674dee25c031703b2ffc35064bd0df2e0fac319", size = 12066766 },
    { url = "https://files.pythonhosted.org/packages/4b/bb/f01bebf76811475d66359c259eabe40766d2f8ac8b8250d4e224bb6df379/mypy-1.14.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:c99f27732c0b7dc847adb21c9d47ce57eb48fa33a17bc6d7d5c5e9f9e7ae5bac", size = 12787111 },
    { url = "https://files.pythonhosted.org/packages/2f/c9/84837ff891edcb6dcc3c27d85ea52aab0c4a34740ff5f0ccc0eb87c56139/mypy-1.14.1-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:bce23c7377b43602baa0bd22ea3265c49b9ff0b76eb315d6c34721af4cdf1d9b", size = 12974331 },
    { url = "https://files.pythonhosted.org/packages/84/5f/901e18464e6a13f8949b4909535be3fa7f823291b8ab4e4b36cfe57d6769/mypy-1.14.1-cp38-cp38-win_amd64.whl", hash = "sha256:8edc07eeade7ebc771ff9cf6b211b9a7d93687ff892150cb5692e4f4272b0837", size = 9763210 },
    { url = "https://files.pythonhosted.org/packages/ca/1f/186d133ae2514633f8558e78cd658070ba686c0e9275c5a5c24a1e1f0d67/mypy-1.14.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:3888a1816d69f7ab92092f785a462944b3ca16d7c470d564165fe703b0970c35", size = 11200493 },
    { url = "https://files.pythonhosted.org/packages/af/fc/4842485d034e38a4646cccd1369f6b1ccd7bc86989c52770d75d719a9941/mypy-1.14.1-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:46c756a444117c43ee984bd055db99e498bc613a70bbbc120272bd13ca579fbc", size = 10357702 },
    { url = "https://files.pythonhosted.org/packages/b4/e6/457b83f2d701e23869cfec013a48a12638f75b9d37612a9ddf99072c1051/mypy-1.14.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.manylinux_2_28_aarch64.whl", hash = "sha256:27fc248022907e72abfd8e22ab1f10e903915ff69961174784a3900a8cba9ad9", size = 12091104 },
    { url = "https://files.pythonhosted.org/packages/f1/bf/76a569158db678fee59f4fd30b8e7a0d75bcbaeef49edd882a0d63af6d66/mypy-1.14.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_28_x86_64.whl", hash = "sha256:499d6a72fb7e5de92218db961f1a66d5f11783f9ae549d214617edab5d4dbdbb", size = 12830167 },
    { url = "https://files.pythonhosted.org/packages/43/bc/0bc6b694b3103de9fed61867f1c8bd33336b913d16831431e7cb48ef1c92/mypy-1.14.1-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:57961db9795eb566dc1d1b4e9139ebc4c6b0cb6e7254ecde69d1552bf7613f60", size = 13013834 },
    { url = "https://files.pythonhosted.org/packages/b0/79/5f5ec47849b6df1e6943d5fd8e6632fbfc04b4fd4acfa5a5a9535d11b4e2/mypy-1.14.1-cp39-cp39-win_amd64.whl", hash = "sha256:07ba89fdcc9451f2ebb02853deb6aaaa3d2239a236669a63ab3801bbf923ef5c", size = 9781231 },
    { url = "https://files.pythonhosted.org/packages/a0/b5/32dd67b69a16d088e533962e5044e51004176a9952419de0370cdaead0f8/mypy-1.14.1-py3-none-any.whl", hash = "sha256:b66a60cc4073aeb8ae00057f9c1f64d49e90f918fbcef9a977eb121da8b8f1d1", size = 2752905 },
]

[[package]]
name = "mypy-extensions"
version = "1.0.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/98/a4/1ab47638b92648243faf97a5aeb6ea83059cc3624972ab6b8d2316078d3f/mypy_extensions-1.0.0.tar.gz", hash = "sha256:75dbf8955dc00442a438fc4d0666508a9a97b6bd41aa2f0ffe9d2f2725af0782", size = 4433 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/2a/e2/5d3f6ada4297caebe1a2add3b126fe800c96f56dbe5d1988a2cbe0b267aa/mypy_extensions-1.0.0-py3-none-any.whl", hash = "sha256:4392f6c0eb8a5668a69e23d168ffa70f0be9ccfd32b5cc2d26a34ae5b844552d", size = 4695 },
]

[[package]]
name = "nltk"
version = "3.9.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "click" },
    { name = "joblib" },
    { name = "regex" },
    { name = "tqdm" },
]
sdist = { url = "https://files.pythonhosted.org/packages/3c/87/db8be88ad32c2d042420b6fd9ffd4a149f9a0d7f0e86b3f543be2eeeedd2/nltk-3.9.1.tar.gz", hash = "sha256:87d127bd3de4bd89a4f81265e5fa59cb1b199b27440175370f7417d2bc7ae868", size = 2904691 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/4d/66/7d9e26593edda06e8cb531874633f7c2372279c3b0f46235539fe546df8b/nltk-3.9.1-py3-none-any.whl", hash = "sha256:4fa26829c5b00715afe3061398a8989dc643b92ce7dd93fb4585a70930d168a1", size = 1505442 },
]

[[package]]
name = "numpy"
version = "1.24.4"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/a4/9b/027bec52c633f6556dba6b722d9a0befb40498b9ceddd29cbe67a45a127c/numpy-1.24.4.tar.gz", hash = "sha256:80f5e3a4e498641401868df4208b74581206afbee7cf7b8329daae82676d9463", size = 10911229 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/6b/80/6cdfb3e275d95155a34659163b83c09e3a3ff9f1456880bec6cc63d71083/numpy-1.24.4-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:c0bfb52d2169d58c1cdb8cc1f16989101639b34c7d3ce60ed70b19c63eba0b64", size = 19789140 },
    { url = "https://files.pythonhosted.org/packages/64/5f/3f01d753e2175cfade1013eea08db99ba1ee4bdb147ebcf3623b75d12aa7/numpy-1.24.4-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:ed094d4f0c177b1b8e7aa9cba7d6ceed51c0e569a5318ac0ca9a090680a6a1b1", size = 13854297 },
    { url = "https://files.pythonhosted.org/packages/5a/b3/2f9c21d799fa07053ffa151faccdceeb69beec5a010576b8991f614021f7/numpy-1.24.4-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:79fc682a374c4a8ed08b331bef9c5f582585d1048fa6d80bc6c35bc384eee9b4", size = 13995611 },
    { url = "https://files.pythonhosted.org/packages/10/be/ae5bf4737cb79ba437879915791f6f26d92583c738d7d960ad94e5c36adf/numpy-1.24.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7ffe43c74893dbf38c2b0a1f5428760a1a9c98285553c89e12d70a96a7f3a4d6", size = 17282357 },
    { url = "https://files.pythonhosted.org/packages/c0/64/908c1087be6285f40e4b3e79454552a701664a079321cff519d8c7051d06/numpy-1.24.4-cp310-cp310-win32.whl", hash = "sha256:4c21decb6ea94057331e111a5bed9a79d335658c27ce2adb580fb4d54f2ad9bc", size = 12429222 },
    { url = "https://files.pythonhosted.org/packages/22/55/3d5a7c1142e0d9329ad27cece17933b0e2ab4e54ddc5c1861fbfeb3f7693/numpy-1.24.4-cp310-cp310-win_amd64.whl", hash = "sha256:b4bea75e47d9586d31e892a7401f76e909712a0fd510f58f5337bea9572c571e", size = 14841514 },
    { url = "https://files.pythonhosted.org/packages/a9/cc/5ed2280a27e5dab12994c884f1f4d8c3bd4d885d02ae9e52a9d213a6a5e2/numpy-1.24.4-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:f136bab9c2cfd8da131132c2cf6cc27331dd6fae65f95f69dcd4ae3c3639c810", size = 19775508 },
    { url = "https://files.pythonhosted.org/packages/c0/bc/77635c657a3668cf652806210b8662e1aff84b818a55ba88257abf6637a8/numpy-1.24.4-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:e2926dac25b313635e4d6cf4dc4e51c8c0ebfed60b801c799ffc4c32bf3d1254", size = 13840033 },
    { url = "https://files.pythonhosted.org/packages/a7/4c/96cdaa34f54c05e97c1c50f39f98d608f96f0677a6589e64e53104e22904/numpy-1.24.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:222e40d0e2548690405b0b3c7b21d1169117391c2e82c378467ef9ab4c8f0da7", size = 13991951 },
    { url = "https://files.pythonhosted.org/packages/22/97/dfb1a31bb46686f09e68ea6ac5c63fdee0d22d7b23b8f3f7ea07712869ef/numpy-1.24.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7215847ce88a85ce39baf9e89070cb860c98fdddacbaa6c0da3ffb31b3350bd5", size = 17278923 },
    { url = "https://files.pythonhosted.org/packages/35/e2/76a11e54139654a324d107da1d98f99e7aa2a7ef97cfd7c631fba7dbde71/numpy-1.24.4-cp311-cp311-win32.whl", hash = "sha256:4979217d7de511a8d57f4b4b5b2b965f707768440c17cb70fbf254c4b225238d", size = 12422446 },
    { url = "https://files.pythonhosted.org/packages/d8/ec/ebef2f7d7c28503f958f0f8b992e7ce606fb74f9e891199329d5f5f87404/numpy-1.24.4-cp311-cp311-win_amd64.whl", hash = "sha256:b7b1fc9864d7d39e28f41d089bfd6353cb5f27ecd9905348c24187a768c79694", size = 14834466 },
    { url = "https://files.pythonhosted.org/packages/11/10/943cfb579f1a02909ff96464c69893b1d25be3731b5d3652c2e0cf1281ea/numpy-1.24.4-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:1452241c290f3e2a312c137a9999cdbf63f78864d63c79039bda65ee86943f61", size = 19780722 },
    { url = "https://files.pythonhosted.org/packages/a7/ae/f53b7b265fdc701e663fbb322a8e9d4b14d9cb7b2385f45ddfabfc4327e4/numpy-1.24.4-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:04640dab83f7c6c85abf9cd729c5b65f1ebd0ccf9de90b270cd61935eef0197f", size = 13843102 },
    { url = "https://files.pythonhosted.org/packages/25/6f/2586a50ad72e8dbb1d8381f837008a0321a3516dfd7cb57fc8cf7e4bb06b/numpy-1.24.4-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a5425b114831d1e77e4b5d812b69d11d962e104095a5b9c3b641a218abcc050e", size = 14039616 },
    { url = "https://files.pythonhosted.org/packages/98/5d/5738903efe0ecb73e51eb44feafba32bdba2081263d40c5043568ff60faf/numpy-1.24.4-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:dd80e219fd4c71fc3699fc1dadac5dcf4fd882bfc6f7ec53d30fa197b8ee22dc", size = 17316263 },
    { url = "https://files.pythonhosted.org/packages/d1/57/8d328f0b91c733aa9aa7ee540dbc49b58796c862b4fbcb1146c701e888da/numpy-1.24.4-cp38-cp38-win32.whl", hash = "sha256:4602244f345453db537be5314d3983dbf5834a9701b7723ec28923e2889e0bb2", size = 12455660 },
    { url = "https://files.pythonhosted.org/packages/69/65/0d47953afa0ad569d12de5f65d964321c208492064c38fe3b0b9744f8d44/numpy-1.24.4-cp38-cp38-win_amd64.whl", hash = "sha256:692f2e0f55794943c5bfff12b3f56f99af76f902fc47487bdfe97856de51a706", size = 14868112 },
    { url = "https://files.pythonhosted.org/packages/9a/cd/d5b0402b801c8a8b56b04c1e85c6165efab298d2f0ab741c2406516ede3a/numpy-1.24.4-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:2541312fbf09977f3b3ad449c4e5f4bb55d0dbf79226d7724211acc905049400", size = 19816549 },
    { url = "https://files.pythonhosted.org/packages/14/27/638aaa446f39113a3ed38b37a66243e21b38110d021bfcb940c383e120f2/numpy-1.24.4-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:9667575fb6d13c95f1b36aca12c5ee3356bf001b714fc354eb5465ce1609e62f", size = 13879950 },
    { url = "https://files.pythonhosted.org/packages/8f/27/91894916e50627476cff1a4e4363ab6179d01077d71b9afed41d9e1f18bf/numpy-1.24.4-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f3a86ed21e4f87050382c7bc96571755193c4c1392490744ac73d660e8f564a9", size = 14030228 },
    { url = "https://files.pythonhosted.org/packages/7a/7c/d7b2a0417af6428440c0ad7cb9799073e507b1a465f827d058b826236964/numpy-1.24.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d11efb4dbecbdf22508d55e48d9c8384db795e1b7b51ea735289ff96613ff74d", size = 17311170 },
    { url = "https://files.pythonhosted.org/packages/18/9d/e02ace5d7dfccee796c37b995c63322674daf88ae2f4a4724c5dd0afcc91/numpy-1.24.4-cp39-cp39-win32.whl", hash = "sha256:6620c0acd41dbcb368610bb2f4d83145674040025e5536954782467100aa8835", size = 12454918 },
    { url = "https://files.pythonhosted.org/packages/63/38/6cc19d6b8bfa1d1a459daf2b3fe325453153ca7019976274b6f33d8b5663/numpy-1.24.4-cp39-cp39-win_amd64.whl", hash = "sha256:befe2bf740fd8373cf56149a5c23a0f601e82869598d41f8e188a0e9869926f8", size = 14867441 },
    { url = "https://files.pythonhosted.org/packages/a4/fd/8dff40e25e937c94257455c237b9b6bf5a30d42dd1cc11555533be099492/numpy-1.24.4-pp38-pypy38_pp73-macosx_10_9_x86_64.whl", hash = "sha256:31f13e25b4e304632a4619d0e0777662c2ffea99fcae2029556b17d8ff958aef", size = 19156590 },
    { url = "https://files.pythonhosted.org/packages/42/e7/4bf953c6e05df90c6d351af69966384fed8e988d0e8c54dad7103b59f3ba/numpy-1.24.4-pp38-pypy38_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:95f7ac6540e95bc440ad77f56e520da5bf877f87dca58bd095288dce8940532a", size = 16705744 },
    { url = "https://files.pythonhosted.org/packages/fc/dd/9106005eb477d022b60b3817ed5937a43dad8fd1f20b0610ea8a32fcb407/numpy-1.24.4-pp38-pypy38_pp73-win_amd64.whl", hash = "sha256:e98f220aa76ca2a977fe435f5b04d7b3470c0a2e6312907b37ba6068f26787f2", size = 14734290 },
]

[[package]]
name = "openpyxl"
version = "3.1.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "et-xmlfile" },
]
sdist = { url = "https://files.pythonhosted.org/packages/3d/f9/88d94a75de065ea32619465d2f77b29a0469500e99012523b91cc4141cd1/openpyxl-3.1.5.tar.gz", hash = "sha256:cf0e3cf56142039133628b5acffe8ef0c12bc902d2aadd3e0fe5878dc08d1050", size = 186464 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c0/da/977ded879c29cbd04de313843e76868e6e13408a94ed6b987245dc7c8506/openpyxl-3.1.5-py2.py3-none-any.whl", hash = "sha256:5282c12b107bffeef825f4617dc029afaf41d0ea60823bbb665ef3079dc79de2", size = 250910 },
]

[[package]]
name = "packaging"
version = "24.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d0/63/68dbb6eb2de9cb10ee4c9c14a0148804425e13c4fb20d61cce69f53106da/packaging-24.2.tar.gz", hash = "sha256:c228a6dc5e932d346bc5739379109d49e8853dd8223571c7c5b55260edc0b97f", size = 163950 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/88/ef/eb23f262cca3c0c4eb7ab1933c3b1f03d021f2c48f54763065b6f0e321be/packaging-24.2-py3-none-any.whl", hash = "sha256:09abb1bccd265c01f4a3aa3f7a7db064b36514d2cba19a2f694fe6150451a759", size = 65451 },
]

[[package]]
name = "pandas"
version = "2.0.3"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "numpy" },
    { name = "python-dateutil" },
    { name = "pytz" },
    { name = "tzdata" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b1/a7/824332581e258b5aa4f3763ecb2a797e5f9a54269044ba2e50ac19936b32/pandas-2.0.3.tar.gz", hash = "sha256:c02f372a88e0d17f36d3093a644c73cfc1788e876a7c4bcb4020a77512e2043c", size = 5284455 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/3c/b2/0d4a5729ce1ce11630c4fc5d5522a33b967b3ca146c210f58efde7c40e99/pandas-2.0.3-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:e4c7c9f27a4185304c7caf96dc7d91bc60bc162221152de697c98eb0b2648dd8", size = 11760908 },
    { url = "https://files.pythonhosted.org/packages/4a/f6/f620ca62365d83e663a255a41b08d2fc2eaf304e0b8b21bb6d62a7390fe3/pandas-2.0.3-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:f167beed68918d62bffb6ec64f2e1d8a7d297a038f86d4aed056b9493fca407f", size = 10823486 },
    { url = "https://files.pythonhosted.org/packages/c2/59/cb4234bc9b968c57e81861b306b10cd8170272c57b098b724d3de5eda124/pandas-2.0.3-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ce0c6f76a0f1ba361551f3e6dceaff06bde7514a374aa43e33b588ec10420183", size = 11571897 },
    { url = "https://files.pythonhosted.org/packages/e3/59/35a2892bf09ded9c1bf3804461efe772836a5261ef5dfb4e264ce813ff99/pandas-2.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ba619e410a21d8c387a1ea6e8a0e49bb42216474436245718d7f2e88a2f8d7c0", size = 12306421 },
    { url = "https://files.pythonhosted.org/packages/94/71/3a0c25433c54bb29b48e3155b959ac78f4c4f2f06f94d8318aac612cb80f/pandas-2.0.3-cp310-cp310-win32.whl", hash = "sha256:3ef285093b4fe5058eefd756100a367f27029913760773c8bf1d2d8bebe5d210", size = 9540792 },
    { url = "https://files.pythonhosted.org/packages/ed/30/b97456e7063edac0e5a405128065f0cd2033adfe3716fb2256c186bd41d0/pandas-2.0.3-cp310-cp310-win_amd64.whl", hash = "sha256:9ee1a69328d5c36c98d8e74db06f4ad518a1840e8ccb94a4ba86920986bb617e", size = 10664333 },
    { url = "https://files.pythonhosted.org/packages/b3/92/a5e5133421b49e901a12e02a6a7ef3a0130e10d13db8cb657fdd0cba3b90/pandas-2.0.3-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:b084b91d8d66ab19f5bb3256cbd5ea661848338301940e17f4492b2ce0801fe8", size = 11645672 },
    { url = "https://files.pythonhosted.org/packages/8f/bb/aea1fbeed5b474cb8634364718abe9030d7cc7a30bf51f40bd494bbc89a2/pandas-2.0.3-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:37673e3bdf1551b95bf5d4ce372b37770f9529743d2498032439371fc7b7eb26", size = 10693229 },
    { url = "https://files.pythonhosted.org/packages/d6/90/e7d387f1a416b14e59290baa7a454a90d719baebbf77433ff1bdcc727800/pandas-2.0.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b9cb1e14fdb546396b7e1b923ffaeeac24e4cedd14266c3497216dd4448e4f2d", size = 11581591 },
    { url = "https://files.pythonhosted.org/packages/d0/28/88b81881c056376254618fad622a5e94b5126db8c61157ea1910cd1c040a/pandas-2.0.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d9cd88488cceb7635aebb84809d087468eb33551097d600c6dad13602029c2df", size = 12219370 },
    { url = "https://files.pythonhosted.org/packages/e4/a5/212b9039e25bf8ebb97e417a96660e3dc925dacd3f8653d531b8f7fd9be4/pandas-2.0.3-cp311-cp311-win32.whl", hash = "sha256:694888a81198786f0e164ee3a581df7d505024fbb1f15202fc7db88a71d84ebd", size = 9482935 },
    { url = "https://files.pythonhosted.org/packages/9e/71/756a1be6bee0209d8c0d8c5e3b9fc72c00373f384a4017095ec404aec3ad/pandas-2.0.3-cp311-cp311-win_amd64.whl", hash = "sha256:6a21ab5c89dcbd57f78d0ae16630b090eec626360085a4148693def5452d8a6b", size = 10607692 },
    { url = "https://files.pythonhosted.org/packages/78/a8/07dd10f90ca915ed914853cd57f79bfc22e1ef4384ab56cb4336d2fc1f2a/pandas-2.0.3-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:9e4da0d45e7f34c069fe4d522359df7d23badf83abc1d1cef398895822d11061", size = 11653303 },
    { url = "https://files.pythonhosted.org/packages/53/c3/f8e87361f7fdf42012def602bfa2a593423c729f5cb7c97aed7f51be66ac/pandas-2.0.3-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:32fca2ee1b0d93dd71d979726b12b61faa06aeb93cf77468776287f41ff8fdc5", size = 10710932 },
    { url = "https://files.pythonhosted.org/packages/a7/87/828d50c81ce0f434163bf70b925a0eec6076808e0bca312a79322b141f66/pandas-2.0.3-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:258d3624b3ae734490e4d63c430256e716f488c4fcb7c8e9bde2d3aa46c29089", size = 11684018 },
    { url = "https://files.pythonhosted.org/packages/f8/7f/5b047effafbdd34e52c9e2d7e44f729a0655efafb22198c45cf692cdc157/pandas-2.0.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9eae3dc34fa1aa7772dd3fc60270d13ced7346fcbcfee017d3132ec625e23bb0", size = 12353723 },
    { url = "https://files.pythonhosted.org/packages/ea/ae/26a2eda7fa581347d69e51f93892493b2074ef3352ac71033c9f32c52389/pandas-2.0.3-cp38-cp38-win32.whl", hash = "sha256:f3421a7afb1a43f7e38e82e844e2bca9a6d793d66c1a7f9f0ff39a795bbc5e02", size = 9646403 },
    { url = "https://files.pythonhosted.org/packages/c3/6c/ea362eef61f05553aaf1a24b3e96b2d0603f5dc71a3bd35688a24ed88843/pandas-2.0.3-cp38-cp38-win_amd64.whl", hash = "sha256:69d7f3884c95da3a31ef82b7618af5710dba95bb885ffab339aad925c3e8ce78", size = 10777638 },
    { url = "https://files.pythonhosted.org/packages/f8/c7/cfef920b7b457dff6928e824896cb82367650ea127d048ee0b820026db4f/pandas-2.0.3-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:5247fb1ba347c1261cbbf0fcfba4a3121fbb4029d95d9ef4dc45406620b25c8b", size = 11834160 },
    { url = "https://files.pythonhosted.org/packages/6c/1c/689c9d99bc4e5d366a5fd871f0bcdee98a6581e240f96b78d2d08f103774/pandas-2.0.3-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:81af086f4543c9d8bb128328b5d32e9986e0c84d3ee673a2ac6fb57fd14f755e", size = 10862752 },
    { url = "https://files.pythonhosted.org/packages/cc/b8/4d082f41c27c95bf90485d1447b647cc7e5680fea75e315669dc6e4cb398/pandas-2.0.3-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1994c789bf12a7c5098277fb43836ce090f1073858c10f9220998ac74f37c69b", size = 11715852 },
    { url = "https://files.pythonhosted.org/packages/9e/0d/91a9fd2c202f2b1d97a38ab591890f86480ecbb596cbc56d035f6f23fdcc/pandas-2.0.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:5ec591c48e29226bcbb316e0c1e9423622bc7a4eaf1ef7c3c9fa1a3981f89641", size = 12398496 },
    { url = "https://files.pythonhosted.org/packages/26/7d/d8aa0a2c4f3f5f8ea59fb946c8eafe8f508090ca73e2b08a9af853c1103e/pandas-2.0.3-cp39-cp39-win32.whl", hash = "sha256:04dbdbaf2e4d46ca8da896e1805bc04eb85caa9a82e259e8eed00254d5e0c682", size = 9630766 },
    { url = "https://files.pythonhosted.org/packages/9a/f2/0ad053856debbe90c83de1b4f05915f85fd2146f20faf9daa3b320d36df3/pandas-2.0.3-cp39-cp39-win_amd64.whl", hash = "sha256:1168574b036cd8b93abc746171c9b4f1b83467438a5e45909fed645cf8692dbc", size = 10755902 },
]

[[package]]
name = "paragraphs"
version = "1.0.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/24/71/2462530f2e70991c1d19c03423a0bc1cdde8e49a415762edaebe7c19f9a3/paragraphs-1.0.1.tar.gz", hash = "sha256:ad393f2e99432740f36c115280aa454c53c8048e6a2cda0b81df4effc8043a60", size = 7045 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/18/79/806f22675c50f9cc827376756186c8601ef52a9cf08d2c7b80964e1daba2/paragraphs-1.0.1-py3-none-any.whl", hash = "sha256:9a189d8dfc6241b5caa9b3ae730ee6ccce53e483d3b45183d13f657f7d0d1b35", size = 5139 },
]

[[package]]
name = "pdf2image"
version = "1.17.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "pillow" },
]
sdist = { url = "https://files.pythonhosted.org/packages/00/d8/b280f01045555dc257b8153c00dee3bc75830f91a744cd5f84ef3a0a64b1/pdf2image-1.17.0.tar.gz", hash = "sha256:eaa959bc116b420dd7ec415fcae49b98100dda3dd18cd2fdfa86d09f112f6d57", size = 12811 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/62/33/61766ae033518957f877ab246f87ca30a85b778ebaad65b7f74fa7e52988/pdf2image-1.17.0-py3-none-any.whl", hash = "sha256:ecdd58d7afb810dffe21ef2b1bbc057ef434dabbac6c33778a38a3f7744a27e2", size = 11618 },
]

[[package]]
name = "pdfminer-six"
version = "20231228"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "charset-normalizer" },
    { name = "cryptography" },
]
sdist = { url = "https://files.pythonhosted.org/packages/31/b1/a43e3bd872ded4deea4f8efc7aff1703fca8c5455d0c06e20506a06a44ff/pdfminer.six-20231228.tar.gz", hash = "sha256:6004da3ad1a7a4d45930cb950393df89b068e73be365a6ff64a838d37bcb08c4", size = 7362505 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/eb/9c/e46fe7502b32d7db6af6e36a9105abb93301fa1ec475b5ddcba8b35ae23a/pdfminer.six-20231228-py3-none-any.whl", hash = "sha256:e8d3c3310e6fbc1fe414090123ab01351634b4ecb021232206c4c9a8ca3e3b8f", size = 5614515 },
]

[[package]]
name = "pdfplumber"
version = "0.11.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "pdfminer-six" },
    { name = "pillow" },
    { name = "pypdfium2" },
]
sdist = { url = "https://files.pythonhosted.org/packages/28/55/33d265185b4e7e6ac81e64478750ea26310055b1b5b278851b981a1c57e5/pdfplumber-0.11.5.tar.gz", hash = "sha256:dadd81b62a0b23e078cdd89de26e013850d4daf5690fcf46dec396b07e6737d6", size = 114626 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/18/fe/eebf169301bd1c1c69d639e81ba226d333d35c5ad105b7cd3cfc40a44862/pdfplumber-0.11.5-py3-none-any.whl", hash = "sha256:a6e0921a57e0ef7356001a0fd811250b0e37a0b42630a922ee48f55cdd534070", size = 59515 },
]

[[package]]
name = "pillow"
version = "10.4.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/cd/74/ad3d526f3bf7b6d3f408b73fde271ec69dfac8b81341a318ce825f2b3812/pillow-10.4.0.tar.gz", hash = "sha256:166c1cd4d24309b30d61f79f4a9114b7b2313d7450912277855ff5dfd7cd4a06", size = 46555059 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/0e/69/a31cccd538ca0b5272be2a38347f8839b97a14be104ea08b0db92f749c74/pillow-10.4.0-cp310-cp310-macosx_10_10_x86_64.whl", hash = "sha256:4d9667937cfa347525b319ae34375c37b9ee6b525440f3ef48542fcf66f2731e", size = 3509271 },
    { url = "https://files.pythonhosted.org/packages/9a/9e/4143b907be8ea0bce215f2ae4f7480027473f8b61fcedfda9d851082a5d2/pillow-10.4.0-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:543f3dc61c18dafb755773efc89aae60d06b6596a63914107f75459cf984164d", size = 3375658 },
    { url = "https://files.pythonhosted.org/packages/8a/25/1fc45761955f9359b1169aa75e241551e74ac01a09f487adaaf4c3472d11/pillow-10.4.0-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:7928ecbf1ece13956b95d9cbcfc77137652b02763ba384d9ab508099a2eca856", size = 4332075 },
    { url = "https://files.pythonhosted.org/packages/5e/dd/425b95d0151e1d6c951f45051112394f130df3da67363b6bc75dc4c27aba/pillow-10.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:e4d49b85c4348ea0b31ea63bc75a9f3857869174e2bf17e7aba02945cd218e6f", size = 4444808 },
    { url = "https://files.pythonhosted.org/packages/b1/84/9a15cc5726cbbfe7f9f90bfb11f5d028586595907cd093815ca6644932e3/pillow-10.4.0-cp310-cp310-manylinux_2_28_aarch64.whl", hash = "sha256:6c762a5b0997f5659a5ef2266abc1d8851ad7749ad9a6a5506eb23d314e4f46b", size = 4356290 },
    { url = "https://files.pythonhosted.org/packages/b5/5b/6651c288b08df3b8c1e2f8c1152201e0b25d240e22ddade0f1e242fc9fa0/pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl", hash = "sha256:a985e028fc183bf12a77a8bbf36318db4238a3ded7fa9df1b9a133f1cb79f8fc", size = 4525163 },
    { url = "https://files.pythonhosted.org/packages/07/8b/34854bf11a83c248505c8cb0fcf8d3d0b459a2246c8809b967963b6b12ae/pillow-10.4.0-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:812f7342b0eee081eaec84d91423d1b4650bb9828eb53d8511bcef8ce5aecf1e", size = 4463100 },
    { url = "https://files.pythonhosted.org/packages/78/63/0632aee4e82476d9cbe5200c0cdf9ba41ee04ed77887432845264d81116d/pillow-10.4.0-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:ac1452d2fbe4978c2eec89fb5a23b8387aba707ac72810d9490118817d9c0b46", size = 4592880 },
    { url = "https://files.pythonhosted.org/packages/df/56/b8663d7520671b4398b9d97e1ed9f583d4afcbefbda3c6188325e8c297bd/pillow-10.4.0-cp310-cp310-win32.whl", hash = "sha256:bcd5e41a859bf2e84fdc42f4edb7d9aba0a13d29a2abadccafad99de3feff984", size = 2235218 },
    { url = "https://files.pythonhosted.org/packages/f4/72/0203e94a91ddb4a9d5238434ae6c1ca10e610e8487036132ea9bf806ca2a/pillow-10.4.0-cp310-cp310-win_amd64.whl", hash = "sha256:ecd85a8d3e79cd7158dec1c9e5808e821feea088e2f69a974db5edf84dc53141", size = 2554487 },
    { url = "https://files.pythonhosted.org/packages/bd/52/7e7e93d7a6e4290543f17dc6f7d3af4bd0b3dd9926e2e8a35ac2282bc5f4/pillow-10.4.0-cp310-cp310-win_arm64.whl", hash = "sha256:ff337c552345e95702c5fde3158acb0625111017d0e5f24bf3acdb9cc16b90d1", size = 2243219 },
    { url = "https://files.pythonhosted.org/packages/a7/62/c9449f9c3043c37f73e7487ec4ef0c03eb9c9afc91a92b977a67b3c0bbc5/pillow-10.4.0-cp311-cp311-macosx_10_10_x86_64.whl", hash = "sha256:0a9ec697746f268507404647e531e92889890a087e03681a3606d9b920fbee3c", size = 3509265 },
    { url = "https://files.pythonhosted.org/packages/f4/5f/491dafc7bbf5a3cc1845dc0430872e8096eb9e2b6f8161509d124594ec2d/pillow-10.4.0-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:dfe91cb65544a1321e631e696759491ae04a2ea11d36715eca01ce07284738be", size = 3375655 },
    { url = "https://files.pythonhosted.org/packages/73/d5/c4011a76f4207a3c151134cd22a1415741e42fa5ddecec7c0182887deb3d/pillow-10.4.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5dc6761a6efc781e6a1544206f22c80c3af4c8cf461206d46a1e6006e4429ff3", size = 4340304 },
    { url = "https://files.pythonhosted.org/packages/ac/10/c67e20445a707f7a610699bba4fe050583b688d8cd2d202572b257f46600/pillow-10.4.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:5e84b6cc6a4a3d76c153a6b19270b3526a5a8ed6b09501d3af891daa2a9de7d6", size = 4452804 },
    { url = "https://files.pythonhosted.org/packages/a9/83/6523837906d1da2b269dee787e31df3b0acb12e3d08f024965a3e7f64665/pillow-10.4.0-cp311-cp311-manylinux_2_28_aarch64.whl", hash = "sha256:bbc527b519bd3aa9d7f429d152fea69f9ad37c95f0b02aebddff592688998abe", size = 4365126 },
    { url = "https://files.pythonhosted.org/packages/ba/e5/8c68ff608a4203085158cff5cc2a3c534ec384536d9438c405ed6370d080/pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl", hash = "sha256:76a911dfe51a36041f2e756b00f96ed84677cdeb75d25c767f296c1c1eda1319", size = 4533541 },
    { url = "https://files.pythonhosted.org/packages/f4/7c/01b8dbdca5bc6785573f4cee96e2358b0918b7b2c7b60d8b6f3abf87a070/pillow-10.4.0-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:59291fb29317122398786c2d44427bbd1a6d7ff54017075b22be9d21aa59bd8d", size = 4471616 },
    { url = "https://files.pythonhosted.org/packages/c8/57/2899b82394a35a0fbfd352e290945440e3b3785655a03365c0ca8279f351/pillow-10.4.0-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:416d3a5d0e8cfe4f27f574362435bc9bae57f679a7158e0096ad2beb427b8696", size = 4600802 },
    { url = "https://files.pythonhosted.org/packages/4d/d7/a44f193d4c26e58ee5d2d9db3d4854b2cfb5b5e08d360a5e03fe987c0086/pillow-10.4.0-cp311-cp311-win32.whl", hash = "sha256:7086cc1d5eebb91ad24ded9f58bec6c688e9f0ed7eb3dbbf1e4800280a896496", size = 2235213 },
    { url = "https://files.pythonhosted.org/packages/c1/d0/5866318eec2b801cdb8c82abf190c8343d8a1cd8bf5a0c17444a6f268291/pillow-10.4.0-cp311-cp311-win_amd64.whl", hash = "sha256:cbed61494057c0f83b83eb3a310f0bf774b09513307c434d4366ed64f4128a91", size = 2554498 },
    { url = "https://files.pythonhosted.org/packages/d4/c8/310ac16ac2b97e902d9eb438688de0d961660a87703ad1561fd3dfbd2aa0/pillow-10.4.0-cp311-cp311-win_arm64.whl", hash = "sha256:f5f0c3e969c8f12dd2bb7e0b15d5c468b51e5017e01e2e867335c81903046a22", size = 2243219 },
    { url = "https://files.pythonhosted.org/packages/05/cb/0353013dc30c02a8be34eb91d25e4e4cf594b59e5a55ea1128fde1e5f8ea/pillow-10.4.0-cp312-cp312-macosx_10_10_x86_64.whl", hash = "sha256:673655af3eadf4df6b5457033f086e90299fdd7a47983a13827acf7459c15d94", size = 3509350 },
    { url = "https://files.pythonhosted.org/packages/e7/cf/5c558a0f247e0bf9cec92bff9b46ae6474dd736f6d906315e60e4075f737/pillow-10.4.0-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:866b6942a92f56300012f5fbac71f2d610312ee65e22f1aa2609e491284e5597", size = 3374980 },
    { url = "https://files.pythonhosted.org/packages/84/48/6e394b86369a4eb68b8a1382c78dc092245af517385c086c5094e3b34428/pillow-10.4.0-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:29dbdc4207642ea6aad70fbde1a9338753d33fb23ed6956e706936706f52dd80", size = 4343799 },
    { url = "https://files.pythonhosted.org/packages/3b/f3/a8c6c11fa84b59b9df0cd5694492da8c039a24cd159f0f6918690105c3be/pillow-10.4.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bf2342ac639c4cf38799a44950bbc2dfcb685f052b9e262f446482afaf4bffca", size = 4459973 },
    { url = "https://files.pythonhosted.org/packages/7d/1b/c14b4197b80150fb64453585247e6fb2e1d93761fa0fa9cf63b102fde822/pillow-10.4.0-cp312-cp312-manylinux_2_28_aarch64.whl", hash = "sha256:f5b92f4d70791b4a67157321c4e8225d60b119c5cc9aee8ecf153aace4aad4ef", size = 4370054 },
    { url = "https://files.pythonhosted.org/packages/55/77/40daddf677897a923d5d33329acd52a2144d54a9644f2a5422c028c6bf2d/pillow-10.4.0-cp312-cp312-manylinux_2_28_x86_64.whl", hash = "sha256:86dcb5a1eb778d8b25659d5e4341269e8590ad6b4e8b44d9f4b07f8d136c414a", size = 4539484 },
    { url = "https://files.pythonhosted.org/packages/40/54/90de3e4256b1207300fb2b1d7168dd912a2fb4b2401e439ba23c2b2cabde/pillow-10.4.0-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:780c072c2e11c9b2c7ca37f9a2ee8ba66f44367ac3e5c7832afcfe5104fd6d1b", size = 4477375 },
    { url = "https://files.pythonhosted.org/packages/13/24/1bfba52f44193860918ff7c93d03d95e3f8748ca1de3ceaf11157a14cf16/pillow-10.4.0-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:37fb69d905be665f68f28a8bba3c6d3223c8efe1edf14cc4cfa06c241f8c81d9", size = 4608773 },
    { url = "https://files.pythonhosted.org/packages/55/04/5e6de6e6120451ec0c24516c41dbaf80cce1b6451f96561235ef2429da2e/pillow-10.4.0-cp312-cp312-win32.whl", hash = "sha256:7dfecdbad5c301d7b5bde160150b4db4c659cee2b69589705b6f8a0c509d9f42", size = 2235690 },
    { url = "https://files.pythonhosted.org/packages/74/0a/d4ce3c44bca8635bd29a2eab5aa181b654a734a29b263ca8efe013beea98/pillow-10.4.0-cp312-cp312-win_amd64.whl", hash = "sha256:1d846aea995ad352d4bdcc847535bd56e0fd88d36829d2c90be880ef1ee4668a", size = 2554951 },
    { url = "https://files.pythonhosted.org/packages/b5/ca/184349ee40f2e92439be9b3502ae6cfc43ac4b50bc4fc6b3de7957563894/pillow-10.4.0-cp312-cp312-win_arm64.whl", hash = "sha256:e553cad5179a66ba15bb18b353a19020e73a7921296a7979c4a2b7f6a5cd57f9", size = 2243427 },
    { url = "https://files.pythonhosted.org/packages/c3/00/706cebe7c2c12a6318aabe5d354836f54adff7156fd9e1bd6c89f4ba0e98/pillow-10.4.0-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:8bc1a764ed8c957a2e9cacf97c8b2b053b70307cf2996aafd70e91a082e70df3", size = 3525685 },
    { url = "https://files.pythonhosted.org/packages/cf/76/f658cbfa49405e5ecbfb9ba42d07074ad9792031267e782d409fd8fe7c69/pillow-10.4.0-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:6209bb41dc692ddfee4942517c19ee81b86c864b626dbfca272ec0f7cff5d9fb", size = 3374883 },
    { url = "https://files.pythonhosted.org/packages/46/2b/99c28c4379a85e65378211971c0b430d9c7234b1ec4d59b2668f6299e011/pillow-10.4.0-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bee197b30783295d2eb680b311af15a20a8b24024a19c3a26431ff83eb8d1f70", size = 4339837 },
    { url = "https://files.pythonhosted.org/packages/f1/74/b1ec314f624c0c43711fdf0d8076f82d9d802afd58f1d62c2a86878e8615/pillow-10.4.0-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1ef61f5dd14c300786318482456481463b9d6b91ebe5ef12f405afbba77ed0be", size = 4455562 },
    { url = "https://files.pythonhosted.org/packages/4a/2a/4b04157cb7b9c74372fa867096a1607e6fedad93a44deeff553ccd307868/pillow-10.4.0-cp313-cp313-manylinux_2_28_aarch64.whl", hash = "sha256:297e388da6e248c98bc4a02e018966af0c5f92dfacf5a5ca22fa01cb3179bca0", size = 4366761 },
    { url = "https://files.pythonhosted.org/packages/ac/7b/8f1d815c1a6a268fe90481232c98dd0e5fa8c75e341a75f060037bd5ceae/pillow-10.4.0-cp313-cp313-manylinux_2_28_x86_64.whl", hash = "sha256:e4db64794ccdf6cb83a59d73405f63adbe2a1887012e308828596100a0b2f6cc", size = 4536767 },
    { url = "https://files.pythonhosted.org/packages/e5/77/05fa64d1f45d12c22c314e7b97398ffb28ef2813a485465017b7978b3ce7/pillow-10.4.0-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:bd2880a07482090a3bcb01f4265f1936a903d70bc740bfcb1fd4e8a2ffe5cf5a", size = 4477989 },
    { url = "https://files.pythonhosted.org/packages/12/63/b0397cfc2caae05c3fb2f4ed1b4fc4fc878f0243510a7a6034ca59726494/pillow-10.4.0-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:4b35b21b819ac1dbd1233317adeecd63495f6babf21b7b2512d244ff6c6ce309", size = 4610255 },
    { url = "https://files.pythonhosted.org/packages/7b/f9/cfaa5082ca9bc4a6de66ffe1c12c2d90bf09c309a5f52b27759a596900e7/pillow-10.4.0-cp313-cp313-win32.whl", hash = "sha256:551d3fd6e9dc15e4c1eb6fc4ba2b39c0c7933fa113b220057a34f4bb3268a060", size = 2235603 },
    { url = "https://files.pythonhosted.org/packages/01/6a/30ff0eef6e0c0e71e55ded56a38d4859bf9d3634a94a88743897b5f96936/pillow-10.4.0-cp313-cp313-win_amd64.whl", hash = "sha256:030abdbe43ee02e0de642aee345efa443740aa4d828bfe8e2eb11922ea6a21ea", size = 2554972 },
    { url = "https://files.pythonhosted.org/packages/48/2c/2e0a52890f269435eee38b21c8218e102c621fe8d8df8b9dd06fabf879ba/pillow-10.4.0-cp313-cp313-win_arm64.whl", hash = "sha256:5b001114dd152cfd6b23befeb28d7aee43553e2402c9f159807bf55f33af8a8d", size = 2243375 },
    { url = "https://files.pythonhosted.org/packages/56/70/f40009702a477ce87d8d9faaa4de51d6562b3445d7a314accd06e4ffb01d/pillow-10.4.0-cp38-cp38-macosx_10_10_x86_64.whl", hash = "sha256:8d4d5063501b6dd4024b8ac2f04962d661222d120381272deea52e3fc52d3736", size = 3509213 },
    { url = "https://files.pythonhosted.org/packages/10/43/105823d233c5e5d31cea13428f4474ded9d961652307800979a59d6a4276/pillow-10.4.0-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:7c1ee6f42250df403c5f103cbd2768a28fe1a0ea1f0f03fe151c8741e1469c8b", size = 3375883 },
    { url = "https://files.pythonhosted.org/packages/3c/ad/7850c10bac468a20c918f6a5dbba9ecd106ea1cdc5db3c35e33a60570408/pillow-10.4.0-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b15e02e9bb4c21e39876698abf233c8c579127986f8207200bc8a8f6bb27acf2", size = 4330810 },
    { url = "https://files.pythonhosted.org/packages/84/4c/69bbed9e436ac22f9ed193a2b64f64d68fcfbc9f4106249dc7ed4889907b/pillow-10.4.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7a8d4bade9952ea9a77d0c3e49cbd8b2890a399422258a77f357b9cc9be8d680", size = 4444341 },
    { url = "https://files.pythonhosted.org/packages/8f/4f/c183c63828a3f37bf09644ce94cbf72d4929b033b109160a5379c2885932/pillow-10.4.0-cp38-cp38-manylinux_2_28_aarch64.whl", hash = "sha256:43efea75eb06b95d1631cb784aa40156177bf9dd5b4b03ff38979e048258bc6b", size = 4356005 },
    { url = "https://files.pythonhosted.org/packages/fb/ad/435fe29865f98a8fbdc64add8875a6e4f8c97749a93577a8919ec6f32c64/pillow-10.4.0-cp38-cp38-manylinux_2_28_x86_64.whl", hash = "sha256:950be4d8ba92aca4b2bb0741285a46bfae3ca699ef913ec8416c1b78eadd64cd", size = 4525201 },
    { url = "https://files.pythonhosted.org/packages/80/74/be8bf8acdfd70e91f905a12ae13cfb2e17c0f1da745c40141e26d0971ff5/pillow-10.4.0-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:d7480af14364494365e89d6fddc510a13e5a2c3584cb19ef65415ca57252fb84", size = 4460635 },
    { url = "https://files.pythonhosted.org/packages/e4/90/763616e66dc9ad59c9b7fb58f863755e7934ef122e52349f62c7742b82d3/pillow-10.4.0-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:73664fe514b34c8f02452ffb73b7a92c6774e39a647087f83d67f010eb9a0cf0", size = 4590283 },
    { url = "https://files.pythonhosted.org/packages/69/66/03002cb5b2c27bb519cba63b9f9aa3709c6f7a5d3b285406c01f03fb77e5/pillow-10.4.0-cp38-cp38-win32.whl", hash = "sha256:e88d5e6ad0d026fba7bdab8c3f225a69f063f116462c49892b0149e21b6c0a0e", size = 2235185 },
    { url = "https://files.pythonhosted.org/packages/f2/75/3cb820b2812405fc7feb3d0deb701ef0c3de93dc02597115e00704591bc9/pillow-10.4.0-cp38-cp38-win_amd64.whl", hash = "sha256:5161eef006d335e46895297f642341111945e2c1c899eb406882a6c61a4357ab", size = 2554594 },
    { url = "https://files.pythonhosted.org/packages/31/85/955fa5400fa8039921f630372cfe5056eed6e1b8e0430ee4507d7de48832/pillow-10.4.0-cp39-cp39-macosx_10_10_x86_64.whl", hash = "sha256:0ae24a547e8b711ccaaf99c9ae3cd975470e1a30caa80a6aaee9a2f19c05701d", size = 3509283 },
    { url = "https://files.pythonhosted.org/packages/23/9c/343827267eb28d41cd82b4180d33b10d868af9077abcec0af9793aa77d2d/pillow-10.4.0-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:298478fe4f77a4408895605f3482b6cc6222c018b2ce565c2b6b9c354ac3229b", size = 3375691 },
    { url = "https://files.pythonhosted.org/packages/60/a3/7ebbeabcd341eab722896d1a5b59a3df98c4b4d26cf4b0385f8aa94296f7/pillow-10.4.0-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:134ace6dc392116566980ee7436477d844520a26a4b1bd4053f6f47d096997fd", size = 4328295 },
    { url = "https://files.pythonhosted.org/packages/32/3f/c02268d0c6fb6b3958bdda673c17b315c821d97df29ae6969f20fb49388a/pillow-10.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:930044bb7679ab003b14023138b50181899da3f25de50e9dbee23b61b4de2126", size = 4440810 },
    { url = "https://files.pythonhosted.org/packages/67/5d/1c93c8cc35f2fdd3d6cc7e4ad72d203902859a2867de6ad957d9b708eb8d/pillow-10.4.0-cp39-cp39-manylinux_2_28_aarch64.whl", hash = "sha256:c76e5786951e72ed3686e122d14c5d7012f16c8303a674d18cdcd6d89557fc5b", size = 4352283 },
    { url = "https://files.pythonhosted.org/packages/bc/a8/8655557c9c7202b8abbd001f61ff36711cefaf750debcaa1c24d154ef602/pillow-10.4.0-cp39-cp39-manylinux_2_28_x86_64.whl", hash = "sha256:b2724fdb354a868ddf9a880cb84d102da914e99119211ef7ecbdc613b8c96b3c", size = 4521800 },
    { url = "https://files.pythonhosted.org/packages/58/78/6f95797af64d137124f68af1bdaa13b5332da282b86031f6fa70cf368261/pillow-10.4.0-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:dbc6ae66518ab3c5847659e9988c3b60dc94ffb48ef9168656e0019a93dbf8a1", size = 4459177 },
    { url = "https://files.pythonhosted.org/packages/8a/6d/2b3ce34f1c4266d79a78c9a51d1289a33c3c02833fe294ef0dcbb9cba4ed/pillow-10.4.0-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:06b2f7898047ae93fad74467ec3d28fe84f7831370e3c258afa533f81ef7f3df", size = 4589079 },
    { url = "https://files.pythonhosted.org/packages/e3/e0/456258c74da1ff5bf8ef1eab06a95ca994d8b9ed44c01d45c3f8cbd1db7e/pillow-10.4.0-cp39-cp39-win32.whl", hash = "sha256:7970285ab628a3779aecc35823296a7869f889b8329c16ad5a71e4901a3dc4ef", size = 2235247 },
    { url = "https://files.pythonhosted.org/packages/37/f8/bef952bdb32aa53741f58bf21798642209e994edc3f6598f337f23d5400a/pillow-10.4.0-cp39-cp39-win_amd64.whl", hash = "sha256:961a7293b2457b405967af9c77dcaa43cc1a8cd50d23c532e62d48ab6cdd56f5", size = 2554479 },
    { url = "https://files.pythonhosted.org/packages/bb/8e/805201619cad6651eef5fc1fdef913804baf00053461522fabbc5588ea12/pillow-10.4.0-cp39-cp39-win_arm64.whl", hash = "sha256:32cda9e3d601a52baccb2856b8ea1fc213c90b340c542dcef77140dfa3278a9e", size = 2243226 },
    { url = "https://files.pythonhosted.org/packages/38/30/095d4f55f3a053392f75e2eae45eba3228452783bab3d9a920b951ac495c/pillow-10.4.0-pp310-pypy310_pp73-macosx_10_15_x86_64.whl", hash = "sha256:5b4815f2e65b30f5fbae9dfffa8636d992d49705723fe86a3661806e069352d4", size = 3493889 },
    { url = "https://files.pythonhosted.org/packages/f3/e8/4ff79788803a5fcd5dc35efdc9386af153569853767bff74540725b45863/pillow-10.4.0-pp310-pypy310_pp73-macosx_11_0_arm64.whl", hash = "sha256:8f0aef4ef59694b12cadee839e2ba6afeab89c0f39a3adc02ed51d109117b8da", size = 3346160 },
    { url = "https://files.pythonhosted.org/packages/d7/ac/4184edd511b14f760c73f5bb8a5d6fd85c591c8aff7c2229677a355c4179/pillow-10.4.0-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:9f4727572e2918acaa9077c919cbbeb73bd2b3ebcfe033b72f858fc9fbef0026", size = 3435020 },
    { url = "https://files.pythonhosted.org/packages/da/21/1749cd09160149c0a246a81d646e05f35041619ce76f6493d6a96e8d1103/pillow-10.4.0-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ff25afb18123cea58a591ea0244b92eb1e61a1fd497bf6d6384f09bc3262ec3e", size = 3490539 },
    { url = "https://files.pythonhosted.org/packages/b6/f5/f71fe1888b96083b3f6dfa0709101f61fc9e972c0c8d04e9d93ccef2a045/pillow-10.4.0-pp310-pypy310_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:dc3e2db6ba09ffd7d02ae9141cfa0ae23393ee7687248d46a7507b75d610f4f5", size = 3476125 },
    { url = "https://files.pythonhosted.org/packages/96/b9/c0362c54290a31866c3526848583a2f45a535aa9d725fd31e25d318c805f/pillow-10.4.0-pp310-pypy310_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:02a2be69f9c9b8c1e97cf2713e789d4e398c751ecfd9967c18d0ce304efbf885", size = 3579373 },
    { url = "https://files.pythonhosted.org/packages/52/3b/ce7a01026a7cf46e5452afa86f97a5e88ca97f562cafa76570178ab56d8d/pillow-10.4.0-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:0755ffd4a0c6f267cccbae2e9903d95477ca2f77c4fcf3a3a09570001856c8a5", size = 2554661 },
    { url = "https://files.pythonhosted.org/packages/e1/1f/5a9fcd6ced51633c22481417e11b1b47d723f64fb536dfd67c015eb7f0ab/pillow-10.4.0-pp39-pypy39_pp73-macosx_10_15_x86_64.whl", hash = "sha256:a02364621fe369e06200d4a16558e056fe2805d3468350df3aef21e00d26214b", size = 3493850 },
    { url = "https://files.pythonhosted.org/packages/cb/e6/3ea4755ed5320cb62aa6be2f6de47b058c6550f752dd050e86f694c59798/pillow-10.4.0-pp39-pypy39_pp73-macosx_11_0_arm64.whl", hash = "sha256:1b5dea9831a90e9d0721ec417a80d4cbd7022093ac38a568db2dd78363b00908", size = 3346118 },
    { url = "https://files.pythonhosted.org/packages/0a/22/492f9f61e4648422b6ca39268ec8139277a5b34648d28f400faac14e0f48/pillow-10.4.0-pp39-pypy39_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:9b885f89040bb8c4a1573566bbb2f44f5c505ef6e74cec7ab9068c900047f04b", size = 3434958 },
    { url = "https://files.pythonhosted.org/packages/f9/19/559a48ad4045704bb0547965b9a9345f5cd461347d977a56d178db28819e/pillow-10.4.0-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:87dd88ded2e6d74d31e1e0a99a726a6765cda32d00ba72dc37f0651f306daaa8", size = 3490340 },
    { url = "https://files.pythonhosted.org/packages/d9/de/cebaca6fb79905b3a1aa0281d238769df3fb2ede34fd7c0caa286575915a/pillow-10.4.0-pp39-pypy39_pp73-manylinux_2_28_aarch64.whl", hash = "sha256:2db98790afc70118bd0255c2eeb465e9767ecf1f3c25f9a1abb8ffc8cfd1fe0a", size = 3476048 },
    { url = "https://files.pythonhosted.org/packages/71/f0/86d5b2f04693b0116a01d75302b0a307800a90d6c351a8aa4f8ae76cd499/pillow-10.4.0-pp39-pypy39_pp73-manylinux_2_28_x86_64.whl", hash = "sha256:f7baece4ce06bade126fb84b8af1c33439a76d8a6fd818970215e0560ca28c27", size = 3579366 },
    { url = "https://files.pythonhosted.org/packages/37/ae/2dbfc38cc4fd14aceea14bc440d5151b21f64c4c3ba3f6f4191610b7ee5d/pillow-10.4.0-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:cfdd747216947628af7b259d274771d84db2268ca062dd5faf373639d00113a3", size = 2554652 },
]

[[package]]
name = "pipeline"
version = "0.1.0"
source = { editable = "." }
dependencies = [
    { name = "pydantic" },
    { name = "pyyaml" },
    { name = "typing-extensions" },
]

[package.optional-dependencies]
all = [
    { name = "docx2python" },
    { name = "openpyxl" },
    { name = "pandas" },
    { name = "pillow" },
    { name = "pymupdf" },
    { name = "pypdf2" },
    { name = "python-docx" },
]
analysis = [
    { name = "beautifulsoup4" },
    { name = "lxml" },
    { name = "matplotlib" },
    { name = "nltk" },
    { name = "scikit-learn" },
    { name = "seaborn" },
    { name = "spacy", version = "3.7.5", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.9'" },
    { name = "spacy", version = "3.8.2", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.9'" },
]
dev = [
    { name = "mypy" },
    { name = "pytest" },
    { name = "pytest-cov" },
    { name = "pytest-mock" },
    { name = "pytest-sugar" },
    { name = "pytest-xdist" },
    { name = "ruff" },
]
excel = [
    { name = "openpyxl" },
    { name = "pandas" },
    { name = "pyxlsb" },
    { name = "xlrd" },
    { name = "xlsxwriter" },
    { name = "xlwings" },
]
pdf = [
    { name = "camelot-py" },
    { name = "pdf2image" },
    { name = "pdfminer-six" },
    { name = "pdfplumber" },
    { name = "pillow" },
    { name = "pymupdf" },
    { name = "pypdf2" },
    { name = "pytesseract" },
    { name = "tabula-py" },
]
word = [
    { name = "docx2python" },
    { name = "docx2txt" },
    { name = "mammoth" },
    { name = "python-docx" },
    { name = "pywin32" },
]

[package.metadata]
requires-dist = [
    { name = "beautifulsoup4", marker = "extra == 'analysis'", specifier = ">=4.12.2" },
    { name = "camelot-py", marker = "extra == 'pdf'", specifier = ">=0.11.0" },
    { name = "docx2python", marker = "extra == 'all'", specifier = ">=2.0.1" },
    { name = "docx2python", marker = "extra == 'word'", specifier = ">=2.0.1" },
    { name = "docx2txt", marker = "extra == 'word'", specifier = ">=0.8" },
    { name = "lxml", marker = "extra == 'analysis'", specifier = ">=4.9.3" },
    { name = "mammoth", marker = "extra == 'word'", specifier = ">=1.6.0" },
    { name = "matplotlib", marker = "extra == 'analysis'", specifier = ">=3.7.2" },
    { name = "mypy", marker = "extra == 'dev'" },
    { name = "nltk", marker = "extra == 'analysis'", specifier = ">=3.8.1" },
    { name = "openpyxl", marker = "extra == 'all'", specifier = ">=3.1.2" },
    { name = "openpyxl", marker = "extra == 'excel'", specifier = ">=3.1.2" },
    { name = "pandas", marker = "extra == 'all'", specifier = ">=2.0.0" },
    { name = "pandas", marker = "extra == 'excel'", specifier = ">=2.0.0" },
    { name = "pdf2image", marker = "extra == 'pdf'", specifier = ">=1.16.3" },
    { name = "pdfminer-six", marker = "extra == 'pdf'", specifier = ">=20221105" },
    { name = "pdfplumber", marker = "extra == 'pdf'", specifier = ">=0.10.2" },
    { name = "pillow", marker = "extra == 'all'", specifier = ">=10.0.0" },
    { name = "pillow", marker = "extra == 'pdf'", specifier = ">=10.0.0" },
    { name = "pydantic", specifier = ">=2.0.0" },
    { name = "pymupdf", marker = "extra == 'all'", specifier = ">=1.22.5" },
    { name = "pymupdf", marker = "extra == 'pdf'", specifier = ">=1.22.5" },
    { name = "pypdf2", marker = "extra == 'all'", specifier = ">=3.0.0" },
    { name = "pypdf2", marker = "extra == 'pdf'", specifier = ">=3.0.0" },
    { name = "pytesseract", marker = "extra == 'pdf'", specifier = ">=0.3.10" },
    { name = "pytest", marker = "extra == 'dev'", specifier = ">=7.4.0" },
    { name = "pytest-cov", marker = "extra == 'dev'", specifier = ">=4.1.0" },
    { name = "pytest-mock", marker = "extra == 'dev'", specifier = ">=3.11.1" },
    { name = "pytest-sugar", marker = "extra == 'dev'", specifier = ">=0.9.7" },
    { name = "pytest-xdist", marker = "extra == 'dev'", specifier = ">=3.3.1" },
    { name = "python-docx", marker = "extra == 'all'", specifier = ">=1.0.0" },
    { name = "python-docx", marker = "extra == 'word'", specifier = ">=1.0.0" },
    { name = "pywin32", marker = "extra == 'word'", specifier = ">=306" },
    { name = "pyxlsb", marker = "extra == 'excel'", specifier = ">=1.0.10" },
    { name = "pyyaml" },
    { name = "ruff", marker = "extra == 'dev'" },
    { name = "scikit-learn", marker = "extra == 'analysis'", specifier = ">=1.3.0" },
    { name = "seaborn", marker = "extra == 'analysis'", specifier = ">=0.12.2" },
    { name = "spacy", marker = "extra == 'analysis'", specifier = ">=3.6.1" },
    { name = "tabula-py", marker = "extra == 'pdf'", specifier = ">=2.7.0" },
    { name = "typing-extensions" },
    { name = "xlrd", marker = "extra == 'excel'", specifier = ">=2.0.1" },
    { name = "xlsxwriter", marker = "extra == 'excel'", specifier = ">=3.1.0" },
    { name = "xlwings", marker = "extra == 'excel'", specifier = ">=0.30.10" },
]

[[package]]
name = "pluggy"
version = "1.5.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/96/2d/02d4312c973c6050a18b314a5ad0b3210edb65a906f868e31c111dede4a6/pluggy-1.5.0.tar.gz", hash = "sha256:2cffa88e94fdc978c4c574f15f9e59b7f4201d439195c3715ca9e2486f1d0cf1", size = 67955 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/88/5f/e351af9a41f866ac3f1fac4ca0613908d9a41741cfcf2228f4ad853b697d/pluggy-1.5.0-py3-none-any.whl", hash = "sha256:44e1ad92c8ca002de6377e165f3e0f1be63266ab4d554740532335b9d75ea669", size = 20556 },
]

[[package]]
name = "preshed"
version = "3.0.9"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "cymem" },
    { name = "murmurhash" },
]
sdist = { url = "https://files.pythonhosted.org/packages/f2/4e/76dbf784e7d4ed069f91a4c249b1d6ec6856ef0c0b2fd96992895d458b15/preshed-3.0.9.tar.gz", hash = "sha256:721863c5244ffcd2651ad0928951a2c7c77b102f4e11a251ad85d37ee7621660", size = 14478 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/38/7f/a7d3eeaee67ecebbe51866c1aae6310e34cefa0a64821aed963a0a167b51/preshed-3.0.9-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:4f96ef4caf9847b2bb9868574dcbe2496f974e41c2b83d6621c24fb4c3fc57e3", size = 132225 },
    { url = "https://files.pythonhosted.org/packages/61/4e/f251271ee9f0e0eb0ebe219a8df57ff8511a3b7a83e79e24d37105034164/preshed-3.0.9-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:a61302cf8bd30568631adcdaf9e6b21d40491bd89ba8ebf67324f98b6c2a2c05", size = 127791 },
    { url = "https://files.pythonhosted.org/packages/eb/8b/6c8a153ea39b4750c20ed48dd9be4bf9d8c0b4e7822fc63c68cd2891703d/preshed-3.0.9-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:99499e8a58f58949d3f591295a97bca4e197066049c96f5d34944dd21a497193", size = 150279 },
    { url = "https://files.pythonhosted.org/packages/42/59/8f65ad22c13020ff281529e415c32a56cfa691d24b0eca2eb3d756e4d644/preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ea6b6566997dc3acd8c6ee11a89539ac85c77275b4dcefb2dc746d11053a5af8", size = 156914 },
    { url = "https://files.pythonhosted.org/packages/f3/72/108426ca3b6e7f16db30b3b9396e3fa45a3fd5a76f6532ab04beada2e4e3/preshed-3.0.9-cp310-cp310-win_amd64.whl", hash = "sha256:bfd523085a84b1338ff18f61538e1cfcdedc4b9e76002589a301c364d19a2e36", size = 122224 },
    { url = "https://files.pythonhosted.org/packages/c0/1e/05fa559f53b635d96b233b63e93accb75215025b997486f7290991bec6c3/preshed-3.0.9-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:e7c2364da27f2875524ce1ca754dc071515a9ad26eb5def4c7e69129a13c9a59", size = 132972 },
    { url = "https://files.pythonhosted.org/packages/a8/b3/1a73ba16bab53043fd19dd0a7838ae05c705dccb329404dd4ad5925767f1/preshed-3.0.9-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:182138033c0730c683a6d97e567ceb8a3e83f3bff5704f300d582238dbd384b3", size = 128751 },
    { url = "https://files.pythonhosted.org/packages/2c/9a/919d3708f6fa98d9eab1a186e6b30ab25a4595907bbc1fea5c1e8faa9b9d/preshed-3.0.9-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:345a10be3b86bcc6c0591d343a6dc2bfd86aa6838c30ced4256dfcfa836c3a64", size = 150050 },
    { url = "https://files.pythonhosted.org/packages/db/69/d9ab108dc670b5be9e292bbd555f39e6eb0a4baab25cd28f792850d5e65b/preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:51d0192274aa061699b284f9fd08416065348edbafd64840c3889617ee1609de", size = 157159 },
    { url = "https://files.pythonhosted.org/packages/e4/fc/78cdbdb79f5d6d45949e72c32445d6c060977ad50a1dcfc0392622165f7c/preshed-3.0.9-cp311-cp311-win_amd64.whl", hash = "sha256:96b857d7a62cbccc3845ac8c41fd23addf052821be4eb987f2eb0da3d8745aa1", size = 122323 },
    { url = "https://files.pythonhosted.org/packages/fe/7e/a41595876f644d8bd2c3d5422d7211e876b1848a8cc0c03cce33d9cd048a/preshed-3.0.9-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:b4fe6720012c62e6d550d6a5c1c7ad88cacef8388d186dad4bafea4140d9d198", size = 133196 },
    { url = "https://files.pythonhosted.org/packages/e7/68/1b4772ff3232e71b63a9206936eb1f75e976ebf4e4e24dc9b3ea7b68369b/preshed-3.0.9-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:e04f05758875be9751e483bd3c519c22b00d3b07f5a64441ec328bb9e3c03700", size = 128594 },
    { url = "https://files.pythonhosted.org/packages/f3/52/48eefe876a3841c5850bd955daf145d0e408567c8f46a997bce136dc259d/preshed-3.0.9-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4a55091d0e395f1fdb62ab43401bb9f8b46c7d7794d5b071813c29dc1ab22fd0", size = 149220 },
    { url = "https://files.pythonhosted.org/packages/55/ea/9e6c1a7b1d623f6340379290d603a3b8a71ce52a93f842fbf7547f7f1812/preshed-3.0.9-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7de8f5138bcac7870424e09684dc3dd33c8e30e81b269f6c9ede3d8c7bb8e257", size = 156809 },
    { url = "https://files.pythonhosted.org/packages/db/e4/d074efb7e8a8873d346d2fb8dd43e19b1eae0697351c0d79cff947cba46e/preshed-3.0.9-cp312-cp312-win_amd64.whl", hash = "sha256:24229c77364628743bc29c5620c5d6607ed104f0e02ae31f8a030f99a78a5ceb", size = 122428 },
    { url = "https://files.pythonhosted.org/packages/58/bc/972e89282e93d97bcc566461ea79d6663cabc1ecae78634dd9d7db604ac9/preshed-3.0.9-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:3452b64d97ce630e200c415073040aa494ceec6b7038f7a2a3400cbd7858e952", size = 135683 },
    { url = "https://files.pythonhosted.org/packages/13/88/9ed5c9e1eff13ee64544dec8f4fd2c5bfa17f9d06d039fb7dfb6c8f23f55/preshed-3.0.9-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:ac970d97b905e9e817ec13d31befd5b07c9cfec046de73b551d11a6375834b79", size = 131041 },
    { url = "https://files.pythonhosted.org/packages/4b/8b/411479cd7c4129ce3e821aadebf06c2b3bbc42a48d87e2163162ab851c8a/preshed-3.0.9-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:eebaa96ece6641cd981491cba995b68c249e0b6877c84af74971eacf8990aa19", size = 148397 },
    { url = "https://files.pythonhosted.org/packages/aa/7c/f36a498cb114765d0ecec946e6be46d2aadaea19317a1a1828e4aa2383d8/preshed-3.0.9-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2d473c5f6856e07a88d41fe00bb6c206ecf7b34c381d30de0b818ba2ebaf9406", size = 154199 },
    { url = "https://files.pythonhosted.org/packages/11/d6/52e305ae0d66769c926a02a1f0e87f9918a25a68360de83365b1ff902ef0/preshed-3.0.9-cp38-cp38-win_amd64.whl", hash = "sha256:0de63a560f10107a3f0a9e252cc3183b8fdedcb5f81a86938fd9f1dcf8a64adf", size = 122978 },
    { url = "https://files.pythonhosted.org/packages/f6/8a/1744a672c0e7138b92a87c8468bfb8737db5503546a788f073ca76e02f6e/preshed-3.0.9-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:3a9ad9f738084e048a7c94c90f40f727217387115b2c9a95c77f0ce943879fcd", size = 133494 },
    { url = "https://files.pythonhosted.org/packages/e3/e2/fa3986b6ddbdf05f1a86094c3dfaccdcf424c8f358ac9a5b643d07d09b44/preshed-3.0.9-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:a671dfa30b67baa09391faf90408b69c8a9a7f81cb9d83d16c39a182355fbfce", size = 129080 },
    { url = "https://files.pythonhosted.org/packages/a7/85/1ca49dca7fd58646d16509a48de0f57d3adc8aa6c21f2a92de7c1125be4e/preshed-3.0.9-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:23906d114fc97c17c5f8433342495d7562e96ecfd871289c2bb2ed9a9df57c3f", size = 150851 },
    { url = "https://files.pythonhosted.org/packages/33/eb/13594be35f34d84fd82ba0300df6d10cc12314c7a1dad1fe19637001696e/preshed-3.0.9-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:778cf71f82cedd2719b256f3980d556d6fb56ec552334ba79b49d16e26e854a0", size = 157461 },
    { url = "https://files.pythonhosted.org/packages/14/d6/adcc6ffbb5d400b3e780f2468f89242e1e24b5c04eb6ee5c6e0f3a84f2e4/preshed-3.0.9-cp39-cp39-win_amd64.whl", hash = "sha256:a6e579439b329eb93f32219ff27cb358b55fbb52a4862c31a915a098c8a22ac2", size = 122730 },
]

[[package]]
name = "psutil"
version = "7.0.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/2a/80/336820c1ad9286a4ded7e845b2eccfcb27851ab8ac6abece774a6ff4d3de/psutil-7.0.0.tar.gz", hash = "sha256:7be9c3eba38beccb6495ea33afd982a44074b78f28c434a1f51cc07fd315c456", size = 497003 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/ed/e6/2d26234410f8b8abdbf891c9da62bee396583f713fb9f3325a4760875d22/psutil-7.0.0-cp36-abi3-macosx_10_9_x86_64.whl", hash = "sha256:101d71dc322e3cffd7cea0650b09b3d08b8e7c4109dd6809fe452dfd00e58b25", size = 238051 },
    { url = "https://files.pythonhosted.org/packages/04/8b/30f930733afe425e3cbfc0e1468a30a18942350c1a8816acfade80c005c4/psutil-7.0.0-cp36-abi3-macosx_11_0_arm64.whl", hash = "sha256:39db632f6bb862eeccf56660871433e111b6ea58f2caea825571951d4b6aa3da", size = 239535 },
]

[[package]]
name = "pycparser"
version = "2.22"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/1d/b2/31537cf4b1ca988837256c910a668b553fceb8f069bedc4b1c826024b52c/pycparser-2.22.tar.gz", hash = "sha256:491c8be9c040f5390f5bf44a5b07752bd07f56edf992381b05c701439eec10f6", size = 172736 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/13/a3/a812df4e2dd5696d1f351d58b8fe16a405b234ad2886a0dab9183fb78109/pycparser-2.22-py3-none-any.whl", hash = "sha256:c3702b6d3dd8c7abc1afa565d7e63d53a1d0bd86cdc24edd75470f4de499cfcc", size = 117552 },
]

[[package]]
name = "pydantic"
version = "2.10.6"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "annotated-types" },
    { name = "pydantic-core" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b7/ae/d5220c5c52b158b1de7ca89fc5edb72f304a70a4c540c84c8844bf4008de/pydantic-2.10.6.tar.gz", hash = "sha256:ca5daa827cce33de7a42be142548b0096bf05a7e7b365aebfa5f8eeec7128236", size = 761681 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f4/3c/8cc1cc84deffa6e25d2d0c688ebb80635dfdbf1dbea3e30c541c8cf4d860/pydantic-2.10.6-py3-none-any.whl", hash = "sha256:427d664bf0b8a2b34ff5dd0f5a18df00591adcee7198fbd71981054cef37b584", size = 431696 },
]

[[package]]
name = "pydantic-core"
version = "2.27.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/fc/01/f3e5ac5e7c25833db5eb555f7b7ab24cd6f8c322d3a3ad2d67a952dc0abc/pydantic_core-2.27.2.tar.gz", hash = "sha256:eb026e5a4c1fee05726072337ff51d1efb6f59090b7da90d30ea58625b1ffb39", size = 413443 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/3a/bc/fed5f74b5d802cf9a03e83f60f18864e90e3aed7223adaca5ffb7a8d8d64/pydantic_core-2.27.2-cp310-cp310-macosx_10_12_x86_64.whl", hash = "sha256:2d367ca20b2f14095a8f4fa1210f5a7b78b8a20009ecced6b12818f455b1e9fa", size = 1895938 },
    { url = "https://files.pythonhosted.org/packages/71/2a/185aff24ce844e39abb8dd680f4e959f0006944f4a8a0ea372d9f9ae2e53/pydantic_core-2.27.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:491a2b73db93fab69731eaee494f320faa4e093dbed776be1a829c2eb222c34c", size = 1815684 },
    { url = "https://files.pythonhosted.org/packages/c3/43/fafabd3d94d159d4f1ed62e383e264f146a17dd4d48453319fd782e7979e/pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:7969e133a6f183be60e9f6f56bfae753585680f3b7307a8e555a948d443cc05a", size = 1829169 },
    { url = "https://files.pythonhosted.org/packages/a2/d1/f2dfe1a2a637ce6800b799aa086d079998959f6f1215eb4497966efd2274/pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:3de9961f2a346257caf0aa508a4da705467f53778e9ef6fe744c038119737ef5", size = 1867227 },
    { url = "https://files.pythonhosted.org/packages/7d/39/e06fcbcc1c785daa3160ccf6c1c38fea31f5754b756e34b65f74e99780b5/pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:e2bb4d3e5873c37bb3dd58714d4cd0b0e6238cebc4177ac8fe878f8b3aa8e74c", size = 2037695 },
    { url = "https://files.pythonhosted.org/packages/7a/67/61291ee98e07f0650eb756d44998214231f50751ba7e13f4f325d95249ab/pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:280d219beebb0752699480fe8f1dc61ab6615c2046d76b7ab7ee38858de0a4e7", size = 2741662 },
    { url = "https://files.pythonhosted.org/packages/32/90/3b15e31b88ca39e9e626630b4c4a1f5a0dfd09076366f4219429e6786076/pydantic_core-2.27.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:47956ae78b6422cbd46f772f1746799cbb862de838fd8d1fbd34a82e05b0983a", size = 1993370 },
    { url = "https://files.pythonhosted.org/packages/ff/83/c06d333ee3a67e2e13e07794995c1535565132940715931c1c43bfc85b11/pydantic_core-2.27.2-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:14d4a5c49d2f009d62a2a7140d3064f686d17a5d1a268bc641954ba181880236", size = 1996813 },
    { url = "https://files.pythonhosted.org/packages/7c/f7/89be1c8deb6e22618a74f0ca0d933fdcb8baa254753b26b25ad3acff8f74/pydantic_core-2.27.2-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:337b443af21d488716f8d0b6164de833e788aa6bd7e3a39c005febc1284f4962", size = 2005287 },
    { url = "https://files.pythonhosted.org/packages/b7/7d/8eb3e23206c00ef7feee17b83a4ffa0a623eb1a9d382e56e4aa46fd15ff2/pydantic_core-2.27.2-cp310-cp310-musllinux_1_1_armv7l.whl", hash = "sha256:03d0f86ea3184a12f41a2d23f7ccb79cdb5a18e06993f8a45baa8dfec746f0e9", size = 2128414 },
    { url = "https://files.pythonhosted.org/packages/4e/99/fe80f3ff8dd71a3ea15763878d464476e6cb0a2db95ff1c5c554133b6b83/pydantic_core-2.27.2-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:7041c36f5680c6e0f08d922aed302e98b3745d97fe1589db0a3eebf6624523af", size = 2155301 },
    { url = "https://files.pythonhosted.org/packages/2b/a3/e50460b9a5789ca1451b70d4f52546fa9e2b420ba3bfa6100105c0559238/pydantic_core-2.27.2-cp310-cp310-win32.whl", hash = "sha256:50a68f3e3819077be2c98110c1f9dcb3817e93f267ba80a2c05bb4f8799e2ff4", size = 1816685 },
    { url = "https://files.pythonhosted.org/packages/57/4c/a8838731cb0f2c2a39d3535376466de6049034d7b239c0202a64aaa05533/pydantic_core-2.27.2-cp310-cp310-win_amd64.whl", hash = "sha256:e0fd26b16394ead34a424eecf8a31a1f5137094cabe84a1bcb10fa6ba39d3d31", size = 1982876 },
    { url = "https://files.pythonhosted.org/packages/c2/89/f3450af9d09d44eea1f2c369f49e8f181d742f28220f88cc4dfaae91ea6e/pydantic_core-2.27.2-cp311-cp311-macosx_10_12_x86_64.whl", hash = "sha256:8e10c99ef58cfdf2a66fc15d66b16c4a04f62bca39db589ae8cba08bc55331bc", size = 1893421 },
    { url = "https://files.pythonhosted.org/packages/9e/e3/71fe85af2021f3f386da42d291412e5baf6ce7716bd7101ea49c810eda90/pydantic_core-2.27.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:26f32e0adf166a84d0cb63be85c562ca8a6fa8de28e5f0d92250c6b7e9e2aff7", size = 1814998 },
    { url = "https://files.pythonhosted.org/packages/a6/3c/724039e0d848fd69dbf5806894e26479577316c6f0f112bacaf67aa889ac/pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8c19d1ea0673cd13cc2f872f6c9ab42acc4e4f492a7ca9d3795ce2b112dd7e15", size = 1826167 },
    { url = "https://files.pythonhosted.org/packages/2b/5b/1b29e8c1fb5f3199a9a57c1452004ff39f494bbe9bdbe9a81e18172e40d3/pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:5e68c4446fe0810e959cdff46ab0a41ce2f2c86d227d96dc3847af0ba7def306", size = 1865071 },
    { url = "https://files.pythonhosted.org/packages/89/6c/3985203863d76bb7d7266e36970d7e3b6385148c18a68cc8915fd8c84d57/pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:d9640b0059ff4f14d1f37321b94061c6db164fbe49b334b31643e0528d100d99", size = 2036244 },
    { url = "https://files.pythonhosted.org/packages/0e/41/f15316858a246b5d723f7d7f599f79e37493b2e84bfc789e58d88c209f8a/pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:40d02e7d45c9f8af700f3452f329ead92da4c5f4317ca9b896de7ce7199ea459", size = 2737470 },
    { url = "https://files.pythonhosted.org/packages/a8/7c/b860618c25678bbd6d1d99dbdfdf0510ccb50790099b963ff78a124b754f/pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1c1fd185014191700554795c99b347d64f2bb637966c4cfc16998a0ca700d048", size = 1992291 },
    { url = "https://files.pythonhosted.org/packages/bf/73/42c3742a391eccbeab39f15213ecda3104ae8682ba3c0c28069fbcb8c10d/pydantic_core-2.27.2-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:d81d2068e1c1228a565af076598f9e7451712700b673de8f502f0334f281387d", size = 1994613 },
    { url = "https://files.pythonhosted.org/packages/94/7a/941e89096d1175d56f59340f3a8ebaf20762fef222c298ea96d36a6328c5/pydantic_core-2.27.2-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:1a4207639fb02ec2dbb76227d7c751a20b1a6b4bc52850568e52260cae64ca3b", size = 2002355 },
    { url = "https://files.pythonhosted.org/packages/6e/95/2359937a73d49e336a5a19848713555605d4d8d6940c3ec6c6c0ca4dcf25/pydantic_core-2.27.2-cp311-cp311-musllinux_1_1_armv7l.whl", hash = "sha256:3de3ce3c9ddc8bbd88f6e0e304dea0e66d843ec9de1b0042b0911c1663ffd474", size = 2126661 },
    { url = "https://files.pythonhosted.org/packages/2b/4c/ca02b7bdb6012a1adef21a50625b14f43ed4d11f1fc237f9d7490aa5078c/pydantic_core-2.27.2-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:30c5f68ded0c36466acede341551106821043e9afaad516adfb6e8fa80a4e6a6", size = 2153261 },
    { url = "https://files.pythonhosted.org/packages/72/9d/a241db83f973049a1092a079272ffe2e3e82e98561ef6214ab53fe53b1c7/pydantic_core-2.27.2-cp311-cp311-win32.whl", hash = "sha256:c70c26d2c99f78b125a3459f8afe1aed4d9687c24fd677c6a4436bc042e50d6c", size = 1812361 },
    { url = "https://files.pythonhosted.org/packages/e8/ef/013f07248041b74abd48a385e2110aa3a9bbfef0fbd97d4e6d07d2f5b89a/pydantic_core-2.27.2-cp311-cp311-win_amd64.whl", hash = "sha256:08e125dbdc505fa69ca7d9c499639ab6407cfa909214d500897d02afb816e7cc", size = 1982484 },
    { url = "https://files.pythonhosted.org/packages/10/1c/16b3a3e3398fd29dca77cea0a1d998d6bde3902fa2706985191e2313cc76/pydantic_core-2.27.2-cp311-cp311-win_arm64.whl", hash = "sha256:26f0d68d4b235a2bae0c3fc585c585b4ecc51382db0e3ba402a22cbc440915e4", size = 1867102 },
    { url = "https://files.pythonhosted.org/packages/d6/74/51c8a5482ca447871c93e142d9d4a92ead74de6c8dc5e66733e22c9bba89/pydantic_core-2.27.2-cp312-cp312-macosx_10_12_x86_64.whl", hash = "sha256:9e0c8cfefa0ef83b4da9588448b6d8d2a2bf1a53c3f1ae5fca39eb3061e2f0b0", size = 1893127 },
    { url = "https://files.pythonhosted.org/packages/d3/f3/c97e80721735868313c58b89d2de85fa80fe8dfeeed84dc51598b92a135e/pydantic_core-2.27.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:83097677b8e3bd7eaa6775720ec8e0405f1575015a463285a92bfdfe254529ef", size = 1811340 },
    { url = "https://files.pythonhosted.org/packages/9e/91/840ec1375e686dbae1bd80a9e46c26a1e0083e1186abc610efa3d9a36180/pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:172fce187655fece0c90d90a678424b013f8fbb0ca8b036ac266749c09438cb7", size = 1822900 },
    { url = "https://files.pythonhosted.org/packages/f6/31/4240bc96025035500c18adc149aa6ffdf1a0062a4b525c932065ceb4d868/pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:519f29f5213271eeeeb3093f662ba2fd512b91c5f188f3bb7b27bc5973816934", size = 1869177 },
    { url = "https://files.pythonhosted.org/packages/fa/20/02fbaadb7808be578317015c462655c317a77a7c8f0ef274bc016a784c54/pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:05e3a55d124407fffba0dd6b0c0cd056d10e983ceb4e5dbd10dda135c31071d6", size = 2038046 },
    { url = "https://files.pythonhosted.org/packages/06/86/7f306b904e6c9eccf0668248b3f272090e49c275bc488a7b88b0823444a4/pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:9c3ed807c7b91de05e63930188f19e921d1fe90de6b4f5cd43ee7fcc3525cb8c", size = 2685386 },
    { url = "https://files.pythonhosted.org/packages/8d/f0/49129b27c43396581a635d8710dae54a791b17dfc50c70164866bbf865e3/pydantic_core-2.27.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6fb4aadc0b9a0c063206846d603b92030eb6f03069151a625667f982887153e2", size = 1997060 },
    { url = "https://files.pythonhosted.org/packages/0d/0f/943b4af7cd416c477fd40b187036c4f89b416a33d3cc0ab7b82708a667aa/pydantic_core-2.27.2-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:28ccb213807e037460326424ceb8b5245acb88f32f3d2777427476e1b32c48c4", size = 2004870 },
    { url = "https://files.pythonhosted.org/packages/35/40/aea70b5b1a63911c53a4c8117c0a828d6790483f858041f47bab0b779f44/pydantic_core-2.27.2-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:de3cd1899e2c279b140adde9357c4495ed9d47131b4a4eaff9052f23398076b3", size = 1999822 },
    { url = "https://files.pythonhosted.org/packages/f2/b3/807b94fd337d58effc5498fd1a7a4d9d59af4133e83e32ae39a96fddec9d/pydantic_core-2.27.2-cp312-cp312-musllinux_1_1_armv7l.whl", hash = "sha256:220f892729375e2d736b97d0e51466252ad84c51857d4d15f5e9692f9ef12be4", size = 2130364 },
    { url = "https://files.pythonhosted.org/packages/fc/df/791c827cd4ee6efd59248dca9369fb35e80a9484462c33c6649a8d02b565/pydantic_core-2.27.2-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:a0fcd29cd6b4e74fe8ddd2c90330fd8edf2e30cb52acda47f06dd615ae72da57", size = 2158303 },
    { url = "https://files.pythonhosted.org/packages/9b/67/4e197c300976af185b7cef4c02203e175fb127e414125916bf1128b639a9/pydantic_core-2.27.2-cp312-cp312-win32.whl", hash = "sha256:1e2cb691ed9834cd6a8be61228471d0a503731abfb42f82458ff27be7b2186fc", size = 1834064 },
    { url = "https://files.pythonhosted.org/packages/1f/ea/cd7209a889163b8dcca139fe32b9687dd05249161a3edda62860430457a5/pydantic_core-2.27.2-cp312-cp312-win_amd64.whl", hash = "sha256:cc3f1a99a4f4f9dd1de4fe0312c114e740b5ddead65bb4102884b384c15d8bc9", size = 1989046 },
    { url = "https://files.pythonhosted.org/packages/bc/49/c54baab2f4658c26ac633d798dab66b4c3a9bbf47cff5284e9c182f4137a/pydantic_core-2.27.2-cp312-cp312-win_arm64.whl", hash = "sha256:3911ac9284cd8a1792d3cb26a2da18f3ca26c6908cc434a18f730dc0db7bfa3b", size = 1885092 },
    { url = "https://files.pythonhosted.org/packages/41/b1/9bc383f48f8002f99104e3acff6cba1231b29ef76cfa45d1506a5cad1f84/pydantic_core-2.27.2-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:7d14bd329640e63852364c306f4d23eb744e0f8193148d4044dd3dacdaacbd8b", size = 1892709 },
    { url = "https://files.pythonhosted.org/packages/10/6c/e62b8657b834f3eb2961b49ec8e301eb99946245e70bf42c8817350cbefc/pydantic_core-2.27.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:82f91663004eb8ed30ff478d77c4d1179b3563df6cdb15c0817cd1cdaf34d154", size = 1811273 },
    { url = "https://files.pythonhosted.org/packages/ba/15/52cfe49c8c986e081b863b102d6b859d9defc63446b642ccbbb3742bf371/pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:71b24c7d61131bb83df10cc7e687433609963a944ccf45190cfc21e0887b08c9", size = 1823027 },
    { url = "https://files.pythonhosted.org/packages/b1/1c/b6f402cfc18ec0024120602bdbcebc7bdd5b856528c013bd4d13865ca473/pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:fa8e459d4954f608fa26116118bb67f56b93b209c39b008277ace29937453dc9", size = 1868888 },
    { url = "https://files.pythonhosted.org/packages/bd/7b/8cb75b66ac37bc2975a3b7de99f3c6f355fcc4d89820b61dffa8f1e81677/pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:ce8918cbebc8da707ba805b7fd0b382816858728ae7fe19a942080c24e5b7cd1", size = 2037738 },
    { url = "https://files.pythonhosted.org/packages/c8/f1/786d8fe78970a06f61df22cba58e365ce304bf9b9f46cc71c8c424e0c334/pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:eda3f5c2a021bbc5d976107bb302e0131351c2ba54343f8a496dc8783d3d3a6a", size = 2685138 },
    { url = "https://files.pythonhosted.org/packages/a6/74/d12b2cd841d8724dc8ffb13fc5cef86566a53ed358103150209ecd5d1999/pydantic_core-2.27.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bd8086fa684c4775c27f03f062cbb9eaa6e17f064307e86b21b9e0abc9c0f02e", size = 1997025 },
    { url = "https://files.pythonhosted.org/packages/a0/6e/940bcd631bc4d9a06c9539b51f070b66e8f370ed0933f392db6ff350d873/pydantic_core-2.27.2-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:8d9b3388db186ba0c099a6d20f0604a44eabdeef1777ddd94786cdae158729e4", size = 2004633 },
    { url = "https://files.pythonhosted.org/packages/50/cc/a46b34f1708d82498c227d5d80ce615b2dd502ddcfd8376fc14a36655af1/pydantic_core-2.27.2-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:7a66efda2387de898c8f38c0cf7f14fca0b51a8ef0b24bfea5849f1b3c95af27", size = 1999404 },
    { url = "https://files.pythonhosted.org/packages/ca/2d/c365cfa930ed23bc58c41463bae347d1005537dc8db79e998af8ba28d35e/pydantic_core-2.27.2-cp313-cp313-musllinux_1_1_armv7l.whl", hash = "sha256:18a101c168e4e092ab40dbc2503bdc0f62010e95d292b27827871dc85450d7ee", size = 2130130 },
    { url = "https://files.pythonhosted.org/packages/f4/d7/eb64d015c350b7cdb371145b54d96c919d4db516817f31cd1c650cae3b21/pydantic_core-2.27.2-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:ba5dd002f88b78a4215ed2f8ddbdf85e8513382820ba15ad5ad8955ce0ca19a1", size = 2157946 },
    { url = "https://files.pythonhosted.org/packages/a4/99/bddde3ddde76c03b65dfd5a66ab436c4e58ffc42927d4ff1198ffbf96f5f/pydantic_core-2.27.2-cp313-cp313-win32.whl", hash = "sha256:1ebaf1d0481914d004a573394f4be3a7616334be70261007e47c2a6fe7e50130", size = 1834387 },
    { url = "https://files.pythonhosted.org/packages/71/47/82b5e846e01b26ac6f1893d3c5f9f3a2eb6ba79be26eef0b759b4fe72946/pydantic_core-2.27.2-cp313-cp313-win_amd64.whl", hash = "sha256:953101387ecf2f5652883208769a79e48db18c6df442568a0b5ccd8c2723abee", size = 1990453 },
    { url = "https://files.pythonhosted.org/packages/51/b2/b2b50d5ecf21acf870190ae5d093602d95f66c9c31f9d5de6062eb329ad1/pydantic_core-2.27.2-cp313-cp313-win_arm64.whl", hash = "sha256:ac4dbfd1691affb8f48c2c13241a2e3b60ff23247cbcf981759c768b6633cf8b", size = 1885186 },
    { url = "https://files.pythonhosted.org/packages/43/53/13e9917fc69c0a4aea06fd63ed6a8d6cda9cf140ca9584d49c1650b0ef5e/pydantic_core-2.27.2-cp38-cp38-macosx_10_12_x86_64.whl", hash = "sha256:d3e8d504bdd3f10835468f29008d72fc8359d95c9c415ce6e767203db6127506", size = 1899595 },
    { url = "https://files.pythonhosted.org/packages/f4/20/26c549249769ed84877f862f7bb93f89a6ee08b4bee1ed8781616b7fbb5e/pydantic_core-2.27.2-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:521eb9b7f036c9b6187f0b47318ab0d7ca14bd87f776240b90b21c1f4f149320", size = 1775010 },
    { url = "https://files.pythonhosted.org/packages/35/eb/8234e05452d92d2b102ffa1b56d801c3567e628fdc63f02080fdfc68fd5e/pydantic_core-2.27.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:85210c4d99a0114f5a9481b44560d7d1e35e32cc5634c656bc48e590b669b145", size = 1830727 },
    { url = "https://files.pythonhosted.org/packages/8f/df/59f915c8b929d5f61e5a46accf748a87110ba145156f9326d1a7d28912b2/pydantic_core-2.27.2-cp38-cp38-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:d716e2e30c6f140d7560ef1538953a5cd1a87264c737643d481f2779fc247fe1", size = 1868393 },
    { url = "https://files.pythonhosted.org/packages/d5/52/81cf4071dca654d485c277c581db368b0c95b2b883f4d7b736ab54f72ddf/pydantic_core-2.27.2-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:f66d89ba397d92f840f8654756196d93804278457b5fbede59598a1f9f90b228", size = 2040300 },
    { url = "https://files.pythonhosted.org/packages/9c/00/05197ce1614f5c08d7a06e1d39d5d8e704dc81971b2719af134b844e2eaf/pydantic_core-2.27.2-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:669e193c1c576a58f132e3158f9dfa9662969edb1a250c54d8fa52590045f046", size = 2738785 },
    { url = "https://files.pythonhosted.org/packages/f7/a3/5f19bc495793546825ab160e530330c2afcee2281c02b5ffafd0b32ac05e/pydantic_core-2.27.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9fdbe7629b996647b99c01b37f11170a57ae675375b14b8c13b8518b8320ced5", size = 1996493 },
    { url = "https://files.pythonhosted.org/packages/ed/e8/e0102c2ec153dc3eed88aea03990e1b06cfbca532916b8a48173245afe60/pydantic_core-2.27.2-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:d262606bf386a5ba0b0af3b97f37c83d7011439e3dc1a9298f21efb292e42f1a", size = 1998544 },
    { url = "https://files.pythonhosted.org/packages/fb/a3/4be70845b555bd80aaee9f9812a7cf3df81550bce6dadb3cfee9c5d8421d/pydantic_core-2.27.2-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:cabb9bcb7e0d97f74df8646f34fc76fbf793b7f6dc2438517d7a9e50eee4f14d", size = 2007449 },
    { url = "https://files.pythonhosted.org/packages/e3/9f/b779ed2480ba355c054e6d7ea77792467631d674b13d8257085a4bc7dcda/pydantic_core-2.27.2-cp38-cp38-musllinux_1_1_armv7l.whl", hash = "sha256:d2d63f1215638d28221f664596b1ccb3944f6e25dd18cd3b86b0a4c408d5ebb9", size = 2129460 },
    { url = "https://files.pythonhosted.org/packages/a0/f0/a6ab0681f6e95260c7fbf552874af7302f2ea37b459f9b7f00698f875492/pydantic_core-2.27.2-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:bca101c00bff0adb45a833f8451b9105d9df18accb8743b08107d7ada14bd7da", size = 2159609 },
    { url = "https://files.pythonhosted.org/packages/8a/2b/e1059506795104349712fbca647b18b3f4a7fd541c099e6259717441e1e0/pydantic_core-2.27.2-cp38-cp38-win32.whl", hash = "sha256:f6f8e111843bbb0dee4cb6594cdc73e79b3329b526037ec242a3e49012495b3b", size = 1819886 },
    { url = "https://files.pythonhosted.org/packages/aa/6d/df49c17f024dfc58db0bacc7b03610058018dd2ea2eaf748ccbada4c3d06/pydantic_core-2.27.2-cp38-cp38-win_amd64.whl", hash = "sha256:fd1aea04935a508f62e0d0ef1f5ae968774a32afc306fb8545e06f5ff5cdf3ad", size = 1980773 },
    { url = "https://files.pythonhosted.org/packages/27/97/3aef1ddb65c5ccd6eda9050036c956ff6ecbfe66cb7eb40f280f121a5bb0/pydantic_core-2.27.2-cp39-cp39-macosx_10_12_x86_64.whl", hash = "sha256:c10eb4f1659290b523af58fa7cffb452a61ad6ae5613404519aee4bfbf1df993", size = 1896475 },
    { url = "https://files.pythonhosted.org/packages/ad/d3/5668da70e373c9904ed2f372cb52c0b996426f302e0dee2e65634c92007d/pydantic_core-2.27.2-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:ef592d4bad47296fb11f96cd7dc898b92e795032b4894dfb4076cfccd43a9308", size = 1772279 },
    { url = "https://files.pythonhosted.org/packages/8a/9e/e44b8cb0edf04a2f0a1f6425a65ee089c1d6f9c4c2dcab0209127b6fdfc2/pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c61709a844acc6bf0b7dce7daae75195a10aac96a596ea1b776996414791ede4", size = 1829112 },
    { url = "https://files.pythonhosted.org/packages/1c/90/1160d7ac700102effe11616e8119e268770f2a2aa5afb935f3ee6832987d/pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:42c5f762659e47fdb7b16956c71598292f60a03aa92f8b6351504359dbdba6cf", size = 1866780 },
    { url = "https://files.pythonhosted.org/packages/ee/33/13983426df09a36d22c15980008f8d9c77674fc319351813b5a2739b70f3/pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:4c9775e339e42e79ec99c441d9730fccf07414af63eac2f0e48e08fd38a64d76", size = 2037943 },
    { url = "https://files.pythonhosted.org/packages/01/d7/ced164e376f6747e9158c89988c293cd524ab8d215ae4e185e9929655d5c/pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:57762139821c31847cfb2df63c12f725788bd9f04bc2fb392790959b8f70f118", size = 2740492 },
    { url = "https://files.pythonhosted.org/packages/8b/1f/3dc6e769d5b7461040778816aab2b00422427bcaa4b56cc89e9c653b2605/pydantic_core-2.27.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0d1e85068e818c73e048fe28cfc769040bb1f475524f4745a5dc621f75ac7630", size = 1995714 },
    { url = "https://files.pythonhosted.org/packages/07/d7/a0bd09bc39283530b3f7c27033a814ef254ba3bd0b5cfd040b7abf1fe5da/pydantic_core-2.27.2-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:097830ed52fd9e427942ff3b9bc17fab52913b2f50f2880dc4a5611446606a54", size = 1997163 },
    { url = "https://files.pythonhosted.org/packages/2d/bb/2db4ad1762e1c5699d9b857eeb41959191980de6feb054e70f93085e1bcd/pydantic_core-2.27.2-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:044a50963a614ecfae59bb1eaf7ea7efc4bc62f49ed594e18fa1e5d953c40e9f", size = 2005217 },
    { url = "https://files.pythonhosted.org/packages/53/5f/23a5a3e7b8403f8dd8fc8a6f8b49f6b55c7d715b77dcf1f8ae919eeb5628/pydantic_core-2.27.2-cp39-cp39-musllinux_1_1_armv7l.whl", hash = "sha256:4e0b4220ba5b40d727c7f879eac379b822eee5d8fff418e9d3381ee45b3b0362", size = 2127899 },
    { url = "https://files.pythonhosted.org/packages/c2/ae/aa38bb8dd3d89c2f1d8362dd890ee8f3b967330821d03bbe08fa01ce3766/pydantic_core-2.27.2-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:5e4f4bb20d75e9325cc9696c6802657b58bc1dbbe3022f32cc2b2b632c3fbb96", size = 2155726 },
    { url = "https://files.pythonhosted.org/packages/98/61/4f784608cc9e98f70839187117ce840480f768fed5d386f924074bf6213c/pydantic_core-2.27.2-cp39-cp39-win32.whl", hash = "sha256:cca63613e90d001b9f2f9a9ceb276c308bfa2a43fafb75c8031c4f66039e8c6e", size = 1817219 },
    { url = "https://files.pythonhosted.org/packages/57/82/bb16a68e4a1a858bb3768c2c8f1ff8d8978014e16598f001ea29a25bf1d1/pydantic_core-2.27.2-cp39-cp39-win_amd64.whl", hash = "sha256:77d1bca19b0f7021b3a982e6f903dcd5b2b06076def36a652e3907f596e29f67", size = 1985382 },
    { url = "https://files.pythonhosted.org/packages/46/72/af70981a341500419e67d5cb45abe552a7c74b66326ac8877588488da1ac/pydantic_core-2.27.2-pp310-pypy310_pp73-macosx_10_12_x86_64.whl", hash = "sha256:2bf14caea37e91198329b828eae1618c068dfb8ef17bb33287a7ad4b61ac314e", size = 1891159 },
    { url = "https://files.pythonhosted.org/packages/ad/3d/c5913cccdef93e0a6a95c2d057d2c2cba347815c845cda79ddd3c0f5e17d/pydantic_core-2.27.2-pp310-pypy310_pp73-macosx_11_0_arm64.whl", hash = "sha256:b0cb791f5b45307caae8810c2023a184c74605ec3bcbb67d13846c28ff731ff8", size = 1768331 },
    { url = "https://files.pythonhosted.org/packages/f6/f0/a3ae8fbee269e4934f14e2e0e00928f9346c5943174f2811193113e58252/pydantic_core-2.27.2-pp310-pypy310_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:688d3fd9fcb71f41c4c015c023d12a79d1c4c0732ec9eb35d96e3388a120dcf3", size = 1822467 },
    { url = "https://files.pythonhosted.org/packages/d7/7a/7bbf241a04e9f9ea24cd5874354a83526d639b02674648af3f350554276c/pydantic_core-2.27.2-pp310-pypy310_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3d591580c34f4d731592f0e9fe40f9cc1b430d297eecc70b962e93c5c668f15f", size = 1979797 },
    { url = "https://files.pythonhosted.org/packages/4f/5f/4784c6107731f89e0005a92ecb8a2efeafdb55eb992b8e9d0a2be5199335/pydantic_core-2.27.2-pp310-pypy310_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:82f986faf4e644ffc189a7f1aafc86e46ef70372bb153e7001e8afccc6e54133", size = 1987839 },
    { url = "https://files.pythonhosted.org/packages/6d/a7/61246562b651dff00de86a5f01b6e4befb518df314c54dec187a78d81c84/pydantic_core-2.27.2-pp310-pypy310_pp73-musllinux_1_1_aarch64.whl", hash = "sha256:bec317a27290e2537f922639cafd54990551725fc844249e64c523301d0822fc", size = 1998861 },
    { url = "https://files.pythonhosted.org/packages/86/aa/837821ecf0c022bbb74ca132e117c358321e72e7f9702d1b6a03758545e2/pydantic_core-2.27.2-pp310-pypy310_pp73-musllinux_1_1_armv7l.whl", hash = "sha256:0296abcb83a797db256b773f45773da397da75a08f5fcaef41f2044adec05f50", size = 2116582 },
    { url = "https://files.pythonhosted.org/packages/81/b0/5e74656e95623cbaa0a6278d16cf15e10a51f6002e3ec126541e95c29ea3/pydantic_core-2.27.2-pp310-pypy310_pp73-musllinux_1_1_x86_64.whl", hash = "sha256:0d75070718e369e452075a6017fbf187f788e17ed67a3abd47fa934d001863d9", size = 2151985 },
    { url = "https://files.pythonhosted.org/packages/63/37/3e32eeb2a451fddaa3898e2163746b0cffbbdbb4740d38372db0490d67f3/pydantic_core-2.27.2-pp310-pypy310_pp73-win_amd64.whl", hash = "sha256:7e17b560be3c98a8e3aa66ce828bdebb9e9ac6ad5466fba92eb74c4c95cb1151", size = 2004715 },
    { url = "https://files.pythonhosted.org/packages/29/0e/dcaea00c9dbd0348b723cae82b0e0c122e0fa2b43fa933e1622fd237a3ee/pydantic_core-2.27.2-pp39-pypy39_pp73-macosx_10_12_x86_64.whl", hash = "sha256:c33939a82924da9ed65dab5a65d427205a73181d8098e79b6b426bdf8ad4e656", size = 1891733 },
    { url = "https://files.pythonhosted.org/packages/86/d3/e797bba8860ce650272bda6383a9d8cad1d1c9a75a640c9d0e848076f85e/pydantic_core-2.27.2-pp39-pypy39_pp73-macosx_11_0_arm64.whl", hash = "sha256:00bad2484fa6bda1e216e7345a798bd37c68fb2d97558edd584942aa41b7d278", size = 1768375 },
    { url = "https://files.pythonhosted.org/packages/41/f7/f847b15fb14978ca2b30262548f5fc4872b2724e90f116393eb69008299d/pydantic_core-2.27.2-pp39-pypy39_pp73-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c817e2b40aba42bac6f457498dacabc568c3b7a986fc9ba7c8d9d260b71485fb", size = 1822307 },
    { url = "https://files.pythonhosted.org/packages/9c/63/ed80ec8255b587b2f108e514dc03eed1546cd00f0af281e699797f373f38/pydantic_core-2.27.2-pp39-pypy39_pp73-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:251136cdad0cb722e93732cb45ca5299fb56e1344a833640bf93b2803f8d1bfd", size = 1979971 },
    { url = "https://files.pythonhosted.org/packages/a9/6d/6d18308a45454a0de0e975d70171cadaf454bc7a0bf86b9c7688e313f0bb/pydantic_core-2.27.2-pp39-pypy39_pp73-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:d2088237af596f0a524d3afc39ab3b036e8adb054ee57cbb1dcf8e09da5b29cc", size = 1987616 },
    { url = "https://files.pythonhosted.org/packages/82/8a/05f8780f2c1081b800a7ca54c1971e291c2d07d1a50fb23c7e4aef4ed403/pydantic_core-2.27.2-pp39-pypy39_pp73-musllinux_1_1_aarch64.whl", hash = "sha256:d4041c0b966a84b4ae7a09832eb691a35aec90910cd2dbe7a208de59be77965b", size = 1998943 },
    { url = "https://files.pythonhosted.org/packages/5e/3e/fe5b6613d9e4c0038434396b46c5303f5ade871166900b357ada4766c5b7/pydantic_core-2.27.2-pp39-pypy39_pp73-musllinux_1_1_armv7l.whl", hash = "sha256:8083d4e875ebe0b864ffef72a4304827015cff328a1be6e22cc850753bfb122b", size = 2116654 },
    { url = "https://files.pythonhosted.org/packages/db/ad/28869f58938fad8cc84739c4e592989730bfb69b7c90a8fff138dff18e1e/pydantic_core-2.27.2-pp39-pypy39_pp73-musllinux_1_1_x86_64.whl", hash = "sha256:f141ee28a0ad2123b6611b6ceff018039df17f32ada8b534e6aa039545a3efb2", size = 2152292 },
    { url = "https://files.pythonhosted.org/packages/a1/0c/c5c5cd3689c32ed1fe8c5d234b079c12c281c051759770c05b8bed6412b5/pydantic_core-2.27.2-pp39-pypy39_pp73-win_amd64.whl", hash = "sha256:7d0c8399fcc1848491f00e0314bd59fb34a9c008761bcb422a057670c3f65e35", size = 2004961 },
]

[[package]]
name = "pygments"
version = "2.19.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/7c/2d/c3338d48ea6cc0feb8446d8e6937e1408088a72a39937982cc6111d17f84/pygments-2.19.1.tar.gz", hash = "sha256:61c16d2a8576dc0649d9f39e089b5f02bcd27fba10d8fb4dcc28173f7a45151f", size = 4968581 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/8a/0b/9fcc47d19c48b59121088dd6da2488a49d5f72dacf8262e2790a1d2c7d15/pygments-2.19.1-py3-none-any.whl", hash = "sha256:9ea1544ad55cecf4b8242fab6dd35a93bbce657034b0611ee383099054ab6d8c", size = 1225293 },
]

[[package]]
name = "pymupdf"
version = "1.24.11"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d4/a3/3edbb6be649e311107b320141cae0353d4cc9c6593eba7691f16c53c9c71/PyMuPDF-1.24.11.tar.gz", hash = "sha256:6e45e57f14ac902029d4aacf07684958d0e58c769f47d9045b2048d0a3d20155", size = 51199098 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f5/75/b059d603530d99926de2b6a64314f3534e2149ee5496142de550c66907ac/PyMuPDF-1.24.11-cp38-abi3-macosx_10_9_x86_64.whl", hash = "sha256:24c35ba9e731027ff24566b90d4986e9aac75e1ce47589b25de51e3c687ddb73", size = 18895391 },
    { url = "https://files.pythonhosted.org/packages/16/f8/8396ca7218622cb3600c919b320a24f05b7c14bd81eea03f3f2182844a06/PyMuPDF-1.24.11-cp38-abi3-macosx_11_0_arm64.whl", hash = "sha256:20c8eb65b855a33411246d6697a3f3166727fe2d8585753cf0db648730104be6", size = 18152689 },
    { url = "https://files.pythonhosted.org/packages/55/3d/84bd559129d2ff07267baae0bde0c6f4f49232408b547971f7a2e1534cb9/PyMuPDF-1.24.11-cp38-abi3-manylinux2014_aarch64.manylinux_2_17_aarch64.whl", hash = "sha256:32fd013e3c844f105c0a6a43ee82acc7cd0c900f6ff14f5eed9492840bbcbdd9", size = 19033047 },
    { url = "https://files.pythonhosted.org/packages/ca/21/ad66778ad2485f87ef1d5a36f17ec8d4aee8ce247c8e46c673eff776a877/PyMuPDF-1.24.11-cp38-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl", hash = "sha256:2efb793644df99db0fe2468149048175cf25c5803997828efc9152aca838f5f2", size = 19563533 },
    { url = "https://files.pythonhosted.org/packages/6a/92/9ff020892560f80433876ec904c0f2669d1d69403adf412565e54a946615/PyMuPDF-1.24.11-cp38-abi3-musllinux_1_2_x86_64.whl", hash = "sha256:9b7ac5b8ec3daec17f2e830962ed091610e576a5e531d2fe28c437fbd69b1969", size = 20691324 },
    { url = "https://files.pythonhosted.org/packages/28/6b/a0247598f06585d84ae9927d6ed191d89d38686ad6bf0dadc0ed699a77e7/PyMuPDF-1.24.11-cp38-abi3-win32.whl", hash = "sha256:6fda6c7ed7e6ad74d9cfac5c3837ef42efd58c506440e2513a0a200bc3c4dbc0", size = 14685566 },
    { url = "https://files.pythonhosted.org/packages/f6/03/99895f003d7ff59c83d524aeccecff4e1ee1f39a7724f88acfda4f67b8bc/PyMuPDF-1.24.11-cp38-abi3-win_amd64.whl", hash = "sha256:745ce77532702d6ddeeecb47306d3669629aa5ff82708318cd652881f493b0ba", size = 15984328 },
]

[[package]]
name = "pyparsing"
version = "3.1.4"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/83/08/13f3bce01b2061f2bbd582c9df82723de943784cf719a35ac886c652043a/pyparsing-3.1.4.tar.gz", hash = "sha256:f86ec8d1a83f11977c9a6ea7598e8c27fc5cddfa5b07ea2241edbbde1d7bc032", size = 900231 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e5/0c/0e3c05b1c87bb6a1c76d281b0f35e78d2d80ac91b5f8f524cebf77f51049/pyparsing-3.1.4-py3-none-any.whl", hash = "sha256:a6a7ee4235a3f944aa1fa2249307708f893fe5717dc603503c6c7969c070fb7c", size = 104100 },
]

[[package]]
name = "pypdf"
version = "5.3.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions", marker = "python_full_version < '3.11'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/da/5b/67df68ec4b934aae9ca89edfb43a869c5edb3bd504dd275be9e83001d3e9/pypdf-5.3.1.tar.gz", hash = "sha256:0b9b715252b3c60bacc052e6a780e8b742cee9b9a2135f6007bb018e22a5adad", size = 5011845 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f4/0c/75da081f5948e07f373a92087e4808739a3248d308f01c78c9bd4a51defa/pypdf-5.3.1-py3-none-any.whl", hash = "sha256:20ea5b8686faad1b695fda054462b667d5e5f51e25fbbc092f12c5e0bb20d738", size = 302042 },
]

[[package]]
name = "pypdf2"
version = "3.0.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions", marker = "python_full_version < '3.10'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/9f/bb/18dc3062d37db6c491392007dfd1a7f524bb95886eb956569ac38a23a784/PyPDF2-3.0.1.tar.gz", hash = "sha256:a74408f69ba6271f71b9352ef4ed03dc53a31aa404d29b5d31f53bfecfee1440", size = 227419 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/8e/5e/c86a5643653825d3c913719e788e41386bee415c2b87b4f955432f2de6b2/pypdf2-3.0.1-py3-none-any.whl", hash = "sha256:d16e4205cfee272fbdc0568b68d82be796540b1537508cef59388f839c191928", size = 232572 },
]

[[package]]
name = "pypdfium2"
version = "4.30.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/55/d4/905e621c62598a08168c272b42fc00136c8861cfce97afb2a1ecbd99487a/pypdfium2-4.30.1.tar.gz", hash = "sha256:5f5c7c6d03598e107d974f66b220a49436aceb191da34cda5f692be098a814ce", size = 164854 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/30/8e/3ce0856b3af0f058dd3655ce57d31d1dbde4d4bd0e172022ffbf1b58a4b9/pypdfium2-4.30.1-py3-none-macosx_10_13_x86_64.whl", hash = "sha256:e07c47633732cc18d890bb7e965ad28a9c5a932e548acb928596f86be2e5ae37", size = 2889836 },
    { url = "https://files.pythonhosted.org/packages/c2/6a/f6995b21f9c6c155487ce7df70632a2df1ba49efcb291b9943ea45f28b15/pypdfium2-4.30.1-py3-none-macosx_11_0_arm64.whl", hash = "sha256:5ea2d44e96d361123b67b00f527017aa9c847c871b5714e013c01c3eb36a79fe", size = 2769232 },
    { url = "https://files.pythonhosted.org/packages/53/91/79060923148e6d380b8a299b32bba46d70aac5fe1cd4f04320bcbd1a48d3/pypdfium2-4.30.1-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1de7a3a36803171b3f66911131046d65a732f9e7834438191cb58235e6163c4e", size = 2847531 },
    { url = "https://files.pythonhosted.org/packages/a8/6c/93507f87c159e747eaab54352c0fccbaec3f1b3749d0bb9085a47899f898/pypdfium2-4.30.1-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:b8a4231efb13170354f568c722d6540b8d5b476b08825586d48ef70c40d16e03", size = 2636266 },
    { url = "https://files.pythonhosted.org/packages/24/dc/d56f74a092f2091e328d6485f16562e2fc51cffb0ad6d5c616d80c1eb53c/pypdfium2-4.30.1-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:6f434a4934e8244aa95343ffcf24e9ad9f120dbb4785f631bb40a88c39292493", size = 2919296 },
    { url = "https://files.pythonhosted.org/packages/be/d9/a2f1ee03d47fbeb48bcfde47ed7155772739622cfadf7135a84ba6a97824/pypdfium2-4.30.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f454032a0bc7681900170f67d8711b3942824531e765f91c2f5ce7937f999794", size = 2866119 },
    { url = "https://files.pythonhosted.org/packages/01/47/6aa019c32aa39d3f33347c458c0c5887e84096cbe444456402bc97e66704/pypdfium2-4.30.1-py3-none-musllinux_1_1_aarch64.whl", hash = "sha256:bbf9130a72370ee9d602e39949b902db669a2a1c24746a91e5586eb829055d9f", size = 6228684 },
    { url = "https://files.pythonhosted.org/packages/4c/07/2954c15b3f7c85ceb80cad36757fd41b3aba0dd14e68f4bed9ce3f2e7e74/pypdfium2-4.30.1-py3-none-musllinux_1_1_i686.whl", hash = "sha256:5cb52884b1583b96e94fd78542c63bb42e06df5e8f9e52f8f31f5ad5a1e53367", size = 6231815 },
    { url = "https://files.pythonhosted.org/packages/b4/9b/b4667e95754624f4af5a912001abba90c046e1c80d4a4e887f0af664ffec/pypdfium2-4.30.1-py3-none-musllinux_1_1_x86_64.whl", hash = "sha256:1a9e372bd4867ff223cc8c338e33fe11055dad12f22885950fc27646cc8d9122", size = 6313429 },
    { url = "https://files.pythonhosted.org/packages/43/38/f9e77cf55ba5546a39fa659404b78b97de2ca344848271e7731efb0954cd/pypdfium2-4.30.1-py3-none-win32.whl", hash = "sha256:421f1cf205e213e07c1f2934905779547f4f4a2ff2f59dde29da3d511d3fc806", size = 2834989 },
    { url = "https://files.pythonhosted.org/packages/a4/f3/8d3a350efb4286b5ebdabcf6736f51d8e3b10dbe68804c6930b00f5cf329/pypdfium2-4.30.1-py3-none-win_amd64.whl", hash = "sha256:598a7f20264ab5113853cba6d86c4566e4356cad037d7d1f849c8c9021007e05", size = 2960157 },
    { url = "https://files.pythonhosted.org/packages/e1/6b/2706497c86e8d69fb76afe5ea857fe1794621aa0f3b1d863feb953fe0f22/pypdfium2-4.30.1-py3-none-win_arm64.whl", hash = "sha256:c2b6d63f6d425d9416c08d2511822b54b8e3ac38e639fc41164b1d75584b3a8c", size = 2814810 },
]

[[package]]
name = "pytesseract"
version = "0.3.13"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "packaging" },
    { name = "pillow" },
]
sdist = { url = "https://files.pythonhosted.org/packages/9f/a6/7d679b83c285974a7cb94d739b461fa7e7a9b17a3abfd7bf6cbc5c2394b0/pytesseract-0.3.13.tar.gz", hash = "sha256:4bf5f880c99406f52a3cfc2633e42d9dc67615e69d8a509d74867d3baddb5db9", size = 17689 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7a/33/8312d7ce74670c9d39a532b2c246a853861120486be9443eebf048043637/pytesseract-0.3.13-py3-none-any.whl", hash = "sha256:7a99c6c2ac598360693d83a416e36e0b33a67638bb9d77fdcac094a3589d4b34", size = 14705 },
]

[[package]]
name = "pytest"
version = "8.3.5"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "colorama", marker = "sys_platform == 'win32'" },
    { name = "exceptiongroup", marker = "python_full_version < '3.11'" },
    { name = "iniconfig" },
    { name = "packaging" },
    { name = "pluggy" },
    { name = "tomli", marker = "python_full_version < '3.11'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/ae/3c/c9d525a414d506893f0cd8a8d0de7706446213181570cdbd766691164e40/pytest-8.3.5.tar.gz", hash = "sha256:f4efe70cc14e511565ac476b57c279e12a855b11f48f212af1080ef2263d3845", size = 1450891 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/30/3d/64ad57c803f1fa1e963a7946b6e0fea4a70df53c1a7fed304586539c2bac/pytest-8.3.5-py3-none-any.whl", hash = "sha256:c69214aa47deac29fad6c2a4f590b9c4a9fdb16a403176fe154b79c0b4d4d820", size = 343634 },
]

[[package]]
name = "pytest-cov"
version = "5.0.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "coverage", extra = ["toml"] },
    { name = "pytest" },
]
sdist = { url = "https://files.pythonhosted.org/packages/74/67/00efc8d11b630c56f15f4ad9c7f9223f1e5ec275aaae3fa9118c6a223ad2/pytest-cov-5.0.0.tar.gz", hash = "sha256:5837b58e9f6ebd335b0f8060eecce69b662415b16dc503883a02f45dfeb14857", size = 63042 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/78/3a/af5b4fa5961d9a1e6237b530eb87dd04aea6eb83da09d2a4073d81b54ccf/pytest_cov-5.0.0-py3-none-any.whl", hash = "sha256:4f0764a1219df53214206bf1feea4633c3b558a2925c8b59f144f682861ce652", size = 21990 },
]

[[package]]
name = "pytest-mock"
version = "3.14.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "pytest" },
]
sdist = { url = "https://files.pythonhosted.org/packages/c6/90/a955c3ab35ccd41ad4de556596fa86685bf4fc5ffcc62d22d856cfd4e29a/pytest-mock-3.14.0.tar.gz", hash = "sha256:2719255a1efeceadbc056d6bf3df3d1c5015530fb40cf347c0f9afac88410bd0", size = 32814 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f2/3b/b26f90f74e2986a82df6e7ac7e319b8ea7ccece1caec9f8ab6104dc70603/pytest_mock-3.14.0-py3-none-any.whl", hash = "sha256:0b72c38033392a5f4621342fe11e9219ac11ec9d375f8e2a0c164539e0d70f6f", size = 9863 },
]

[[package]]
name = "pytest-sugar"
version = "1.0.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "packaging" },
    { name = "pytest" },
    { name = "termcolor" },
]
sdist = { url = "https://files.pythonhosted.org/packages/f5/ac/5754f5edd6d508bc6493bc37d74b928f102a5fff82d9a80347e180998f08/pytest-sugar-1.0.0.tar.gz", hash = "sha256:6422e83258f5b0c04ce7c632176c7732cab5fdb909cb39cca5c9139f81276c0a", size = 14992 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/92/fb/889f1b69da2f13691de09a111c16c4766a433382d44aa0ecf221deded44a/pytest_sugar-1.0.0-py3-none-any.whl", hash = "sha256:70ebcd8fc5795dc457ff8b69d266a4e2e8a74ae0c3edc749381c64b5246c8dfd", size = 10171 },
]

[[package]]
name = "pytest-xdist"
version = "3.6.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "execnet" },
    { name = "pytest" },
]
sdist = { url = "https://files.pythonhosted.org/packages/41/c4/3c310a19bc1f1e9ef50075582652673ef2bfc8cd62afef9585683821902f/pytest_xdist-3.6.1.tar.gz", hash = "sha256:ead156a4db231eec769737f57668ef58a2084a34b2e55c4a8fa20d861107300d", size = 84060 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/6d/82/1d96bf03ee4c0fdc3c0cbe61470070e659ca78dc0086fb88b66c185e2449/pytest_xdist-3.6.1-py3-none-any.whl", hash = "sha256:9ed4adfb68a016610848639bb7e02c9352d5d9f03d04809919e2dafc3be4cca7", size = 46108 },
]

[[package]]
name = "python-dateutil"
version = "2.9.0.post0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "six" },
]
sdist = { url = "https://files.pythonhosted.org/packages/66/c0/0c8b6ad9f17a802ee498c46e004a0eb49bc148f2fd230864601a86dcf6db/python-dateutil-2.9.0.post0.tar.gz", hash = "sha256:37dd54208da7e1cd875388217d5e00ebd4179249f90fb72437e91a35459a0ad3", size = 342432 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/ec/57/56b9bcc3c9c6a792fcbaf139543cee77261f3651ca9da0c93f5c1221264b/python_dateutil-2.9.0.post0-py2.py3-none-any.whl", hash = "sha256:a8b2bc7bffae282281c8140a97d3aa9c14da0b136dfe83f850eea9a5f7470427", size = 229892 },
]

[[package]]
name = "python-docx"
version = "1.1.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "lxml" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/35/e4/386c514c53684772885009c12b67a7edd526c15157778ac1b138bc75063e/python_docx-1.1.2.tar.gz", hash = "sha256:0cf1f22e95b9002addca7948e16f2cd7acdfd498047f1941ca5d293db7762efd", size = 5656581 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/3e/3d/330d9efbdb816d3f60bf2ad92f05e1708e4a1b9abe80461ac3444c83f749/python_docx-1.1.2-py3-none-any.whl", hash = "sha256:08c20d6058916fb19853fcf080f7f42b6270d89eac9fa5f8c15f691c0017fabe", size = 244315 },
]

[[package]]
name = "pytz"
version = "2025.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/5f/57/df1c9157c8d5a05117e455d66fd7cf6dbc46974f832b1058ed4856785d8a/pytz-2025.1.tar.gz", hash = "sha256:c2db42be2a2518b28e65f9207c4d05e6ff547d1efa4086469ef855e4ab70178e", size = 319617 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/eb/38/ac33370d784287baa1c3d538978b5e2ea064d4c1b93ffbd12826c190dd10/pytz-2025.1-py2.py3-none-any.whl", hash = "sha256:89dd22dca55b46eac6eda23b2d72721bf1bdfef212645d81513ef5d03038de57", size = 507930 },
]

[[package]]
name = "pywin32"
version = "309"
source = { registry = "https://pypi.org/simple" }
wheels = [
    { url = "https://files.pythonhosted.org/packages/8c/fa/aeba8c29ef8cb83402a6f2e6c436d7cc705d79d22db7923704bb6f6af825/pywin32-309-cp310-cp310-win32.whl", hash = "sha256:5b78d98550ca093a6fe7ab6d71733fbc886e2af9d4876d935e7f6e1cd6577ac9", size = 8843231 },
    { url = "https://files.pythonhosted.org/packages/63/53/a568b1501e52363edf02db1ae3d3880d5307c7451dd31fb4f380b968b3c1/pywin32-309-cp310-cp310-win_amd64.whl", hash = "sha256:728d08046f3d65b90d4c77f71b6fbb551699e2005cc31bbffd1febd6a08aa698", size = 9595021 },
    { url = "https://files.pythonhosted.org/packages/1e/ca/effaf45448a988f9a3ef5bb78519632761b9d941a3421c99d8a0a35ed8a2/pywin32-309-cp310-cp310-win_arm64.whl", hash = "sha256:c667bcc0a1e6acaca8984eb3e2b6e42696fc035015f99ff8bc6c3db4c09a466a", size = 8517212 },
    { url = "https://files.pythonhosted.org/packages/05/54/6409b1d98f2b8fed3bc2cc854859e48ae4a2dd956176664e38ee49c50a4c/pywin32-309-cp311-cp311-win32.whl", hash = "sha256:d5df6faa32b868baf9ade7c9b25337fa5eced28eb1ab89082c8dae9c48e4cd51", size = 8779225 },
    { url = "https://files.pythonhosted.org/packages/6a/f0/ae8ddb56771093dd2905baa852958fd65d42a8972aeefcf13578dfae69f4/pywin32-309-cp311-cp311-win_amd64.whl", hash = "sha256:e7ec2cef6df0926f8a89fd64959eba591a1eeaf0258082065f7bdbe2121228db", size = 9514129 },
    { url = "https://files.pythonhosted.org/packages/7a/4b/1f5e377a04448cf410e13040bc0e4c408bfa0a65705cabf96904178f18df/pywin32-309-cp311-cp311-win_arm64.whl", hash = "sha256:54ee296f6d11db1627216e9b4d4c3231856ed2d9f194c82f26c6cb5650163f4c", size = 8450450 },
    { url = "https://files.pythonhosted.org/packages/20/2c/b0240b14ff3dba7a8a7122dc9bbf7fbd21ed0e8b57c109633675b5d1761f/pywin32-309-cp312-cp312-win32.whl", hash = "sha256:de9acacced5fa82f557298b1fed5fef7bd49beee04190f68e1e4783fbdc19926", size = 8790648 },
    { url = "https://files.pythonhosted.org/packages/dd/11/c36884c732e2b3397deee808b5dac1abbb170ec37f94c6606fcb04d1e9d7/pywin32-309-cp312-cp312-win_amd64.whl", hash = "sha256:6ff9eebb77ffc3d59812c68db33c0a7817e1337e3537859499bd27586330fc9e", size = 9497399 },
    { url = "https://files.pythonhosted.org/packages/18/9f/79703972958f8ba3fd38bc9bf1165810bd75124982419b0cc433a2894d46/pywin32-309-cp312-cp312-win_arm64.whl", hash = "sha256:619f3e0a327b5418d833f44dc87859523635cf339f86071cc65a13c07be3110f", size = 8454122 },
    { url = "https://files.pythonhosted.org/packages/6c/c3/51aca6887cc5e410aa4cdc55662cf8438212440c67335c3f141b02eb8d52/pywin32-309-cp313-cp313-win32.whl", hash = "sha256:008bffd4afd6de8ca46c6486085414cc898263a21a63c7f860d54c9d02b45c8d", size = 8789700 },
    { url = "https://files.pythonhosted.org/packages/dd/66/330f265140fa814b4ed1bf16aea701f9d005f8f4ab57a54feb17f53afe7e/pywin32-309-cp313-cp313-win_amd64.whl", hash = "sha256:bd0724f58492db4cbfbeb1fcd606495205aa119370c0ddc4f70e5771a3ab768d", size = 9496714 },
    { url = "https://files.pythonhosted.org/packages/2c/84/9a51e6949a03f25cd329ece54dbf0846d57fadd2e79046c3b8d140aaa132/pywin32-309-cp313-cp313-win_arm64.whl", hash = "sha256:8fd9669cfd41863b688a1bc9b1d4d2d76fd4ba2128be50a70b0ea66b8d37953b", size = 8453052 },
    { url = "https://files.pythonhosted.org/packages/1d/e7/01fbb5f8c7be6403d71dc6793360d2af6f759b4a9a389c5bb9c30bf69d4f/pywin32-309-cp38-cp38-win32.whl", hash = "sha256:617b837dc5d9dfa7e156dbfa7d3906c009a2881849a80a9ae7519f3dd8c6cb86", size = 8849324 },
    { url = "https://files.pythonhosted.org/packages/78/39/eee3a49ac87881277f43506e9391ec27f00ff403a6e060a68b23e540d38a/pywin32-309-cp38-cp38-win_amd64.whl", hash = "sha256:0be3071f555480fbfd86a816a1a773880ee655bf186aa2931860dbb44e8424f8", size = 9601493 },
    { url = "https://files.pythonhosted.org/packages/80/a2/9c0c9bda69e5064b616d4484624e097c13b2a2dfffe601609a1cb8e68ba1/pywin32-309-cp39-cp39-win32.whl", hash = "sha256:72ae9ae3a7a6473223589a1621f9001fe802d59ed227fd6a8503c9af67c1d5f4", size = 8842771 },
    { url = "https://files.pythonhosted.org/packages/89/a5/390fbc106b5998296515d5a88730c6de472a6ed5f051db66d4cc46dd50fd/pywin32-309-cp39-cp39-win_amd64.whl", hash = "sha256:88bc06d6a9feac70783de64089324568ecbc65866e2ab318eab35da3811fd7ef", size = 9594766 },
]

[[package]]
name = "pyxlsb"
version = "1.0.10"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/3f/13/eebaeb7a40b062d1c6f7f91d09e73d30a69e33e4baa7cbe4b7658548b1cd/pyxlsb-1.0.10.tar.gz", hash = "sha256:8062d1ea8626d3f1980e8b1cfe91a4483747449242ecb61013bc2df85435f685", size = 22424 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7e/92/345823838ae367c59b63e03aef9c331f485370f9df6d049256a61a28f06d/pyxlsb-1.0.10-py2.py3-none-any.whl", hash = "sha256:87c122a9a622e35ca5e741d2e541201d28af00fb46bec492cfa9586890b120b4", size = 23849 },
]

[[package]]
name = "pyyaml"
version = "6.0.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/54/ed/79a089b6be93607fa5cdaedf301d7dfb23af5f25c398d5ead2525b063e17/pyyaml-6.0.2.tar.gz", hash = "sha256:d584d9ec91ad65861cc08d42e834324ef890a082e591037abe114850ff7bbc3e", size = 130631 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/9b/95/a3fac87cb7158e231b5a6012e438c647e1a87f09f8e0d123acec8ab8bf71/PyYAML-6.0.2-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:0a9a2848a5b7feac301353437eb7d5957887edbf81d56e903999a75a3d743086", size = 184199 },
    { url = "https://files.pythonhosted.org/packages/c7/7a/68bd47624dab8fd4afbfd3c48e3b79efe09098ae941de5b58abcbadff5cb/PyYAML-6.0.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:29717114e51c84ddfba879543fb232a6ed60086602313ca38cce623c1d62cfbf", size = 171758 },
    { url = "https://files.pythonhosted.org/packages/49/ee/14c54df452143b9ee9f0f29074d7ca5516a36edb0b4cc40c3f280131656f/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:8824b5a04a04a047e72eea5cec3bc266db09e35de6bdfe34c9436ac5ee27d237", size = 718463 },
    { url = "https://files.pythonhosted.org/packages/4d/61/de363a97476e766574650d742205be468921a7b532aa2499fcd886b62530/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:7c36280e6fb8385e520936c3cb3b8042851904eba0e58d277dca80a5cfed590b", size = 719280 },
    { url = "https://files.pythonhosted.org/packages/6b/4e/1523cb902fd98355e2e9ea5e5eb237cbc5f3ad5f3075fa65087aa0ecb669/PyYAML-6.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ec031d5d2feb36d1d1a24380e4db6d43695f3748343d99434e6f5f9156aaa2ed", size = 751239 },
    { url = "https://files.pythonhosted.org/packages/b7/33/5504b3a9a4464893c32f118a9cc045190a91637b119a9c881da1cf6b7a72/PyYAML-6.0.2-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:936d68689298c36b53b29f23c6dbb74de12b4ac12ca6cfe0e047bedceea56180", size = 695802 },
    { url = "https://files.pythonhosted.org/packages/5c/20/8347dcabd41ef3a3cdc4f7b7a2aff3d06598c8779faa189cdbf878b626a4/PyYAML-6.0.2-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:23502f431948090f597378482b4812b0caae32c22213aecf3b55325e049a6c68", size = 720527 },
    { url = "https://files.pythonhosted.org/packages/be/aa/5afe99233fb360d0ff37377145a949ae258aaab831bde4792b32650a4378/PyYAML-6.0.2-cp310-cp310-win32.whl", hash = "sha256:2e99c6826ffa974fe6e27cdb5ed0021786b03fc98e5ee3c5bfe1fd5015f42b99", size = 144052 },
    { url = "https://files.pythonhosted.org/packages/b5/84/0fa4b06f6d6c958d207620fc60005e241ecedceee58931bb20138e1e5776/PyYAML-6.0.2-cp310-cp310-win_amd64.whl", hash = "sha256:a4d3091415f010369ae4ed1fc6b79def9416358877534caf6a0fdd2146c87a3e", size = 161774 },
    { url = "https://files.pythonhosted.org/packages/f8/aa/7af4e81f7acba21a4c6be026da38fd2b872ca46226673c89a758ebdc4fd2/PyYAML-6.0.2-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:cc1c1159b3d456576af7a3e4d1ba7e6924cb39de8f67111c735f6fc832082774", size = 184612 },
    { url = "https://files.pythonhosted.org/packages/8b/62/b9faa998fd185f65c1371643678e4d58254add437edb764a08c5a98fb986/PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:1e2120ef853f59c7419231f3bf4e7021f1b936f6ebd222406c3b60212205d2ee", size = 172040 },
    { url = "https://files.pythonhosted.org/packages/ad/0c/c804f5f922a9a6563bab712d8dcc70251e8af811fce4524d57c2c0fd49a4/PyYAML-6.0.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5d225db5a45f21e78dd9358e58a98702a0302f2659a3c6cd320564b75b86f47c", size = 736829 },
    { url = "https://files.pythonhosted.org/packages/51/16/6af8d6a6b210c8e54f1406a6b9481febf9c64a3109c541567e35a49aa2e7/PyYAML-6.0.2-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5ac9328ec4831237bec75defaf839f7d4564be1e6b25ac710bd1a96321cc8317", size = 764167 },
    { url = "https://files.pythonhosted.org/packages/75/e4/2c27590dfc9992f73aabbeb9241ae20220bd9452df27483b6e56d3975cc5/PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3ad2a3decf9aaba3d29c8f537ac4b243e36bef957511b4766cb0057d32b0be85", size = 762952 },
    { url = "https://files.pythonhosted.org/packages/9b/97/ecc1abf4a823f5ac61941a9c00fe501b02ac3ab0e373c3857f7d4b83e2b6/PyYAML-6.0.2-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:ff3824dc5261f50c9b0dfb3be22b4567a6f938ccce4587b38952d85fd9e9afe4", size = 735301 },
    { url = "https://files.pythonhosted.org/packages/45/73/0f49dacd6e82c9430e46f4a027baa4ca205e8b0a9dce1397f44edc23559d/PyYAML-6.0.2-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:797b4f722ffa07cc8d62053e4cff1486fa6dc094105d13fea7b1de7d8bf71c9e", size = 756638 },
    { url = "https://files.pythonhosted.org/packages/22/5f/956f0f9fc65223a58fbc14459bf34b4cc48dec52e00535c79b8db361aabd/PyYAML-6.0.2-cp311-cp311-win32.whl", hash = "sha256:11d8f3dd2b9c1207dcaf2ee0bbbfd5991f571186ec9cc78427ba5bd32afae4b5", size = 143850 },
    { url = "https://files.pythonhosted.org/packages/ed/23/8da0bbe2ab9dcdd11f4f4557ccaf95c10b9811b13ecced089d43ce59c3c8/PyYAML-6.0.2-cp311-cp311-win_amd64.whl", hash = "sha256:e10ce637b18caea04431ce14fabcf5c64a1c61ec9c56b071a4b7ca131ca52d44", size = 161980 },
    { url = "https://files.pythonhosted.org/packages/86/0c/c581167fc46d6d6d7ddcfb8c843a4de25bdd27e4466938109ca68492292c/PyYAML-6.0.2-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:c70c95198c015b85feafc136515252a261a84561b7b1d51e3384e0655ddf25ab", size = 183873 },
    { url = "https://files.pythonhosted.org/packages/a8/0c/38374f5bb272c051e2a69281d71cba6fdb983413e6758b84482905e29a5d/PyYAML-6.0.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:ce826d6ef20b1bc864f0a68340c8b3287705cae2f8b4b1d932177dcc76721725", size = 173302 },
    { url = "https://files.pythonhosted.org/packages/c3/93/9916574aa8c00aa06bbac729972eb1071d002b8e158bd0e83a3b9a20a1f7/PyYAML-6.0.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1f71ea527786de97d1a0cc0eacd1defc0985dcf6b3f17bb77dcfc8c34bec4dc5", size = 739154 },
    { url = "https://files.pythonhosted.org/packages/95/0f/b8938f1cbd09739c6da569d172531567dbcc9789e0029aa070856f123984/PyYAML-6.0.2-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:9b22676e8097e9e22e36d6b7bda33190d0d400f345f23d4065d48f4ca7ae0425", size = 766223 },
    { url = "https://files.pythonhosted.org/packages/b9/2b/614b4752f2e127db5cc206abc23a8c19678e92b23c3db30fc86ab731d3bd/PyYAML-6.0.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:80bab7bfc629882493af4aa31a4cfa43a4c57c83813253626916b8c7ada83476", size = 767542 },
    { url = "https://files.pythonhosted.org/packages/d4/00/dd137d5bcc7efea1836d6264f049359861cf548469d18da90cd8216cf05f/PyYAML-6.0.2-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:0833f8694549e586547b576dcfaba4a6b55b9e96098b36cdc7ebefe667dfed48", size = 731164 },
    { url = "https://files.pythonhosted.org/packages/c9/1f/4f998c900485e5c0ef43838363ba4a9723ac0ad73a9dc42068b12aaba4e4/PyYAML-6.0.2-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:8b9c7197f7cb2738065c481a0461e50ad02f18c78cd75775628afb4d7137fb3b", size = 756611 },
    { url = "https://files.pythonhosted.org/packages/df/d1/f5a275fdb252768b7a11ec63585bc38d0e87c9e05668a139fea92b80634c/PyYAML-6.0.2-cp312-cp312-win32.whl", hash = "sha256:ef6107725bd54b262d6dedcc2af448a266975032bc85ef0172c5f059da6325b4", size = 140591 },
    { url = "https://files.pythonhosted.org/packages/0c/e8/4f648c598b17c3d06e8753d7d13d57542b30d56e6c2dedf9c331ae56312e/PyYAML-6.0.2-cp312-cp312-win_amd64.whl", hash = "sha256:7e7401d0de89a9a855c839bc697c079a4af81cf878373abd7dc625847d25cbd8", size = 156338 },
    { url = "https://files.pythonhosted.org/packages/ef/e3/3af305b830494fa85d95f6d95ef7fa73f2ee1cc8ef5b495c7c3269fb835f/PyYAML-6.0.2-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:efdca5630322a10774e8e98e1af481aad470dd62c3170801852d752aa7a783ba", size = 181309 },
    { url = "https://files.pythonhosted.org/packages/45/9f/3b1c20a0b7a3200524eb0076cc027a970d320bd3a6592873c85c92a08731/PyYAML-6.0.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:50187695423ffe49e2deacb8cd10510bc361faac997de9efef88badc3bb9e2d1", size = 171679 },
    { url = "https://files.pythonhosted.org/packages/7c/9a/337322f27005c33bcb656c655fa78325b730324c78620e8328ae28b64d0c/PyYAML-6.0.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0ffe8360bab4910ef1b9e87fb812d8bc0a308b0d0eef8c8f44e0254ab3b07133", size = 733428 },
    { url = "https://files.pythonhosted.org/packages/a3/69/864fbe19e6c18ea3cc196cbe5d392175b4cf3d5d0ac1403ec3f2d237ebb5/PyYAML-6.0.2-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:17e311b6c678207928d649faa7cb0d7b4c26a0ba73d41e99c4fff6b6c3276484", size = 763361 },
    { url = "https://files.pythonhosted.org/packages/04/24/b7721e4845c2f162d26f50521b825fb061bc0a5afcf9a386840f23ea19fa/PyYAML-6.0.2-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:70b189594dbe54f75ab3a1acec5f1e3faa7e8cf2f1e08d9b561cb41b845f69d5", size = 759523 },
    { url = "https://files.pythonhosted.org/packages/2b/b2/e3234f59ba06559c6ff63c4e10baea10e5e7df868092bf9ab40e5b9c56b6/PyYAML-6.0.2-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:41e4e3953a79407c794916fa277a82531dd93aad34e29c2a514c2c0c5fe971cc", size = 726660 },
    { url = "https://files.pythonhosted.org/packages/fe/0f/25911a9f080464c59fab9027482f822b86bf0608957a5fcc6eaac85aa515/PyYAML-6.0.2-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:68ccc6023a3400877818152ad9a1033e3db8625d899c72eacb5a668902e4d652", size = 751597 },
    { url = "https://files.pythonhosted.org/packages/14/0d/e2c3b43bbce3cf6bd97c840b46088a3031085179e596d4929729d8d68270/PyYAML-6.0.2-cp313-cp313-win32.whl", hash = "sha256:bc2fa7c6b47d6bc618dd7fb02ef6fdedb1090ec036abab80d4681424b84c1183", size = 140527 },
    { url = "https://files.pythonhosted.org/packages/fa/de/02b54f42487e3d3c6efb3f89428677074ca7bf43aae402517bc7cca949f3/PyYAML-6.0.2-cp313-cp313-win_amd64.whl", hash = "sha256:8388ee1976c416731879ac16da0aff3f63b286ffdd57cdeb95f3f2e085687563", size = 156446 },
    { url = "https://files.pythonhosted.org/packages/74/d9/323a59d506f12f498c2097488d80d16f4cf965cee1791eab58b56b19f47a/PyYAML-6.0.2-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:24471b829b3bf607e04e88d79542a9d48bb037c2267d7927a874e6c205ca7e9a", size = 183218 },
    { url = "https://files.pythonhosted.org/packages/74/cc/20c34d00f04d785f2028737e2e2a8254e1425102e730fee1d6396f832577/PyYAML-6.0.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d7fded462629cfa4b685c5416b949ebad6cec74af5e2d42905d41e257e0869f5", size = 728067 },
    { url = "https://files.pythonhosted.org/packages/20/52/551c69ca1501d21c0de51ddafa8c23a0191ef296ff098e98358f69080577/PyYAML-6.0.2-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:d84a1718ee396f54f3a086ea0a66d8e552b2ab2017ef8b420e92edbc841c352d", size = 757812 },
    { url = "https://files.pythonhosted.org/packages/fd/7f/2c3697bba5d4aa5cc2afe81826d73dfae5f049458e44732c7a0938baa673/PyYAML-6.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9056c1ecd25795207ad294bcf39f2db3d845767be0ea6e6a34d856f006006083", size = 746531 },
    { url = "https://files.pythonhosted.org/packages/8c/ab/6226d3df99900e580091bb44258fde77a8433511a86883bd4681ea19a858/PyYAML-6.0.2-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:82d09873e40955485746739bcb8b4586983670466c23382c19cffecbf1fd8706", size = 800820 },
    { url = "https://files.pythonhosted.org/packages/a0/99/a9eb0f3e710c06c5d922026f6736e920d431812ace24aae38228d0d64b04/PyYAML-6.0.2-cp38-cp38-win32.whl", hash = "sha256:43fa96a3ca0d6b1812e01ced1044a003533c47f6ee8aca31724f78e93ccc089a", size = 145514 },
    { url = "https://files.pythonhosted.org/packages/75/8a/ee831ad5fafa4431099aa4e078d4c8efd43cd5e48fbc774641d233b683a9/PyYAML-6.0.2-cp38-cp38-win_amd64.whl", hash = "sha256:01179a4a8559ab5de078078f37e5c1a30d76bb88519906844fd7bdea1b7729ff", size = 162702 },
    { url = "https://files.pythonhosted.org/packages/65/d8/b7a1db13636d7fb7d4ff431593c510c8b8fca920ade06ca8ef20015493c5/PyYAML-6.0.2-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:688ba32a1cffef67fd2e9398a2efebaea461578b0923624778664cc1c914db5d", size = 184777 },
    { url = "https://files.pythonhosted.org/packages/0a/02/6ec546cd45143fdf9840b2c6be8d875116a64076218b61d68e12548e5839/PyYAML-6.0.2-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:a8786accb172bd8afb8be14490a16625cbc387036876ab6ba70912730faf8e1f", size = 172318 },
    { url = "https://files.pythonhosted.org/packages/0e/9a/8cc68be846c972bda34f6c2a93abb644fb2476f4dcc924d52175786932c9/PyYAML-6.0.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d8e03406cac8513435335dbab54c0d385e4a49e4945d2909a581c83647ca0290", size = 720891 },
    { url = "https://files.pythonhosted.org/packages/e9/6c/6e1b7f40181bc4805e2e07f4abc10a88ce4648e7e95ff1abe4ae4014a9b2/PyYAML-6.0.2-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f753120cb8181e736c57ef7636e83f31b9c0d1722c516f7e86cf15b7aa57ff12", size = 722614 },
    { url = "https://files.pythonhosted.org/packages/3d/32/e7bd8535d22ea2874cef6a81021ba019474ace0d13a4819c2a4bce79bd6a/PyYAML-6.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3b1fdb9dc17f5a7677423d508ab4f243a726dea51fa5e70992e59a7411c89d19", size = 737360 },
    { url = "https://files.pythonhosted.org/packages/d7/12/7322c1e30b9be969670b672573d45479edef72c9a0deac3bb2868f5d7469/PyYAML-6.0.2-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:0b69e4ce7a131fe56b7e4d770c67429700908fc0752af059838b1cfb41960e4e", size = 699006 },
    { url = "https://files.pythonhosted.org/packages/82/72/04fcad41ca56491995076630c3ec1e834be241664c0c09a64c9a2589b507/PyYAML-6.0.2-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:a9f8c2e67970f13b16084e04f134610fd1d374bf477b17ec1599185cf611d725", size = 723577 },
    { url = "https://files.pythonhosted.org/packages/ed/5e/46168b1f2757f1fcd442bc3029cd8767d88a98c9c05770d8b420948743bb/PyYAML-6.0.2-cp39-cp39-win32.whl", hash = "sha256:6395c297d42274772abc367baaa79683958044e5d3835486c16da75d2a694631", size = 144593 },
    { url = "https://files.pythonhosted.org/packages/19/87/5124b1c1f2412bb95c59ec481eaf936cd32f0fe2a7b16b97b81c4c017a6a/PyYAML-6.0.2-cp39-cp39-win_amd64.whl", hash = "sha256:39693e1f8320ae4f43943590b49779ffb98acb81f788220ea932a6b6c51004d8", size = 162312 },
]

[[package]]
name = "regex"
version = "2024.11.6"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/8e/5f/bd69653fbfb76cf8604468d3b4ec4c403197144c7bfe0e6a5fc9e02a07cb/regex-2024.11.6.tar.gz", hash = "sha256:7ab159b063c52a0333c884e4679f8d7a85112ee3078fe3d9004b2dd875585519", size = 399494 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/95/3c/4651f6b130c6842a8f3df82461a8950f923925db8b6961063e82744bddcc/regex-2024.11.6-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:ff590880083d60acc0433f9c3f713c51f7ac6ebb9adf889c79a261ecf541aa91", size = 482674 },
    { url = "https://files.pythonhosted.org/packages/15/51/9f35d12da8434b489c7b7bffc205c474a0a9432a889457026e9bc06a297a/regex-2024.11.6-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:658f90550f38270639e83ce492f27d2c8d2cd63805c65a13a14d36ca126753f0", size = 287684 },
    { url = "https://files.pythonhosted.org/packages/bd/18/b731f5510d1b8fb63c6b6d3484bfa9a59b84cc578ac8b5172970e05ae07c/regex-2024.11.6-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:164d8b7b3b4bcb2068b97428060b2a53be050085ef94eca7f240e7947f1b080e", size = 284589 },
    { url = "https://files.pythonhosted.org/packages/78/a2/6dd36e16341ab95e4c6073426561b9bfdeb1a9c9b63ab1b579c2e96cb105/regex-2024.11.6-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:d3660c82f209655a06b587d55e723f0b813d3a7db2e32e5e7dc64ac2a9e86fde", size = 782511 },
    { url = "https://files.pythonhosted.org/packages/1b/2b/323e72d5d2fd8de0d9baa443e1ed70363ed7e7b2fb526f5950c5cb99c364/regex-2024.11.6-cp310-cp310-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:d22326fcdef5e08c154280b71163ced384b428343ae16a5ab2b3354aed12436e", size = 821149 },
    { url = "https://files.pythonhosted.org/packages/90/30/63373b9ea468fbef8a907fd273e5c329b8c9535fee36fc8dba5fecac475d/regex-2024.11.6-cp310-cp310-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:f1ac758ef6aebfc8943560194e9fd0fa18bcb34d89fd8bd2af18183afd8da3a2", size = 809707 },
    { url = "https://files.pythonhosted.org/packages/f2/98/26d3830875b53071f1f0ae6d547f1d98e964dd29ad35cbf94439120bb67a/regex-2024.11.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:997d6a487ff00807ba810e0f8332c18b4eb8d29463cfb7c820dc4b6e7562d0cf", size = 781702 },
    { url = "https://files.pythonhosted.org/packages/87/55/eb2a068334274db86208ab9d5599ffa63631b9f0f67ed70ea7c82a69bbc8/regex-2024.11.6-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:02a02d2bb04fec86ad61f3ea7f49c015a0681bf76abb9857f945d26159d2968c", size = 771976 },
    { url = "https://files.pythonhosted.org/packages/74/c0/be707bcfe98254d8f9d2cff55d216e946f4ea48ad2fd8cf1428f8c5332ba/regex-2024.11.6-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:f02f93b92358ee3f78660e43b4b0091229260c5d5c408d17d60bf26b6c900e86", size = 697397 },
    { url = "https://files.pythonhosted.org/packages/49/dc/bb45572ceb49e0f6509f7596e4ba7031f6819ecb26bc7610979af5a77f45/regex-2024.11.6-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:06eb1be98df10e81ebaded73fcd51989dcf534e3c753466e4b60c4697a003b67", size = 768726 },
    { url = "https://files.pythonhosted.org/packages/5a/db/f43fd75dc4c0c2d96d0881967897926942e935d700863666f3c844a72ce6/regex-2024.11.6-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:040df6fe1a5504eb0f04f048e6d09cd7c7110fef851d7c567a6b6e09942feb7d", size = 775098 },
    { url = "https://files.pythonhosted.org/packages/99/d7/f94154db29ab5a89d69ff893159b19ada89e76b915c1293e98603d39838c/regex-2024.11.6-cp310-cp310-musllinux_1_2_ppc64le.whl", hash = "sha256:fdabbfc59f2c6edba2a6622c647b716e34e8e3867e0ab975412c5c2f79b82da2", size = 839325 },
    { url = "https://files.pythonhosted.org/packages/f7/17/3cbfab1f23356fbbf07708220ab438a7efa1e0f34195bf857433f79f1788/regex-2024.11.6-cp310-cp310-musllinux_1_2_s390x.whl", hash = "sha256:8447d2d39b5abe381419319f942de20b7ecd60ce86f16a23b0698f22e1b70008", size = 843277 },
    { url = "https://files.pythonhosted.org/packages/7e/f2/48b393b51900456155de3ad001900f94298965e1cad1c772b87f9cfea011/regex-2024.11.6-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:da8f5fc57d1933de22a9e23eec290a0d8a5927a5370d24bda9a6abe50683fe62", size = 773197 },
    { url = "https://files.pythonhosted.org/packages/45/3f/ef9589aba93e084cd3f8471fded352826dcae8489b650d0b9b27bc5bba8a/regex-2024.11.6-cp310-cp310-win32.whl", hash = "sha256:b489578720afb782f6ccf2840920f3a32e31ba28a4b162e13900c3e6bd3f930e", size = 261714 },
    { url = "https://files.pythonhosted.org/packages/42/7e/5f1b92c8468290c465fd50c5318da64319133231415a8aa6ea5ab995a815/regex-2024.11.6-cp310-cp310-win_amd64.whl", hash = "sha256:5071b2093e793357c9d8b2929dfc13ac5f0a6c650559503bb81189d0a3814519", size = 274042 },
    { url = "https://files.pythonhosted.org/packages/58/58/7e4d9493a66c88a7da6d205768119f51af0f684fe7be7bac8328e217a52c/regex-2024.11.6-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:5478c6962ad548b54a591778e93cd7c456a7a29f8eca9c49e4f9a806dcc5d638", size = 482669 },
    { url = "https://files.pythonhosted.org/packages/34/4c/8f8e631fcdc2ff978609eaeef1d6994bf2f028b59d9ac67640ed051f1218/regex-2024.11.6-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:2c89a8cc122b25ce6945f0423dc1352cb9593c68abd19223eebbd4e56612c5b7", size = 287684 },
    { url = "https://files.pythonhosted.org/packages/c5/1b/f0e4d13e6adf866ce9b069e191f303a30ab1277e037037a365c3aad5cc9c/regex-2024.11.6-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:94d87b689cdd831934fa3ce16cc15cd65748e6d689f5d2b8f4f4df2065c9fa20", size = 284589 },
    { url = "https://files.pythonhosted.org/packages/25/4d/ab21047f446693887f25510887e6820b93f791992994f6498b0318904d4a/regex-2024.11.6-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1062b39a0a2b75a9c694f7a08e7183a80c63c0d62b301418ffd9c35f55aaa114", size = 792121 },
    { url = "https://files.pythonhosted.org/packages/45/ee/c867e15cd894985cb32b731d89576c41a4642a57850c162490ea34b78c3b/regex-2024.11.6-cp311-cp311-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:167ed4852351d8a750da48712c3930b031f6efdaa0f22fa1933716bfcd6bf4a3", size = 831275 },
    { url = "https://files.pythonhosted.org/packages/b3/12/b0f480726cf1c60f6536fa5e1c95275a77624f3ac8fdccf79e6727499e28/regex-2024.11.6-cp311-cp311-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:2d548dafee61f06ebdb584080621f3e0c23fff312f0de1afc776e2a2ba99a74f", size = 818257 },
    { url = "https://files.pythonhosted.org/packages/bf/ce/0d0e61429f603bac433910d99ef1a02ce45a8967ffbe3cbee48599e62d88/regex-2024.11.6-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:f2a19f302cd1ce5dd01a9099aaa19cae6173306d1302a43b627f62e21cf18ac0", size = 792727 },
    { url = "https://files.pythonhosted.org/packages/e4/c1/243c83c53d4a419c1556f43777ccb552bccdf79d08fda3980e4e77dd9137/regex-2024.11.6-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:bec9931dfb61ddd8ef2ebc05646293812cb6b16b60cf7c9511a832b6f1854b55", size = 780667 },
    { url = "https://files.pythonhosted.org/packages/c5/f4/75eb0dd4ce4b37f04928987f1d22547ddaf6c4bae697623c1b05da67a8aa/regex-2024.11.6-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:9714398225f299aa85267fd222f7142fcb5c769e73d7733344efc46f2ef5cf89", size = 776963 },
    { url = "https://files.pythonhosted.org/packages/16/5d/95c568574e630e141a69ff8a254c2f188b4398e813c40d49228c9bbd9875/regex-2024.11.6-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:202eb32e89f60fc147a41e55cb086db2a3f8cb82f9a9a88440dcfc5d37faae8d", size = 784700 },
    { url = "https://files.pythonhosted.org/packages/8e/b5/f8495c7917f15cc6fee1e7f395e324ec3e00ab3c665a7dc9d27562fd5290/regex-2024.11.6-cp311-cp311-musllinux_1_2_ppc64le.whl", hash = "sha256:4181b814e56078e9b00427ca358ec44333765f5ca1b45597ec7446d3a1ef6e34", size = 848592 },
    { url = "https://files.pythonhosted.org/packages/1c/80/6dd7118e8cb212c3c60b191b932dc57db93fb2e36fb9e0e92f72a5909af9/regex-2024.11.6-cp311-cp311-musllinux_1_2_s390x.whl", hash = "sha256:068376da5a7e4da51968ce4c122a7cd31afaaec4fccc7856c92f63876e57b51d", size = 852929 },
    { url = "https://files.pythonhosted.org/packages/11/9b/5a05d2040297d2d254baf95eeeb6df83554e5e1df03bc1a6687fc4ba1f66/regex-2024.11.6-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:ac10f2c4184420d881a3475fb2c6f4d95d53a8d50209a2500723d831036f7c45", size = 781213 },
    { url = "https://files.pythonhosted.org/packages/26/b7/b14e2440156ab39e0177506c08c18accaf2b8932e39fb092074de733d868/regex-2024.11.6-cp311-cp311-win32.whl", hash = "sha256:c36f9b6f5f8649bb251a5f3f66564438977b7ef8386a52460ae77e6070d309d9", size = 261734 },
    { url = "https://files.pythonhosted.org/packages/80/32/763a6cc01d21fb3819227a1cc3f60fd251c13c37c27a73b8ff4315433a8e/regex-2024.11.6-cp311-cp311-win_amd64.whl", hash = "sha256:02e28184be537f0e75c1f9b2f8847dc51e08e6e171c6bde130b2687e0c33cf60", size = 274052 },
    { url = "https://files.pythonhosted.org/packages/ba/30/9a87ce8336b172cc232a0db89a3af97929d06c11ceaa19d97d84fa90a8f8/regex-2024.11.6-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:52fb28f528778f184f870b7cf8f225f5eef0a8f6e3778529bdd40c7b3920796a", size = 483781 },
    { url = "https://files.pythonhosted.org/packages/01/e8/00008ad4ff4be8b1844786ba6636035f7ef926db5686e4c0f98093612add/regex-2024.11.6-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:fdd6028445d2460f33136c55eeb1f601ab06d74cb3347132e1c24250187500d9", size = 288455 },
    { url = "https://files.pythonhosted.org/packages/60/85/cebcc0aff603ea0a201667b203f13ba75d9fc8668fab917ac5b2de3967bc/regex-2024.11.6-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:805e6b60c54bf766b251e94526ebad60b7de0c70f70a4e6210ee2891acb70bf2", size = 284759 },
    { url = "https://files.pythonhosted.org/packages/94/2b/701a4b0585cb05472a4da28ee28fdfe155f3638f5e1ec92306d924e5faf0/regex-2024.11.6-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b85c2530be953a890eaffde05485238f07029600e8f098cdf1848d414a8b45e4", size = 794976 },
    { url = "https://files.pythonhosted.org/packages/4b/bf/fa87e563bf5fee75db8915f7352e1887b1249126a1be4813837f5dbec965/regex-2024.11.6-cp312-cp312-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:bb26437975da7dc36b7efad18aa9dd4ea569d2357ae6b783bf1118dabd9ea577", size = 833077 },
    { url = "https://files.pythonhosted.org/packages/a1/56/7295e6bad94b047f4d0834e4779491b81216583c00c288252ef625c01d23/regex-2024.11.6-cp312-cp312-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:abfa5080c374a76a251ba60683242bc17eeb2c9818d0d30117b4486be10c59d3", size = 823160 },
    { url = "https://files.pythonhosted.org/packages/fb/13/e3b075031a738c9598c51cfbc4c7879e26729c53aa9cca59211c44235314/regex-2024.11.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:70b7fa6606c2881c1db9479b0eaa11ed5dfa11c8d60a474ff0e095099f39d98e", size = 796896 },
    { url = "https://files.pythonhosted.org/packages/24/56/0b3f1b66d592be6efec23a795b37732682520b47c53da5a32c33ed7d84e3/regex-2024.11.6-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:0c32f75920cf99fe6b6c539c399a4a128452eaf1af27f39bce8909c9a3fd8cbe", size = 783997 },
    { url = "https://files.pythonhosted.org/packages/f9/a1/eb378dada8b91c0e4c5f08ffb56f25fcae47bf52ad18f9b2f33b83e6d498/regex-2024.11.6-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:982e6d21414e78e1f51cf595d7f321dcd14de1f2881c5dc6a6e23bbbbd68435e", size = 781725 },
    { url = "https://files.pythonhosted.org/packages/83/f2/033e7dec0cfd6dda93390089864732a3409246ffe8b042e9554afa9bff4e/regex-2024.11.6-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:a7c2155f790e2fb448faed6dd241386719802296ec588a8b9051c1f5c481bc29", size = 789481 },
    { url = "https://files.pythonhosted.org/packages/83/23/15d4552ea28990a74e7696780c438aadd73a20318c47e527b47a4a5a596d/regex-2024.11.6-cp312-cp312-musllinux_1_2_ppc64le.whl", hash = "sha256:149f5008d286636e48cd0b1dd65018548944e495b0265b45e1bffecce1ef7f39", size = 852896 },
    { url = "https://files.pythonhosted.org/packages/e3/39/ed4416bc90deedbfdada2568b2cb0bc1fdb98efe11f5378d9892b2a88f8f/regex-2024.11.6-cp312-cp312-musllinux_1_2_s390x.whl", hash = "sha256:e5364a4502efca094731680e80009632ad6624084aff9a23ce8c8c6820de3e51", size = 860138 },
    { url = "https://files.pythonhosted.org/packages/93/2d/dd56bb76bd8e95bbce684326302f287455b56242a4f9c61f1bc76e28360e/regex-2024.11.6-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:0a86e7eeca091c09e021db8eb72d54751e527fa47b8d5787caf96d9831bd02ad", size = 787692 },
    { url = "https://files.pythonhosted.org/packages/0b/55/31877a249ab7a5156758246b9c59539abbeba22461b7d8adc9e8475ff73e/regex-2024.11.6-cp312-cp312-win32.whl", hash = "sha256:32f9a4c643baad4efa81d549c2aadefaeba12249b2adc5af541759237eee1c54", size = 262135 },
    { url = "https://files.pythonhosted.org/packages/38/ec/ad2d7de49a600cdb8dd78434a1aeffe28b9d6fc42eb36afab4a27ad23384/regex-2024.11.6-cp312-cp312-win_amd64.whl", hash = "sha256:a93c194e2df18f7d264092dc8539b8ffb86b45b899ab976aa15d48214138e81b", size = 273567 },
    { url = "https://files.pythonhosted.org/packages/90/73/bcb0e36614601016552fa9344544a3a2ae1809dc1401b100eab02e772e1f/regex-2024.11.6-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:a6ba92c0bcdf96cbf43a12c717eae4bc98325ca3730f6b130ffa2e3c3c723d84", size = 483525 },
    { url = "https://files.pythonhosted.org/packages/0f/3f/f1a082a46b31e25291d830b369b6b0c5576a6f7fb89d3053a354c24b8a83/regex-2024.11.6-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:525eab0b789891ac3be914d36893bdf972d483fe66551f79d3e27146191a37d4", size = 288324 },
    { url = "https://files.pythonhosted.org/packages/09/c9/4e68181a4a652fb3ef5099e077faf4fd2a694ea6e0f806a7737aff9e758a/regex-2024.11.6-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:086a27a0b4ca227941700e0b31425e7a28ef1ae8e5e05a33826e17e47fbfdba0", size = 284617 },
    { url = "https://files.pythonhosted.org/packages/fc/fd/37868b75eaf63843165f1d2122ca6cb94bfc0271e4428cf58c0616786dce/regex-2024.11.6-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bde01f35767c4a7899b7eb6e823b125a64de314a8ee9791367c9a34d56af18d0", size = 795023 },
    { url = "https://files.pythonhosted.org/packages/c4/7c/d4cd9c528502a3dedb5c13c146e7a7a539a3853dc20209c8e75d9ba9d1b2/regex-2024.11.6-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:b583904576650166b3d920d2bcce13971f6f9e9a396c673187f49811b2769dc7", size = 833072 },
    { url = "https://files.pythonhosted.org/packages/4f/db/46f563a08f969159c5a0f0e722260568425363bea43bb7ae370becb66a67/regex-2024.11.6-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:1c4de13f06a0d54fa0d5ab1b7138bfa0d883220965a29616e3ea61b35d5f5fc7", size = 823130 },
    { url = "https://files.pythonhosted.org/packages/db/60/1eeca2074f5b87df394fccaa432ae3fc06c9c9bfa97c5051aed70e6e00c2/regex-2024.11.6-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3cde6e9f2580eb1665965ce9bf17ff4952f34f5b126beb509fee8f4e994f143c", size = 796857 },
    { url = "https://files.pythonhosted.org/packages/10/db/ac718a08fcee981554d2f7bb8402f1faa7e868c1345c16ab1ebec54b0d7b/regex-2024.11.6-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:0d7f453dca13f40a02b79636a339c5b62b670141e63efd511d3f8f73fba162b3", size = 784006 },
    { url = "https://files.pythonhosted.org/packages/c2/41/7da3fe70216cea93144bf12da2b87367590bcf07db97604edeea55dac9ad/regex-2024.11.6-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:59dfe1ed21aea057a65c6b586afd2a945de04fc7db3de0a6e3ed5397ad491b07", size = 781650 },
    { url = "https://files.pythonhosted.org/packages/a7/d5/880921ee4eec393a4752e6ab9f0fe28009435417c3102fc413f3fe81c4e5/regex-2024.11.6-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:b97c1e0bd37c5cd7902e65f410779d39eeda155800b65fc4d04cc432efa9bc6e", size = 789545 },
    { url = "https://files.pythonhosted.org/packages/dc/96/53770115e507081122beca8899ab7f5ae28ae790bfcc82b5e38976df6a77/regex-2024.11.6-cp313-cp313-musllinux_1_2_ppc64le.whl", hash = "sha256:f9d1e379028e0fc2ae3654bac3cbbef81bf3fd571272a42d56c24007979bafb6", size = 853045 },
    { url = "https://files.pythonhosted.org/packages/31/d3/1372add5251cc2d44b451bd94f43b2ec78e15a6e82bff6a290ef9fd8f00a/regex-2024.11.6-cp313-cp313-musllinux_1_2_s390x.whl", hash = "sha256:13291b39131e2d002a7940fb176e120bec5145f3aeb7621be6534e46251912c4", size = 860182 },
    { url = "https://files.pythonhosted.org/packages/ed/e3/c446a64984ea9f69982ba1a69d4658d5014bc7a0ea468a07e1a1265db6e2/regex-2024.11.6-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:4f51f88c126370dcec4908576c5a627220da6c09d0bff31cfa89f2523843316d", size = 787733 },
    { url = "https://files.pythonhosted.org/packages/2b/f1/e40c8373e3480e4f29f2692bd21b3e05f296d3afebc7e5dcf21b9756ca1c/regex-2024.11.6-cp313-cp313-win32.whl", hash = "sha256:63b13cfd72e9601125027202cad74995ab26921d8cd935c25f09c630436348ff", size = 262122 },
    { url = "https://files.pythonhosted.org/packages/45/94/bc295babb3062a731f52621cdc992d123111282e291abaf23faa413443ea/regex-2024.11.6-cp313-cp313-win_amd64.whl", hash = "sha256:2b3361af3198667e99927da8b84c1b010752fa4b1115ee30beaa332cabc3ef1a", size = 273545 },
    { url = "https://files.pythonhosted.org/packages/44/0f/207b37e6e08d548fac0aa00bf0b7464126315d58ab5161216b8cb3abb2aa/regex-2024.11.6-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:3a51ccc315653ba012774efca4f23d1d2a8a8f278a6072e29c7147eee7da446b", size = 482777 },
    { url = "https://files.pythonhosted.org/packages/5a/5a/586bafa294c5d2451265d3685815606c61e620f469cac3b946fff0a4aa48/regex-2024.11.6-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:ad182d02e40de7459b73155deb8996bbd8e96852267879396fb274e8700190e3", size = 287751 },
    { url = "https://files.pythonhosted.org/packages/08/92/9df786fad8a4e0766bfc9a2e334c5f0757356070c9639b2ec776b8cdef3d/regex-2024.11.6-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:ba9b72e5643641b7d41fa1f6d5abda2c9a263ae835b917348fc3c928182ad467", size = 284552 },
    { url = "https://files.pythonhosted.org/packages/0a/27/0b3cf7d9fbe43301aa3473d54406019a7380abe4e3c9ae250bac13c4fdb3/regex-2024.11.6-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:40291b1b89ca6ad8d3f2b82782cc33807f1406cf68c8d440861da6304d8ffbbd", size = 783587 },
    { url = "https://files.pythonhosted.org/packages/89/38/499b32cbb61163af60a5c5ff26aacea7836fe7e3d821e76af216e996088c/regex-2024.11.6-cp38-cp38-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:cdf58d0e516ee426a48f7b2c03a332a4114420716d55769ff7108c37a09951bf", size = 822904 },
    { url = "https://files.pythonhosted.org/packages/3f/a4/e3b11c643e5ae1059a08aeef971973f0c803d2a9ae2e7a86f97c68146a6c/regex-2024.11.6-cp38-cp38-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:a36fdf2af13c2b14738f6e973aba563623cb77d753bbbd8d414d18bfaa3105dd", size = 809900 },
    { url = "https://files.pythonhosted.org/packages/5a/c8/dc7153ceb5bcc344f5c4f0291ea45925a5f00009afa3849e91561ac2e847/regex-2024.11.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d1cee317bfc014c2419a76bcc87f071405e3966da434e03e13beb45f8aced1a6", size = 785105 },
    { url = "https://files.pythonhosted.org/packages/2a/29/841489ea52013062b22625fbaf49b0916aeb62bae2e56425ac30f9dead46/regex-2024.11.6-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:50153825ee016b91549962f970d6a4442fa106832e14c918acd1c8e479916c4f", size = 773033 },
    { url = "https://files.pythonhosted.org/packages/3e/4e/4a0da5e87f7c2dc73a8505785d5af2b1a19c66f4645b93caa50b7eb08242/regex-2024.11.6-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:ea1bfda2f7162605f6e8178223576856b3d791109f15ea99a9f95c16a7636fb5", size = 702374 },
    { url = "https://files.pythonhosted.org/packages/94/6e/444e66346600d11e8a0f4bb31611973cffa772d5033ba1cf1f15de8a0d52/regex-2024.11.6-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:df951c5f4a1b1910f1a99ff42c473ff60f8225baa1cdd3539fe2819d9543e9df", size = 769990 },
    { url = "https://files.pythonhosted.org/packages/da/28/95c3ed6cd51b27f54e59940400e2a3ddd3f8bbbc3aaf947e57a67104ecbd/regex-2024.11.6-cp38-cp38-musllinux_1_2_i686.whl", hash = "sha256:072623554418a9911446278f16ecb398fb3b540147a7828c06e2011fa531e773", size = 775345 },
    { url = "https://files.pythonhosted.org/packages/07/5d/0cd19cf44d96a7aa31526611c24235d21d27c23b65201cb2c5cac508dd42/regex-2024.11.6-cp38-cp38-musllinux_1_2_ppc64le.whl", hash = "sha256:f654882311409afb1d780b940234208a252322c24a93b442ca714d119e68086c", size = 840379 },
    { url = "https://files.pythonhosted.org/packages/2a/13/ec3f8d85b789ee1c6ffbdfd4092fd901416716317ee17bf51aa2890bac96/regex-2024.11.6-cp38-cp38-musllinux_1_2_s390x.whl", hash = "sha256:89d75e7293d2b3e674db7d4d9b1bee7f8f3d1609428e293771d1a962617150cc", size = 845842 },
    { url = "https://files.pythonhosted.org/packages/50/cb/7170247e65afea2bf9204bcb2682f292b0a3a57d112478da199b84d59792/regex-2024.11.6-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:f65557897fc977a44ab205ea871b690adaef6b9da6afda4790a2484b04293a5f", size = 775026 },
    { url = "https://files.pythonhosted.org/packages/cc/06/c817c9201f09b7d9dd033039ba90d8197c91e9fe2984141f2d1de270c159/regex-2024.11.6-cp38-cp38-win32.whl", hash = "sha256:6f44ec28b1f858c98d3036ad5d7d0bfc568bdd7a74f9c24e25f41ef1ebfd81a4", size = 261738 },
    { url = "https://files.pythonhosted.org/packages/cf/69/c39e16320400842eb4358c982ef5fc680800866f35ebfd4dd38a22967ce0/regex-2024.11.6-cp38-cp38-win_amd64.whl", hash = "sha256:bb8f74f2f10dbf13a0be8de623ba4f9491faf58c24064f32b65679b021ed0001", size = 274094 },
    { url = "https://files.pythonhosted.org/packages/89/23/c4a86df398e57e26f93b13ae63acce58771e04bdde86092502496fa57f9c/regex-2024.11.6-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:5704e174f8ccab2026bd2f1ab6c510345ae8eac818b613d7d73e785f1310f839", size = 482682 },
    { url = "https://files.pythonhosted.org/packages/3c/8b/45c24ab7a51a1658441b961b86209c43e6bb9d39caf1e63f46ce6ea03bc7/regex-2024.11.6-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:220902c3c5cc6af55d4fe19ead504de80eb91f786dc102fbd74894b1551f095e", size = 287679 },
    { url = "https://files.pythonhosted.org/packages/7a/d1/598de10b17fdafc452d11f7dada11c3be4e379a8671393e4e3da3c4070df/regex-2024.11.6-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:5e7e351589da0850c125f1600a4c4ba3c722efefe16b297de54300f08d734fbf", size = 284578 },
    { url = "https://files.pythonhosted.org/packages/49/70/c7eaa219efa67a215846766fde18d92d54cb590b6a04ffe43cef30057622/regex-2024.11.6-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5056b185ca113c88e18223183aa1a50e66507769c9640a6ff75859619d73957b", size = 782012 },
    { url = "https://files.pythonhosted.org/packages/89/e5/ef52c7eb117dd20ff1697968219971d052138965a4d3d9b95e92e549f505/regex-2024.11.6-cp39-cp39-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:2e34b51b650b23ed3354b5a07aab37034d9f923db2a40519139af34f485f77d0", size = 820580 },
    { url = "https://files.pythonhosted.org/packages/5f/3f/9f5da81aff1d4167ac52711acf789df13e789fe6ac9545552e49138e3282/regex-2024.11.6-cp39-cp39-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:5670bce7b200273eee1840ef307bfa07cda90b38ae56e9a6ebcc9f50da9c469b", size = 809110 },
    { url = "https://files.pythonhosted.org/packages/86/44/2101cc0890c3621b90365c9ee8d7291a597c0722ad66eccd6ffa7f1bcc09/regex-2024.11.6-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:08986dce1339bc932923e7d1232ce9881499a0e02925f7402fb7c982515419ef", size = 780919 },
    { url = "https://files.pythonhosted.org/packages/ce/2e/3e0668d8d1c7c3c0d397bf54d92fc182575b3a26939aed5000d3cc78760f/regex-2024.11.6-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:93c0b12d3d3bc25af4ebbf38f9ee780a487e8bf6954c115b9f015822d3bb8e48", size = 771515 },
    { url = "https://files.pythonhosted.org/packages/a6/49/1bc4584254355e3dba930a3a2fd7ad26ccba3ebbab7d9100db0aff2eedb0/regex-2024.11.6-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl", hash = "sha256:764e71f22ab3b305e7f4c21f1a97e1526a25ebdd22513e251cf376760213da13", size = 696957 },
    { url = "https://files.pythonhosted.org/packages/c8/dd/42879c1fc8a37a887cd08e358af3d3ba9e23038cd77c7fe044a86d9450ba/regex-2024.11.6-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:f056bf21105c2515c32372bbc057f43eb02aae2fda61052e2f7622c801f0b4e2", size = 768088 },
    { url = "https://files.pythonhosted.org/packages/89/96/c05a0fe173cd2acd29d5e13c1adad8b706bcaa71b169e1ee57dcf2e74584/regex-2024.11.6-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:69ab78f848845569401469da20df3e081e6b5a11cb086de3eed1d48f5ed57c95", size = 774752 },
    { url = "https://files.pythonhosted.org/packages/b5/f3/a757748066255f97f14506483436c5f6aded7af9e37bca04ec30c90ca683/regex-2024.11.6-cp39-cp39-musllinux_1_2_ppc64le.whl", hash = "sha256:86fddba590aad9208e2fa8b43b4c098bb0ec74f15718bb6a704e3c63e2cef3e9", size = 838862 },
    { url = "https://files.pythonhosted.org/packages/5c/93/c6d2092fd479dcaeea40fc8fa673822829181ded77d294a7f950f1dda6e2/regex-2024.11.6-cp39-cp39-musllinux_1_2_s390x.whl", hash = "sha256:684d7a212682996d21ca12ef3c17353c021fe9de6049e19ac8481ec35574a70f", size = 842622 },
    { url = "https://files.pythonhosted.org/packages/ff/9c/daa99532c72f25051a90ef90e1413a8d54413a9e64614d9095b0c1c154d0/regex-2024.11.6-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:a03e02f48cd1abbd9f3b7e3586d97c8f7a9721c436f51a5245b3b9483044480b", size = 772713 },
    { url = "https://files.pythonhosted.org/packages/13/5d/61a533ccb8c231b474ac8e3a7d70155b00dfc61af6cafdccd1947df6d735/regex-2024.11.6-cp39-cp39-win32.whl", hash = "sha256:41758407fc32d5c3c5de163888068cfee69cb4c2be844e7ac517a52770f9af57", size = 261756 },
    { url = "https://files.pythonhosted.org/packages/dc/7b/e59b7f7c91ae110d154370c24133f947262525b5d6406df65f23422acc17/regex-2024.11.6-cp39-cp39-win_amd64.whl", hash = "sha256:b2837718570f95dd41675328e111345f9b7095d821bac435aac173ac80b19983", size = 274110 },
]

[[package]]
name = "requests"
version = "2.32.3"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "certifi" },
    { name = "charset-normalizer" },
    { name = "idna" },
    { name = "urllib3" },
]
sdist = { url = "https://files.pythonhosted.org/packages/63/70/2bf7780ad2d390a8d301ad0b550f1581eadbd9a20f896afe06353c2a2913/requests-2.32.3.tar.gz", hash = "sha256:55365417734eb18255590a9ff9eb97e9e1da868d4ccd6402399eaf68af20a760", size = 131218 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f9/9b/335f9764261e915ed497fcdeb11df5dfd6f7bf257d4a6a2a686d80da4d54/requests-2.32.3-py3-none-any.whl", hash = "sha256:70761cfe03c773ceb22aa2f671b4757976145175cdfca038c02654d061d6dcc6", size = 64928 },
]

[[package]]
name = "rich"
version = "13.9.4"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "markdown-it-py" },
    { name = "pygments" },
    { name = "typing-extensions", marker = "python_full_version < '3.11'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/ab/3a/0316b28d0761c6734d6bc14e770d85506c986c85ffb239e688eeaab2c2bc/rich-13.9.4.tar.gz", hash = "sha256:439594978a49a09530cff7ebc4b5c7103ef57baf48d5ea3184f21d9a2befa098", size = 223149 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/19/71/39c7c0d87f8d4e6c020a393182060eaefeeae6c01dab6a84ec346f2567df/rich-13.9.4-py3-none-any.whl", hash = "sha256:6049d5e6ec054bf2779ab3358186963bac2ea89175919d699e378b99738c2a90", size = 242424 },
]

[[package]]
name = "ruff"
version = "0.11.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/77/2b/7ca27e854d92df5e681e6527dc0f9254c9dc06c8408317893cf96c851cdd/ruff-0.11.0.tar.gz", hash = "sha256:e55c620690a4a7ee6f1cccb256ec2157dc597d109400ae75bbf944fc9d6462e2", size = 3799407 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/48/40/3d0340a9e5edc77d37852c0cd98c5985a5a8081fc3befaeb2ae90aaafd2b/ruff-0.11.0-py3-none-linux_armv6l.whl", hash = "sha256:dc67e32bc3b29557513eb7eeabb23efdb25753684b913bebb8a0c62495095acb", size = 10098158 },
    { url = "https://files.pythonhosted.org/packages/ec/a9/d8f5abb3b87b973b007649ac7bf63665a05b2ae2b2af39217b09f52abbbf/ruff-0.11.0-py3-none-macosx_10_12_x86_64.whl", hash = "sha256:38c23fd9bdec4eb437b4c1e3595905a0a8edfccd63a790f818b28c78fe345639", size = 10879071 },
    { url = "https://files.pythonhosted.org/packages/ab/62/aaa198614c6211677913ec480415c5e6509586d7b796356cec73a2f8a3e6/ruff-0.11.0-py3-none-macosx_11_0_arm64.whl", hash = "sha256:7c8661b0be91a38bd56db593e9331beaf9064a79028adee2d5f392674bbc5e88", size = 10247944 },
    { url = "https://files.pythonhosted.org/packages/9f/52/59e0a9f2cf1ce5e6cbe336b6dd0144725c8ea3b97cac60688f4e7880bf13/ruff-0.11.0-py3-none-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b6c0e8d3d2db7e9f6efd884f44b8dc542d5b6b590fc4bb334fdbc624d93a29a2", size = 10421725 },
    { url = "https://files.pythonhosted.org/packages/a6/c3/dcd71acc6dff72ce66d13f4be5bca1dbed4db678dff2f0f6f307b04e5c02/ruff-0.11.0-py3-none-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:3c3156d3f4b42e57247275a0a7e15a851c165a4fc89c5e8fa30ea6da4f7407b8", size = 9954435 },
    { url = "https://files.pythonhosted.org/packages/a6/9a/342d336c7c52dbd136dee97d4c7797e66c3f92df804f8f3b30da59b92e9c/ruff-0.11.0-py3-none-manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:490b1e147c1260545f6d041c4092483e3f6d8eba81dc2875eaebcf9140b53905", size = 11492664 },
    { url = "https://files.pythonhosted.org/packages/84/35/6e7defd2d7ca95cc385ac1bd9f7f2e4a61b9cc35d60a263aebc8e590c462/ruff-0.11.0-py3-none-manylinux_2_17_ppc64.manylinux2014_ppc64.whl", hash = "sha256:1bc09a7419e09662983b1312f6fa5dab829d6ab5d11f18c3760be7ca521c9329", size = 12207856 },
    { url = "https://files.pythonhosted.org/packages/22/78/da669c8731bacf40001c880ada6d31bcfb81f89cc996230c3b80d319993e/ruff-0.11.0-py3-none-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:bcfa478daf61ac8002214eb2ca5f3e9365048506a9d52b11bea3ecea822bb844", size = 11645156 },
    { url = "https://files.pythonhosted.org/packages/ee/47/e27d17d83530a208f4a9ab2e94f758574a04c51e492aa58f91a3ed7cbbcb/ruff-0.11.0-py3-none-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:6fbb2aed66fe742a6a3a0075ed467a459b7cedc5ae01008340075909d819df1e", size = 13884167 },
    { url = "https://files.pythonhosted.org/packages/9f/5e/42ffbb0a5d4b07bbc642b7d58357b4e19a0f4774275ca6ca7d1f7b5452cd/ruff-0.11.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:92c0c1ff014351c0b0cdfdb1e35fa83b780f1e065667167bb9502d47ca41e6db", size = 11348311 },
    { url = "https://files.pythonhosted.org/packages/c8/51/dc3ce0c5ce1a586727a3444a32f98b83ba99599bb1ebca29d9302886e87f/ruff-0.11.0-py3-none-musllinux_1_2_aarch64.whl", hash = "sha256:e4fd5ff5de5f83e0458a138e8a869c7c5e907541aec32b707f57cf9a5e124445", size = 10305039 },
    { url = "https://files.pythonhosted.org/packages/60/e0/475f0c2f26280f46f2d6d1df1ba96b3399e0234cf368cc4c88e6ad10dcd9/ruff-0.11.0-py3-none-musllinux_1_2_armv7l.whl", hash = "sha256:96bc89a5c5fd21a04939773f9e0e276308be0935de06845110f43fd5c2e4ead7", size = 9937939 },
    { url = "https://files.pythonhosted.org/packages/e2/d3/3e61b7fd3e9cdd1e5b8c7ac188bec12975c824e51c5cd3d64caf81b0331e/ruff-0.11.0-py3-none-musllinux_1_2_i686.whl", hash = "sha256:a9352b9d767889ec5df1483f94870564e8102d4d7e99da52ebf564b882cdc2c7", size = 10923259 },
    { url = "https://files.pythonhosted.org/packages/30/32/cd74149ebb40b62ddd14bd2d1842149aeb7f74191fb0f49bd45c76909ff2/ruff-0.11.0-py3-none-musllinux_1_2_x86_64.whl", hash = "sha256:049a191969a10897fe052ef9cc7491b3ef6de79acd7790af7d7897b7a9bfbcb6", size = 11406212 },
    { url = "https://files.pythonhosted.org/packages/00/ef/033022a6b104be32e899b00de704d7c6d1723a54d4c9e09d147368f14b62/ruff-0.11.0-py3-none-win32.whl", hash = "sha256:3191e9116b6b5bbe187447656f0c8526f0d36b6fd89ad78ccaad6bdc2fad7df2", size = 10310905 },
    { url = "https://files.pythonhosted.org/packages/ed/8a/163f2e78c37757d035bd56cd60c8d96312904ca4a6deeab8442d7b3cbf89/ruff-0.11.0-py3-none-win_amd64.whl", hash = "sha256:c58bfa00e740ca0a6c43d41fb004cd22d165302f360aaa56f7126d544db31a21", size = 11411730 },
    { url = "https://files.pythonhosted.org/packages/4e/f7/096f6efabe69b49d7ca61052fc70289c05d8d35735c137ef5ba5ef423662/ruff-0.11.0-py3-none-win_arm64.whl", hash = "sha256:868364fc23f5aa122b00c6f794211e85f7e78f5dffdf7c590ab90b8c4e69b657", size = 10538956 },
]

[[package]]
name = "scikit-learn"
version = "1.3.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "joblib" },
    { name = "numpy" },
    { name = "scipy" },
    { name = "threadpoolctl" },
]
sdist = { url = "https://files.pythonhosted.org/packages/88/00/835e3d280fdd7784e76bdef91dd9487582d7951a7254f59fc8004fc8b213/scikit-learn-1.3.2.tar.gz", hash = "sha256:a2f54c76accc15a34bfb9066e6c7a56c1e7235dda5762b990792330b52ccfb05", size = 7510251 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/0d/53/570b55a6e10b8694ac1e3024d2df5cd443f1b4ff6d28430845da8b9019b3/scikit_learn-1.3.2-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:e326c0eb5cf4d6ba40f93776a20e9a7a69524c4db0757e7ce24ba222471ee8a1", size = 10209999 },
    { url = "https://files.pythonhosted.org/packages/70/d0/50ace22129f79830e3cf682d0a2bd4843ef91573299d43112d52790163a8/scikit_learn-1.3.2-cp310-cp310-macosx_12_0_arm64.whl", hash = "sha256:535805c2a01ccb40ca4ab7d081d771aea67e535153e35a1fd99418fcedd1648a", size = 9479353 },
    { url = "https://files.pythonhosted.org/packages/8f/46/fcc35ed7606c50d3072eae5a107a45cfa5b7f5fa8cc48610edd8cc8e8550/scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1215e5e58e9880b554b01187b8c9390bf4dc4692eedeaf542d3273f4785e342c", size = 10304705 },
    { url = "https://files.pythonhosted.org/packages/d0/0b/26ad95cf0b747be967b15fb71a06f5ac67aba0fd2f9cd174de6edefc4674/scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0ee107923a623b9f517754ea2f69ea3b62fc898a3641766cb7deb2f2ce450161", size = 10827807 },
    { url = "https://files.pythonhosted.org/packages/69/8a/cf17d6443f5f537e099be81535a56ab68a473f9393fbffda38cd19899fc8/scikit_learn-1.3.2-cp310-cp310-win_amd64.whl", hash = "sha256:35a22e8015048c628ad099da9df5ab3004cdbf81edc75b396fd0cff8699ac58c", size = 9255427 },
    { url = "https://files.pythonhosted.org/packages/08/5d/e5acecd6e99a6b656e42e7a7b18284e2f9c9f512e8ed6979e1e75d25f05f/scikit_learn-1.3.2-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:6fb6bc98f234fda43163ddbe36df8bcde1d13ee176c6dc9b92bb7d3fc842eb66", size = 10116376 },
    { url = "https://files.pythonhosted.org/packages/40/c6/2e91eefb757822e70d351e02cc38d07c137212ae7c41ac12746415b4860a/scikit_learn-1.3.2-cp311-cp311-macosx_12_0_arm64.whl", hash = "sha256:18424efee518a1cde7b0b53a422cde2f6625197de6af36da0b57ec502f126157", size = 9383415 },
    { url = "https://files.pythonhosted.org/packages/fa/fd/b3637639e73bb72b12803c5245f2a7299e09b2acd85a0f23937c53369a1c/scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:3271552a5eb16f208a6f7f617b8cc6d1f137b52c8a1ef8edf547db0259b2c9fb", size = 10279163 },
    { url = "https://files.pythonhosted.org/packages/0c/2a/d3ff6091406bc2207e0adb832ebd15e40ac685811c7e2e3b432bfd969b71/scikit_learn-1.3.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fc4144a5004a676d5022b798d9e573b05139e77f271253a4703eed295bde0433", size = 10884422 },
    { url = "https://files.pythonhosted.org/packages/4e/ba/ce9bd1cd4953336a0e213b29cb80bb11816f2a93de8c99f88ef0b446ad0c/scikit_learn-1.3.2-cp311-cp311-win_amd64.whl", hash = "sha256:67f37d708f042a9b8d59551cf94d30431e01374e00dc2645fa186059c6c5d78b", size = 9207060 },
    { url = "https://files.pythonhosted.org/packages/26/7e/2c3b82c8c29aa384c8bf859740419278627d2cdd0050db503c8840e72477/scikit_learn-1.3.2-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:8db94cd8a2e038b37a80a04df8783e09caac77cbe052146432e67800e430c028", size = 9979322 },
    { url = "https://files.pythonhosted.org/packages/cf/fc/6c52ffeb587259b6b893b7cac268f1eb1b5426bcce1aa20e53523bfe6944/scikit_learn-1.3.2-cp312-cp312-macosx_12_0_arm64.whl", hash = "sha256:61a6efd384258789aa89415a410dcdb39a50e19d3d8410bd29be365bcdd512d5", size = 9270688 },
    { url = "https://files.pythonhosted.org/packages/e5/a7/6f4ae76f72ae9de162b97acbf1f53acbe404c555f968d13da21e4112a002/scikit_learn-1.3.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:cb06f8dce3f5ddc5dee1715a9b9f19f20d295bed8e3cd4fa51e1d050347de525", size = 10280398 },
    { url = "https://files.pythonhosted.org/packages/5d/b7/ee35904c07a0666784349529412fbb9814a56382b650d30fd9d6be5e5054/scikit_learn-1.3.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:5b2de18d86f630d68fe1f87af690d451388bb186480afc719e5f770590c2ef6c", size = 10796478 },
    { url = "https://files.pythonhosted.org/packages/fe/6b/db949ed5ac367987b1f250f070f340b7715d22f0c9c965bdf07de6ca75a3/scikit_learn-1.3.2-cp312-cp312-win_amd64.whl", hash = "sha256:0402638c9a7c219ee52c94cbebc8fcb5eb9fe9c773717965c1f4185588ad3107", size = 9133979 },
    { url = "https://files.pythonhosted.org/packages/e3/52/fd60b0b022af41fbf3463587ddc719288f0f2d4e46603ab3184996cd5f04/scikit_learn-1.3.2-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:a19f90f95ba93c1a7f7924906d0576a84da7f3b2282ac3bfb7a08a32801add93", size = 10064879 },
    { url = "https://files.pythonhosted.org/packages/a4/62/92e9cec3deca8b45abf62dd8f6469d688b3f28b9c170809fcc46f110b523/scikit_learn-1.3.2-cp38-cp38-macosx_12_0_arm64.whl", hash = "sha256:b8692e395a03a60cd927125eef3a8e3424d86dde9b2370d544f0ea35f78a8073", size = 9373934 },
    { url = "https://files.pythonhosted.org/packages/49/81/91585dc83ec81dcd52e934f6708bf350b06949d8bfa13bf3b711b851c3f4/scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:15e1e94cc23d04d39da797ee34236ce2375ddea158b10bee3c343647d615581d", size = 10499159 },
    { url = "https://files.pythonhosted.org/packages/3f/48/6fdd99f5717045f9984616b5c2ec683d6286d30c0ac234563062132b83ab/scikit_learn-1.3.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:785a2213086b7b1abf037aeadbbd6d67159feb3e30263434139c98425e3dcfcf", size = 11067392 },
    { url = "https://files.pythonhosted.org/packages/52/2d/ad6928a578c78bb0e44e34a5a922818b14c56716b81d145924f1f291416f/scikit_learn-1.3.2-cp38-cp38-win_amd64.whl", hash = "sha256:64381066f8aa63c2710e6b56edc9f0894cc7bf59bd71b8ce5613a4559b6145e0", size = 9257871 },
    { url = "https://files.pythonhosted.org/packages/f8/67/584acfc492ae1bd293d80c7a8c57ba7456e4e415c64869b7c240679eaf78/scikit_learn-1.3.2-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:6c43290337f7a4b969d207e620658372ba3c1ffb611f8bc2b6f031dc5c6d1d03", size = 10232286 },
    { url = "https://files.pythonhosted.org/packages/20/0f/51e3ccdc87c25e2e33bf7962249ff8c5ab1d6aed0144fb003348ce8bd352/scikit_learn-1.3.2-cp39-cp39-macosx_12_0_arm64.whl", hash = "sha256:dc9002fc200bed597d5d34e90c752b74df516d592db162f756cc52836b38fe0e", size = 9504918 },
    { url = "https://files.pythonhosted.org/packages/61/2e/5bbf3c9689d2911b65297fb5861c4257e54c797b3158c9fca8a5c576644b/scikit_learn-1.3.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1d08ada33e955c54355d909b9c06a4789a729977f165b8bae6f225ff0a60ec4a", size = 10358127 },
    { url = "https://files.pythonhosted.org/packages/25/89/dce01a35d354159dcc901e3c7e7eb3fe98de5cb3639c6cd39518d8830caa/scikit_learn-1.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:763f0ae4b79b0ff9cca0bf3716bcc9915bdacff3cebea15ec79652d1cc4fa5c9", size = 10890482 },
    { url = "https://files.pythonhosted.org/packages/1c/49/30ffcac5af06d08dfdd27da322ce31a373b733711bb272941877c1e4794a/scikit_learn-1.3.2-cp39-cp39-win_amd64.whl", hash = "sha256:ed932ea780517b00dae7431e031faae6b49b20eb6950918eb83bd043237950e0", size = 9331050 },
]

[[package]]
name = "scipy"
version = "1.10.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "numpy" },
]
sdist = { url = "https://files.pythonhosted.org/packages/84/a9/2bf119f3f9cff1f376f924e39cfae18dec92a1514784046d185731301281/scipy-1.10.1.tar.gz", hash = "sha256:2cf9dfb80a7b4589ba4c40ce7588986d6d5cebc5457cad2c2880f6bc2d42f3a5", size = 42407997 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/0a/ac/b1f1bbf7b01d96495f35be003b881f10f85bf6559efb6e9578da832c2140/scipy-1.10.1-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:e7354fd7527a4b0377ce55f286805b34e8c54b91be865bac273f527e1b839019", size = 35093243 },
    { url = "https://files.pythonhosted.org/packages/ea/e5/452086ebed676ce4000ceb5eeeb0ee4f8c6f67c7e70fb9323a370ff95c1f/scipy-1.10.1-cp310-cp310-macosx_12_0_arm64.whl", hash = "sha256:4b3f429188c66603a1a5c549fb414e4d3bdc2a24792e061ffbd607d3d75fd84e", size = 28772969 },
    { url = "https://files.pythonhosted.org/packages/04/0b/a1b119c869b79a2ab459b7f9fd7e2dea75a9c7d432e64e915e75586bd00b/scipy-1.10.1-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:1553b5dcddd64ba9a0d95355e63fe6c3fc303a8fd77c7bc91e77d61363f7433f", size = 30886961 },
    { url = "https://files.pythonhosted.org/packages/1f/4b/3bacad9a166350cb2e518cea80ab891016933cc1653f15c90279512c5fa9/scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:4c0ff64b06b10e35215abce517252b375e580a6125fd5fdf6421b98efbefb2d2", size = 34422544 },
    { url = "https://files.pythonhosted.org/packages/ec/e3/b06ac3738bf365e89710205a471abe7dceec672a51c244b469bc5d1291c7/scipy-1.10.1-cp310-cp310-win_amd64.whl", hash = "sha256:fae8a7b898c42dffe3f7361c40d5952b6bf32d10c4569098d276b4c547905ee1", size = 42484848 },
    { url = "https://files.pythonhosted.org/packages/e7/53/053cd3669be0d474deae8fe5f757bff4c4f480b8a410231e0631c068873d/scipy-1.10.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:0f1564ea217e82c1bbe75ddf7285ba0709ecd503f048cb1236ae9995f64217bd", size = 35003170 },
    { url = "https://files.pythonhosted.org/packages/0d/3e/d05b9de83677195886fb79844fcca19609a538db63b1790fa373155bc3cf/scipy-1.10.1-cp311-cp311-macosx_12_0_arm64.whl", hash = "sha256:d925fa1c81b772882aa55bcc10bf88324dadb66ff85d548c71515f6689c6dac5", size = 28717513 },
    { url = "https://files.pythonhosted.org/packages/a5/3d/b69746c50e44893da57a68457da3d7e5bb75f6a37fbace3769b70d017488/scipy-1.10.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:aaea0a6be54462ec027de54fca511540980d1e9eea68b2d5c1dbfe084797be35", size = 30687257 },
    { url = "https://files.pythonhosted.org/packages/21/cd/fe2d4af234b80dc08c911ce63fdaee5badcdde3e9bcd9a68884580652ef0/scipy-1.10.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:15a35c4242ec5f292c3dd364a7c71a61be87a3d4ddcc693372813c0b73c9af1d", size = 34124096 },
    { url = "https://files.pythonhosted.org/packages/65/76/903324159e4a3566e518c558aeb21571d642f781d842d8dd0fd9c6b0645a/scipy-1.10.1-cp311-cp311-win_amd64.whl", hash = "sha256:43b8e0bcb877faf0abfb613d51026cd5cc78918e9530e375727bf0625c82788f", size = 42238704 },
    { url = "https://files.pythonhosted.org/packages/a0/e3/37508a11dae501349d7c16e4dd18c706a023629eedc650ee094593887a89/scipy-1.10.1-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:5678f88c68ea866ed9ebe3a989091088553ba12c6090244fdae3e467b1139c35", size = 35041063 },
    { url = "https://files.pythonhosted.org/packages/93/4a/50c436de1353cce8b66b26e49a687f10b91fe7465bf34e4565d810153003/scipy-1.10.1-cp38-cp38-macosx_12_0_arm64.whl", hash = "sha256:39becb03541f9e58243f4197584286e339029e8908c46f7221abeea4b749fa88", size = 28797694 },
    { url = "https://files.pythonhosted.org/packages/d2/b5/ff61b79ad0ebd15d87ade10e0f4e80114dd89fac34a5efade39e99048c91/scipy-1.10.1-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bce5869c8d68cf383ce240e44c1d9ae7c06078a9396df68ce88a1230f93a30c1", size = 31024657 },
    { url = "https://files.pythonhosted.org/packages/69/f0/fb07a9548e48b687b8bf2fa81d71aba9cfc548d365046ca1c791e24db99d/scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:07c3457ce0b3ad5124f98a86533106b643dd811dd61b548e78cf4c8786652f6f", size = 34540352 },
    { url = "https://files.pythonhosted.org/packages/32/8e/7f403535ddf826348c9b8417791e28712019962f7e90ff845896d6325d09/scipy-1.10.1-cp38-cp38-win_amd64.whl", hash = "sha256:049a8bbf0ad95277ffba9b3b7d23e5369cc39e66406d60422c8cfef40ccc8415", size = 42215036 },
    { url = "https://files.pythonhosted.org/packages/d9/7d/78b8035bc93c869b9f17261c87aae97a9cdb937f65f0d453c2831aa172fc/scipy-1.10.1-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:cd9f1027ff30d90618914a64ca9b1a77a431159df0e2a195d8a9e8a04c78abf9", size = 35158611 },
    { url = "https://files.pythonhosted.org/packages/e7/f0/55d81813b1a4cb79ce7dc8290eac083bf38bfb36e1ada94ea13b7b1a5f79/scipy-1.10.1-cp39-cp39-macosx_12_0_arm64.whl", hash = "sha256:79c8e5a6c6ffaf3a2262ef1be1e108a035cf4f05c14df56057b64acc5bebffb6", size = 28902591 },
    { url = "https://files.pythonhosted.org/packages/77/d1/722c457b319eed1d642e0a14c9be37eb475f0e6ed1f3401fa480d5d6d36e/scipy-1.10.1-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:51af417a000d2dbe1ec6c372dfe688e041a7084da4fdd350aeb139bd3fb55353", size = 30960654 },
    { url = "https://files.pythonhosted.org/packages/5d/30/b2a2a5bf1a3beefb7609fb871dcc6aef7217c69cef19a4631b7ab5622a8a/scipy-1.10.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1b4735d6c28aad3cdcf52117e0e91d6b39acd4272f3f5cd9907c24ee931ad601", size = 34458863 },
    { url = "https://files.pythonhosted.org/packages/35/20/0ec6246bbb43d18650c9a7cad6602e1a84fd8f9564a9b84cc5faf1e037d0/scipy-1.10.1-cp39-cp39-win_amd64.whl", hash = "sha256:7ff7f37b1bf4417baca958d254e8e2875d0cc23aaadbe65b3d5b3077b0eb23ea", size = 42509516 },
]

[[package]]
name = "seaborn"
version = "0.13.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "matplotlib" },
    { name = "numpy" },
    { name = "pandas" },
]
sdist = { url = "https://files.pythonhosted.org/packages/86/59/a451d7420a77ab0b98f7affa3a1d78a313d2f7281a57afb1a34bae8ab412/seaborn-0.13.2.tar.gz", hash = "sha256:93e60a40988f4d65e9f4885df477e2fdaff6b73a9ded434c1ab356dd57eefff7", size = 1457696 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/83/11/00d3c3dfc25ad54e731d91449895a79e4bf2384dc3ac01809010ba88f6d5/seaborn-0.13.2-py3-none-any.whl", hash = "sha256:636f8336facf092165e27924f223d3c62ca560b1f2bb5dff7ab7fad265361987", size = 294914 },
]

[[package]]
name = "setuptools"
version = "75.3.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/5c/01/771ea46cce201dd42cff043a5eea929d1c030fb3d1c2ee2729d02ca7814c/setuptools-75.3.2.tar.gz", hash = "sha256:3c1383e1038b68556a382c1e8ded8887cd20141b0eb5708a6c8d277de49364f5", size = 1354489 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/15/65/3f0dba35760d902849d39d38c0a72767794b1963227b69a587f8a336d08c/setuptools-75.3.2-py3-none-any.whl", hash = "sha256:90ab613b6583fc02d5369cbca13ea26ea0e182d1df2d943ee9cbe81d4c61add9", size = 1251198 },
]

[[package]]
name = "shellingham"
version = "1.5.4"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/58/15/8b3609fd3830ef7b27b655beb4b4e9c62313a4e8da8c676e142cc210d58e/shellingham-1.5.4.tar.gz", hash = "sha256:8dbca0739d487e5bd35ab3ca4b36e11c4078f3a234bfce294b0a0291363404de", size = 10310 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl", hash = "sha256:7ecfff8f2fd72616f7481040475a65b2bf8af90a56c89140852d1120324e8686", size = 9755 },
]

[[package]]
name = "six"
version = "1.17.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/94/e7/b2c673351809dca68a0e064b6af791aa332cf192da575fd474ed7d6f16a2/six-1.17.0.tar.gz", hash = "sha256:ff70335d468e7eb6ec65b95b99d3a2836546063f63acc5171de367e834932a81", size = 34031 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b7/ce/149a00dd41f10bc29e5921b496af8b574d8413afcd5e30dfa0ed46c2cc5e/six-1.17.0-py2.py3-none-any.whl", hash = "sha256:4721f391ed90541fddacab5acf947aa0d3dc7d27b2e1e8eda2be8970586c3274", size = 11050 },
]

[[package]]
name = "smart-open"
version = "7.1.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "wrapt" },
]
sdist = { url = "https://files.pythonhosted.org/packages/21/30/1f41c3d3b8cec82024b4b277bfd4e5b18b765ae7279eb9871fa25c503778/smart_open-7.1.0.tar.gz", hash = "sha256:a4f09f84f0f6d3637c6543aca7b5487438877a21360e7368ccf1f704789752ba", size = 72044 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7a/18/9a8d9f01957aa1f8bbc5676d54c2e33102d247e146c1a3679d3bd5cc2e3a/smart_open-7.1.0-py3-none-any.whl", hash = "sha256:4b8489bb6058196258bafe901730c7db0dcf4f083f316e97269c66f45502055b", size = 61746 },
]

[[package]]
name = "soupsieve"
version = "2.6"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d7/ce/fbaeed4f9fb8b2daa961f90591662df6a86c1abf25c548329a86920aedfb/soupsieve-2.6.tar.gz", hash = "sha256:e2e68417777af359ec65daac1057404a3c8a5455bb8abc36f1a9866ab1a51abb", size = 101569 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d1/c2/fe97d779f3ef3b15f05c94a2f1e3d21732574ed441687474db9d342a7315/soupsieve-2.6-py3-none-any.whl", hash = "sha256:e72c4ff06e4fb6e4b5a9f0f55fe6e81514581fca1515028625d0f299c602ccc9", size = 36186 },
]

[[package]]
name = "spacy"
version = "3.7.5"
source = { registry = "https://pypi.org/simple" }
resolution-markers = [
    "python_full_version < '3.9'",
]
dependencies = [
    { name = "catalogue", marker = "python_full_version < '3.9'" },
    { name = "cymem", marker = "python_full_version < '3.9'" },
    { name = "jinja2", marker = "python_full_version < '3.9'" },
    { name = "langcodes", marker = "python_full_version < '3.9'" },
    { name = "murmurhash", marker = "python_full_version < '3.9'" },
    { name = "numpy", marker = "python_full_version < '3.9'" },
    { name = "packaging", marker = "python_full_version < '3.9'" },
    { name = "preshed", marker = "python_full_version < '3.9'" },
    { name = "pydantic", marker = "python_full_version < '3.9'" },
    { name = "requests", marker = "python_full_version < '3.9'" },
    { name = "setuptools", marker = "python_full_version < '3.9'" },
    { name = "spacy-legacy", marker = "python_full_version < '3.9'" },
    { name = "spacy-loggers", marker = "python_full_version < '3.9'" },
    { name = "srsly", marker = "python_full_version < '3.9'" },
    { name = "thinc", version = "8.2.5", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.9'" },
    { name = "tqdm", marker = "python_full_version < '3.9'" },
    { name = "typer", marker = "python_full_version < '3.9'" },
    { name = "wasabi", marker = "python_full_version < '3.9'" },
    { name = "weasel", marker = "python_full_version < '3.9'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/21/1e/94e3981516db6fcd6685f058c43c3fa81805c120b04829596367dad1aa4e/spacy-3.7.5.tar.gz", hash = "sha256:a648c6cbf2acc7a55a69ee9e7fa4f22bdf69aa828a587a1bc5cfff08cf3c2dd3", size = 1274806 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c2/5e/f3a851f4c90e61c64956c952387db9b6557863a15050616929886cdcab45/spacy-3.7.5-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:8002897701429ee2ab5ff6921ae43560f4cd17184cb1e10dad761901c12dcb85", size = 6847778 },
    { url = "https://files.pythonhosted.org/packages/c6/3a/8c5446c40306f876f12c2f9c814c731913f775c9342348333342312bf202/spacy-3.7.5-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:43acd19efc845e9126b61a05ed7508a0aff509e96e15563f30f810c19e636b7c", size = 6609906 },
    { url = "https://files.pythonhosted.org/packages/18/91/2fbd1c23467cbad666dbcdb9cf7d3c04d620a2f470281a9d341acccad9b2/spacy-3.7.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:f044522b1271ea54718dc43b6f593b5dad349cd31b3827764c501529b599e09a", size = 6250741 },
    { url = "https://files.pythonhosted.org/packages/07/52/117eae6b96e79207234bf546271bc4d8bb1ec5bf5dd1d8ddf15f12cdbf2e/spacy-3.7.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6a7dbfbca42c1c128fefa6832631fe49e11c850e963af99229f14e2d0ae94f34", size = 6606864 },
    { url = "https://files.pythonhosted.org/packages/df/9d/b46b6f0a4ad66498c388a94e7efbff51044be92ecc1d0f5ea02dc45ef2d1/spacy-3.7.5-cp310-cp310-win_amd64.whl", hash = "sha256:2a21b2a1e1e5d10d15c6f75990b7341d0fc9b454083dfd4222fdd75b9164831c", size = 12081318 },
    { url = "https://files.pythonhosted.org/packages/80/36/53a831d2e82a432d785823cdff56f84737aed26e8f7667d423ee32c3983d/spacy-3.7.5-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:cd93c34bf2a02bbed7df73d42aed8df5e3eb9688c4ea84ec576f740ba939cce5", size = 6750524 },
    { url = "https://files.pythonhosted.org/packages/72/49/bd65abe76607c86dc1f104ad545eeb3e771f474b7e259e64e5a16614615b/spacy-3.7.5-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:190ba0032a5efdb138487c587c0ebb7a98f86adb917f464b252ee8766b8eec4a", size = 6517941 },
    { url = "https://files.pythonhosted.org/packages/51/83/ec38e9bddb17b8f07539a49a19f2b30ce8e7d7a3d4f94dda31ea9bd043f7/spacy-3.7.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:38de1c9bbb73b8cdfea2dd6e57450f093c1a1af47515870c1c8640b85b35ab16", size = 6236788 },
    { url = "https://files.pythonhosted.org/packages/e0/ce/b5e6b02165881547ad251b0b172ebf496b9181a95833f94012af82d044df/spacy-3.7.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3dad4853950a2fe6c7a0bdfd791a762d1f8cedd2915c4ae41b2e0ca3a850eefc", size = 6585757 },
    { url = "https://files.pythonhosted.org/packages/39/e1/08681583569f435347ced0535b27c073fcc9a927d9b4293c963092f2d01c/spacy-3.7.5-cp311-cp311-win_amd64.whl", hash = "sha256:4e00d076871af784c2e43185a71ee676b58893853a05c5b81717b8af2b666c07", size = 12078792 },
    { url = "https://files.pythonhosted.org/packages/3d/c8/413225de79e71dd9ca353d597ea4890a43fa60ff98cf9615b1606680ab95/spacy-3.7.5-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:bf54c3c2425428b328b53a65913d47eb4cb27a1429aa4e8ed979ffc97d4663e0", size = 6324302 },
    { url = "https://files.pythonhosted.org/packages/60/f9/726e977c5430c44912ed97d7d965ef35d2563978b38076b254379652a522/spacy-3.7.5-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:4145cea7f9814fa7d86b2028c2dd83e02f13f80d5ac604a400b2f7d7b26a0e8c", size = 6112434 },
    { url = "https://files.pythonhosted.org/packages/53/ff/4b3a9d3063ba98d3ce27a0c2a60e3c25e4650b7c3c7555a47179dac5c282/spacy-3.7.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:262f8ebb71f7ed5ffe8e4f384b2594b7a296be50241ce9fbd9277b5da2f46f38", size = 6065925 },
    { url = "https://files.pythonhosted.org/packages/ef/9f/70bed4cb66629ad1fa5f45220d47bbbf6c858e70e5d69f7ca1de95dd2b92/spacy-3.7.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:faa1e2b6234ae33c0b1f8dfa5a8dcb66fb891f19231725dfcff4b2666125c250", size = 6455942 },
    { url = "https://files.pythonhosted.org/packages/58/42/b6bb76b08f4a0ccb0e2d0e4f3524acadf1ba929e2b93f90e4652d1c3cbd3/spacy-3.7.5-cp312-cp312-win_amd64.whl", hash = "sha256:07677e270a6d729453cc04b5e2247a96a86320b8845e6428d9f90f217eff0f56", size = 11673681 },
    { url = "https://files.pythonhosted.org/packages/09/ba/996a28e21563e2747c117bd1b9ab14f807653b9c00dc33f28775ccca5760/spacy-3.7.5-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:d9108f67675fb2078ed77cda61fd4cfc197f9256c28d35cfd946dcb080190ddc", size = 6784514 },
    { url = "https://files.pythonhosted.org/packages/5e/54/7c97ae19a166b8a18952ed783c718f2bec818567ac745efcd79e56a263d5/spacy-3.7.5-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:12fdc01a4391299a47f16915505cc515fd059e71c7239904e216523354eeb9d9", size = 6573194 },
    { url = "https://files.pythonhosted.org/packages/3b/92/b9ee150580afbcbf0a65029fc1e5a117a09e972fca8a7086a25fde56c3d1/spacy-3.7.5-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:7f8fbe9f6b9de1bf05d163a9dd88108b8f20b138986e6ed36f960832e3fcab33", size = 6375088 },
    { url = "https://files.pythonhosted.org/packages/2c/db/91859e17da8ef43a3f52e0eb3172cfdf407497e4370addea8d577a4864a7/spacy-3.7.5-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:d244d524ab5a33530ac5c50fc92c9a41da6c3980f452048b9fc29e1ff1bdd03e", size = 6737497 },
    { url = "https://files.pythonhosted.org/packages/df/9c/0b8e2d21775215bfca705e5d4b6d55211c2a4a4f2317bfa56309340805f2/spacy-3.7.5-cp38-cp38-win_amd64.whl", hash = "sha256:8b493a8b79a7f3754102fa5ef7e2615568a390fec7ea20db49af55e5f0841fcf", size = 12472463 },
    { url = "https://files.pythonhosted.org/packages/6f/a8/2d21671166cf1d3a4664d39f059715889ec6396ae56b7f36a3e13bfd393b/spacy-3.7.5-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:fdbb667792d6ca93899645774d1db3fccc327088a92072029be1e4bc25d7cf15", size = 6896104 },
    { url = "https://files.pythonhosted.org/packages/2f/8e/037a45182f60714cc873dc07faa2540db5cc1a77c20164a449640882a07c/spacy-3.7.5-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:4cfb85309e11a39681c9d4941aebb95c1f5e2e3b77a61a5451e2c3849da4b92e", size = 6649203 },
    { url = "https://files.pythonhosted.org/packages/74/54/d2464f0f1e216d0d07aec87d352a2ffaf4d7dac61c946a40df3d473ab41f/spacy-3.7.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4b0bf1788ca397eef8e67e9c07cfd9287adac438512dd191e6e6ca0f36357201", size = 6267580 },
    { url = "https://files.pythonhosted.org/packages/f9/4a/1067b8dd25ef1677c4ed633cda9598c77412e5554f35121db72cc75d1bed/spacy-3.7.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:591d90d8504e9bd5be5b482be7c6d6a974afbaeb62c3181e966f4e407e0ab300", size = 6606428 },
    { url = "https://files.pythonhosted.org/packages/f6/2b/853b46847e826c2b6eaa9811c8514d7dccd02fe88e6a2e14fee39e56c7a4/spacy-3.7.5-cp39-cp39-win_amd64.whl", hash = "sha256:713b56fe008c79df01617f3602a0b7e523292211337eb999bdffb910ea1f4825", size = 12165757 },
]

[[package]]
name = "spacy"
version = "3.8.2"
source = { registry = "https://pypi.org/simple" }
resolution-markers = [
    "python_full_version == '3.9.*'",
    "python_full_version == '3.10.*'",
    "python_full_version == '3.11.*'",
    "python_full_version >= '3.12'",
]
dependencies = [
    { name = "catalogue", marker = "python_full_version >= '3.9'" },
    { name = "cymem", marker = "python_full_version >= '3.9'" },
    { name = "jinja2", marker = "python_full_version >= '3.9'" },
    { name = "langcodes", marker = "python_full_version >= '3.9'" },
    { name = "murmurhash", marker = "python_full_version >= '3.9'" },
    { name = "numpy", marker = "python_full_version >= '3.9'" },
    { name = "packaging", marker = "python_full_version >= '3.9'" },
    { name = "preshed", marker = "python_full_version >= '3.9'" },
    { name = "pydantic", marker = "python_full_version >= '3.9'" },
    { name = "requests", marker = "python_full_version >= '3.9'" },
    { name = "setuptools", marker = "python_full_version >= '3.9'" },
    { name = "spacy-legacy", marker = "python_full_version >= '3.9'" },
    { name = "spacy-loggers", marker = "python_full_version >= '3.9'" },
    { name = "srsly", marker = "python_full_version >= '3.9'" },
    { name = "thinc", version = "8.3.4", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.9'" },
    { name = "tqdm", marker = "python_full_version >= '3.9'" },
    { name = "typer", marker = "python_full_version >= '3.9'" },
    { name = "wasabi", marker = "python_full_version >= '3.9'" },
    { name = "weasel", marker = "python_full_version >= '3.9'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/07/53/536941af8fbb5cb10a778f0dbd2a17b0f13e7ebfc11e67b154be60508fdf/spacy-3.8.2.tar.gz", hash = "sha256:4b37ebd25ada4059b0dc9e0893e70dde5df83485329a068ef04580e70892a65d", size = 1291174 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/ed/cb/85fb9ce87e0d37a7f532dc60c1be98ce320326bdd4a0222756b4262d2bb0/spacy-3.8.2-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:795e74493036dda0a576093b797a4fdc1aaa83d66f6c9af0e5b6b1c640dc2222", size = 6610807 },
    { url = "https://files.pythonhosted.org/packages/7b/10/63bcc4a9d3d902a66d7d6bd410fc9596403780de769973ea450e62606c67/spacy-3.8.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:d432e78fe2a7424aba9a741db07ce58487d3b74fae4e20a779142828e61bc402", size = 6305899 },
    { url = "https://files.pythonhosted.org/packages/8e/13/143fce10ae7a8c4d083f00d7a69b46057db47d252072359ecfc2c458f71b/spacy-3.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:536a8ba17359540de502285934bf357805d978128d7bd5e84ba53d28b32a0ffb", size = 29148862 },
    { url = "https://files.pythonhosted.org/packages/2b/c4/890f8ebf861878fdb8bf08998e0e30bf30c32e9daa4f3b7062f4117c9efc/spacy-3.8.2-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:6a0d0d39baa1cb9f5bb82874cbe1067bf494f76277a383f1f7b29f7a855d41a9", size = 29911788 },
    { url = "https://files.pythonhosted.org/packages/65/a0/f06628e75fa12873fb7a0aeeae44f3a44060e7901a9cf9eeebff04b20bd1/spacy-3.8.2-cp310-cp310-win_amd64.whl", hash = "sha256:9dcfcfda558b3e47946b2041c7a4203b78e542d0de20997a7c0a6d11b58b2522", size = 12205288 },
    { url = "https://files.pythonhosted.org/packages/d0/bb/132811a8d7fb814ce693bb6317650d2c25b57bb1789d151f330207c5213f/spacy-3.8.2-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:7e5d48918028cff6d69d9915dad64f0e32ebd5f1e4f1fa81a2e17e56a6f61e05", size = 6574075 },
    { url = "https://files.pythonhosted.org/packages/e4/18/c72f0aed98b99219556c13b2a7b8f013a8e992699845076fd89a82a5808f/spacy-3.8.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:455f845b88ed795d7e595070ee84b65b3ea382357811e09fc744789a20b7b5f7", size = 6264480 },
    { url = "https://files.pythonhosted.org/packages/ee/4a/9d5b4e982ace094a44bc53bde40af525d3ad1d61f2fc631690d7a011963b/spacy-3.8.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:05d8a4cbfdb90049053564790a0d12fa790c9471580cb6a1f8bdc2b6e74703dd", size = 30567923 },
    { url = "https://files.pythonhosted.org/packages/c3/42/c5601c31cdf64e2c09d56210c4b97325fdc890acd17094444f082b042ddc/spacy-3.8.2-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:e3c3e67f786f1410d08420ffcaba0f80dc58387ab6172dcdac1a73353d3a85c7", size = 31110934 },
    { url = "https://files.pythonhosted.org/packages/03/56/dce58155b3bce42f987dbf6cc23e820e037bc02abc99ade6ae3ad8d619a9/spacy-3.8.2-cp311-cp311-win_amd64.whl", hash = "sha256:cfe0c4558f635c67677e36d9a315f51d51f824870589c4846c95e880042a2ceb", size = 12200693 },
    { url = "https://files.pythonhosted.org/packages/36/6e/3eb3d39029571ed096fcf95f097be496670dad2b457ae0e1bbc1ee0c49d0/spacy-3.8.2-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:0ce56f3c46dd4cebb5aaa3a40966e813b7fc6a540d547788a7d00cca10cd60a9", size = 6293337 },
    { url = "https://files.pythonhosted.org/packages/19/e6/ae2c4b1b898dc48fd9c221a0d2458e4fc3d337f3ece183e4ebe945dd1c1f/spacy-3.8.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:09faa873cf23d5136b1c1ce6378054a885f650fda96e1655a3ab49e2e7fdd15b", size = 5977424 },
    { url = "https://files.pythonhosted.org/packages/98/b8/12abefe9d8830797dcea4c822e503eede1128e44ef0fef6fdd80a8a1eb47/spacy-3.8.2-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:33e992a11de9b727c61288541945c0ffc37ed998aca76bfd557937c2c195d7d4", size = 31813151 },
    { url = "https://files.pythonhosted.org/packages/ce/b4/2abb75e44b92950789b51493b605bf5822a57d6b21991d9ba4cbf48ba2d7/spacy-3.8.2-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:be962a8188fb20d6c2065e1e865d1799ebbf544c1af67ab8c75cb279bf5448c7", size = 32103979 },
    { url = "https://files.pythonhosted.org/packages/aa/ad/833e22a92c221e0871509b7c1463efbc6f33a93a0c396744f217e5c0b265/spacy-3.8.2-cp312-cp312-win_amd64.whl", hash = "sha256:04546c5f5ed607387d4e9ecf57614e90c5784866a10a3c6dbe5b06e9b18a2f29", size = 11786464 },
    { url = "https://files.pythonhosted.org/packages/ed/bc/7a77d95b89ee16ddeec5cbcd67d92426ae880e4ce95abb4211189995e0e1/spacy-3.8.2-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:7c5fb8b804ebf1c2791b384d61391e9d0227bcfdecd6c861291690813b8a6eb1", size = 6546464 },
    { url = "https://files.pythonhosted.org/packages/35/d6/dbc693d52d6ba7206ec8d0005476e429aa7f9d22402f8f078af013e43fa0/spacy-3.8.2-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:3647233b2454e8e7bae94232563c9bff849db9e26bf61ef51122ef723de009fe", size = 6259406 },
    { url = "https://files.pythonhosted.org/packages/9c/14/ea91402b6e1942c72213c0024a71057e7044eae51ed3c0466c3412648e41/spacy-3.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ca20e2d9b4aeaedd7068d6419762d66cfad82bc8b1e63e36714601686d67f163", size = 29353704 },
    { url = "https://files.pythonhosted.org/packages/12/a3/2f1cf9c87e5887cd5be9f21324abb3166a3a3ae5e3d7b15a38cb8950a148/spacy-3.8.2-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:be3aa3e7d456627acbcb7f585156ee463c01d006a07aeb20b43a8543a02cd047", size = 30032291 },
    { url = "https://files.pythonhosted.org/packages/73/46/dcc614b2ebbd19280a5f05e87663a1dc81121444c6e3e9a6444298cb30b5/spacy-3.8.2-cp39-cp39-win_amd64.whl", hash = "sha256:54c63d31ef410ebb5b0fd72729afaf50f876bf2bc29f73c6c5fc3676ae4158a1", size = 12302561 },
]

[[package]]
name = "spacy-legacy"
version = "3.0.12"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d9/79/91f9d7cc8db5642acad830dcc4b49ba65a7790152832c4eceb305e46d681/spacy-legacy-3.0.12.tar.gz", hash = "sha256:b37d6e0c9b6e1d7ca1cf5bc7152ab64a4c4671f59c85adaf7a3fcb870357a774", size = 23806 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/c3/55/12e842c70ff8828e34e543a2c7176dac4da006ca6901c9e8b43efab8bc6b/spacy_legacy-3.0.12-py2.py3-none-any.whl", hash = "sha256:476e3bd0d05f8c339ed60f40986c07387c0a71479245d6d0f4298dbd52cda55f", size = 29971 },
]

[[package]]
name = "spacy-loggers"
version = "1.0.5"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/67/3d/926db774c9c98acf66cb4ed7faf6c377746f3e00b84b700d0868b95d0712/spacy-loggers-1.0.5.tar.gz", hash = "sha256:d60b0bdbf915a60e516cc2e653baeff946f0cfc461b452d11a4d5458c6fe5f24", size = 20811 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl", hash = "sha256:196284c9c446cc0cdb944005384270d775fdeaf4f494d8e269466cfa497ef645", size = 22343 },
]

[[package]]
name = "srsly"
version = "2.4.8"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "catalogue" },
]
sdist = { url = "https://files.pythonhosted.org/packages/59/7f/17259e0962bb9433f39aa99ec45fd36851961491c562bc2f8c731cc476a6/srsly-2.4.8.tar.gz", hash = "sha256:b24d95a65009c2447e0b49cda043ac53fecf4f09e358d87a57446458f91b8a91", size = 351651 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f6/48/363ffe49690ff5cd8597a2fce311890825595c20153b5fd1db7477d1e2cd/srsly-2.4.8-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:17f3bcb418bb4cf443ed3d4dcb210e491bd9c1b7b0185e6ab10b6af3271e63b2", size = 492893 },
    { url = "https://files.pythonhosted.org/packages/b2/19/39c39e1ed436852946924fb043cbf1f7bf96682d8ef6ad0c2b14fee235c0/srsly-2.4.8-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:0b070a58e21ab0e878fd949f932385abb4c53dd0acb6d3a7ee75d95d447bc609", size = 491198 },
    { url = "https://files.pythonhosted.org/packages/56/2b/e4ea56011ed3b66b372ff55463b4f0f8db7245b95cec2fb2042ffec291f0/srsly-2.4.8-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:98286d20014ed2067ad02b0be1e17c7e522255b188346e79ff266af51a54eb33", size = 488980 },
    { url = "https://files.pythonhosted.org/packages/32/69/2c054c6c5dc5daf5648f994f22377f3be44f79d643f3c3db255b4e86b391/srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:18685084e2e0cc47c25158cbbf3e44690e494ef77d6418c2aae0598c893f35b0", size = 493019 },
    { url = "https://files.pythonhosted.org/packages/0a/ed/d2c37221fe1975f4b6e8e3cf200d25b905b77e18f6a660b3dc149ade6192/srsly-2.4.8-cp310-cp310-win_amd64.whl", hash = "sha256:980a179cbf4eb5bc56f7507e53f76720d031bcf0cef52cd53c815720eb2fc30c", size = 481871 },
    { url = "https://files.pythonhosted.org/packages/40/fe/baa4056b7e8585f4c3478d3d1d3a2c1c3095ff066e4fb420bb000abb6cc2/srsly-2.4.8-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:5472ed9f581e10c32e79424c996cf54c46c42237759f4224806a0cd4bb770993", size = 490026 },
    { url = "https://files.pythonhosted.org/packages/1b/d7/0800af1a75008b3a6a6a24f3efd165f2d2208076e9b8a4b11b66f16217f3/srsly-2.4.8-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:50f10afe9230072c5aad9f6636115ea99b32c102f4c61e8236d8642c73ec7a13", size = 488409 },
    { url = "https://files.pythonhosted.org/packages/0e/05/006dd2fdd74248d3fad492e864c2dc75260d52759d526a7cb9c7c08b0fe9/srsly-2.4.8-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c994a89ba247a4d4f63ef9fdefb93aa3e1f98740e4800d5351ebd56992ac75e3", size = 487672 },
    { url = "https://files.pythonhosted.org/packages/e2/a0/153375ade1ca9d33543da7d512329ea9a7d40dc0e0832599f4228b9d761b/srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ace7ed4a0c20fa54d90032be32f9c656b6d75445168da78d14fe9080a0c208ad", size = 490912 },
    { url = "https://files.pythonhosted.org/packages/eb/f5/e3f29993f673d91623df6413ba64e815dd2676fd7932cbc5e7347402ddae/srsly-2.4.8-cp311-cp311-win_amd64.whl", hash = "sha256:7a919236a090fb93081fbd1cec030f675910f3863825b34a9afbcae71f643127", size = 479719 },
    { url = "https://files.pythonhosted.org/packages/b1/1a/d96117461e16203ee35dda67153db00572935e5d7fc211d091a34fec24c8/srsly-2.4.8-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:7583c03d114b4478b7a357a1915305163e9eac2dfe080da900555c975cca2a11", size = 488406 },
    { url = "https://files.pythonhosted.org/packages/9a/47/13fbea357e7eb9ee823b54cbead30a6adc6686bb3f73e76563b13dcbb2f8/srsly-2.4.8-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:94ccdd2f6db824c31266aaf93e0f31c1c43b8bc531cd2b3a1d924e3c26a4f294", size = 486434 },
    { url = "https://files.pythonhosted.org/packages/0e/3d/462cec40c9ce15f8a3a97c972058ce1d2688abcad2dfc4eea3c888391c11/srsly-2.4.8-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:db72d2974f91aee652d606c7def98744ca6b899bd7dd3009fd75ebe0b5a51034", size = 486968 },
    { url = "https://files.pythonhosted.org/packages/a1/1d/c4b28e95d9ec4c2e7dad201fa415a483e173fcce444d52dd53be0b0469f3/srsly-2.4.8-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6a60c905fd2c15e848ce1fc315fd34d8a9cc72c1dee022a0d8f4c62991131307", size = 491730 },
    { url = "https://files.pythonhosted.org/packages/06/b4/d620235df9104c9049c5378027fb2692a8a51fafc775e2feae815ff99599/srsly-2.4.8-cp312-cp312-win_amd64.whl", hash = "sha256:e0b8d5722057000694edf105b8f492e7eb2f3aa6247a5f0c9170d1e0d074151c", size = 478845 },
    { url = "https://files.pythonhosted.org/packages/82/41/4d759a425297672e1e243b304aa32ffaad945d4fe3977b3bf38dac3af7a8/srsly-2.4.8-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:ec37233fe39af97b00bf20dc2ceda04d39b9ea19ce0ee605e16ece9785e11f65", size = 490901 },
    { url = "https://files.pythonhosted.org/packages/d2/dc/36bff7e940e26c6ca0b4c1ece905463b04530a2bdbc266d3e1f18ef30428/srsly-2.4.8-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:d2fd4bc081f1d6a6063396b6d97b00d98e86d9d3a3ac2949dba574a84e148080", size = 489613 },
    { url = "https://files.pythonhosted.org/packages/fb/f5/3ee20f828b5f68e48fc3db1691a902b24c6e32274238d6ec0faa20641810/srsly-2.4.8-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:7347cff1eb4ef3fc335d9d4acc89588051b2df43799e5d944696ef43da79c873", size = 491016 },
    { url = "https://files.pythonhosted.org/packages/21/38/545d49d1f4042c4d1b97e5b860730d23654dbb13911801a9ed0bfe85578c/srsly-2.4.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:5a9dc1da5cc94d77056b91ba38365c72ae08556b6345bef06257c7e9eccabafe", size = 494290 },
    { url = "https://files.pythonhosted.org/packages/4b/93/e4eb7683e742912989278c182efff5d5afb76b830414c2aae2d4c01e59e6/srsly-2.4.8-cp38-cp38-win_amd64.whl", hash = "sha256:dc0bf7b6f23c9ecb49ec0924dc645620276b41e160e9b283ed44ca004c060d79", size = 483719 },
    { url = "https://files.pythonhosted.org/packages/0d/fd/d804d99cb5d5b3f84053c454068ec66b27b4c08aa2906855cc0b9aad4015/srsly-2.4.8-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:ff8df21d00d73c371bead542cefef365ee87ca3a5660de292444021ff84e3b8c", size = 493095 },
    { url = "https://files.pythonhosted.org/packages/23/87/f6dc2625010feb7f647b0dc3b0bcb12643d0b0895fa4f265bbefbb801a99/srsly-2.4.8-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:0ac3e340e65a9fe265105705586aa56054dc3902789fcb9a8f860a218d6c0a00", size = 491541 },
    { url = "https://files.pythonhosted.org/packages/12/42/8dbb4cb8640842bc14041ff2482ddf78039df114416c338ad66e5acbe56b/srsly-2.4.8-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:06d1733f4275eff4448e96521cc7dcd8fdabd68ba9b54ca012dcfa2690db2644", size = 489290 },
    { url = "https://files.pythonhosted.org/packages/f9/81/7b25bc53fc3b95b072d258e04d82372a46dbf8f8c5b3b554ee93d7887fa5/srsly-2.4.8-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:be5b751ad88fdb58fb73871d456248c88204f213aaa3c9aab49b6a1802b3fa8d", size = 492418 },
    { url = "https://files.pythonhosted.org/packages/52/b1/970e7085fbb47fbc824adb0b0f211039ee3da01daa29a69ca99dd926dd48/srsly-2.4.8-cp39-cp39-win_amd64.whl", hash = "sha256:822a38b8cf112348f3accbc73274a94b7bf82515cb14a85ba586d126a5a72851", size = 483839 },
]

[[package]]
name = "tabula-py"
version = "2.9.3"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "distro" },
    { name = "numpy" },
    { name = "pandas" },
]
sdist = { url = "https://files.pythonhosted.org/packages/37/71/2744ce6c3b50250fce562ea6099d555bf8fdfbb3c31813aa46621e36bd8d/tabula_py-2.9.3.tar.gz", hash = "sha256:2e1a458d97f4e4422d82e9ed07c7180711efa623b158d2b7b53303e864e74834", size = 12459728 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/42/b6/d7901588dc97719101fefa79215287177f59be8af892c04cded3362195cf/tabula_py-2.9.3-py3-none-any.whl", hash = "sha256:e2c537c021ca0dc385b094e5e113f1bd5041d967bcc1532c4c3bd64755129ffe", size = 12020976 },
]

[[package]]
name = "tabulate"
version = "0.9.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/ec/fe/802052aecb21e3797b8f7902564ab6ea0d60ff8ca23952079064155d1ae1/tabulate-0.9.0.tar.gz", hash = "sha256:0095b12bf5966de529c0feb1fa08671671b3368eec77d7ef7ab114be2c068b3c", size = 81090 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/40/44/4a5f08c96eb108af5cb50b41f76142f0afa346dfa99d5296fe7202a11854/tabulate-0.9.0-py3-none-any.whl", hash = "sha256:024ca478df22e9340661486f85298cff5f6dcdba14f3813e8830015b9ed1948f", size = 35252 },
]

[[package]]
name = "termcolor"
version = "2.4.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/10/56/d7d66a84f96d804155f6ff2873d065368b25a07222a6fd51c4f24ef6d764/termcolor-2.4.0.tar.gz", hash = "sha256:aab9e56047c8ac41ed798fa36d892a37aca6b3e9159f3e0c24bc64a9b3ac7b7a", size = 12664 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d9/5f/8c716e47b3a50cbd7c146f45881e11d9414def768b7cd9c5e6650ec2a80a/termcolor-2.4.0-py3-none-any.whl", hash = "sha256:9297c0df9c99445c2412e832e882a7884038a25617c60cea2ad69488d4040d63", size = 7719 },
]

[[package]]
name = "thinc"
version = "8.2.5"
source = { registry = "https://pypi.org/simple" }
resolution-markers = [
    "python_full_version < '3.9'",
]
dependencies = [
    { name = "blis", version = "0.7.11", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version < '3.9'" },
    { name = "catalogue", marker = "python_full_version < '3.9'" },
    { name = "confection", marker = "python_full_version < '3.9'" },
    { name = "cymem", marker = "python_full_version < '3.9'" },
    { name = "murmurhash", marker = "python_full_version < '3.9'" },
    { name = "numpy", marker = "python_full_version < '3.9'" },
    { name = "packaging", marker = "python_full_version < '3.9'" },
    { name = "preshed", marker = "python_full_version < '3.9'" },
    { name = "pydantic", marker = "python_full_version < '3.9'" },
    { name = "setuptools", marker = "python_full_version < '3.9'" },
    { name = "srsly", marker = "python_full_version < '3.9'" },
    { name = "wasabi", marker = "python_full_version < '3.9'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/3b/2a/0e2e961e6152bedecca70e6833f6e827ee621efcee7496643242b506d54f/thinc-8.2.5.tar.gz", hash = "sha256:c2963791c934cc7fbd8f9b942d571cac79892ad11630bfca690a868c32752b75", size = 193031 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/a2/76/1994abe2bf5cbe5f68231fd2c177e384b19bed86268d56c1b6b2dc19e203/thinc-8.2.5-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:dc267f6aad80a681a85f50383afe91da9e2bec56fefdda86bfa2e4f529bef191", size = 843631 },
    { url = "https://files.pythonhosted.org/packages/e5/76/47e94af32943bd92d7cda4e92d185331a89116a0bf87123cc71796f21a00/thinc-8.2.5-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:d80f1e497971c9fa0938f5cc8fe607bbe87356b405fb7bbc3ff9f32fb4eed3bb", size = 779045 },
    { url = "https://files.pythonhosted.org/packages/c0/76/7dcce5cd2b5a9fe92b76767d688f17fe459543c13893e588545db3c0dc85/thinc-8.2.5-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0933adbd3e65e30d3bef903e77a368bc8a41bed34b0d18df6d4fc0536908e21f", size = 868726 },
    { url = "https://files.pythonhosted.org/packages/d7/b5/ad029dc7346381922b7fd655b3fc39009cf675766345d8e13f9f8282bde8/thinc-8.2.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:54bac2ba23b208fdaf267cd6113d26a5ecbb3b0e0c6015dff784ae6a9c5e78ca", size = 922374 },
    { url = "https://files.pythonhosted.org/packages/f6/3e/fb96407db92a15b5c0feb0deb930c4c223bdb772e04b51b9798a86059a26/thinc-8.2.5-cp310-cp310-win_amd64.whl", hash = "sha256:399260197ef3f8d9600315fc5b5a1d5940400fceb0361de642e9fe3506d82385", size = 1482115 },
    { url = "https://files.pythonhosted.org/packages/76/37/8acfeba6bb25b08c2a33bfae5301a5df4dc164d2d17040bebbcf66d783a1/thinc-8.2.5-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:a75c0de3340afed594beda293661de145f3842873df56d9989bc338148f13fab", size = 839072 },
    { url = "https://files.pythonhosted.org/packages/e9/eb/753a85875fb0261c83ca87a1a36d41346bde662c3a029ace9d68fe32bc5b/thinc-8.2.5-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:6b166d1a22003ee03bc236370fff2884744c1fb758a6209a2512d305773d07d7", size = 773885 },
    { url = "https://files.pythonhosted.org/packages/34/47/06810a1bd9d3287076ba17299abec82c8c643563661b1af9b1d5d9aeab38/thinc-8.2.5-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:34db8a023b9f70645fdf06c510584ba6d8b97ec53c1e094f42d95652bf8c875f", size = 868332 },
    { url = "https://files.pythonhosted.org/packages/1a/19/cd73e3b5f22d5d9399f6f2931ab0fb985415f34030dcfead070181866761/thinc-8.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8901b30db1071ea8d5e4437429c8632535bf5ed87938ce3bb5057bed9f15aed8", size = 920152 },
    { url = "https://files.pythonhosted.org/packages/5e/0e/5e7b24e046e0725eafc37ded0cd9bfaf789efb894101a7aca8a73dba81de/thinc-8.2.5-cp311-cp311-win_amd64.whl", hash = "sha256:8ef5d46d62e31f2450224ab22391a606cf427b13e20cfc570f70422e2f333872", size = 1480120 },
    { url = "https://files.pythonhosted.org/packages/a4/9d/d2ed3aef9bb75ab86c521bde58f897db6a572c9fd639448173b516269a69/thinc-8.2.5-cp312-cp312-macosx_10_9_x86_64.whl", hash = "sha256:9fc26697e2358c71a5fe243d52e98ae67ee1a3b314eead5031845b6d1c0d121c", size = 824150 },
    { url = "https://files.pythonhosted.org/packages/66/a6/30ed1edb2adab585b5f7d5d99e89b5be3014dcbf3f4e263997b2c2426681/thinc-8.2.5-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:8e299d4dc41107385d6d14d8604a060825798a031cabe2b894b22f9d75d9eaad", size = 760640 },
    { url = "https://files.pythonhosted.org/packages/82/ce/aaff1f39bcc1e9a97bec5f3d20aa771c005a9faff3944fc56c7492c24466/thinc-8.2.5-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:e8a8f2f249f2be9a5ce2a81a6efe7503b68be7b57e47ad54ab28204e1f0c723b", size = 818820 },
    { url = "https://files.pythonhosted.org/packages/d7/fa/c96b01e46e5962d02de1206e497fda2902aef2b8ffb2926d66d5f0159040/thinc-8.2.5-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:87e729f33c76ec6df9b375989743252ab880d79f3a2b4175169b21dece90f102", size = 865047 },
    { url = "https://files.pythonhosted.org/packages/cd/26/306b8bedb678c52464ed00e576edf9d365fce0bcae597a333bdad9fb5d67/thinc-8.2.5-cp312-cp312-win_amd64.whl", hash = "sha256:c5f750ea2dd32ca6d46947025dacfc0f6037340c4e5f7adb9af84c75f65aa7d8", size = 1447893 },
    { url = "https://files.pythonhosted.org/packages/66/d3/bcaec5ef068f81f8c38ba31bbc9947086e44c24bdc86fca2c7cba76eabf7/thinc-8.2.5-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:bb97e2f699a3df16112ef5460cbfb0c9189a5fbc0e76bcf170ed7d995bdce367", size = 847916 },
    { url = "https://files.pythonhosted.org/packages/f0/b9/44994ada2968523788b1bc9a7d424ea52a4685adc85f5dfff05b0dc1c8cf/thinc-8.2.5-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:5c78fb218273894168d1ca2dd3a20f28dba5a7fa698c4f2a2fc425eda2086cfc", size = 780529 },
    { url = "https://files.pythonhosted.org/packages/13/e9/8a915d106e6a255aca57f3573e7807eb1faafac29f4aeea2b4c14a6dc833/thinc-8.2.5-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:cdc27da534807a2addd1c3d2a3d19f99e3eb67fdbce81c21f4e4c8bfa94ac15b", size = 882069 },
    { url = "https://files.pythonhosted.org/packages/5a/19/d03443aea8aba65a6f882ebcade9a8d486722f716be1d02e9132165fc139/thinc-8.2.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:5b884e56eaeb9e5c7bfeb1c8810a3cbad19a599b33b9f3152b90b67f468471ac", size = 937812 },
    { url = "https://files.pythonhosted.org/packages/64/2f/3f9456b18d32f5d22fe1bfe036f9ddab9880463234b5b17940a7b79983f1/thinc-8.2.5-cp39-cp39-win_amd64.whl", hash = "sha256:df2138cf379061017ecb8bf609a8857e7904709ef0a9a2252783c16f67a2b749", size = 1491844 },
]

[[package]]
name = "thinc"
version = "8.3.4"
source = { registry = "https://pypi.org/simple" }
resolution-markers = [
    "python_full_version == '3.9.*'",
    "python_full_version == '3.10.*'",
    "python_full_version == '3.11.*'",
    "python_full_version >= '3.12'",
]
dependencies = [
    { name = "blis", version = "1.2.0", source = { registry = "https://pypi.org/simple" }, marker = "python_full_version >= '3.9'" },
    { name = "catalogue", marker = "python_full_version >= '3.9'" },
    { name = "confection", marker = "python_full_version >= '3.9'" },
    { name = "cymem", marker = "python_full_version >= '3.9'" },
    { name = "murmurhash", marker = "python_full_version >= '3.9'" },
    { name = "numpy", marker = "python_full_version >= '3.9'" },
    { name = "packaging", marker = "python_full_version >= '3.9'" },
    { name = "preshed", marker = "python_full_version >= '3.9'" },
    { name = "pydantic", marker = "python_full_version >= '3.9'" },
    { name = "setuptools", marker = "python_full_version >= '3.9'" },
    { name = "srsly", marker = "python_full_version >= '3.9'" },
    { name = "wasabi", marker = "python_full_version >= '3.9'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b5/ff/60c9bcfe28e56c905aac8e61a838c7afe5dc3073c9beed0b63a26ace0bb7/thinc-8.3.4.tar.gz", hash = "sha256:b5925482498bbb6dca0771e375b35c915818f735891e93d93a662dab15f6ffd8", size = 193903 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f9/c8/13db2e346d2e199f679fc3f620da53af561ea74b43b38e5b4a0a79a12860/thinc-8.3.4-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:916ea79a7c7462664be9435679b7769b4fc1ecea3886db6da6118e4eb5cc8c8b", size = 843884 },
    { url = "https://files.pythonhosted.org/packages/ff/32/c25d68b5030f91c8506dfbba706f24b1cd1d0d4950cb0e3de17d176a5411/thinc-8.3.4-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:6c985ce9cf82a611f4f348c721372d073537ca0e8b7bbb8bd865c1598ddd79d1", size = 779384 },
    { url = "https://files.pythonhosted.org/packages/5d/5f/8a88959191f8c9f7eed61a7efec45f0222720c6318c09f9a058609810128/thinc-8.3.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:2fff4b30f8513832d13a31486e9074a7020de3d48f8a3d1527e369c242d6ebe9", size = 3673814 },
    { url = "https://files.pythonhosted.org/packages/6f/4f/ea998b85cece6c2441a2416c795476776a5c11f7f2c7fb478a00d407d7f6/thinc-8.3.4-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:a9ee46d19b9f4cac13a5539f97978c857338a31e4bf8d9b3a7741dcbc792220f", size = 4685083 },
    { url = "https://files.pythonhosted.org/packages/0b/d0/295add6fcac8b633877a3a8d4b323e8cac4f4078f4f48910deb8c29666cb/thinc-8.3.4-cp310-cp310-win_amd64.whl", hash = "sha256:d08529d53f8652e15e4f3c0f6953e73f85cc71d3b6e4750d2d9ace23616dbe8f", size = 1492082 },
    { url = "https://files.pythonhosted.org/packages/85/47/68187c78a04cdc31cbd3ae393068f994b60476b5ecac6dfe7d04b124aacf/thinc-8.3.4-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:a8bb4b47358a1855803b375f4432cefdf373f46ef249b554418d2e77c7323040", size = 839320 },
    { url = "https://files.pythonhosted.org/packages/49/ea/066dd415e61fcef20083bbca41c2c02e640fea71326531f2619708efee1e/thinc-8.3.4-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:00ed92f9a34b9794f51fcd48467c863f4eb7c5b41559aef6ef3c980c21378fec", size = 774196 },
    { url = "https://files.pythonhosted.org/packages/8c/68/36c1a92a374891e0d496677c59f5f9fdc1e57bbb214c487bb8bb3e9290c2/thinc-8.3.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:85691fca84a6a1506f7ddbd2c1706a5524d56f65582e76b2e260a06d9e83e86d", size = 3922504 },
    { url = "https://files.pythonhosted.org/packages/ec/8a/48e463240a586e91f83c87660986e520aa91fbd839f6631ee9bc0fbb3cbd/thinc-8.3.4-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:eae1573fc19e514defc1bfd4f93f0b4bfc1dcefdb6d70bad1863825747f24800", size = 4932946 },
    { url = "https://files.pythonhosted.org/packages/d9/98/f910b8d8113ab9b955a68e9bbf0d5bd0e828f22dd6d3c226af6ec3970817/thinc-8.3.4-cp311-cp311-win_amd64.whl", hash = "sha256:81e8638f9bdc38e366674acc4b63cf7c6267266a15477963a5db21b3d9f1aa36", size = 1490133 },
    { url = "https://files.pythonhosted.org/packages/90/ff/d1b5d7e1a7f95581e9a736f50a5a9aff72327ddbbc629a68070c36acefd9/thinc-8.3.4-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:c9da6375b106df5186bd2bfd1273bc923c01ab7d482f8942e4ee528a28965c3a", size = 825099 },
    { url = "https://files.pythonhosted.org/packages/ce/0b/d207c917886dc40671361de0880ec3ea0443a718aae9dbb0a50ac0849f92/thinc-8.3.4-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:07091c6b5faace50857c4cf0982204969d77388d0a6f156dd2442297dceeb838", size = 761024 },
    { url = "https://files.pythonhosted.org/packages/4b/a3/3ec5e9d7cbebc3257b8223a3d188216b91ab6ec1e66b6fdd99d22394bc62/thinc-8.3.4-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fd40ad71bcd8b1b9daa0462e1255b1c1e86e901c2fd773966601f44a95878032", size = 3710390 },
    { url = "https://files.pythonhosted.org/packages/40/ee/955c74e4e6ff2f694c99dcbbf7be8d478a8868503aeb3474517277c07667/thinc-8.3.4-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:eb10823b3a3f1c6440998b11bf9a3571dd859feaed0fdb510a1c1097d9dc6a86", size = 4731524 },
    { url = "https://files.pythonhosted.org/packages/a4/44/3786431e5c1eeebed3d7a4c97122896ca6d4a502b03d02c2171c417052fd/thinc-8.3.4-cp312-cp312-win_amd64.whl", hash = "sha256:b5e5e7bf5dae142fd50ed9785971292c4aab4d9ed18e4947653b6a0584d5227c", size = 1455883 },
    { url = "https://files.pythonhosted.org/packages/30/2f/b1d2da14d3f24bea660d48ad150dc816581a03a15c608fa3f84fe9402abc/thinc-8.3.4-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:960366f41f0d5c4cecdf8610d03bdf80b14a959a7fe94008b788a5336d388781", size = 848021 },
    { url = "https://files.pythonhosted.org/packages/5b/de/2e4a4e41c4e3d7b1bf8bceedc9fb0123cf479c670f9d6742b72d5779cbec/thinc-8.3.4-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:d85babfae9b31e2e20f4884787b1391ca126f84e9b9f7f498990c07f7019f848", size = 780832 },
    { url = "https://files.pythonhosted.org/packages/0f/94/acdd6fa476c12d94364414ce2fe42558236cf0e6f23d4aa1959ed5f94eff/thinc-8.3.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8791c87857c474499455bfdd3f58432e2dc1e2cdadf46eb2f3c2293851a8a837", size = 3732986 },
    { url = "https://files.pythonhosted.org/packages/f7/2f/5cf44a5777ae9a6c7b5509ab1c87a23ea1bfc42c8ccb0d6e0b35d674a413/thinc-8.3.4-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:c95456cbc1344ab9041c2e16c9fa065ac2b56520929a5a594b3c80ddda136b1e", size = 4738084 },
    { url = "https://files.pythonhosted.org/packages/ea/f5/9bb31d5994bc409baffd57248d870c9fd3a697e260933ad12e358846032b/thinc-8.3.4-cp39-cp39-win_amd64.whl", hash = "sha256:11e6e14c1bfdb7c456f3da19dcf94def8304a7b279329f328e55062a292bc79f", size = 1503215 },
]

[[package]]
name = "threadpoolctl"
version = "3.5.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/bd/55/b5148dcbf72f5cde221f8bfe3b6a540da7aa1842f6b491ad979a6c8b84af/threadpoolctl-3.5.0.tar.gz", hash = "sha256:082433502dd922bf738de0d8bcc4fdcbf0979ff44c42bd40f5af8a282f6fa107", size = 41936 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/4b/2c/ffbf7a134b9ab11a67b0cf0726453cedd9c5043a4fe7a35d1cefa9a1bcfb/threadpoolctl-3.5.0-py3-none-any.whl", hash = "sha256:56c1e26c150397e58c4926da8eeee87533b1e32bef131bd4bf6a2f45f3185467", size = 18414 },
]

[[package]]
name = "tomli"
version = "2.2.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/18/87/302344fed471e44a87289cf4967697d07e532f2421fdaf868a303cbae4ff/tomli-2.2.1.tar.gz", hash = "sha256:cd45e1dc79c835ce60f7404ec8119f2eb06d38b1deba146f07ced3bbc44505ff", size = 17175 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/43/ca/75707e6efa2b37c77dadb324ae7d9571cb424e61ea73fad7c56c2d14527f/tomli-2.2.1-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:678e4fa69e4575eb77d103de3df8a895e1591b48e740211bd1067378c69e8249", size = 131077 },
    { url = "https://files.pythonhosted.org/packages/c7/16/51ae563a8615d472fdbffc43a3f3d46588c264ac4f024f63f01283becfbb/tomli-2.2.1-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:023aa114dd824ade0100497eb2318602af309e5a55595f76b626d6d9f3b7b0a6", size = 123429 },
    { url = "https://files.pythonhosted.org/packages/f1/dd/4f6cd1e7b160041db83c694abc78e100473c15d54620083dbd5aae7b990e/tomli-2.2.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:ece47d672db52ac607a3d9599a9d48dcb2f2f735c6c2d1f34130085bb12b112a", size = 226067 },
    { url = "https://files.pythonhosted.org/packages/a9/6b/c54ede5dc70d648cc6361eaf429304b02f2871a345bbdd51e993d6cdf550/tomli-2.2.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:6972ca9c9cc9f0acaa56a8ca1ff51e7af152a9f87fb64623e31d5c83700080ee", size = 236030 },
    { url = "https://files.pythonhosted.org/packages/1f/47/999514fa49cfaf7a92c805a86c3c43f4215621855d151b61c602abb38091/tomli-2.2.1-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:c954d2250168d28797dd4e3ac5cf812a406cd5a92674ee4c8f123c889786aa8e", size = 240898 },
    { url = "https://files.pythonhosted.org/packages/73/41/0a01279a7ae09ee1573b423318e7934674ce06eb33f50936655071d81a24/tomli-2.2.1-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:8dd28b3e155b80f4d54beb40a441d366adcfe740969820caf156c019fb5c7ec4", size = 229894 },
    { url = "https://files.pythonhosted.org/packages/55/18/5d8bc5b0a0362311ce4d18830a5d28943667599a60d20118074ea1b01bb7/tomli-2.2.1-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:e59e304978767a54663af13c07b3d1af22ddee3bb2fb0618ca1593e4f593a106", size = 245319 },
    { url = "https://files.pythonhosted.org/packages/92/a3/7ade0576d17f3cdf5ff44d61390d4b3febb8a9fc2b480c75c47ea048c646/tomli-2.2.1-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:33580bccab0338d00994d7f16f4c4ec25b776af3ffaac1ed74e0b3fc95e885a8", size = 238273 },
    { url = "https://files.pythonhosted.org/packages/72/6f/fa64ef058ac1446a1e51110c375339b3ec6be245af9d14c87c4a6412dd32/tomli-2.2.1-cp311-cp311-win32.whl", hash = "sha256:465af0e0875402f1d226519c9904f37254b3045fc5084697cefb9bdde1ff99ff", size = 98310 },
    { url = "https://files.pythonhosted.org/packages/6a/1c/4a2dcde4a51b81be3530565e92eda625d94dafb46dbeb15069df4caffc34/tomli-2.2.1-cp311-cp311-win_amd64.whl", hash = "sha256:2d0f2fdd22b02c6d81637a3c95f8cd77f995846af7414c5c4b8d0545afa1bc4b", size = 108309 },
    { url = "https://files.pythonhosted.org/packages/52/e1/f8af4c2fcde17500422858155aeb0d7e93477a0d59a98e56cbfe75070fd0/tomli-2.2.1-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:4a8f6e44de52d5e6c657c9fe83b562f5f4256d8ebbfe4ff922c495620a7f6cea", size = 132762 },
    { url = "https://files.pythonhosted.org/packages/03/b8/152c68bb84fc00396b83e7bbddd5ec0bd3dd409db4195e2a9b3e398ad2e3/tomli-2.2.1-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:8d57ca8095a641b8237d5b079147646153d22552f1c637fd3ba7f4b0b29167a8", size = 123453 },
    { url = "https://files.pythonhosted.org/packages/c8/d6/fc9267af9166f79ac528ff7e8c55c8181ded34eb4b0e93daa767b8841573/tomli-2.2.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4e340144ad7ae1533cb897d406382b4b6fede8890a03738ff1683af800d54192", size = 233486 },
    { url = "https://files.pythonhosted.org/packages/5c/51/51c3f2884d7bab89af25f678447ea7d297b53b5a3b5730a7cb2ef6069f07/tomli-2.2.1-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:db2b95f9de79181805df90bedc5a5ab4c165e6ec3fe99f970d0e302f384ad222", size = 242349 },
    { url = "https://files.pythonhosted.org/packages/ab/df/bfa89627d13a5cc22402e441e8a931ef2108403db390ff3345c05253935e/tomli-2.2.1-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:40741994320b232529c802f8bc86da4e1aa9f413db394617b9a256ae0f9a7f77", size = 252159 },
    { url = "https://files.pythonhosted.org/packages/9e/6e/fa2b916dced65763a5168c6ccb91066f7639bdc88b48adda990db10c8c0b/tomli-2.2.1-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:400e720fe168c0f8521520190686ef8ef033fb19fc493da09779e592861b78c6", size = 237243 },
    { url = "https://files.pythonhosted.org/packages/b4/04/885d3b1f650e1153cbb93a6a9782c58a972b94ea4483ae4ac5cedd5e4a09/tomli-2.2.1-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:02abe224de6ae62c19f090f68da4e27b10af2b93213d36cf44e6e1c5abd19fdd", size = 259645 },
    { url = "https://files.pythonhosted.org/packages/9c/de/6b432d66e986e501586da298e28ebeefd3edc2c780f3ad73d22566034239/tomli-2.2.1-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:b82ebccc8c8a36f2094e969560a1b836758481f3dc360ce9a3277c65f374285e", size = 244584 },
    { url = "https://files.pythonhosted.org/packages/1c/9a/47c0449b98e6e7d1be6cbac02f93dd79003234ddc4aaab6ba07a9a7482e2/tomli-2.2.1-cp312-cp312-win32.whl", hash = "sha256:889f80ef92701b9dbb224e49ec87c645ce5df3fa2cc548664eb8a25e03127a98", size = 98875 },
    { url = "https://files.pythonhosted.org/packages/ef/60/9b9638f081c6f1261e2688bd487625cd1e660d0a85bd469e91d8db969734/tomli-2.2.1-cp312-cp312-win_amd64.whl", hash = "sha256:7fc04e92e1d624a4a63c76474610238576942d6b8950a2d7f908a340494e67e4", size = 109418 },
    { url = "https://files.pythonhosted.org/packages/04/90/2ee5f2e0362cb8a0b6499dc44f4d7d48f8fff06d28ba46e6f1eaa61a1388/tomli-2.2.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:f4039b9cbc3048b2416cc57ab3bda989a6fcf9b36cf8937f01a6e731b64f80d7", size = 132708 },
    { url = "https://files.pythonhosted.org/packages/c0/ec/46b4108816de6b385141f082ba99e315501ccd0a2ea23db4a100dd3990ea/tomli-2.2.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:286f0ca2ffeeb5b9bd4fcc8d6c330534323ec51b2f52da063b11c502da16f30c", size = 123582 },
    { url = "https://files.pythonhosted.org/packages/a0/bd/b470466d0137b37b68d24556c38a0cc819e8febe392d5b199dcd7f578365/tomli-2.2.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:a92ef1a44547e894e2a17d24e7557a5e85a9e1d0048b0b5e7541f76c5032cb13", size = 232543 },
    { url = "https://files.pythonhosted.org/packages/d9/e5/82e80ff3b751373f7cead2815bcbe2d51c895b3c990686741a8e56ec42ab/tomli-2.2.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9316dc65bed1684c9a98ee68759ceaed29d229e985297003e494aa825ebb0281", size = 241691 },
    { url = "https://files.pythonhosted.org/packages/05/7e/2a110bc2713557d6a1bfb06af23dd01e7dde52b6ee7dadc589868f9abfac/tomli-2.2.1-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:e85e99945e688e32d5a35c1ff38ed0b3f41f43fad8df0bdf79f72b2ba7bc5272", size = 251170 },
    { url = "https://files.pythonhosted.org/packages/64/7b/22d713946efe00e0adbcdfd6d1aa119ae03fd0b60ebed51ebb3fa9f5a2e5/tomli-2.2.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:ac065718db92ca818f8d6141b5f66369833d4a80a9d74435a268c52bdfa73140", size = 236530 },
    { url = "https://files.pythonhosted.org/packages/38/31/3a76f67da4b0cf37b742ca76beaf819dca0ebef26d78fc794a576e08accf/tomli-2.2.1-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:d920f33822747519673ee656a4b6ac33e382eca9d331c87770faa3eef562aeb2", size = 258666 },
    { url = "https://files.pythonhosted.org/packages/07/10/5af1293da642aded87e8a988753945d0cf7e00a9452d3911dd3bb354c9e2/tomli-2.2.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:a198f10c4d1b1375d7687bc25294306e551bf1abfa4eace6650070a5c1ae2744", size = 243954 },
    { url = "https://files.pythonhosted.org/packages/5b/b9/1ed31d167be802da0fc95020d04cd27b7d7065cc6fbefdd2f9186f60d7bd/tomli-2.2.1-cp313-cp313-win32.whl", hash = "sha256:d3f5614314d758649ab2ab3a62d4f2004c825922f9e370b29416484086b264ec", size = 98724 },
    { url = "https://files.pythonhosted.org/packages/c7/32/b0963458706accd9afcfeb867c0f9175a741bf7b19cd424230714d722198/tomli-2.2.1-cp313-cp313-win_amd64.whl", hash = "sha256:a38aa0308e754b0e3c67e344754dff64999ff9b513e691d0e786265c93583c69", size = 109383 },
    { url = "https://files.pythonhosted.org/packages/6e/c2/61d3e0f47e2b74ef40a68b9e6ad5984f6241a942f7cd3bbfbdbd03861ea9/tomli-2.2.1-py3-none-any.whl", hash = "sha256:cb55c73c5f4408779d0cf3eef9f762b9c9f147a77de7b258bef0a5628adc85cc", size = 14257 },
]

[[package]]
name = "tqdm"
version = "4.67.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "colorama", marker = "platform_system == 'Windows'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a8/4b/29b4ef32e036bb34e4ab51796dd745cdba7ed47ad142a9f4a1eb8e0c744d/tqdm-4.67.1.tar.gz", hash = "sha256:f8aef9c52c08c13a65f30ea34f4e5aac3fd1a34959879d7e59e63027286627f2", size = 169737 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl", hash = "sha256:26445eca388f82e72884e0d580d5464cd801a3ea01e63e5601bdff9ba6a48de2", size = 78540 },
]

[[package]]
name = "typer"
version = "0.15.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "click" },
    { name = "rich" },
    { name = "shellingham" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/8b/6f/3991f0f1c7fcb2df31aef28e0594d8d54b05393a0e4e34c65e475c2a5d41/typer-0.15.2.tar.gz", hash = "sha256:ab2fab47533a813c49fe1f16b1a370fd5819099c00b119e0633df65f22144ba5", size = 100711 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7f/fc/5b29fea8cee020515ca82cc68e3b8e1e34bb19a3535ad854cac9257b414c/typer-0.15.2-py3-none-any.whl", hash = "sha256:46a499c6107d645a9c13f7ee46c5d5096cae6f5fc57dd11eccbbb9ae3e44ddfc", size = 45061 },
]

[[package]]
name = "types-html5lib"
version = "1.1.11.20241018"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/b6/9d/f6fbcc8246f5e46845b4f989c4e17e6fb3ce572f7065b185e515bf8a3be7/types-html5lib-1.1.11.20241018.tar.gz", hash = "sha256:98042555ff78d9e3a51c77c918b1041acbb7eb6c405408d8a9e150ff5beccafa", size = 11370 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/ba/7c/f862b1dc31268ef10fe95b43dcdf216ba21a592fafa2d124445cd6b92e93/types_html5lib-1.1.11.20241018-py3-none-any.whl", hash = "sha256:3f1e064d9ed2c289001ae6392c84c93833abb0816165c6ff0abfc304a779f403", size = 17292 },
]

[[package]]
name = "types-lxml"
version = "2025.3.4"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "beautifulsoup4" },
    { name = "cssselect" },
    { name = "types-html5lib" },
    { name = "typing-extensions", marker = "python_full_version < '3.13'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/78/18/68b393281eecab7fec4aa9452e52217ad0580ba93f1b8f585d1274e95a24/types_lxml-2025.3.4.tar.gz", hash = "sha256:aee7e89b33d9fd3656aa4ef3ea4073fcef82f430e2c02ab7b803abce78fb2f94", size = 141112 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/32/3a/411f44d0d0256b14aa4f4875563a7fc040ea0d27d9d3c0d6771b25bd59b9/types_lxml-2025.3.4-py3-none-any.whl", hash = "sha256:ef94bd705ca0f4b613ea4c72d614c3d456d833df4034e9b488f9f8ae000bed0e", size = 91543 },
]

[[package]]
name = "typing-extensions"
version = "4.12.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/df/db/f35a00659bc03fec321ba8bce9420de607a1d37f8342eee1863174c69557/typing_extensions-4.12.2.tar.gz", hash = "sha256:1a7ead55c7e559dd4dee8856e3a88b41225abfe1ce8df57b7c13915fe121ffb8", size = 85321 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/26/9f/ad63fc0248c5379346306f8668cda6e2e2e9c95e01216d2b8ffd9ff037d0/typing_extensions-4.12.2-py3-none-any.whl", hash = "sha256:04e5ca0351e0f3f85c6853954072df659d0d13fac324d0072316b67d7794700d", size = 37438 },
]

[[package]]
name = "tzdata"
version = "2025.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/43/0f/fa4723f22942480be4ca9527bbde8d43f6c3f2fe8412f00e7f5f6746bc8b/tzdata-2025.1.tar.gz", hash = "sha256:24894909e88cdb28bd1636c6887801df64cb485bd593f2fd83ef29075a81d694", size = 194950 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/0f/dd/84f10e23edd882c6f968c21c2434fe67bd4a528967067515feca9e611e5e/tzdata-2025.1-py2.py3-none-any.whl", hash = "sha256:7e127113816800496f027041c570f50bcd464a020098a3b6b199517772303639", size = 346762 },
]

[[package]]
name = "urllib3"
version = "2.2.3"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/ed/63/22ba4ebfe7430b76388e7cd448d5478814d3032121827c12a2cc287e2260/urllib3-2.2.3.tar.gz", hash = "sha256:e7d814a81dad81e6caf2ec9fdedb284ecc9c73076b62654547cc64ccdcae26e9", size = 300677 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/ce/d9/5f4c13cecde62396b0d3fe530a50ccea91e7dfc1ccf0e09c228841bb5ba8/urllib3-2.2.3-py3-none-any.whl", hash = "sha256:ca899ca043dcb1bafa3e262d73aa25c465bfb49e0bd9dd5d59f1d0acba2f8fac", size = 126338 },
]

[[package]]
name = "wasabi"
version = "1.1.3"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "colorama", marker = "sys_platform == 'win32'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/ac/f9/054e6e2f1071e963b5e746b48d1e3727470b2a490834d18ad92364929db3/wasabi-1.1.3.tar.gz", hash = "sha256:4bb3008f003809db0c3e28b4daf20906ea871a2bb43f9914197d540f4f2e0878", size = 30391 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/06/7c/34330a89da55610daa5f245ddce5aab81244321101614751e7537f125133/wasabi-1.1.3-py3-none-any.whl", hash = "sha256:f76e16e8f7e79f8c4c8be49b4024ac725713ab10cd7f19350ad18a8e3f71728c", size = 27880 },
]

[[package]]
name = "weasel"
version = "0.4.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "cloudpathlib" },
    { name = "confection" },
    { name = "packaging" },
    { name = "pydantic" },
    { name = "requests" },
    { name = "smart-open" },
    { name = "srsly" },
    { name = "typer" },
    { name = "wasabi" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a7/1a/9c522dd61b52939c217925d3e55c95f9348b73a66a956f52608e1e59a2c0/weasel-0.4.1.tar.gz", hash = "sha256:aabc210f072e13f6744e5c3a28037f93702433405cd35673f7c6279147085aa9", size = 38417 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/2a/87/abd57374044e1f627f0a905ac33c1a7daab35a3a815abfea4e1bafd3fdb1/weasel-0.4.1-py3-none-any.whl", hash = "sha256:24140a090ea1ac512a2b2f479cc64192fd1d527a7f3627671268d08ed5ac418c", size = 50270 },
]

[[package]]
name = "wrapt"
version = "1.17.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/c3/fc/e91cc220803d7bc4db93fb02facd8461c37364151b8494762cc88b0fbcef/wrapt-1.17.2.tar.gz", hash = "sha256:41388e9d4d1522446fe79d3213196bd9e3b301a336965b9e27ca2788ebd122f3", size = 55531 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/5a/d1/1daec934997e8b160040c78d7b31789f19b122110a75eca3d4e8da0049e1/wrapt-1.17.2-cp310-cp310-macosx_10_9_universal2.whl", hash = "sha256:3d57c572081fed831ad2d26fd430d565b76aa277ed1d30ff4d40670b1c0dd984", size = 53307 },
    { url = "https://files.pythonhosted.org/packages/1b/7b/13369d42651b809389c1a7153baa01d9700430576c81a2f5c5e460df0ed9/wrapt-1.17.2-cp310-cp310-macosx_10_9_x86_64.whl", hash = "sha256:b5e251054542ae57ac7f3fba5d10bfff615b6c2fb09abeb37d2f1463f841ae22", size = 38486 },
    { url = "https://files.pythonhosted.org/packages/62/bf/e0105016f907c30b4bd9e377867c48c34dc9c6c0c104556c9c9126bd89ed/wrapt-1.17.2-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:80dd7db6a7cb57ffbc279c4394246414ec99537ae81ffd702443335a61dbf3a7", size = 38777 },
    { url = "https://files.pythonhosted.org/packages/27/70/0f6e0679845cbf8b165e027d43402a55494779295c4b08414097b258ac87/wrapt-1.17.2-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0a6e821770cf99cc586d33833b2ff32faebdbe886bd6322395606cf55153246c", size = 83314 },
    { url = "https://files.pythonhosted.org/packages/0f/77/0576d841bf84af8579124a93d216f55d6f74374e4445264cb378a6ed33eb/wrapt-1.17.2-cp310-cp310-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:b60fb58b90c6d63779cb0c0c54eeb38941bae3ecf7a73c764c52c88c2dcb9d72", size = 74947 },
    { url = "https://files.pythonhosted.org/packages/90/ec/00759565518f268ed707dcc40f7eeec38637d46b098a1f5143bff488fe97/wrapt-1.17.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b870b5df5b71d8c3359d21be8f0d6c485fa0ebdb6477dda51a1ea54a9b558061", size = 82778 },
    { url = "https://files.pythonhosted.org/packages/f8/5a/7cffd26b1c607b0b0c8a9ca9d75757ad7620c9c0a9b4a25d3f8a1480fafc/wrapt-1.17.2-cp310-cp310-musllinux_1_2_aarch64.whl", hash = "sha256:4011d137b9955791f9084749cba9a367c68d50ab8d11d64c50ba1688c9b457f2", size = 81716 },
    { url = "https://files.pythonhosted.org/packages/7e/09/dccf68fa98e862df7e6a60a61d43d644b7d095a5fc36dbb591bbd4a1c7b2/wrapt-1.17.2-cp310-cp310-musllinux_1_2_i686.whl", hash = "sha256:1473400e5b2733e58b396a04eb7f35f541e1fb976d0c0724d0223dd607e0f74c", size = 74548 },
    { url = "https://files.pythonhosted.org/packages/b7/8e/067021fa3c8814952c5e228d916963c1115b983e21393289de15128e867e/wrapt-1.17.2-cp310-cp310-musllinux_1_2_x86_64.whl", hash = "sha256:3cedbfa9c940fdad3e6e941db7138e26ce8aad38ab5fe9dcfadfed9db7a54e62", size = 81334 },
    { url = "https://files.pythonhosted.org/packages/4b/0d/9d4b5219ae4393f718699ca1c05f5ebc0c40d076f7e65fd48f5f693294fb/wrapt-1.17.2-cp310-cp310-win32.whl", hash = "sha256:582530701bff1dec6779efa00c516496968edd851fba224fbd86e46cc6b73563", size = 36427 },
    { url = "https://files.pythonhosted.org/packages/72/6a/c5a83e8f61aec1e1aeef939807602fb880e5872371e95df2137142f5c58e/wrapt-1.17.2-cp310-cp310-win_amd64.whl", hash = "sha256:58705da316756681ad3c9c73fd15499aa4d8c69f9fd38dc8a35e06c12468582f", size = 38774 },
    { url = "https://files.pythonhosted.org/packages/cd/f7/a2aab2cbc7a665efab072344a8949a71081eed1d2f451f7f7d2b966594a2/wrapt-1.17.2-cp311-cp311-macosx_10_9_universal2.whl", hash = "sha256:ff04ef6eec3eee8a5efef2401495967a916feaa353643defcc03fc74fe213b58", size = 53308 },
    { url = "https://files.pythonhosted.org/packages/50/ff/149aba8365fdacef52b31a258c4dc1c57c79759c335eff0b3316a2664a64/wrapt-1.17.2-cp311-cp311-macosx_10_9_x86_64.whl", hash = "sha256:4db983e7bca53819efdbd64590ee96c9213894272c776966ca6306b73e4affda", size = 38488 },
    { url = "https://files.pythonhosted.org/packages/65/46/5a917ce85b5c3b490d35c02bf71aedaa9f2f63f2d15d9949cc4ba56e8ba9/wrapt-1.17.2-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:9abc77a4ce4c6f2a3168ff34b1da9b0f311a8f1cfd694ec96b0603dff1c79438", size = 38776 },
    { url = "https://files.pythonhosted.org/packages/ca/74/336c918d2915a4943501c77566db41d1bd6e9f4dbc317f356b9a244dfe83/wrapt-1.17.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0b929ac182f5ace000d459c59c2c9c33047e20e935f8e39371fa6e3b85d56f4a", size = 83776 },
    { url = "https://files.pythonhosted.org/packages/09/99/c0c844a5ccde0fe5761d4305485297f91d67cf2a1a824c5f282e661ec7ff/wrapt-1.17.2-cp311-cp311-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:f09b286faeff3c750a879d336fb6d8713206fc97af3adc14def0cdd349df6000", size = 75420 },
    { url = "https://files.pythonhosted.org/packages/b4/b0/9fc566b0fe08b282c850063591a756057c3247b2362b9286429ec5bf1721/wrapt-1.17.2-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:1a7ed2d9d039bd41e889f6fb9364554052ca21ce823580f6a07c4ec245c1f5d6", size = 83199 },
    { url = "https://files.pythonhosted.org/packages/9d/4b/71996e62d543b0a0bd95dda485219856def3347e3e9380cc0d6cf10cfb2f/wrapt-1.17.2-cp311-cp311-musllinux_1_2_aarch64.whl", hash = "sha256:129a150f5c445165ff941fc02ee27df65940fcb8a22a61828b1853c98763a64b", size = 82307 },
    { url = "https://files.pythonhosted.org/packages/39/35/0282c0d8789c0dc9bcc738911776c762a701f95cfe113fb8f0b40e45c2b9/wrapt-1.17.2-cp311-cp311-musllinux_1_2_i686.whl", hash = "sha256:1fb5699e4464afe5c7e65fa51d4f99e0b2eadcc176e4aa33600a3df7801d6662", size = 75025 },
    { url = "https://files.pythonhosted.org/packages/4f/6d/90c9fd2c3c6fee181feecb620d95105370198b6b98a0770cba090441a828/wrapt-1.17.2-cp311-cp311-musllinux_1_2_x86_64.whl", hash = "sha256:9a2bce789a5ea90e51a02dfcc39e31b7f1e662bc3317979aa7e5538e3a034f72", size = 81879 },
    { url = "https://files.pythonhosted.org/packages/8f/fa/9fb6e594f2ce03ef03eddbdb5f4f90acb1452221a5351116c7c4708ac865/wrapt-1.17.2-cp311-cp311-win32.whl", hash = "sha256:4afd5814270fdf6380616b321fd31435a462019d834f83c8611a0ce7484c7317", size = 36419 },
    { url = "https://files.pythonhosted.org/packages/47/f8/fb1773491a253cbc123c5d5dc15c86041f746ed30416535f2a8df1f4a392/wrapt-1.17.2-cp311-cp311-win_amd64.whl", hash = "sha256:acc130bc0375999da18e3d19e5a86403667ac0c4042a094fefb7eec8ebac7cf3", size = 38773 },
    { url = "https://files.pythonhosted.org/packages/a1/bd/ab55f849fd1f9a58ed7ea47f5559ff09741b25f00c191231f9f059c83949/wrapt-1.17.2-cp312-cp312-macosx_10_13_universal2.whl", hash = "sha256:d5e2439eecc762cd85e7bd37161d4714aa03a33c5ba884e26c81559817ca0925", size = 53799 },
    { url = "https://files.pythonhosted.org/packages/53/18/75ddc64c3f63988f5a1d7e10fb204ffe5762bc663f8023f18ecaf31a332e/wrapt-1.17.2-cp312-cp312-macosx_10_13_x86_64.whl", hash = "sha256:3fc7cb4c1c744f8c05cd5f9438a3caa6ab94ce8344e952d7c45a8ed59dd88392", size = 38821 },
    { url = "https://files.pythonhosted.org/packages/48/2a/97928387d6ed1c1ebbfd4efc4133a0633546bec8481a2dd5ec961313a1c7/wrapt-1.17.2-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:8fdbdb757d5390f7c675e558fd3186d590973244fab0c5fe63d373ade3e99d40", size = 38919 },
    { url = "https://files.pythonhosted.org/packages/73/54/3bfe5a1febbbccb7a2f77de47b989c0b85ed3a6a41614b104204a788c20e/wrapt-1.17.2-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5bb1d0dbf99411f3d871deb6faa9aabb9d4e744d67dcaaa05399af89d847a91d", size = 88721 },
    { url = "https://files.pythonhosted.org/packages/25/cb/7262bc1b0300b4b64af50c2720ef958c2c1917525238d661c3e9a2b71b7b/wrapt-1.17.2-cp312-cp312-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:d18a4865f46b8579d44e4fe1e2bcbc6472ad83d98e22a26c963d46e4c125ef0b", size = 80899 },
    { url = "https://files.pythonhosted.org/packages/2a/5a/04cde32b07a7431d4ed0553a76fdb7a61270e78c5fd5a603e190ac389f14/wrapt-1.17.2-cp312-cp312-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:bc570b5f14a79734437cb7b0500376b6b791153314986074486e0b0fa8d71d98", size = 89222 },
    { url = "https://files.pythonhosted.org/packages/09/28/2e45a4f4771fcfb109e244d5dbe54259e970362a311b67a965555ba65026/wrapt-1.17.2-cp312-cp312-musllinux_1_2_aarch64.whl", hash = "sha256:6d9187b01bebc3875bac9b087948a2bccefe464a7d8f627cf6e48b1bbae30f82", size = 86707 },
    { url = "https://files.pythonhosted.org/packages/c6/d2/dcb56bf5f32fcd4bd9aacc77b50a539abdd5b6536872413fd3f428b21bed/wrapt-1.17.2-cp312-cp312-musllinux_1_2_i686.whl", hash = "sha256:9e8659775f1adf02eb1e6f109751268e493c73716ca5761f8acb695e52a756ae", size = 79685 },
    { url = "https://files.pythonhosted.org/packages/80/4e/eb8b353e36711347893f502ce91c770b0b0929f8f0bed2670a6856e667a9/wrapt-1.17.2-cp312-cp312-musllinux_1_2_x86_64.whl", hash = "sha256:e8b2816ebef96d83657b56306152a93909a83f23994f4b30ad4573b00bd11bb9", size = 87567 },
    { url = "https://files.pythonhosted.org/packages/17/27/4fe749a54e7fae6e7146f1c7d914d28ef599dacd4416566c055564080fe2/wrapt-1.17.2-cp312-cp312-win32.whl", hash = "sha256:468090021f391fe0056ad3e807e3d9034e0fd01adcd3bdfba977b6fdf4213ea9", size = 36672 },
    { url = "https://files.pythonhosted.org/packages/15/06/1dbf478ea45c03e78a6a8c4be4fdc3c3bddea5c8de8a93bc971415e47f0f/wrapt-1.17.2-cp312-cp312-win_amd64.whl", hash = "sha256:ec89ed91f2fa8e3f52ae53cd3cf640d6feff92ba90d62236a81e4e563ac0e991", size = 38865 },
    { url = "https://files.pythonhosted.org/packages/ce/b9/0ffd557a92f3b11d4c5d5e0c5e4ad057bd9eb8586615cdaf901409920b14/wrapt-1.17.2-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:6ed6ffac43aecfe6d86ec5b74b06a5be33d5bb9243d055141e8cabb12aa08125", size = 53800 },
    { url = "https://files.pythonhosted.org/packages/c0/ef/8be90a0b7e73c32e550c73cfb2fa09db62234227ece47b0e80a05073b375/wrapt-1.17.2-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:35621ae4c00e056adb0009f8e86e28eb4a41a4bfa8f9bfa9fca7d343fe94f998", size = 38824 },
    { url = "https://files.pythonhosted.org/packages/36/89/0aae34c10fe524cce30fe5fc433210376bce94cf74d05b0d68344c8ba46e/wrapt-1.17.2-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:a604bf7a053f8362d27eb9fefd2097f82600b856d5abe996d623babd067b1ab5", size = 38920 },
    { url = "https://files.pythonhosted.org/packages/3b/24/11c4510de906d77e0cfb5197f1b1445d4fec42c9a39ea853d482698ac681/wrapt-1.17.2-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:5cbabee4f083b6b4cd282f5b817a867cf0b1028c54d445b7ec7cfe6505057cf8", size = 88690 },
    { url = "https://files.pythonhosted.org/packages/71/d7/cfcf842291267bf455b3e266c0c29dcb675b5540ee8b50ba1699abf3af45/wrapt-1.17.2-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:49703ce2ddc220df165bd2962f8e03b84c89fee2d65e1c24a7defff6f988f4d6", size = 80861 },
    { url = "https://files.pythonhosted.org/packages/d5/66/5d973e9f3e7370fd686fb47a9af3319418ed925c27d72ce16b791231576d/wrapt-1.17.2-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:8112e52c5822fc4253f3901b676c55ddf288614dc7011634e2719718eaa187dc", size = 89174 },
    { url = "https://files.pythonhosted.org/packages/a7/d3/8e17bb70f6ae25dabc1aaf990f86824e4fd98ee9cadf197054e068500d27/wrapt-1.17.2-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:9fee687dce376205d9a494e9c121e27183b2a3df18037f89d69bd7b35bcf59e2", size = 86721 },
    { url = "https://files.pythonhosted.org/packages/6f/54/f170dfb278fe1c30d0ff864513cff526d624ab8de3254b20abb9cffedc24/wrapt-1.17.2-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:18983c537e04d11cf027fbb60a1e8dfd5190e2b60cc27bc0808e653e7b218d1b", size = 79763 },
    { url = "https://files.pythonhosted.org/packages/4a/98/de07243751f1c4a9b15c76019250210dd3486ce098c3d80d5f729cba029c/wrapt-1.17.2-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:703919b1633412ab54bcf920ab388735832fdcb9f9a00ae49387f0fe67dad504", size = 87585 },
    { url = "https://files.pythonhosted.org/packages/f9/f0/13925f4bd6548013038cdeb11ee2cbd4e37c30f8bfd5db9e5a2a370d6e20/wrapt-1.17.2-cp313-cp313-win32.whl", hash = "sha256:abbb9e76177c35d4e8568e58650aa6926040d6a9f6f03435b7a522bf1c487f9a", size = 36676 },
    { url = "https://files.pythonhosted.org/packages/bf/ae/743f16ef8c2e3628df3ddfd652b7d4c555d12c84b53f3d8218498f4ade9b/wrapt-1.17.2-cp313-cp313-win_amd64.whl", hash = "sha256:69606d7bb691b50a4240ce6b22ebb319c1cfb164e5f6569835058196e0f3a845", size = 38871 },
    { url = "https://files.pythonhosted.org/packages/3d/bc/30f903f891a82d402ffb5fda27ec1d621cc97cb74c16fea0b6141f1d4e87/wrapt-1.17.2-cp313-cp313t-macosx_10_13_universal2.whl", hash = "sha256:4a721d3c943dae44f8e243b380cb645a709ba5bd35d3ad27bc2ed947e9c68192", size = 56312 },
    { url = "https://files.pythonhosted.org/packages/8a/04/c97273eb491b5f1c918857cd26f314b74fc9b29224521f5b83f872253725/wrapt-1.17.2-cp313-cp313t-macosx_10_13_x86_64.whl", hash = "sha256:766d8bbefcb9e00c3ac3b000d9acc51f1b399513f44d77dfe0eb026ad7c9a19b", size = 40062 },
    { url = "https://files.pythonhosted.org/packages/4e/ca/3b7afa1eae3a9e7fefe499db9b96813f41828b9fdb016ee836c4c379dadb/wrapt-1.17.2-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:e496a8ce2c256da1eb98bd15803a79bee00fc351f5dfb9ea82594a3f058309e0", size = 40155 },
    { url = "https://files.pythonhosted.org/packages/89/be/7c1baed43290775cb9030c774bc53c860db140397047cc49aedaf0a15477/wrapt-1.17.2-cp313-cp313t-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:40d615e4fe22f4ad3528448c193b218e077656ca9ccb22ce2cb20db730f8d306", size = 113471 },
    { url = "https://files.pythonhosted.org/packages/32/98/4ed894cf012b6d6aae5f5cc974006bdeb92f0241775addad3f8cd6ab71c8/wrapt-1.17.2-cp313-cp313t-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:a5aaeff38654462bc4b09023918b7f21790efb807f54c000a39d41d69cf552cb", size = 101208 },
    { url = "https://files.pythonhosted.org/packages/ea/fd/0c30f2301ca94e655e5e057012e83284ce8c545df7661a78d8bfca2fac7a/wrapt-1.17.2-cp313-cp313t-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:9a7d15bbd2bc99e92e39f49a04653062ee6085c0e18b3b7512a4f2fe91f2d681", size = 109339 },
    { url = "https://files.pythonhosted.org/packages/75/56/05d000de894c4cfcb84bcd6b1df6214297b8089a7bd324c21a4765e49b14/wrapt-1.17.2-cp313-cp313t-musllinux_1_2_aarch64.whl", hash = "sha256:e3890b508a23299083e065f435a492b5435eba6e304a7114d2f919d400888cc6", size = 110232 },
    { url = "https://files.pythonhosted.org/packages/53/f8/c3f6b2cf9b9277fb0813418e1503e68414cd036b3b099c823379c9575e6d/wrapt-1.17.2-cp313-cp313t-musllinux_1_2_i686.whl", hash = "sha256:8c8b293cd65ad716d13d8dd3624e42e5a19cc2a2f1acc74b30c2c13f15cb61a6", size = 100476 },
    { url = "https://files.pythonhosted.org/packages/a7/b1/0bb11e29aa5139d90b770ebbfa167267b1fc548d2302c30c8f7572851738/wrapt-1.17.2-cp313-cp313t-musllinux_1_2_x86_64.whl", hash = "sha256:4c82b8785d98cdd9fed4cac84d765d234ed3251bd6afe34cb7ac523cb93e8b4f", size = 106377 },
    { url = "https://files.pythonhosted.org/packages/6a/e1/0122853035b40b3f333bbb25f1939fc1045e21dd518f7f0922b60c156f7c/wrapt-1.17.2-cp313-cp313t-win32.whl", hash = "sha256:13e6afb7fe71fe7485a4550a8844cc9ffbe263c0f1a1eea569bc7091d4898555", size = 37986 },
    { url = "https://files.pythonhosted.org/packages/09/5e/1655cf481e079c1f22d0cabdd4e51733679932718dc23bf2db175f329b76/wrapt-1.17.2-cp313-cp313t-win_amd64.whl", hash = "sha256:eaf675418ed6b3b31c7a989fd007fa7c3be66ce14e5c3b27336383604c9da85c", size = 40750 },
    { url = "https://files.pythonhosted.org/packages/0c/66/95b9e90e6e1274999b183c9c3f984996d870e933ca9560115bd1cd1d6f77/wrapt-1.17.2-cp38-cp38-macosx_10_9_universal2.whl", hash = "sha256:5c803c401ea1c1c18de70a06a6f79fcc9c5acfc79133e9869e730ad7f8ad8ef9", size = 53234 },
    { url = "https://files.pythonhosted.org/packages/a4/b6/6eced5e2db5924bf6d9223d2bb96b62e00395aae77058e6a9e11bf16b3bd/wrapt-1.17.2-cp38-cp38-macosx_10_9_x86_64.whl", hash = "sha256:f917c1180fdb8623c2b75a99192f4025e412597c50b2ac870f156de8fb101119", size = 38462 },
    { url = "https://files.pythonhosted.org/packages/5d/a4/c8472fe2568978b5532df84273c53ddf713f689d408a4335717ab89547e0/wrapt-1.17.2-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:ecc840861360ba9d176d413a5489b9a0aff6d6303d7e733e2c4623cfa26904a6", size = 38730 },
    { url = "https://files.pythonhosted.org/packages/3c/70/1d259c6b1ad164eb23ff70e3e452dd1950f96e6473f72b7207891d0fd1f0/wrapt-1.17.2-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:bb87745b2e6dc56361bfde481d5a378dc314b252a98d7dd19a651a3fa58f24a9", size = 86225 },
    { url = "https://files.pythonhosted.org/packages/a9/68/6b83367e1afb8de91cbea4ef8e85b58acdf62f034f05d78c7b82afaa23d8/wrapt-1.17.2-cp38-cp38-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:58455b79ec2661c3600e65c0a716955adc2410f7383755d537584b0de41b1d8a", size = 78055 },
    { url = "https://files.pythonhosted.org/packages/0d/21/09573d2443916705c57fdab85d508f592c0a58d57becc53e15755d67fba2/wrapt-1.17.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:b4e42a40a5e164cbfdb7b386c966a588b1047558a990981ace551ed7e12ca9c2", size = 85592 },
    { url = "https://files.pythonhosted.org/packages/45/ce/700e17a852dd5dec894e241c72973ea82363486bcc1fb05d47b4fbd1d683/wrapt-1.17.2-cp38-cp38-musllinux_1_2_aarch64.whl", hash = "sha256:91bd7d1773e64019f9288b7a5101f3ae50d3d8e6b1de7edee9c2ccc1d32f0c0a", size = 83906 },
    { url = "https://files.pythonhosted.org/packages/37/14/bd210faf0a66faeb8529d42b6b45a25d6aa6ce25ddfc19168e4161aed227/wrapt-1.17.2-cp38-cp38-musllinux_1_2_i686.whl", hash = "sha256:bb90fb8bda722a1b9d48ac1e6c38f923ea757b3baf8ebd0c82e09c5c1a0e7a04", size = 76763 },
    { url = "https://files.pythonhosted.org/packages/34/0c/85af70d291f44659c422416f0272046109e785bf6db8c081cfeeae5715c5/wrapt-1.17.2-cp38-cp38-musllinux_1_2_x86_64.whl", hash = "sha256:08e7ce672e35efa54c5024936e559469436f8b8096253404faeb54d2a878416f", size = 83573 },
    { url = "https://files.pythonhosted.org/packages/f8/1e/b215068e824878f69ea945804fa26c176f7c2735a3ad5367d78930bd076a/wrapt-1.17.2-cp38-cp38-win32.whl", hash = "sha256:410a92fefd2e0e10d26210e1dfb4a876ddaf8439ef60d6434f21ef8d87efc5b7", size = 36408 },
    { url = "https://files.pythonhosted.org/packages/52/27/3dd9ad5f1097b33c95d05929e409cc86d7c765cb5437b86694dc8f8e9af0/wrapt-1.17.2-cp38-cp38-win_amd64.whl", hash = "sha256:95c658736ec15602da0ed73f312d410117723914a5c91a14ee4cdd72f1d790b3", size = 38737 },
    { url = "https://files.pythonhosted.org/packages/8a/f4/6ed2b8f6f1c832933283974839b88ec7c983fd12905e01e97889dadf7559/wrapt-1.17.2-cp39-cp39-macosx_10_9_universal2.whl", hash = "sha256:99039fa9e6306880572915728d7f6c24a86ec57b0a83f6b2491e1d8ab0235b9a", size = 53308 },
    { url = "https://files.pythonhosted.org/packages/a2/a9/712a53f8f4f4545768ac532619f6e56d5d0364a87b2212531685e89aeef8/wrapt-1.17.2-cp39-cp39-macosx_10_9_x86_64.whl", hash = "sha256:2696993ee1eebd20b8e4ee4356483c4cb696066ddc24bd70bcbb80fa56ff9061", size = 38489 },
    { url = "https://files.pythonhosted.org/packages/fa/9b/e172c8f28a489a2888df18f953e2f6cb8d33b1a2e78c9dfc52d8bf6a5ead/wrapt-1.17.2-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:612dff5db80beef9e649c6d803a8d50c409082f1fedc9dbcdfde2983b2025b82", size = 38776 },
    { url = "https://files.pythonhosted.org/packages/cf/cb/7a07b51762dcd59bdbe07aa97f87b3169766cadf240f48d1cbe70a1be9db/wrapt-1.17.2-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:62c2caa1585c82b3f7a7ab56afef7b3602021d6da34fbc1cf234ff139fed3cd9", size = 83050 },
    { url = "https://files.pythonhosted.org/packages/a5/51/a42757dd41032afd6d8037617aa3bc6803ba971850733b24dfb7d5c627c4/wrapt-1.17.2-cp39-cp39-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:c958bcfd59bacc2d0249dcfe575e71da54f9dcf4a8bdf89c4cb9a68a1170d73f", size = 74718 },
    { url = "https://files.pythonhosted.org/packages/bf/bb/d552bfe47db02fcfc950fc563073a33500f8108efa5f7b41db2f83a59028/wrapt-1.17.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:fc78a84e2dfbc27afe4b2bd7c80c8db9bca75cc5b85df52bfe634596a1da846b", size = 82590 },
    { url = "https://files.pythonhosted.org/packages/77/99/77b06b3c3c410dbae411105bf22496facf03a5496bfaca8fbcf9da381889/wrapt-1.17.2-cp39-cp39-musllinux_1_2_aarch64.whl", hash = "sha256:ba0f0eb61ef00ea10e00eb53a9129501f52385c44853dbd6c4ad3f403603083f", size = 81462 },
    { url = "https://files.pythonhosted.org/packages/2d/21/cf0bd85ae66f92600829ea1de8e1da778e5e9f6e574ccbe74b66db0d95db/wrapt-1.17.2-cp39-cp39-musllinux_1_2_i686.whl", hash = "sha256:1e1fe0e6ab7775fd842bc39e86f6dcfc4507ab0ffe206093e76d61cde37225c8", size = 74309 },
    { url = "https://files.pythonhosted.org/packages/6d/16/112d25e9092398a0dd6fec50ab7ac1b775a0c19b428f049785096067ada9/wrapt-1.17.2-cp39-cp39-musllinux_1_2_x86_64.whl", hash = "sha256:c86563182421896d73858e08e1db93afdd2b947a70064b813d515d66549e15f9", size = 81081 },
    { url = "https://files.pythonhosted.org/packages/2b/49/364a615a0cc0872685646c495c7172e4fc7bf1959e3b12a1807a03014e05/wrapt-1.17.2-cp39-cp39-win32.whl", hash = "sha256:f393cda562f79828f38a819f4788641ac7c4085f30f1ce1a68672baa686482bb", size = 36423 },
    { url = "https://files.pythonhosted.org/packages/00/ad/5d2c1b34ba3202cd833d9221833e74d6500ce66730974993a8dc9a94fb8c/wrapt-1.17.2-cp39-cp39-win_amd64.whl", hash = "sha256:36ccae62f64235cf8ddb682073a60519426fdd4725524ae38874adf72b5f2aeb", size = 38772 },
    { url = "https://files.pythonhosted.org/packages/2d/82/f56956041adef78f849db6b289b282e72b55ab8045a75abad81898c28d19/wrapt-1.17.2-py3-none-any.whl", hash = "sha256:b18f2d1533a71f069c7f82d524a52599053d4c7166e9dd374ae2136b7f40f7c8", size = 23594 },
]

[[package]]
name = "xlrd"
version = "2.0.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/a6/b3/19a2540d21dea5f908304375bd43f5ed7a4c28a370dc9122c565423e6b44/xlrd-2.0.1.tar.gz", hash = "sha256:f72f148f54442c6b056bf931dbc34f986fd0c3b0b6b5a58d013c9aef274d0c88", size = 100259 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/a6/0c/c2a72d51fe56e08a08acc85d13013558a2d793028ae7385448a6ccdfae64/xlrd-2.0.1-py2.py3-none-any.whl", hash = "sha256:6a33ee89877bd9abc1158129f6e94be74e2679636b8a205b43b85206c3f0bbdd", size = 96531 },
]

[[package]]
name = "xlsxwriter"
version = "3.2.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/a1/08/26f69d1e9264e8107253018de9fc6b96f9219817d01c5f021e927384a8d1/xlsxwriter-3.2.2.tar.gz", hash = "sha256:befc7f92578a85fed261639fb6cde1fd51b79c5e854040847dde59d4317077dc", size = 205202 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/9b/07/df054f7413bdfff5e98f75056e4ed0977d0c8716424011fac2587864d1d3/XlsxWriter-3.2.2-py3-none-any.whl", hash = "sha256:272ce861e7fa5e82a4a6ebc24511f2cb952fde3461f6c6e1a1e81d3272db1471", size = 165121 },
]

[[package]]
name = "xlwings"
version = "0.31.10"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "appscript", marker = "platform_system == 'Darwin'" },
    { name = "psutil", marker = "platform_system == 'Darwin'" },
    { name = "pywin32", marker = "platform_system == 'Windows'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/95/61/d2a61f142ec3883d305da284355cb98366cd3e6ff8643af1f5d8f9c4ba72/xlwings-0.31.10.tar.gz", hash = "sha256:b1b2169c7fa81709b0110401b412fc83247ba437fed347e1dc48d5cc45bb9b8a", size = 1124556 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/f6/8a/7c0290853ccc7f88d886f5f3a1325808e301fc68b9740702bce32130069b/xlwings-0.31.10-cp310-cp310-macosx_10_12_x86_64.whl", hash = "sha256:a882a572a69adde42a73339557a5bfcc9a76d9cfbfd092f84b415906dade4bc5", size = 1437778 },
    { url = "https://files.pythonhosted.org/packages/20/aa/f1ebfdc3b61c2d190232ab6c0ee57118999103d8a714a72f2a371c48bff0/xlwings-0.31.10-cp310-cp310-macosx_11_0_arm64.whl", hash = "sha256:92d9ca531a3b37724ddf3057e5093a92e3de43477dbbfe96d588674ec3afd2a6", size = 1428487 },
    { url = "https://files.pythonhosted.org/packages/f6/0d/52c368ef63ab8c360fc684f8a9a01608061a2cdcacae040c87f6259a4182/xlwings-0.31.10-cp310-cp310-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0665da0740d2586c18413de4a6aced8d4e720abc24d3bbcf7f8165acd28583c7", size = 1507112 },
    { url = "https://files.pythonhosted.org/packages/21/53/d29c608c13e2cd3b5570c1d0390df156e57948cdb531511a6920e452398c/xlwings-0.31.10-cp310-cp310-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:efec3bfe0c6d6d1c93d2ba478220f80bbf88e2caa8a109b2691753bbf6bba9ca", size = 1499474 },
    { url = "https://files.pythonhosted.org/packages/03/3d/6b3ee2bc3532db505e993d0941f3eaadf6c59ac384e998cc73870c0c3b4d/xlwings-0.31.10-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:ecc7e2258d8c66cfc5bf731bd0bb15a16424b13c22b92d2778586c4f30b9c924", size = 1496517 },
    { url = "https://files.pythonhosted.org/packages/02/71/44a867fd374e92e92a0e5b7e88ad7d4c24a2292ece33d14acf3661c05d02/xlwings-0.31.10-cp310-cp310-musllinux_1_1_aarch64.whl", hash = "sha256:bc50f928cc380812e42f17657feb823adcf3eedf7e6056f9be16cc6a9cfc9c48", size = 1685596 },
    { url = "https://files.pythonhosted.org/packages/ae/40/1240b2f3a9e835eb9fbf95873e9c7279bb201f0081a67a2ae80344c12e29/xlwings-0.31.10-cp310-cp310-musllinux_1_1_x86_64.whl", hash = "sha256:bd3832dcce723338672cc6f38fae697661ca35b53221055fc76ed3221e2474d4", size = 1666683 },
    { url = "https://files.pythonhosted.org/packages/74/00/63a649e5ebc3ca6c07c6ede8561f8468edc8723febc041a11d99a2976b89/xlwings-0.31.10-cp310-cp310-win_amd64.whl", hash = "sha256:345497d56b806e017eb868963eeeab165c18b8a3f621667848834bd10e8192c6", size = 1660573 },
    { url = "https://files.pythonhosted.org/packages/61/51/de5170f238695b1079c68a47e97b6935a6ab04357b49c2c657c7f2bb39dd/xlwings-0.31.10-cp311-cp311-macosx_10_12_x86_64.whl", hash = "sha256:5e165cf078075c98eae5e5c9f1a28daf33b4f8e926b3631c4d34aacd9e14335c", size = 1437837 },
    { url = "https://files.pythonhosted.org/packages/19/4f/d92becb60764087aac031ed876b39c013c08a6717a0d78d841099b6ba3e8/xlwings-0.31.10-cp311-cp311-macosx_11_0_arm64.whl", hash = "sha256:ac27d96833e5623aab063d5dcc26d83ea6c1af9a2bd9f2d7ed782638e89e5d2d", size = 1428533 },
    { url = "https://files.pythonhosted.org/packages/5b/c0/51aed66fe93ff3014bd9be72100ac7cee3dc3d326a4c5b6084f744443ece/xlwings-0.31.10-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:b3d4634dce427587dd45aca465122c121c6508f1ac9e9251b9115520ee1651b2", size = 1507176 },
    { url = "https://files.pythonhosted.org/packages/25/92/9646868682eea36c82fbbbedd4cf49e87d18bf4c9ead2df932d698a8ba05/xlwings-0.31.10-cp311-cp311-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:045b3891ea6e07d7f380d058de7dc36821e2013b739bb281add8bd403c6dad56", size = 1499481 },
    { url = "https://files.pythonhosted.org/packages/28/c2/af1b625a073d4d25b2e999438862b9996296aa69b5158bc5d53ac6650653/xlwings-0.31.10-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7c8bf5536e61c4f2a3b153d1d21723438501b41924a6a966fc443d0682b4bdbd", size = 1496592 },
    { url = "https://files.pythonhosted.org/packages/e6/f2/a7dc69e3d9c6ab109bb9db7a42f5a8479942a0acb7640c38d0b807e5c847/xlwings-0.31.10-cp311-cp311-musllinux_1_1_aarch64.whl", hash = "sha256:287e82fba2131f37ac5e85da23a291c24f8f3427870c6acf7e3808d584654de7", size = 1685738 },
    { url = "https://files.pythonhosted.org/packages/df/5d/6f0dfd8eec51c2d137e36c60a08339ab6b5784809b76e3df95ee5b1906de/xlwings-0.31.10-cp311-cp311-musllinux_1_1_x86_64.whl", hash = "sha256:c013c4a17e47ea2a632da34052a2a17a210068b1050287d8b671fdcbe258197f", size = 1666770 },
    { url = "https://files.pythonhosted.org/packages/18/28/113f40ac7feb60653d1dc2db39fa9b0ac2abd7d0116a551a48988d2617a3/xlwings-0.31.10-cp311-cp311-win_amd64.whl", hash = "sha256:56e8996832e119dac8861a0da4d1f69d30ab16d3c489b9fd14ecd5dccc2819ab", size = 1660579 },
    { url = "https://files.pythonhosted.org/packages/a4/ee/7985a284379196888f65f4162f1de1ab96ae9e0b3ec53a5df4778a6f5d14/xlwings-0.31.10-cp312-cp312-macosx_10_12_x86_64.whl", hash = "sha256:fc57edbc509745788096ea2297d9cf22b6733cfcfce7fd5fbac3d10103161d5d", size = 1436302 },
    { url = "https://files.pythonhosted.org/packages/d5/9c/dc4d95ce95c4445fc5d241ec8c94537ddb8aeea508feb501759fe6424098/xlwings-0.31.10-cp312-cp312-macosx_11_0_arm64.whl", hash = "sha256:8818613ae0342bfe4976e9a4d34bb42535c0d2f3e44b924e97a106f15a4f2bf4", size = 1427005 },
    { url = "https://files.pythonhosted.org/packages/c6/23/f931c043f519193c5c1f2b791280914a417f832671e2291dd4e0cb860ba9/xlwings-0.31.10-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:0d754bd2cac5d8f63ff3813e1c0c32b35ae11c7ad354788164e7b0cb72245d83", size = 1505979 },
    { url = "https://files.pythonhosted.org/packages/55/35/f9e34a404818b0c8aebe13f2224d0f8d8e10420a107e7c9e248dabaf030a/xlwings-0.31.10-cp312-cp312-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:549f3f270002d920b2d8573b4464c67c3f3debace5d7f55b9083138a30615977", size = 1500167 },
    { url = "https://files.pythonhosted.org/packages/af/bb/96fadd136d77058fde0c73b831b2297a8f50de64094daa095031f735cd82/xlwings-0.31.10-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:3461caeb54bf03c924a4ce9b8ceea48035ecbb3cb4479d6f3bcecef41a762d47", size = 1495071 },
    { url = "https://files.pythonhosted.org/packages/fd/85/27a09f2bd0f6ed4753f7e06f234a56e5003b2e9abc4cce405ce967ae3469/xlwings-0.31.10-cp312-cp312-musllinux_1_1_aarch64.whl", hash = "sha256:71f24174a00c9e86ac316e2abd7131d759fc389891e99c1f0ad4a5a6490040bb", size = 1684403 },
    { url = "https://files.pythonhosted.org/packages/30/7d/b7ea71982396bf9cd1b0d014eeafc91de62b4091a6df9321bf428eb0cbe8/xlwings-0.31.10-cp312-cp312-musllinux_1_1_x86_64.whl", hash = "sha256:fe415131dcb6df6ecb809378b643e690b86c404f62b4bec366a827a0a0cfe6fa", size = 1665291 },
    { url = "https://files.pythonhosted.org/packages/4c/22/a5e3591d2ace9bbdf411b3c2d3dced74a98dbb11f962e66cdb34a3b79346/xlwings-0.31.10-cp312-cp312-win_amd64.whl", hash = "sha256:1981aa999e94fe4ae855e7a35f8e1a696afeaba0925d61746f080e312b659faf", size = 1660498 },
    { url = "https://files.pythonhosted.org/packages/28/66/58323ef60854c1003a592a24673e05f88b6e7cc80003c3093445b7e8c945/xlwings-0.31.10-cp38-cp38-macosx_10_12_x86_64.whl", hash = "sha256:fda1d8bbb8b439d6dd8ded486710deb606b350a1ec08dde680af89bf16b95d3f", size = 1437738 },
    { url = "https://files.pythonhosted.org/packages/09/a8/25d2dd0910687c25d6cbecb1239fb5b2e10611310c6ecc6c96ce5bedd27d/xlwings-0.31.10-cp38-cp38-macosx_11_0_arm64.whl", hash = "sha256:e442d1b14f6ea5d1e0681f6b39e828dc04deac5d92e746115e798e67b368abe1", size = 1428719 },
    { url = "https://files.pythonhosted.org/packages/af/d5/a6257ea92e29665eceaa92f131a1b758ac643f07a446f67cd503c5bb3db1/xlwings-0.31.10-cp38-cp38-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:c36042af4695be122cba77db20c4681eb73113e8ec205ceb4a22471aef4b97ce", size = 1507236 },
    { url = "https://files.pythonhosted.org/packages/b5/0b/038401406a5c0703221e200303f05aabeaee6077f6007e739b062dbb4870/xlwings-0.31.10-cp38-cp38-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:4eb1fef6ed753f38a88fb499be6099b913de3a123e3066d297a10a735e1f4200", size = 1499979 },
    { url = "https://files.pythonhosted.org/packages/a6/dc/d68d21b42798300a395cc34e7fc7d064f726ef9711e00019a17bfbb8dde4/xlwings-0.31.10-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:a2bf848a7a762a1f1f78deeb1d8da0d0c1a48ef7fed15db20cab2fe1aef3b95c", size = 1496786 },
    { url = "https://files.pythonhosted.org/packages/20/bb/3f494210c1905111d45b99b28c8f2fc81e4c44e932f0efec5fd900afa8df/xlwings-0.31.10-cp38-cp38-musllinux_1_1_aarch64.whl", hash = "sha256:a8d9e4f957831c94d516d3f6a0f7213b5f8656c05122197c9cff931e073fe55c", size = 1685635 },
    { url = "https://files.pythonhosted.org/packages/31/76/ea8737de0fe5cdf2db333897697c57cc497ed6299b29afb80501d2f22c05/xlwings-0.31.10-cp38-cp38-musllinux_1_1_x86_64.whl", hash = "sha256:9f6189d4cd2cd30671e24102ee53bd638824a813f268f6e857ef09a315db833d", size = 1666627 },
    { url = "https://files.pythonhosted.org/packages/39/1d/39343481066eca0f90948c50e31124d30ead4c37fed2e59702db04ec799f/xlwings-0.31.10-cp38-cp38-win_amd64.whl", hash = "sha256:1a09dc33b327233b2aa4cfddd0379600153e8d2ccb89b70de1336f1bc2c93c49", size = 1660654 },
    { url = "https://files.pythonhosted.org/packages/af/89/2b1583161cabae4938a491f961a5a0c8325c11e5a6620587953c54f236e7/xlwings-0.31.10-cp39-cp39-macosx_10_12_x86_64.whl", hash = "sha256:9520872d157eaf3f6981c1881b26d004979ed368deff9a2c2fbe8591c5d80a11", size = 1437709 },
    { url = "https://files.pythonhosted.org/packages/52/03/d5e1390d67269fec9e1c21e3d702de18bb64987e9e8260f184d05e2fe5f4/xlwings-0.31.10-cp39-cp39-macosx_11_0_arm64.whl", hash = "sha256:bd217d601a57d916a1a8976a14423f6e53ce795b5376c91b332c43244e2c1586", size = 1428735 },
    { url = "https://files.pythonhosted.org/packages/0d/ac/00097e1ecb1aa9d92d2edaf77f6f60f8fdbe379a61b9e662a8f6e5f0e26b/xlwings-0.31.10-cp39-cp39-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:6f14a638d9f64d56c8b26e9ce546795e7efaa59e9694cbce88d436f278b416d6", size = 1506929 },
    { url = "https://files.pythonhosted.org/packages/54/e0/b48143917077532bb62863c559998b790776a9249bb5aaa1dc87a4d9b8dc/xlwings-0.31.10-cp39-cp39-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:2997b398ce5be65d4e53e5d2005725ef325857c7d518b76162447bd035abdff3", size = 1499602 },
    { url = "https://files.pythonhosted.org/packages/65/cd/f1b0dacbadd07ac234fda5333aeb398d434f4dd54248a62b0f76f85b8596/xlwings-0.31.10-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:55ca370e1313f51a485542fea91060f76be02a4ddb854b77a56c683abcf4b332", size = 1496414 },
    { url = "https://files.pythonhosted.org/packages/c2/55/d9747eb9f848d5a03cbbf7d10e0a1518ca14d9f0dfc45b6c997355140248/xlwings-0.31.10-cp39-cp39-musllinux_1_1_aarch64.whl", hash = "sha256:f970e5e134f694e64b30fe53298ed42cfdd46d6de6c150d164b1d70e4af1fe8e", size = 1685529 },
    { url = "https://files.pythonhosted.org/packages/65/9b/56c5d7088fabfd7233f845762c0b79b58295871125d5b6a6a5a861ffc08e/xlwings-0.31.10-cp39-cp39-musllinux_1_1_x86_64.whl", hash = "sha256:b1a1e323e731967dfd52f25057fb6ecf9e483eb11f2f06e47d9d0e4c7bdad92f", size = 1666517 },
    { url = "https://files.pythonhosted.org/packages/9c/bd/418ed696202601af741d4c3a3f4e330598723aea65f0c5611a41f1e04cff/xlwings-0.31.10-cp39-cp39-win_amd64.whl", hash = "sha256:2aa7ab60660918176a065b02632cad80f78c51677c6fe0b4f45e4d7fdb2f9720", size = 1660361 },
    { url = "https://files.pythonhosted.org/packages/e5/57/9330fb4d46967b71034ee7c91c60e762c281ef118f5c799648a964be9155/xlwings-0.31.10-py3-none-any.whl", hash = "sha256:30b4b9e6d5bcd9db41af187e5c5b57938738c5d2a6a107f73f86bb48b94d11b5", size = 766496 },
]

[[package]]
name = "zipp"
version = "3.20.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/54/bf/5c0000c44ebc80123ecbdddba1f5dcd94a5ada602a9c225d84b5aaa55e86/zipp-3.20.2.tar.gz", hash = "sha256:bc9eb26f4506fda01b81bcde0ca78103b6e62f991b381fec825435c836edbc29", size = 24199 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/62/8b/5ba542fa83c90e09eac972fc9baca7a88e7e7ca4b221a89251954019308b/zipp-3.20.2-py3-none-any.whl", hash = "sha256:a817ac80d6cf4b23bf7f2828b7cabf326f15a001bea8b1f9b49631780ba28350", size = 9200 },
]

================
File: pipeline/VERIFICATION_PLAN.md
================
# Document Processing Pipeline Verification Plan

This document outlines the plan for verifying the enhancements made to the document processing pipeline, specifically focusing on the classification configuration and data extraction improvements.

## Enhancements to Verify

### 1. Enhanced Data Extraction
- [ ] Complete content extraction (no truncation of section content)
- [ ] Improved table detection with better structure recognition
- [ ] Table headers and column information extraction
- [ ] Enhanced schema storage with content samples and table data

### 2. Configurable Document Classification
- [ ] Central configuration system for document classification
- [ ] Rule-based classifier using configuration instead of hardcoded rules
- [ ] Filename pattern matching for improved classification
- [ ] Configuration examples for different document types

## Testing Methodology

### Step 1: Run Pipeline with Default Configuration
```bash
python -m utils.pipeline.run_pipeline --file "utils/pipeline/data/input/MF-SPECS_232500 FL - HVAC WATER TREATMENT.pdf" --output utils/pipeline/data/output
```
- Expected result: Document likely classified as "FORM" due to generic rule
- Verification: Check classification result in terminal output

### Step 2: Run Pipeline with HVAC Configuration
```bash
python -m utils.pipeline.run_pipeline --file "utils/pipeline/data/input/MF-SPECS_232500 FL - HVAC WATER TREATMENT.pdf" --output utils/pipeline/data/output --config utils/pipeline/config/hvac_config.json
```
- Expected result: Should classify as "HVAC_SPECIFICATION" if configuration is working correctly
- Verification: Check classification result in terminal output

### Step 3: List Schemas to Find Schema IDs
```bash
python -m utils.pipeline.visualize_schema list
```
- Expected result: List of schemas including recently processed documents
- Verification: Note schema IDs for both default and HVAC configuration runs

### Step 4: Verify Table Extraction Enhancements
```bash
python -m utils.pipeline.visualize_schema tables <schema_id>
```
- Expected result: Visualization showing table headers, column counts, and sample data
- Verification: Compare with previous table visualizations to confirm improvements

### Step 5: Verify Content Extraction Enhancements
```bash
python -m utils.pipeline.visualize_schema structure <schema_id>
```
- Expected result: Complete section content without truncation
- Verification: Check for full content in sections

### Step 6: Examine Output JSON Files
```bash
# View the output JSON file
cat utils/pipeline/data/output/MF-SPECS_232500\ FL\ -\ HVAC\ WATER\ TREATMENT.json
```
- Expected result: Complete content, table structures with headers, and proper classification
- Verification: Check for truncation, table structure, and classification information

## Potential Issues and Solutions

### Classification Issues
1. **Issue**: HVAC documents with multiple tables being classified as "FORM"
   - **Root Cause**: Generic rule in `rule_based.py` classifies documents with >3 tables as "FORM" with 0.6 confidence
   - **Solution Options**:
     - Modify `rule_based.py` to prioritize specific document types over generic types
     - Increase confidence threshold for HVAC documents in configuration
     - Add a special case for HVAC documents with tables

### Data Extraction Issues
1. **Issue**: Content truncation
   - **Root Cause**: Previous implementation limited section content to 100 characters
   - **Solution**: Remove content truncation in `pdf_extractor.py`
   - **Verification**: Check for complete content in output

2. **Issue**: Missing table structure information
   - **Root Cause**: Previous implementation didn't capture headers and column information
   - **Solution**: Enhanced table detection in `pdf_extractor.py`
   - **Verification**: Check for headers and column information in output

## Documentation Updates

After verification, the following documentation should be updated:

1. **PIPELINE_USAGE.md**
   - Add examples of using the enhanced configuration system
   - Document new classification options

2. **SCHEMA_VISUALIZATION.md**
   - Update to reflect new visualization capabilities for tables and content

3. **Example Configurations**
   - Create additional example configurations for different document types

## Final Verification Checklist

- [ ] Document classification works correctly with configuration
- [ ] Filename pattern matching improves classification accuracy
- [ ] Section content is complete without truncation
- [ ] Table detection correctly identifies table structures
- [ ] Table headers and column information are captured
- [ ] Schema visualization shows the enhanced data
- [ ] Documentation is updated to reflect all enhancements

================
File: pipeline/verify/base.py
================
"""
Base verifier module.

This module provides the base verifier interface for output verification.
"""

from abc import ABC, abstractmethod
from typing import Any, Dict, List, Tuple

from utils.pipeline.utils.logging import get_logger


class BaseVerifier(ABC):
    """Base class for output verifiers."""

    def __init__(self):
        self.logger = get_logger(__name__)

    @abstractmethod
    def verify(self, data: Dict[str, Any]) -> Tuple[bool, List[str], List[str]]:
        """
        Verify output data structure and content.

        Args:
            data: Output data to verify

        Returns:
            Tuple of (is_valid, errors, warnings)
        """
        pass

================
File: pipeline/verify/factory.py
================
"""
Verifier factory implementation.

This module provides a factory for creating different output verifiers.
"""

from enum import Enum, auto
from typing import Dict, Type

from utils.pipeline.utils.logging import get_logger
from utils.pipeline.verify.base import BaseVerifier
from utils.pipeline.verify.json_tree import JSONTreeVerifier
from utils.pipeline.verify.markdown import MarkdownVerifier


class VerifierType(Enum):
    """Supported verifier types."""

    JSON_TREE = auto()
    MARKDOWN = auto()  # Future implementation


class VerifierFactory:
    """Factory for creating verifier instances."""

    _verifiers: Dict[VerifierType, Type[BaseVerifier]] = {
        VerifierType.JSON_TREE: JSONTreeVerifier,
        VerifierType.MARKDOWN: MarkdownVerifier,
    }

    @classmethod
    def create_verifier(cls, verifier_type: VerifierType) -> BaseVerifier:
        """
        Create a verifier instance for the specified type.

        Args:
            verifier_type: Type of verifier to create

        Returns:
            Verifier instance

        Raises:
            ValueError: If verifier type is not supported
        """
        logger = get_logger(__name__)

        try:
            verifier_class = cls._verifiers[verifier_type]
            return verifier_class()
        except KeyError:
            logger.error(f"Unsupported verifier type: {verifier_type}")
            raise ValueError(f"Unsupported verifier type: {verifier_type}")

    @classmethod
    def register_verifier(
        cls, verifier_type: VerifierType, verifier_class: Type[BaseVerifier]
    ) -> None:
        """
        Register a new verifier type.

        Args:
            verifier_type: Verifier type to register
            verifier_class: Verifier class to use for this type
        """
        logger = get_logger(__name__)
        logger.info(
            f"Registering verifier for {verifier_type}: {verifier_class.__name__}"
        )
        cls._verifiers[verifier_type] = verifier_class

================
File: pipeline/verify/json_tree.py
================
"""
JSON tree structure verifier.

This module provides verification for JSON tree structure output.
"""

from typing import Any, Dict, List, Optional, Set, Tuple

from utils.pipeline.verify.base import BaseVerifier


class JSONTreeVerifier(BaseVerifier):
    """Verifies JSON tree structure output."""

    def verify(self, data: Dict[str, Any]) -> Tuple[bool, List[str], List[str]]:
        """
        Verify JSON tree structure and content.

        Args:
            data: JSON data to verify

        Returns:
            Tuple of (is_valid, errors, warnings)
        """
        errors = []
        warnings = []

        try:
            # Verify required top-level keys
            required_keys = {"document", "content", "validation"}
            self._verify_required_keys(data, required_keys, "root", errors)

            # Verify document metadata
            if "document" in data:
                self._verify_document_metadata(data["document"], errors, warnings)

            # Verify content structure
            if "content" in data:
                self._verify_content_structure(data["content"], errors, warnings)

            # Check for circular references
            if "content" in data:
                self._check_circular_references(data["content"], errors)

            is_valid = len(errors) == 0
            return is_valid, errors, warnings

        except Exception as e:
            errors.append(f"Verification failed: {str(e)}")
            return False, errors, warnings

    def _verify_required_keys(
        self,
        data: Dict[str, Any],
        required_keys: Set[str],
        context: str,
        errors: List[str],
    ) -> None:
        """Verify all required keys are present."""
        missing_keys = required_keys - set(data.keys())
        if missing_keys:
            errors.append(
                f"Missing required keys in {context}: {', '.join(missing_keys)}"
            )

    def _verify_document_metadata(
        self, document: Dict[str, Any], errors: List[str], warnings: List[str]
    ) -> None:
        """Verify document metadata structure."""
        required_metadata = {"metadata", "path", "type"}
        self._verify_required_keys(document, required_metadata, "document", errors)

        metadata = document.get("metadata", {})
        if not isinstance(metadata, dict):
            errors.append("Document metadata must be a dictionary")

    def _verify_content_structure(
        self,
        content: List[Dict[str, Any]],
        errors: List[str],
        warnings: List[str],
        parent_level: Optional[int] = None,
    ) -> None:
        """Verify content structure recursively."""
        if not isinstance(content, list):
            errors.append("Content must be a list of sections")
            return

        for section in content:
            if not isinstance(section, dict):
                errors.append("Each section must be a dictionary")
                continue

            # Check required section keys
            required_keys = {"title", "content", "children", "level"}
            self._verify_required_keys(section, required_keys, "section", errors)

            # Verify level is valid
            level = section.get("level")
            if not isinstance(level, int) or level < 0:
                errors.append(
                    f"Invalid level {level} for section '{section.get('title')}'"
                )
                continue

            # Verify level is consistent with parent
            if parent_level is not None and isinstance(level, int):
                if level <= parent_level:
                    warnings.append(
                        f"Section '{section.get('title')}' level {level} is not greater than parent level {parent_level}"
                    )

            # Verify children recursively
            children = section.get("children", [])
            if children:
                self._verify_content_structure(children, errors, warnings, level)

    def _check_circular_references(
        self,
        content: List[Dict[str, Any]],
        errors: List[str],
        visited: Optional[Set[int]] = None,
    ) -> None:
        """Check for circular references in content structure."""
        if visited is None:
            visited = set()

        for section in content:
            section_id = id(section)
            if section_id in visited:
                errors.append(
                    f"Circular reference detected in section '{section.get('title')}'"
                )
                continue

            visited.add(section_id)
            children = section.get("children", [])
            if children:
                self._check_circular_references(children, errors, visited)
            visited.remove(section_id)

================
File: pipeline/verify/markdown.py
================
"""
Markdown structure verifier.

This module provides verification for Markdown structure output.
"""

from typing import Any, Dict, List, Tuple

from utils.pipeline.verify.base import BaseVerifier


class MarkdownVerifier(BaseVerifier):
    """Verifies Markdown structure output."""

    def verify(self, data: Dict[str, Any]) -> Tuple[bool, List[str], List[str]]:
        """
        Verify Markdown structure and content.

        Args:
            data: Markdown data to verify

        Returns:
            Tuple of (is_valid, errors, warnings)
        """
        errors = []
        warnings = []

        try:
            # Verify required top-level keys
            required_keys = {"document", "content", "validation"}
            self._verify_required_keys(data, required_keys, errors)

            # Verify document metadata
            if "document" in data:
                self._verify_document_metadata(data["document"], errors)

            # Verify content is a string
            if "content" in data:
                self._verify_content(data["content"], errors, warnings)

            # Verify tables format if present
            if "tables" in data:
                self._verify_tables(data["tables"], errors, warnings)

            is_valid = len(errors) == 0
            return is_valid, errors, warnings

        except Exception as e:
            errors.append(f"Verification failed: {str(e)}")
            return False, errors, warnings

    def _verify_required_keys(
        self, data: Dict[str, Any], required_keys: set, errors: List[str]
    ) -> None:
        """Verify all required keys are present."""
        missing_keys = required_keys - set(data.keys())
        if missing_keys:
            errors.append(f"Missing required keys: {', '.join(missing_keys)}")

    def _verify_document_metadata(
        self, document: Dict[str, Any], errors: List[str]
    ) -> None:
        """Verify document metadata structure."""
        required_metadata = {"metadata", "path", "type"}
        self._verify_required_keys(document, required_metadata, errors)

        metadata = document.get("metadata", {})
        if not isinstance(metadata, dict):
            errors.append("Document metadata must be a dictionary")

    def _verify_content(
        self, content: str, errors: List[str], warnings: List[str]
    ) -> None:
        """Verify markdown content structure."""
        if not isinstance(content, str):
            errors.append("Content must be a string")
            return

        # Check for basic markdown structure
        if not content.strip():
            warnings.append("Content is empty")
            return

        # Check for header hierarchy
        lines = content.split("\n")
        current_level = 0
        for line in lines:
            if line.startswith("#"):
                level = len(line) - len(line.lstrip("#"))
                if level > current_level + 1:
                    warnings.append(
                        f"Header level jump from {current_level} to {level}: {line.strip()}"
                    )
                current_level = level

    def _verify_tables(
        self, tables: str, errors: List[str], warnings: List[str]
    ) -> None:
        """Verify markdown tables structure."""
        if not isinstance(tables, str):
            errors.append("Tables must be a string")
            return

        if not tables.strip():
            return

        lines = tables.split("\n")
        in_table = False
        header_count = 0

        for line in lines:
            line = line.strip()
            if not line:
                in_table = False
                continue

            if line.startswith("|"):
                if not in_table:
                    # New table started
                    in_table = True
                    header_count = line.count("|") - 1
                else:
                    # Check consistent column count
                    if line.count("|") - 1 != header_count:
                        errors.append(f"Inconsistent table column count: {line}")

================
File: pipeline/visualize_schema.py
================
#!/usr/bin/env python3
"""
Script to visualize a specific schema.
"""

import os
import sys
from pathlib import Path

# Add parent directory to path to allow imports
sys.path.insert(0, str(Path(__file__).parent.parent.parent))

from utils.pipeline.schema.extended_registry import ExtendedSchemaRegistry
from utils.pipeline.utils.progress import PipelineProgress


def main():
    """Main entry point for schema visualization."""
    progress = PipelineProgress()

    # Check arguments
    if len(sys.argv) < 2:
        print_usage()
        return

    # Parse command
    command = sys.argv[1]

    if command == "list":
        # List available schemas
        list_schemas(progress)
        return
    elif command == "help":
        print_usage()
        return
    elif command in ["clusters", "features", "structure", "tables"]:
        # Visualization command
        visualization_type = command

        # Check if schema ID is provided
        if len(sys.argv) < 3 and visualization_type not in ["clusters", "features"]:
            print(
                f"Error: Schema ID is required for {visualization_type} visualization"
            )
            print_usage()
            return

        # Get schema ID (optional for clusters and features)
        schema_id = sys.argv[2] if len(sys.argv) >= 3 else "all"

        # Generate visualization
        generate_visualization(visualization_type, schema_id, progress)
    else:
        print(f"Unknown command: {command}")
        print_usage()


def print_usage():
    """Print usage information."""
    print("Usage:")
    print(
        "  python visualize_schema.py list                     - List available schemas"
    )
    print(
        "  python visualize_schema.py clusters [schema_id]     - Generate cluster visualization"
    )
    print(
        "  python visualize_schema.py features [schema_id]     - Generate feature visualization"
    )
    print(
        "  python visualize_schema.py structure <schema_id>    - Generate structure visualization"
    )
    print(
        "  python visualize_schema.py tables <schema_id>       - Generate table visualization"
    )
    print(
        "  python visualize_schema.py help                     - Show this help message"
    )


def list_schemas(progress):
    """List available schemas."""
    # Initialize registry
    registry = ExtendedSchemaRegistry()

    # Get all schemas
    schemas = registry.list_schemas()

    if not schemas:
        progress.display_error("No schemas found in registry")
        return

    # Display schemas
    progress.display_success(f"Found {len(schemas)} schemas:")

    # Group schemas by document type
    schemas_by_type = {}
    for schema in schemas:
        doc_type = schema.get("document_type", "UNKNOWN")
        if doc_type not in schemas_by_type:
            schemas_by_type[doc_type] = []
        schemas_by_type[doc_type].append(schema)

    # Display schemas by type
    for doc_type, type_schemas in schemas_by_type.items():
        progress.display_success(f"\n{doc_type} ({len(type_schemas)}):")
        for schema in type_schemas:
            schema_id = schema.get("id")
            recorded_at = schema.get("recorded_at", "Unknown")
            document_name = schema.get("document_name", "")
            progress.display_success(f"  - {schema_id} ({recorded_at}) {document_name}")


def generate_visualization(visualization_type, schema_id, progress):
    """Generate visualization for schema."""
    # Create visualizations directory
    viz_dir = os.path.join("utils", "pipeline", "schema", "data", "visualizations")
    os.makedirs(viz_dir, exist_ok=True)

    # Initialize registry
    registry = ExtendedSchemaRegistry()

    # Prepare schema IDs
    schema_ids = None
    if schema_id != "all":
        schema_ids = [schema_id]

    # Generate visualization
    progress.display_success(
        f"Generating {visualization_type} visualization for schema {schema_id}..."
    )
    viz_path = registry.visualize(visualization_type, schema_ids, viz_dir)

    # Handle multiple visualization paths
    if isinstance(viz_path, list):
        progress.display_success(f"Generated {len(viz_path)} visualizations:")
        for path in viz_path:
            progress.display_success(f"  - {path}")
    else:
        progress.display_success(f"Visualization saved to: {viz_path}")


if __name__ == "__main__":
    main()

================
File: pyproject.toml
================
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "utils"
version = "0.1.0"
description = "Utility scripts for sequence diagram generation and UML tools"
requires-python = ">=3.10,<4.0"
dependencies = [
    # Add any specific dependencies needed only for utils
    # Most dependencies will come from the backend
]

[tool.uv]
# Define development dependencies specific to utils
dev-dependencies = [
    # Add any dev dependencies needed only for utils
]

# Fix for Hatch package discovery
[tool.hatch.build.targets.wheel]
packages = ["."]

================
File: README.md
================
# Utils Package

This directory contains utility scripts for sequence diagram generation, UML tools, and document processing pipelines.

## Setup

The utils package is designed to work with the backend code while maintaining its own virtual environment. This allows you to run the utils scripts independently while still having access to all the backend code and dependencies.

### Creating the Virtual Environment

To set up the virtual environment for utils:

```bash
# From the project root
python utils/setup_venv.py
```

To clean up an existing virtual environment and create a fresh one:

```bash
# From the project root
python utils/setup_venv.py --clean
```

This script will:
1. Create a virtual environment in `utils/.venv/` (or remove the existing one if --clean is used)
2. Install UV package manager (a faster alternative to pip)
3. Install the backend as an editable package using UV
4. Install any utils-specific dependencies

### Activating the Virtual Environment

After setup, you can activate the virtual environment:

**Windows CMD:**
```
utils\.venv\Scripts\activate
```

**Windows Git Bash:**
```
source utils/.venv/Scripts/activate
```

**Unix/Linux/Mac:**
```
source utils/.venv/bin/activate
```

## Running Utils Scripts

Once the virtual environment is activated, you can run the utils scripts:

```bash
# Run with the module syntax
python -m utils.extract_sequence --help

# Or directly (if the script is executable)
python utils/extract_sequence.py --help
```

### Example Usage

Extract a sequence diagram for a class method:
```bash
python -m utils.extract_sequence --dir backend/app --class UserService --method create_user
```

Extract a sequence diagram for a FastAPI router function:
```bash
python -m utils.extract_sequence --dir backend/app --module api.routes.login --function login_access_token
```

## Available Tools

### UML Tools

The UML tools provide functionality for generating UML diagrams from Python code. See the [uml directory](uml/) for more details.

### Pipeline Tool

The pipeline tool is a modular, pipeline-based system for extracting structured data from various document formats (PDF, Excel, Word). It follows SOLID principles and uses the Strategy pattern for extensibility.

For setup and usage instructions, see the [pipeline directory](pipeline/README.md).

## Development

If you need to add new dependencies specific to the utils package, add them to the `utils/pyproject.toml` file and rerun the setup script. The setup script uses UV for package management, which is faster and more reliable than pip.

================
File: run_uml.py
================
#!/usr/bin/env python
"""Script to run the UML generator from the virtual environment."""

import logging
import os
import subprocess
import sys
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(message)s",  # Simple format to match previous print output
)
logger = logging.getLogger(__name__)


class EnvironmentError(Exception):
    """Exception raised when the virtual environment is not properly set up."""

    pass


def check_environment(utils_dir: Path) -> Path:
    """Validate the virtual environment and return the Python executable path.

    Args:
        utils_dir: Path to the utils directory

    Returns:
        Python executable path if found.

    Raises:
        EnvironmentError: If the virtual environment is not properly set up.
    """
    venv_dir = utils_dir / ".venv"
    if not venv_dir.exists():
        error_message = f"Virtual environment not found at {venv_dir}"
        raise EnvironmentError(error_message)

    # Determine the python executable path based on the platform
    python_exe = venv_dir / ("Scripts" if sys.platform == "win32" else "bin") / "python"
    if not python_exe.exists():
        error_message = f"Python executable not found at {python_exe}"
        raise EnvironmentError(error_message)

    return python_exe


def show_help_text() -> None:
    """Display usage information and available commands."""
    logger.info("Usage: python utils/run_uml.py [COMMAND] [ARGS]")
    logger.info("\nAvailable commands:")
    logger.info(
        "  uml/cli/run_uml_generator.py                  - Generate all UML diagrams",
    )
    logger.info(
        "  uml/cli/extract_class.py --source PATH        - Generate class diagrams",
    )
    logger.info(
        "  uml/cli/extract_sequence.py --source PATH     - Generate sequence diagrams",
    )
    logger.info(
        "  uml/cli/extract_activity.py --source PATH     - Generate activity diagrams",
    )
    logger.info(
        "  uml/cli/extract_state.py --source PATH        - Generate state diagrams",
    )
    logger.info(
        "  uml/run.py --type TYPE --source PATH  - Generate diagrams with more options",
    )
    logger.info("\nExamples:")
    logger.info("  python utils/run_uml.py uml/cli/run_uml_generator.py")
    logger.info(
        "  python utils/run_uml.py uml/cli/extract_class.py --source backend/app",
    )
    logger.info("  python utils/run_uml.py uml/run.py --type all --source backend/app")


def setup_python_env(project_root: Path) -> dict[str, str]:
    """Set up the Python environment with the correct PYTHONPATH.

    Args:
        project_root: Path to the project root directory

    Returns:
        Dictionary containing the environment variables
    """
    env = os.environ.copy()
    if "PYTHONPATH" in env:
        env["PYTHONPATH"] = f"{project_root}{os.pathsep}{env['PYTHONPATH']}"
    else:
        env["PYTHONPATH"] = str(project_root)
    return env


def run_uml_command(
    python_exe: Path,
    script_path: Path,
    args: list[str],
    env: dict[str, str],
) -> int:
    """Execute the UML generation command.

    Args:
        python_exe: Path to the Python executable
        script_path: Path to the UML script to run
        args: Command line arguments
        env: Environment variables dictionary

    Returns:
        Exit code (0 for success, 1 for failure)
    """
    try:
        cmd = [str(python_exe), str(script_path)] + args[1:]
        logger.info(f"Running: {' '.join(cmd)}")
        logger.info(f"With PYTHONPATH: {env.get('PYTHONPATH')}")
        subprocess.run(cmd, check=True, env=env)
    except subprocess.CalledProcessError:
        logger.exception("Error running UML command")
        return 1
    else:
        return 0


def main() -> int:
    """Run the UML generator from the virtual environment.

    Returns:
        Exit code (0 for success, 1 for failure)
    """
    utils_dir = Path(__file__).parent.absolute()

    try:
        # Validate environment
        python_exe = check_environment(utils_dir)

        # Get the command line arguments
        args = sys.argv[1:]
        if not args:
            show_help_text()
            return 0

        # Validate script path
        script_path = utils_dir / args[0]
        if not script_path.exists():
            logger.error("Script not found: %s", script_path)
            return 1

        # Set up environment and run command
        env = setup_python_env(utils_dir.parent.absolute())
        return run_uml_command(python_exe, script_path, args, env)

    except EnvironmentError:
        logger.exception("Environment setup error")
        logger.info(
            "Please run utils/install_dev.py first to set up the virtual environment.",
        )
        return 1


if __name__ == "__main__":
    sys.exit(main())

================
File: uml/__init__.py
================
"""UML diagram generation package.

This package provides tools for generating UML diagrams from Python code.
"""

# Import key modules to make them available at the package level
from utils.uml.core.filesystem import DefaultFileSystem, FileSystem
from utils.uml.core.service import UmlService
from utils.uml.factories import DefaultDiagramFactory

# Define package version
__version__ = "0.1.0"

================
File: uml/cli/__init__.py
================
"""CLI package for UML diagram generation."""

================
File: uml/cli/extract_activity.py
================
#!/usr/bin/env python
"""
Script to extract activity diagrams from Python code.
"""

import argparse
import logging
import sys
from pathlib import Path

from utils.uml.core.filesystem import DefaultFileSystem
from utils.uml.core.service import UmlService
from utils.uml.factories import DefaultDiagramFactory
from utils.uml.utils.paths import get_output_dir

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# Constants
OUTPUT_BASE_DIR = get_output_dir("activity")


def parse_arguments() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Generate activity diagrams from Python code.",
    )

    parser.add_argument(
        "--source",
        "-s",
        required=True,
        help="Source directory or file to analyze",
    )

    parser.add_argument(
        "--output",
        "-o",
        default=str(OUTPUT_BASE_DIR),
        help=f"Output directory for diagrams (default: {OUTPUT_BASE_DIR})",
    )

    parser.add_argument(
        "--recursive",
        "-r",
        action="store_true",
        help="Recursively analyze directories",
    )

    parser.add_argument(
        "--exclude",
        "-e",
        action="append",
        default=[],
        help="Patterns to exclude (can be specified multiple times)",
    )

    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Enable verbose logging",
    )

    return parser.parse_args()


def main() -> int:
    """Run the activity diagram generator."""
    args = parse_arguments()

    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Create output directory
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Create service
    file_system = DefaultFileSystem()
    factory = DefaultDiagramFactory(file_system)
    service = UmlService(factory)

    # Generate activity diagrams
    try:
        # Run the UML generator with the activity diagram type
        source_path = Path(args.source)

        # Create analyzer-specific settings
        settings = {
            "recursive": args.recursive,
            "exclude_patterns": args.exclude,
        }

        # Generate the diagram
        service.generate_diagram(
            "activity",
            source_path,
            output_dir / f"{source_path.stem}.puml",
            **settings,
        )

        logger.info(f"Activity diagram generated successfully in {output_dir}")
        return 0
    except Exception as e:
        logger.error(f"Error generating activity diagram: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())

================
File: uml/cli/extract_app_sequences.py
================
#!/usr/bin/env python
"""Extract sequence diagrams from key entry points in the application.

This script analyzes the backend/app and extracts sequence diagrams for
important entry points in the API, creating visual documentation of the
application's key workflows.
"""

import os
import subprocess

from utils.uml.utils.paths import get_output_dir

# Ensure output directory exists
OUTPUT_DIR = get_output_dir("sequence")
os.makedirs(OUTPUT_DIR, exist_ok=True)

# Define important entry points for sequence diagrams
# Format: (class_name, method_name, output_filename)
ENTRY_POINTS = [
    # User Authentication Flows
    ("login", "login_access_token", "authentication_flow"),  # Login flow
    ("login", "test_token", "token_verification"),  # Token verification
    # User Management Flows
    ("users", "create_user", "admin_create_user"),  # Admin creates user
    ("users", "register_user", "user_signup"),  # User signup
    ("users", "update_user_me", "user_update_profile"),  # Update profile
    ("users", "update_password_me", "user_change_password"),  # Change password
    ("users", "delete_user_me", "user_delete_account"),  # Delete account
    # Password Recovery Flow
    (
        "login",
        "recover_password",
        "password_recovery_request",
    ),  # Request password reset
    ("login", "reset_password", "password_reset"),  # Reset password
    # Other API Endpoints
    # Add other important flows here
]

print("Extracting sequence diagrams from backend/app...")
print("=" * 50)

success_count = 0
for module_name, method_name, output_name in ENTRY_POINTS:
    output_file = os.path.join(OUTPUT_DIR, f"{output_name}.puml")

    # For routes modules, we need to specify the full path
    if module_name in ("login", "users", "items", "private", "utils"):
        # API route modules
        module_path = f"api.routes.{module_name}"
    else:
        # Other modules
        module_path = module_name

    print(f"Generating diagram for {module_path}.{method_name}...")

    # Construct the command
    cmd = [
        "python",
        "-m",
        "utils.uml.cli.extract_sequence",
        "--dir",
        "backend/app",
        "--module",
        module_path,
        "--class",
        "router",  # For FastAPI routers, the class is "router"
        "--method",
        method_name,
        "--output",
        str(output_file),
        "--verbose",
    ]

    try:
        # Run the extraction command
        result = subprocess.run(cmd, capture_output=True, text=True, check=False)

        if result.returncode == 0:
            print(f"✓ Successfully generated: {output_file}")
            success_count += 1
        else:
            print(f"× Failed to generate diagram. Error: {result.stderr}")

            # Try an alternative approach for router functions
            # Sometimes router functions are directly accessible by module.function_name
            alternative_cmd = [
                "python",
                "-m",
                "utils.uml.cli.extract_sequence",
                "--dir",
                "backend/app",
                "--module",
                module_path,
                "--function",
                method_name,  # Try as a function instead of a class method
                "--output",
                str(output_file),
                "--verbose",
            ]

            print("  Trying alternative approach...")
            alt_result = subprocess.run(
                alternative_cmd,
                capture_output=True,
                text=True,
                check=False,
            )

            if alt_result.returncode == 0:
                print(
                    f"✓ Successfully generated using alternative approach: {output_file}",
                )
                success_count += 1
            else:
                print(f"× Alternative approach also failed: {alt_result.stderr}")

    except Exception as e:
        print(f"× Error: {e!s}")

print("=" * 50)
print(
    f"Sequence diagram extraction completed: {success_count}/{len(ENTRY_POINTS)} successful",
)
print(f"Diagrams saved to: {OUTPUT_DIR}")

# Remind the user to run the main UML generator to include these in the docs
print("\nTo include these diagrams in the documentation, run:")
print("python -m utils.uml.cli.run_uml_generator")

if success_count == 0:
    print(
        "\nNote: If extraction failed, you may need to modify the extract_sequence.py script",
    )
    print("to better handle the specific structure of your FastAPI application.")

================
File: uml/cli/extract_class.py
================
#!/usr/bin/env python
"""
Script to extract class diagrams from Python code.
"""

import argparse
import logging
import sys
from pathlib import Path

from utils.uml.core.filesystem import DefaultFileSystem
from utils.uml.core.service import UmlService
from utils.uml.factories import DefaultDiagramFactory
from utils.uml.utils.paths import get_output_dir

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# Constants
OUTPUT_BASE_DIR = get_output_dir("class")


def parse_arguments() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Generate class diagrams from Python code.",
    )

    parser.add_argument(
        "--source",
        "-s",
        required=True,
        help="Source directory or file to analyze",
    )

    parser.add_argument(
        "--output",
        "-o",
        default=str(OUTPUT_BASE_DIR),
        help=f"Output directory for diagrams (default: {OUTPUT_BASE_DIR})",
    )

    parser.add_argument(
        "--recursive",
        "-r",
        action="store_true",
        help="Recursively analyze directories",
    )

    parser.add_argument(
        "--exclude",
        "-e",
        action="append",
        default=[],
        help="Patterns to exclude (can be specified multiple times)",
    )

    parser.add_argument(
        "--include-private",
        "-p",
        action="store_true",
        help="Include private members in diagrams",
    )

    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Enable verbose logging",
    )

    return parser.parse_args()


def main() -> int:
    """Run the class diagram generator."""
    args = parse_arguments()

    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Create output directory
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Create service
    file_system = DefaultFileSystem()
    factory = DefaultDiagramFactory(file_system)
    service = UmlService(factory)

    # Generate class diagrams
    try:
        # Run the UML generator with the class diagram type
        source_path = Path(args.source)

        # Create analyzer-specific settings
        settings = {
            "include_private": args.include_private,
            "recursive": args.recursive,
            "exclude_patterns": args.exclude,
        }

        # Generate the diagram
        service.generate_diagram(
            "class",
            source_path,
            output_dir / f"{source_path.stem}.puml",
            **settings,
        )

        logger.info(f"Class diagram generated successfully in {output_dir}")
        return 0
    except Exception as e:
        logger.error(f"Error generating class diagram: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())

================
File: uml/cli/extract_sequence.py
================
#!/usr/bin/env python
"""
Script to extract sequence diagrams from Python code.
"""

import argparse
import logging
import sys
from pathlib import Path

from utils.uml.core.filesystem import DefaultFileSystem
from utils.uml.core.service import UmlService
from utils.uml.factories import DefaultDiagramFactory
from utils.uml.utils.paths import get_output_dir

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# Constants
OUTPUT_BASE_DIR = get_output_dir("sequence")


def parse_arguments() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Generate sequence diagrams from Python code.",
    )

    parser.add_argument(
        "--source",
        "-s",
        required=True,
        help="Source directory or file to analyze",
    )

    parser.add_argument(
        "--output",
        "-o",
        default=str(OUTPUT_BASE_DIR),
        help=f"Output directory for diagrams (default: {OUTPUT_BASE_DIR})",
    )

    parser.add_argument(
        "--recursive",
        "-r",
        action="store_true",
        help="Recursively analyze directories",
    )

    parser.add_argument(
        "--exclude",
        "-e",
        action="append",
        default=[],
        help="Patterns to exclude (can be specified multiple times)",
    )

    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Enable verbose logging",
    )

    return parser.parse_args()


def main() -> int:
    """Run the sequence diagram generator."""
    args = parse_arguments()

    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Create output directory
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Create service
    file_system = DefaultFileSystem()
    factory = DefaultDiagramFactory(file_system)
    service = UmlService(factory)

    # Generate sequence diagrams
    try:
        # Run the UML generator with the sequence diagram type
        source_path = Path(args.source)

        # Create analyzer-specific settings
        settings = {
            "recursive": args.recursive,
            "exclude_patterns": args.exclude,
            "root_dir": str(source_path),
        }

        # Generate the diagram
        service.generate_diagram(
            "sequence",
            source_path,
            output_dir / f"{source_path.stem}.puml",
            **settings,
        )

        logger.info(f"Sequence diagram generated successfully in {output_dir}")
        return 0
    except Exception as e:
        logger.error(f"Error generating sequence diagram: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())

================
File: uml/cli/extract_state.py
================
#!/usr/bin/env python
"""
Script to extract state diagrams from Python code.
"""

import argparse
import logging
import sys
from pathlib import Path

from utils.uml.core.filesystem import DefaultFileSystem
from utils.uml.core.service import UmlService
from utils.uml.factories import DefaultDiagramFactory
from utils.uml.utils.paths import get_output_dir

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# Constants
OUTPUT_BASE_DIR = get_output_dir("state")


def parse_arguments() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Generate state diagrams from Python code.",
    )

    parser.add_argument(
        "--source",
        "-s",
        required=True,
        help="Source directory or file to analyze",
    )

    parser.add_argument(
        "--output",
        "-o",
        default=str(OUTPUT_BASE_DIR),
        help=f"Output directory for diagrams (default: {OUTPUT_BASE_DIR})",
    )

    parser.add_argument(
        "--recursive",
        "-r",
        action="store_true",
        help="Recursively analyze directories",
    )

    parser.add_argument(
        "--exclude",
        "-e",
        action="append",
        default=[],
        help="Patterns to exclude (can be specified multiple times)",
    )

    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Enable verbose logging",
    )

    return parser.parse_args()


def main() -> int:
    """Run the state diagram generator."""
    args = parse_arguments()

    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Create output directory
    output_dir = Path(args.output)
    output_dir.mkdir(parents=True, exist_ok=True)

    # Create service
    file_system = DefaultFileSystem()
    factory = DefaultDiagramFactory(file_system)
    service = UmlService(factory)

    # Generate state diagrams
    try:
        # Run the UML generator with the state diagram type
        source_path = Path(args.source)

        # Create analyzer-specific settings
        settings = {
            "recursive": args.recursive,
            "exclude_patterns": args.exclude,
        }

        # Generate the diagram
        service.generate_diagram(
            "state",
            source_path,
            output_dir / f"{source_path.stem}.puml",
            **settings,
        )

        logger.info(f"State diagram generated successfully in {output_dir}")
        return 0
    except Exception as e:
        logger.error(f"Error generating state diagram: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())

================
File: uml/cli/run_uml_generator.py
================
#!/usr/bin/env python
"""
Script to run the UML generator on the backend/app directory.

This script uses the new unified architecture for UML diagram generation.
"""

import logging
import os
import subprocess
import sys
from pathlib import Path

from utils.uml.core.filesystem import DefaultFileSystem
from utils.uml.core.service import UmlService
from utils.uml.factories import DefaultDiagramFactory
from utils.uml.utils.paths import get_output_base_dir, get_output_dir, get_project_root

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# Project root directory
PROJECT_ROOT = get_project_root()

# Constants
OUTPUT_BASE_DIR = get_output_base_dir()
CLASS_OUTPUT_DIR = get_output_dir("class")
SEQUENCE_OUTPUT_DIR = get_output_dir("sequence")
ACTIVITY_OUTPUT_DIR = get_output_dir("activity")
STATE_OUTPUT_DIR = get_output_dir("state")


def get_directories_to_process() -> dict:
    """Get directories that need to be processed for UML generation."""
    project_root = PROJECT_ROOT

    app_dir = project_root / "backend" / "app"
    if not app_dir.exists():
        logger.error(f"Directory {app_dir} does not exist.")
        return {}

    # Process core components first
    core_dirs = [
        app_dir / "core",
        app_dir / "models" if (app_dir / "models").exists() else app_dir,
        app_dir / "services" if (app_dir / "services").exists() else None,
    ]

    # Process API components
    api_dirs = [app_dir / "api"]

    # Process test components separately with different settings
    test_dirs = [app_dir / "tests"] if (app_dir / "tests").exists() else []

    # Add utils directory
    utils_dir = project_root / "utils"

    # Add uml directory for special handling
    uml_dir = utils_dir / "uml"

    return {
        "core": {
            "dirs": [d for d in core_dirs if d and d.exists()],
            "base_dir": app_dir,
        },
        "api": {"dirs": [d for d in api_dirs if d and d.exists()], "base_dir": app_dir},
        "tests": {"dirs": test_dirs, "base_dir": app_dir},
        "utils": {
            "dirs": [utils_dir] if utils_dir.exists() else [],
            "base_dir": project_root,
        },
        "uml": {
            "dirs": [uml_dir] if uml_dir.exists() else [],
            "base_dir": project_root,
        },
    }


def generate_class_diagrams(service: UmlService, directories: dict) -> None:
    """Generate class diagrams for the specified directories."""
    # Create output directory
    output_dir = CLASS_OUTPUT_DIR
    output_dir.mkdir(parents=True, exist_ok=True)

    logger.info("Generating class diagrams...")

    # Process each directory
    for category, category_info in directories.items():
        for directory in category_info["dirs"]:
            try:
                # Generate class diagram for this directory
                output_path = output_dir / f"{category}_{directory.name}.puml"
                service.generate_diagram(
                    "class",
                    directory,
                    output_path,
                    recursive=True,
                    include_private=False,
                )
                logger.info(f"Generated class diagram for {directory} at {output_path}")
            except Exception as e:
                logger.error(f"Error generating class diagram for {directory}: {e}")


def generate_sequence_diagrams(service: UmlService, directories: dict) -> None:
    """Generate sequence diagrams for the specified directories."""
    # Create output directory
    output_dir = SEQUENCE_OUTPUT_DIR
    output_dir.mkdir(parents=True, exist_ok=True)

    logger.info("Generating sequence diagrams...")

    # Process each directory
    for category, category_info in directories.items():
        for directory in category_info["dirs"]:
            try:
                # Generate sequence diagram for this directory
                output_path = output_dir / f"{category}_{directory.name}.puml"
                service.generate_diagram(
                    "sequence",
                    directory,
                    output_path,
                    recursive=True,
                    root_dir=str(directory),
                )
                logger.info(
                    f"Generated sequence diagram for {directory} at {output_path}",
                )
            except Exception as e:
                logger.error(f"Error generating sequence diagram for {directory}: {e}")


def generate_activity_diagrams(service: UmlService, directories: dict) -> None:
    """Generate activity diagrams for the specified directories."""
    # Create output directory
    output_dir = ACTIVITY_OUTPUT_DIR
    output_dir.mkdir(parents=True, exist_ok=True)

    logger.info("Generating activity diagrams...")

    # Process each directory
    for category, category_info in directories.items():
        for directory in category_info["dirs"]:
            try:
                # Generate activity diagram for this directory
                output_path = output_dir / f"{category}_{directory.name}.puml"
                service.generate_diagram(
                    "activity",
                    directory,
                    output_path,
                    recursive=True,
                )
                logger.info(
                    f"Generated activity diagram for {directory} at {output_path}",
                )
            except Exception as e:
                logger.error(f"Error generating activity diagram for {directory}: {e}")


def generate_state_diagrams(service: UmlService, directories: dict) -> None:
    """Generate state diagrams for the specified directories."""
    # Create output directory
    output_dir = STATE_OUTPUT_DIR
    output_dir.mkdir(parents=True, exist_ok=True)

    logger.info("Generating state diagrams...")

    # Process each directory
    for category, category_info in directories.items():
        for directory in category_info["dirs"]:
            try:
                # Generate state diagram for this directory
                output_path = output_dir / f"{category}_{directory.name}.puml"
                service.generate_diagram(
                    "state",
                    directory,
                    output_path,
                    recursive=True,
                )
                logger.info(f"Generated state diagram for {directory} at {output_path}")
            except Exception as e:
                logger.error(f"Error generating state diagram for {directory}: {e}")


def generate_yaml_sequence_diagrams(service: UmlService) -> None:
    """Generate sequence diagrams from YAML definitions."""
    try:
        import yaml
    except ImportError:
        logger.error("PyYAML is required for sequence diagram generation")
        logger.error("Install with 'pip install pyyaml'")
        return

    sequence_dir = Path("examples/sequence_diagrams")

    if not sequence_dir.exists():
        logger.warning(f"No sequence diagram definitions found at {sequence_dir}")
        return

    logger.info(f"Generating sequence diagrams from {sequence_dir}...")

    # Create output directory
    output_dir = SEQUENCE_OUTPUT_DIR
    output_dir.mkdir(parents=True, exist_ok=True)

    # Process all YAML files
    yaml_count = 0
    for yaml_file in sequence_dir.glob("*.yaml"):
        try:
            output_path = output_dir / f"{yaml_file.stem}.puml"

            # Read YAML file and generate diagram
            with open(yaml_file) as f:
                yaml_content = f.read()

            # Use the sequence diagram generator to process the YAML content
            # This is a placeholder - the actual implementation would depend on
            # how the YAML sequence diagrams are processed in the new architecture
            logger.info(f"Processing sequence diagram from {yaml_file}")

            yaml_count += 1
        except Exception as e:
            logger.error(f"Error processing {yaml_file}: {e}")

    if yaml_count > 0:
        logger.info(
            f"Generated {yaml_count} sequence diagrams from YAML in {output_dir}",
        )
    else:
        logger.warning("No sequence diagrams were generated from YAML")


def verify_generated_files(output_dir: Path) -> None:
    """Verify and log the generated files structure."""
    logger.info("\nVerifying generated files structure:")
    logger.info("===================================")

    for root, dirs, files in os.walk(output_dir):
        rel_path = Path(root).relative_to(output_dir)
        level = 0 if str(rel_path) == "." else len(rel_path.parts)

        indent = "  " * level

        # Print directory name
        if level > 0:
            logger.info(f"{indent[:-2]}+ {rel_path.name}/")

        # Print files
        for file in sorted(files):
            if file.endswith(".puml"):
                logger.info(f"{indent}- {file}")
    logger.info("\nUML diagrams generated in docs/source/_generated_uml/")


def main() -> int:
    """Run the UML generator on the backend/app directory structure."""
    # Get all directories to process
    directories = get_directories_to_process()
    if not directories:
        return 1

    # Create output directories
    OUTPUT_BASE_DIR.mkdir(parents=True, exist_ok=True)

    # Create service
    file_system = DefaultFileSystem()
    factory = DefaultDiagramFactory(file_system)
    service = UmlService(factory)

    # Generate class diagrams
    generate_class_diagrams(service, directories)

    # Generate sequence diagrams
    generate_sequence_diagrams(service, directories)

    # Generate activity diagrams
    generate_activity_diagrams(service, directories)

    # Generate state diagrams
    generate_state_diagrams(service, directories)

    # Generate sequence diagrams from YAML definitions
    generate_yaml_sequence_diagrams(service)

    # Alternative: Use the dedicated script for backend/app sequence diagrams
    try:
        if os.path.exists("utils/uml/cli/extract_app_sequences.py"):
            logger.info(
                "Generating application sequence diagrams using extract_app_sequences.py...",
            )
            subprocess.run(
                ["python", "-m", "utils.uml.cli.extract_app_sequences"],
                stdout=subprocess.PIPE,
                stderr=subprocess.PIPE,
                check=False,
            )
            logger.info("Application sequence diagrams generated successfully.")
    except Exception as e:
        logger.error(f"Error generating application sequence diagrams: {e}")

    # Verify and log the generated files structure
    verify_generated_files(OUTPUT_BASE_DIR)

    logger.info("\nUML diagrams generated successfully.")

    return 0


if __name__ == "__main__":
    sys.exit(main())

================
File: uml/cli/uml_cli.py
================
#!/usr/bin/env python
"""
Unified CLI for UML diagram generation.

This script provides a unified command-line interface for generating all types
of UML diagrams, including class, sequence, activity, and state diagrams.
"""

import argparse
import logging
import sys
from pathlib import Path

# Add the project root to the Python path
sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))

# Import the UML modules
from utils.uml.core.filesystem import FileSystem
from utils.uml.core.service import UmlService
from utils.uml.factories import DefaultDiagramFactory

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# Project root directory
PROJECT_ROOT = Path(__file__).parent.parent.parent.parent

# Constants
OUTPUT_BASE_DIR = Path("docs/source/_generated_uml")


def create_parser() -> argparse.ArgumentParser:
    """Create the command-line argument parser."""
    parser = argparse.ArgumentParser(
        description="Generate UML diagrams from source code.",
    )

    subparsers = parser.add_subparsers(
        dest="command",
        help="Command to execute",
        required=True,
    )

    # Common arguments for all commands
    common_parser = argparse.ArgumentParser(add_help=False)
    common_parser.add_argument(
        "--source",
        "-s",
        required=True,
        help="Source directory or file to analyze",
    )
    common_parser.add_argument(
        "--output",
        "-o",
        help="Output directory for diagrams",
    )
    common_parser.add_argument(
        "--recursive",
        "-r",
        action="store_true",
        help="Recursively analyze directories",
    )
    common_parser.add_argument(
        "--exclude",
        "-e",
        action="append",
        default=[],
        help="Patterns to exclude (can be specified multiple times)",
    )
    common_parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Enable verbose logging",
    )

    # Class diagram command
    class_parser = subparsers.add_parser(
        "class",
        help="Generate class diagrams",
        parents=[common_parser],
    )
    class_parser.add_argument(
        "--include-private",
        "-p",
        action="store_true",
        help="Include private members in diagrams",
    )

    # Sequence diagram command
    sequence_parser = subparsers.add_parser(
        "sequence",
        help="Generate sequence diagrams",
        parents=[common_parser],
    )
    sequence_parser.add_argument(
        "--module",
        "-m",
        help="Module to analyze",
    )
    sequence_parser.add_argument(
        "--class",
        "-c",
        dest="class_name",
        help="Class to analyze",
    )
    sequence_parser.add_argument(
        "--method",
        help="Method to analyze",
    )
    sequence_parser.add_argument(
        "--function",
        "-f",
        help="Function to analyze",
    )

    # Activity diagram command
    activity_parser = subparsers.add_parser(
        "activity",
        help="Generate activity diagrams",
        parents=[common_parser],
    )

    # State diagram command
    state_parser = subparsers.add_parser(
        "state",
        help="Generate state diagrams",
        parents=[common_parser],
    )

    # All diagrams command
    all_parser = subparsers.add_parser(
        "all",
        help="Generate all types of diagrams",
        parents=[common_parser],
    )
    all_parser.add_argument(
        "--include-private",
        "-p",
        action="store_true",
        help="Include private members in class diagrams",
    )

    # App sequences command
    app_sequences_parser = subparsers.add_parser(
        "app-sequences",
        help="Generate sequence diagrams for key application entry points",
    )
    app_sequences_parser.add_argument(
        "--app-dir",
        default="backend/app",
        help="Application directory (default: backend/app)",
    )
    app_sequences_parser.add_argument(
        "--output",
        "-o",
        help="Output directory for diagrams",
    )
    app_sequences_parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Enable verbose logging",
    )

    return parser


def get_output_dir(args: argparse.Namespace, diagram_type: str | None = None) -> Path:
    """Get the output directory for diagrams.

    Args:
        args: Command-line arguments
        diagram_type: Type of diagram (class, sequence, activity, state)

    Returns:
        Path to the output directory
    """
    if args.output:
        output_dir = Path(args.output)
    else:
        output_dir = OUTPUT_BASE_DIR

    if diagram_type:
        output_dir = output_dir / diagram_type

    output_dir.mkdir(parents=True, exist_ok=True)
    return output_dir


def create_service(settings: dict | None = None) -> UmlService:
    """Create and return a UML service with the given settings.

    Args:
        settings: Service settings

    Returns:
        UML service instance
    """
    file_system = FileSystem()
    factory = DefaultDiagramFactory(file_system, settings)
    return UmlService(factory, settings)


def generate_class_diagram(args: argparse.Namespace) -> int:
    """Generate class diagrams.

    Args:
        args: Command-line arguments

    Returns:
        Exit code (0 for success, non-zero for failure)
    """
    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Get output directory
    output_dir = get_output_dir(args, "class")

    # Create service
    settings = {
        "include_private": args.include_private,
        "recursive": args.recursive,
        "exclude_patterns": args.exclude,
    }
    service = create_service(settings)

    # Generate class diagrams
    try:
        source_path = Path(args.source)
        output_path = output_dir / f"{source_path.stem}.puml"

        service.generate_diagram(
            "class",
            source_path,
            output_path,
            **settings,
        )

        logger.info(f"Class diagram generated successfully in {output_dir}")
        return 0
    except Exception as e:
        logger.error(f"Error generating class diagram: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


def generate_sequence_diagram(args: argparse.Namespace) -> int:
    """Generate sequence diagrams.

    Args:
        args: Command-line arguments

    Returns:
        Exit code (0 for success, non-zero for failure)
    """
    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Get output directory
    output_dir = get_output_dir(args, "sequence")

    # Create service
    settings = {
        "recursive": args.recursive,
        "exclude_patterns": args.exclude,
    }

    # Add module, class, method, function if provided
    if args.module:
        settings["module"] = args.module
    if args.class_name:
        settings["class"] = args.class_name
    if args.method:
        settings["method"] = args.method
    if args.function:
        settings["function"] = args.function

    service = create_service(settings)

    # Generate sequence diagrams
    try:
        source_path = Path(args.source)
        output_path = output_dir / f"{source_path.stem}.puml"

        service.generate_diagram(
            "sequence",
            source_path,
            output_path,
            **settings,
        )

        logger.info(f"Sequence diagram generated successfully in {output_dir}")
        return 0
    except Exception as e:
        logger.error(f"Error generating sequence diagram: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


def generate_activity_diagram(args: argparse.Namespace) -> int:
    """Generate activity diagrams.

    Args:
        args: Command-line arguments

    Returns:
        Exit code (0 for success, non-zero for failure)
    """
    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Get output directory
    output_dir = get_output_dir(args, "activity")

    # Create service
    settings = {
        "recursive": args.recursive,
        "exclude_patterns": args.exclude,
    }
    service = create_service(settings)

    # Generate activity diagrams
    try:
        source_path = Path(args.source)
        output_path = output_dir / f"{source_path.stem}.puml"

        service.generate_diagram(
            "activity",
            source_path,
            output_path,
            **settings,
        )

        logger.info(f"Activity diagram generated successfully in {output_dir}")
        return 0
    except Exception as e:
        logger.error(f"Error generating activity diagram: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


def generate_state_diagram(args: argparse.Namespace) -> int:
    """Generate state diagrams.

    Args:
        args: Command-line arguments

    Returns:
        Exit code (0 for success, non-zero for failure)
    """
    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Get output directory
    output_dir = get_output_dir(args, "state")

    # Create service
    settings = {
        "recursive": args.recursive,
        "exclude_patterns": args.exclude,
    }
    service = create_service(settings)

    # Generate state diagrams
    try:
        source_path = Path(args.source)
        output_path = output_dir / f"{source_path.stem}.puml"

        service.generate_diagram(
            "state",
            source_path,
            output_path,
            **settings,
        )

        logger.info(f"State diagram generated successfully in {output_dir}")
        return 0
    except Exception as e:
        logger.error(f"Error generating state diagram: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


def generate_all_diagrams(args: argparse.Namespace) -> int:
    """Generate all types of diagrams.

    Args:
        args: Command-line arguments

    Returns:
        Exit code (0 for success, non-zero for failure)
    """
    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Get output directory
    output_dir = get_output_dir(args)

    # Create service
    settings = {
        "include_private": args.include_private,
        "recursive": args.recursive,
        "exclude_patterns": args.exclude,
    }
    service = create_service(settings)

    # Generate all diagrams
    try:
        source_path = Path(args.source)

        # Convert Path objects to strings to match the expected type
        source_paths = [str(source_path)]
        source_paths_dict = {
            "class": source_paths,
            "sequence": source_paths,
            "activity": source_paths,
            "state": source_paths,
        }

        results = service.generate_all_diagrams(source_paths_dict, output_dir)

        # Log results
        for diagram_type, diagrams in results.items():
            if diagrams:
                logger.info(
                    f"Generated {len(diagrams)} {diagram_type} diagrams in {output_dir / diagram_type}",
                )

        logger.info(f"All UML diagrams generated successfully in {output_dir}")
        return 0
    except Exception as e:
        logger.error(f"Error generating diagrams: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


def generate_app_sequences(args: argparse.Namespace) -> int:
    """Generate sequence diagrams for key application entry points.

    Args:
        args: Command-line arguments

    Returns:
        Exit code (0 for success, non-zero for failure)
    """
    import subprocess

    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    # Get output directory
    output_dir = get_output_dir(args, "sequence")

    # Define important entry points for sequence diagrams
    # Format: (class_name, method_name, output_filename)
    ENTRY_POINTS = [
        # User Authentication Flows
        ("login", "login_access_token", "authentication_flow"),  # Login flow
        ("login", "test_token", "token_verification"),  # Token verification
        # User Management Flows
        ("users", "create_user", "admin_create_user"),  # Admin creates user
        ("users", "register_user", "user_signup"),  # User signup
        ("users", "update_user_me", "user_update_profile"),  # Update profile
        ("users", "update_password_me", "user_change_password"),  # Change password
        ("users", "delete_user_me", "user_delete_account"),  # Delete account
        # Password Recovery Flow
        (
            "login",
            "recover_password",
            "password_recovery_request",
        ),  # Request password reset
        ("login", "reset_password", "password_reset"),  # Reset password
        # Other API Endpoints
        # Add other important flows here
    ]

    print("Extracting sequence diagrams from backend/app...")
    print("=" * 50)

    success_count = 0
    for module_name, method_name, output_name in ENTRY_POINTS:
        output_file = output_dir / f"{output_name}.puml"

        # For routes modules, we need to specify the full path
        if module_name in ("login", "users", "items", "private", "utils"):
            # API route modules
            module_path = f"api.routes.{module_name}"
        else:
            # Other modules
            module_path = module_name

        print(f"Generating diagram for {module_path}.{method_name}...")

        # Construct the command
        cmd = [
            "python",
            "-m",
            "utils.uml.cli.uml_cli",
            "sequence",
            "--dir",
            args.app_dir,
            "--module",
            module_path,
            "--class",
            "router",  # For FastAPI routers, the class is "router"
            "--method",
            method_name,
            "--output",
            str(output_file),
            "--verbose" if args.verbose else "",
        ]

        # Remove empty arguments
        cmd = [arg for arg in cmd if arg]

        try:
            # Run the extraction command
            result = subprocess.run(cmd, capture_output=True, text=True, check=False)

            if result.returncode == 0:
                print(f"✓ Successfully generated: {output_file}")
                success_count += 1
            else:
                print(f"× Failed to generate diagram. Error: {result.stderr}")

                # Try an alternative approach for router functions
                # Sometimes router functions are directly accessible by module.function_name
                alternative_cmd = [
                    "python",
                    "-m",
                    "utils.uml.cli.uml_cli",
                    "sequence",
                    "--dir",
                    args.app_dir,
                    "--module",
                    module_path,
                    "--function",
                    method_name,  # Try as a function instead of a class method
                    "--output",
                    str(output_file),
                    "--verbose" if args.verbose else "",
                ]

                # Remove empty arguments
                alternative_cmd = [arg for arg in alternative_cmd if arg]

                print("  Trying alternative approach...")
                alt_result = subprocess.run(
                    alternative_cmd,
                    capture_output=True,
                    text=True,
                    check=False,
                )

                if alt_result.returncode == 0:
                    print(
                        f"✓ Successfully generated using alternative approach: {output_file}",
                    )
                    success_count += 1
                else:
                    print(f"× Alternative approach also failed: {alt_result.stderr}")

        except Exception as e:
            print(f"× Error: {e!s}")

    print("=" * 50)
    print(
        f"Sequence diagram extraction completed: {success_count}/{len(ENTRY_POINTS)} successful",
    )
    print(f"Diagrams saved to: {output_dir}")

    return 0 if success_count > 0 else 1


def main() -> int:
    """Run the UML generator CLI.

    Returns:
        Exit code (0 for success, non-zero for failure)
    """
    parser = create_parser()
    args = parser.parse_args()

    # Execute the appropriate command
    if args.command == "class":
        return generate_class_diagram(args)
    if args.command == "sequence":
        return generate_sequence_diagram(args)
    if args.command == "activity":
        return generate_activity_diagram(args)
    if args.command == "state":
        return generate_state_diagram(args)
    if args.command == "all":
        return generate_all_diagrams(args)
    if args.command == "app-sequences":
        return generate_app_sequences(args)
    parser.print_help()
    return 1


if __name__ == "__main__":
    sys.exit(main())

================
File: uml/config/__init__.py
================
"""Configuration handling for UML diagram generation.

This module provides functionality for loading and managing configuration for UML generators.
"""

================
File: uml/core/__init__.py
================
"""Core functionality for UML diagram generation.

This module provides the core interfaces and classes used by all diagram types.
"""

================
File: uml/core/exceptions.py
================
"""Exception classes for UML diagram generation.

This module defines the exception classes used throughout the UML generation package.
"""


class UMLGeneratorError(Exception):
    """Base exception for all UML generator errors."""

    def __init__(self, message: str, cause: Exception | None = None):
        """Initialize a UML generator error.

        Args:
            message: The error message
            cause: The exception that caused this error, if any
        """
        self.message = message
        self.cause = cause
        super().__init__(message)


class ConfigurationError(UMLGeneratorError):
    """Exception raised for configuration errors."""

    pass


class ParserError(UMLGeneratorError):
    """Exception raised when parsing code fails."""

    pass


class GeneratorError(UMLGeneratorError):
    """Exception raised when generating diagrams fails."""

    pass


class FileSystemError(UMLGeneratorError):
    """Exception raised for file system operations errors."""

    pass


class DiagramTypeError(UMLGeneratorError):
    """Exception raised when an unsupported diagram type is requested."""

    pass

================
File: uml/core/filesystem.py
================
"""File system operations for UML diagram generation.

This module provides a default implementation of the FileSystem interface
for performing file system operations.
"""

from pathlib import Path

from utils.uml.core.exceptions import FileSystemError


class FileSystem:
    """Interface for file system operations."""

    def read_file(self, path: str | Path) -> str:
        """Read file content as string.

        Args:
            path: Path to the file to read

        Returns:
            The content of the file as a string

        Raises:
            FileSystemError: If the file cannot be read
        """
        ...

    def write_file(self, path: str | Path, content: str) -> None:
        """Write content to file.

        Args:
            path: Path to the file to write
            content: Content to write to the file

        Raises:
            FileSystemError: If the file cannot be written
        """
        ...

    def ensure_directory(self, path: str | Path) -> None:
        """Ensure directory exists, create if needed.

        Args:
            path: Path to the directory to ensure exists

        Raises:
            FileSystemError: If the directory cannot be created
        """
        ...

    def find_files(self, directory: str | Path, pattern: str) -> list[Path]:
        """Find files matching pattern in directory.

        Args:
            directory: Directory to search in
            pattern: Glob pattern to match files against

        Returns:
            A list of paths to files matching the pattern

        Raises:
            FileSystemError: If the directory cannot be accessed
        """
        ...


class DefaultFileSystem(FileSystem):
    """Default implementation of FileSystem interface."""

    def _ensure_path(self, path: str | Path) -> Path:
        """Ensure path is a Path object.

        Args:
            path: Path as string or Path object

        Returns:
            Path object
        """
        return Path(path) if isinstance(path, str) else path

    def read_file(self, path: str | Path) -> str:
        """Read file content as string."""
        try:
            path_obj = self._ensure_path(path)
            with open(path_obj, encoding="utf-8") as f:
                return f.read()
        except Exception as e:
            raise FileSystemError(f"Failed to read file {path}: {e}", cause=e)

    def write_file(self, path: str | Path, content: str) -> None:
        """Write content to file."""
        try:
            path_obj = self._ensure_path(path)
            with open(path_obj, "w", encoding="utf-8") as f:
                f.write(content)
        except Exception as e:
            raise FileSystemError(f"Failed to write file {path}: {e}", cause=e)

    def ensure_directory(self, path: str | Path) -> None:
        """Ensure directory exists, create if needed."""
        try:
            path_obj = self._ensure_path(path)
            path_obj.mkdir(parents=True, exist_ok=True)
        except Exception as e:
            raise FileSystemError(f"Failed to create directory {path}: {e}", cause=e)

    def find_files(self, directory: str | Path, pattern: str) -> list[Path]:
        """Find files matching pattern in directory."""
        try:
            dir_obj = self._ensure_path(directory)
            # Use rglob for recursive search
            return list(dir_obj.rglob(pattern))
        except Exception as e:
            raise FileSystemError(
                f"Failed to find files in {directory} with pattern {pattern}: {e}",
                cause=e,
            )

================
File: uml/core/interfaces.py
================
"""Interfaces for UML diagram generation.

This module defines the core interfaces for UML diagram generation, including
models, analyzers, and generators.
"""

from abc import ABC, abstractmethod
from pathlib import Path


class DiagramModel(ABC):
    """Base interface for all diagram models.

    A diagram model represents the parsed information that will be used to generate
    a UML diagram.
    """

    @property
    @abstractmethod
    def name(self) -> str:
        """Return the name of the diagram."""
        pass

    @property
    @abstractmethod
    def diagram_type(self) -> str:
        """Return the type of the diagram (class, sequence, etc.)."""
        pass


class DiagramAnalyzer(ABC):
    """Base interface for all diagram analyzers.

    A diagram analyzer is responsible for analyzing source code and creating a
    diagram model from it.
    """

    @abstractmethod
    def analyze(self, path: str | Path, **kwargs) -> DiagramModel:
        """Analyze the source code at the given path and return a diagram model.

        Args:
            path: Path to the source code to analyze
            **kwargs: Additional analyzer-specific arguments

        Returns:
            A diagram model containing the analyzed information
        """
        pass


class DiagramGenerator(ABC):
    """Base interface for all diagram generators.

    A diagram generator is responsible for generating a UML diagram from a
    diagram model.
    """

    @abstractmethod
    def generate_diagram(
        self,
        model: DiagramModel,
        output_path: str | Path,
        **kwargs,
    ) -> None:
        """Generate a UML diagram from the given model and write it to the output path.

        Args:
            model: The diagram model to generate a diagram from
            output_path: The path to write the diagram to
            **kwargs: Additional generator-specific arguments
        """
        pass

    @abstractmethod
    def generate_index(
        self,
        output_dir: str | Path,
        diagrams: list[Path],
        **kwargs,
    ) -> None:
        """Generate an index file for all diagrams in the output directory.

        Args:
            output_dir: The directory containing the diagrams
            diagrams: A list of paths to all diagrams
            **kwargs: Additional generator-specific arguments
        """
        pass


class DiagramFactory(ABC):
    """Base interface for diagram factories.

    A diagram factory is responsible for creating appropriate diagram analyzers and
    generators based on the diagram type.
    """

    @abstractmethod
    def create_analyzer(self, diagram_type: str, **kwargs) -> DiagramAnalyzer:
        """Create an analyzer for the given diagram type.

        Args:
            diagram_type: The type of diagram to create an analyzer for
            **kwargs: Additional factory-specific arguments

        Returns:
            A diagram analyzer for the given diagram type
        """
        pass

    @abstractmethod
    def create_generator(self, diagram_type: str, **kwargs) -> DiagramGenerator:
        """Create a generator for the given diagram type.

        Args:
            diagram_type: The type of diagram to create a generator for
            **kwargs: Additional factory-specific arguments

        Returns:
            A diagram generator for the given diagram type
        """
        pass

================
File: uml/core/service.py
================
"""Core service for UML diagram generation.

This module provides the core service for UML diagram generation, including
the main entry point for generating diagrams.
"""

import logging
from pathlib import Path
from typing import Any

from utils.uml.core.exceptions import DiagramTypeError, GeneratorError, ParserError
from utils.uml.core.interfaces import DiagramAnalyzer, DiagramFactory, DiagramGenerator


class UmlService:
    """Core service for UML diagram generation."""

    def __init__(
        self,
        factory: DiagramFactory,
        settings: dict[str, Any] | None = None,
    ):
        """Initialize the UML service.

        Args:
            factory: The diagram factory to use
            settings: Optional settings for the service
        """
        self.factory = factory
        self.settings = settings or {}
        self.logger = logging.getLogger(__name__)

    def _create_components(
        self,
        diagram_type: str,
        **kwargs,
    ) -> tuple[DiagramAnalyzer, DiagramGenerator]:
        """Create analyzer and generator components for the given diagram type.

        Args:
            diagram_type: The type of diagram to create components for
            **kwargs: Additional component-specific arguments

        Returns:
            A tuple of (analyzer, generator) for the given diagram type

        Raises:
            DiagramTypeError: If the diagram type is not supported
        """
        analyzer = self.factory.create_analyzer(diagram_type, **kwargs)
        generator = self.factory.create_generator(diagram_type, **kwargs)
        return analyzer, generator

    def generate_diagram(
        self,
        diagram_type: str,
        source_path: str | Path,
        output_path: str | Path,
        **kwargs,
    ) -> None:
        """Generate a UML diagram from the given source path.

        Args:
            diagram_type: The type of diagram to generate (class, sequence, etc.)
            source_path: The path to the source code or definition file
            output_path: The path to write the diagram to
            **kwargs: Additional diagram-specific arguments

        Raises:
            DiagramTypeError: If the diagram type is not supported
            ParserError: If the source code cannot be parsed
            GeneratorError: If the diagram cannot be generated
        """
        try:
            # Create analyzer and generator
            analyzer, generator = self._create_components(diagram_type, **kwargs)

            # Analyze the source code
            model = analyzer.analyze(source_path, **kwargs)

            # Generate the diagram
            generator.generate_diagram(model, output_path, **kwargs)

            self.logger.info(f"Generated {diagram_type} diagram at {output_path}")
        except (DiagramTypeError, ParserError, GeneratorError) as e:
            self.logger.exception(f"Failed to generate {diagram_type} diagram: {e}")
            raise
        except Exception as e:
            self.logger.exception(
                f"Unexpected error generating {diagram_type} diagram: {e}",
            )
            error_message = f"Unexpected error: {e}"
            raise GeneratorError(error_message, cause=e)

    def _get_output_path(self, source_path: Path, output_dir: Path) -> Path:
        """Determine the output path for a diagram based on the source path.

        Args:
            source_path: The source path
            output_dir: The output directory

        Returns:
            The output path for the diagram
        """
        if source_path.is_file():
            return output_dir / f"{source_path.stem}.puml"
        # For directories, use the directory name
        return output_dir / f"{source_path.name}.puml"

    def generate_diagrams(
        self,
        diagram_type: str,
        source_paths: list[str | Path],
        output_dir: str | Path,
        **kwargs,
    ) -> list[Path]:
        """Generate UML diagrams from the given source paths.

        Args:
            diagram_type: The type of diagram to generate (class, sequence, etc.)
            source_paths: The paths to the source code or definition files
            output_dir: The directory to write the diagrams to
            **kwargs: Additional diagram-specific arguments

        Returns:
            A list of paths to the generated diagrams

        Raises:
            DiagramTypeError: If the diagram type is not supported
        """
        output_dir = Path(output_dir) if isinstance(output_dir, str) else output_dir
        generated_diagrams: list[Path] = []

        # Create analyzer and generator
        analyzer, generator = self._create_components(diagram_type, **kwargs)

        # Process each source path
        for source_path in source_paths:
            source_path = (
                Path(source_path) if isinstance(source_path, str) else source_path
            )

            try:
                # Determine output path
                output_path = self._get_output_path(source_path, output_dir)

                # Analyze the source code
                model = analyzer.analyze(source_path, **kwargs)

                # Generate the diagram
                generator.generate_diagram(model, output_path, **kwargs)

                generated_diagrams.append(output_path)
                self.logger.info(f"Generated {diagram_type} diagram at {output_path}")
            except Exception as e:
                self.logger.exception(f"Error processing {source_path}: {e}")
                # Continue with other source paths

        # Generate index file if diagrams were generated
        self._generate_index_file(generator, output_dir, generated_diagrams, **kwargs)

        return generated_diagrams

    def _generate_index_file(
        self,
        generator: DiagramGenerator,
        output_dir: Path,
        diagrams: list[Path],
        **kwargs,
    ) -> None:
        """Generate an index file for the diagrams.

        Args:
            generator: The diagram generator to use
            output_dir: The output directory
            diagrams: The list of diagram paths
            **kwargs: Additional generator-specific arguments
        """
        if not diagrams:
            return

        try:
            generator.generate_index(output_dir, diagrams, **kwargs)
            self.logger.info(f"Generated index file at {output_dir}")
        except Exception as e:
            self.logger.exception(f"Error generating index file: {e}")

    def generate_all_diagrams(
        self,
        source_paths: dict[str, list[str | Path]],
        output_dir: str | Path,
        **kwargs,
    ) -> dict[str, list[Path]]:
        """Generate all types of UML diagrams from the given source paths.

        Args:
            source_paths: A dictionary mapping diagram types to source paths
            output_dir: The directory to write the diagrams to
            **kwargs: Additional diagram-specific arguments

        Returns:
            A dictionary mapping diagram types to lists of generated diagram paths
        """
        output_dir = Path(output_dir) if isinstance(output_dir, str) else output_dir
        results: dict[str, list[Path]] = {}

        for diagram_type, paths in source_paths.items():
            try:
                # Create type-specific output directory
                type_output_dir = output_dir / diagram_type
                type_output_dir.mkdir(parents=True, exist_ok=True)

                # Generate diagrams for this type
                diagrams = self.generate_diagrams(
                    diagram_type,
                    paths,
                    type_output_dir,
                    **kwargs,
                )
                results[diagram_type] = diagrams
            except DiagramTypeError as e:
                self.logger.exception(f"Unsupported diagram type {e}")
            except Exception as e:
                self.logger.exception(f"Error generating {diagram_type} diagrams: {e}")

        return results

================
File: uml/diagrams/__init__.py
================
"""UML diagram implementations.

This package contains implementations for various types of UML diagrams:
- Class diagrams
- Sequence diagrams
- Activity diagrams (planned)
- State diagrams (planned)
"""

================
File: uml/diagrams/activity_diagram/__init__.py
================
"""Activity diagram generation.

This module will provide functionality for generating UML activity diagrams (planned).
"""

================
File: uml/diagrams/activity_diagram/analyzer.py
================
"""Analyzer for extracting activity diagrams from Python code.

This module provides functionality for analyzing Python code and extracting
activity diagrams from it.
"""

import logging
from pathlib import Path
from typing import Any

from utils.uml.core.exceptions import ParserError
from utils.uml.core.filesystem import FileSystem
from utils.uml.diagrams.activity_diagram.models import (
    ActivityDiagram,
    ActivityModel,
    DecisionNodeModel,
    EndNodeModel,
    StartNodeModel,
    TransitionModel,
)
from utils.uml.diagrams.base import BaseDiagramAnalyzer


class ActivityAnalyzer(BaseDiagramAnalyzer):
    """Analyzer for extracting activity diagrams from Python code."""

    def __init__(self, file_system: FileSystem):
        """Initialize the activity analyzer.

        Args:
            file_system: The file system implementation to use
        """
        super().__init__(file_system)
        self.logger = logging.getLogger(__name__)

    def analyze(
        self,
        path: str | Path,
        **kwargs: Any,
    ) -> ActivityDiagram:
        """Analyze the source code at the given path and generate an activity diagram.

        This is a placeholder implementation that will be expanded in the future.
        Currently, it creates a simple example diagram.

        Args:
            path: Path to the source code to analyze
            **kwargs: Additional analyzer-specific arguments

        Returns:
            An activity diagram model

        Raises:
            ParserError: If the analysis fails
        """
        try:
            # Create a placeholder diagram
            diagram_name = kwargs.get("name", "Activity Diagram")
            if isinstance(path, Path):
                if path.is_file():
                    diagram_name = f"Activity Diagram - {path.stem}"
                else:
                    diagram_name = f"Activity Diagram - {path.name}"

            diagram = ActivityDiagram(diagram_name)

            # This is a placeholder implementation
            # In a real implementation, we would analyze the code and extract activities

            # Add a simple example diagram
            self._create_example_diagram(diagram)

            return diagram
        except Exception as e:
            raise ParserError(f"Failed to analyze code at {path}: {e}", cause=e)

    def _create_example_diagram(self, diagram: ActivityDiagram) -> None:
        """Create a simple example diagram.

        Args:
            diagram: The diagram to populate
        """
        # Add start node
        start = StartNodeModel("start")
        diagram.add_start_node(start)

        # Add activities
        init = ActivityModel("init", "Initialize")
        process = ActivityModel("process", "Process Data")
        validate = ActivityModel("validate", "Validate Results")
        save = ActivityModel("save", "Save Results")

        diagram.add_activity(init)
        diagram.add_activity(process)
        diagram.add_activity(validate)
        diagram.add_activity(save)

        # Add decision node
        decision = DecisionNodeModel("valid", "Is Valid?")
        diagram.add_decision_node(decision)

        # Add end node
        end = EndNodeModel("end")
        diagram.add_end_node(end)

        # Add transitions
        diagram.add_transition(TransitionModel("start", "init"))
        diagram.add_transition(TransitionModel("init", "process"))
        diagram.add_transition(TransitionModel("process", "validate"))
        diagram.add_transition(TransitionModel("validate", "valid"))
        diagram.add_transition(TransitionModel("valid", "save", "yes"))
        diagram.add_transition(TransitionModel("valid", "process", "no", "Retry"))
        diagram.add_transition(TransitionModel("save", "end"))

================
File: uml/diagrams/activity_diagram/generator.py
================
"""Generator for converting activity diagrams to PlantUML format.

This module provides functionality for generating PlantUML activity diagrams from
activity diagram models.
"""

from pathlib import Path
from typing import Any

from utils.uml.core.exceptions import GeneratorError
from utils.uml.core.filesystem import FileSystem
from utils.uml.core.interfaces import DiagramModel
from utils.uml.diagrams.activity_diagram.models import (
    ActivityDiagram,
)
from utils.uml.diagrams.base import BaseDiagramGenerator


class ActivityDiagramGenerator(BaseDiagramGenerator):
    """Generates PlantUML activity diagrams from activity diagram models."""

    def __init__(self, file_system: FileSystem, settings: dict[str, Any] | None = None):
        """Initialize an activity diagram generator.

        Args:
            file_system: The file system implementation to use
            settings: Optional settings for the generator
        """
        super().__init__(file_system, settings)

    def generate_diagram(
        self,
        model: DiagramModel,
        output_path: str | Path,
        **kwargs,
    ) -> None:
        """Generate a UML diagram from the given model and write it to the output path.

        Args:
            model: The diagram model to generate a diagram from
            output_path: The path to write the diagram to
            **kwargs: Additional generator-specific arguments

        Raises:
            GeneratorError: If the diagram cannot be generated
        """
        try:
            # Ensure the model is an ActivityDiagram
            if not isinstance(model, ActivityDiagram):
                raise GeneratorError(
                    f"Expected ActivityDiagram, got {type(model).__name__}",
                )

            # Generate the PlantUML code
            plantuml_code = self.generate_plantuml(model, **kwargs)

            # Ensure output directory exists and write the file
            output_path = (
                Path(output_path) if isinstance(output_path, str) else output_path
            )
            self.file_system.ensure_directory(output_path.parent)
            self.file_system.write_file(output_path, plantuml_code)

        except Exception as e:
            raise GeneratorError(
                f"Failed to generate activity diagram: {e}",
                cause=e,
            )

    def generate_plantuml(
        self,
        diagram: ActivityDiagram,
        **kwargs,
    ) -> str:
        """Generate PlantUML code from an activity diagram model.

        Args:
            diagram: The activity diagram model
            **kwargs: Additional generator-specific arguments

        Returns:
            The generated PlantUML code
        """
        lines = ["@startuml", ""]

        # Add title
        if diagram.name:
            lines.append(f"title {diagram.name}")
            lines.append("")

        # Add global settings
        use_monochrome = self.settings.get("MONOCHROME", True)
        settings = [
            "skinparam ActivityBackgroundColor white",
            "skinparam ActivityBorderColor black",
            "skinparam ArrowColor black",
            "skinparam monochrome true" if use_monochrome else "",
        ]

        # Filter out empty settings
        settings = [s for s in settings if s]
        lines.extend(settings)
        lines.append("")

        # Add start nodes
        for start_node in diagram.start_nodes:
            lines.append("start")

        # Add activities
        for activity in diagram.activities:
            activity_name = activity.name or activity.id
            lines.append(f":{activity_name};")

        # Add decision nodes
        for decision in diagram.decision_nodes:
            decision_name = decision.name or decision.id
            lines.append(f"if ({decision_name}) then (yes)")
            lines.append("else (no)")
            lines.append("endif")

        # Add fork nodes
        for fork in diagram.fork_nodes:
            fork_name = fork.name or fork.id
            lines.append("fork")
            lines.append("fork again")
            lines.append("end fork")

        # Add end nodes
        for end_node in diagram.end_nodes:
            lines.append("stop")

        # Add transitions
        lines.append("")
        lines.append("' Transitions")

        # Process transitions
        for transition in diagram.transitions:
            source = transition.source_id
            target = transition.target_id
            label = f" : {transition.label}" if transition.label else ""

            # For decision nodes, we've already added the if/else structure
            # So we don't need to add explicit transitions
            if any(d.id == source for d in diagram.decision_nodes):
                continue

            lines.append(f"{source} --> {target}{label}")

        # End the diagram
        lines.append("")
        lines.append("@enduml")

        return "\n".join(lines)

    def generate_index(
        self,
        output_dir: str | Path,
        diagrams: list[Path],
        **kwargs,
    ) -> None:
        """Generate an index file for all diagrams in the output directory.

        Args:
            output_dir: The directory containing the diagrams
            diagrams: A list of paths to all diagrams
            **kwargs: Additional generator-specific arguments

        Raises:
            GeneratorError: If the index file cannot be generated
        """
        # Filter to only include activity diagrams
        activity_diagrams = [
            d
            for d in diagrams
            if d.name.endswith(".puml") and self._is_activity_diagram(d)
        ]

        if not activity_diagrams:
            return

        try:
            output_dir = Path(output_dir) if isinstance(output_dir, str) else output_dir
            index_path = output_dir / "activity_index.rst"

            # Create basic RST index
            lines = [
                "Activity Diagrams",
                "=================",
                "",
                ".. toctree::",
                "   :maxdepth: 1",
                "",
            ]

            # Add diagram references
            for diagram in sorted(activity_diagrams):
                rel_path = diagram.relative_to(output_dir)
                # Use forward slashes for cross-platform compatibility
                lines.append(f"   {str(rel_path).replace('\\', '/')}")

            lines.append("")  # Add trailing newline

            # Write the index file
            self.file_system.write_file(index_path, "\n".join(lines))

        except Exception as e:
            raise GeneratorError(
                f"Failed to generate activity diagram index: {e}",
                cause=e,
            )

    def _is_activity_diagram(self, file_path: Path) -> bool:
        """Check if a file is an activity diagram.

        Args:
            file_path: The path to the file to check

        Returns:
            True if the file is an activity diagram, False otherwise
        """
        try:
            content = self.file_system.read_file(file_path)
            # Simple heuristic: look for activity diagram indicators
            indicators = [
                "start",
                "stop",
                "if (",
                "fork",
                "skinparam ActivityBackgroundColor",
            ]
            return any(indicator in content for indicator in indicators)
        except Exception:
            return False

================
File: uml/diagrams/activity_diagram/models.py
================
"""Models for activity diagrams.

This module provides models for representing activity diagrams.
"""

from utils.uml.diagrams.base import BaseDiagramModel


class ActivityDiagram(BaseDiagramModel):
    """Model for an activity diagram."""

    def __init__(self, name: str):
        """Initialize an activity diagram.

        Args:
            name: The name of the diagram
        """
        super().__init__(name, "activity")
        self.activities: list[ActivityModel] = []
        self.transitions: list[TransitionModel] = []
        self.start_nodes: list[StartNodeModel] = []
        self.end_nodes: list[EndNodeModel] = []
        self.decision_nodes: list[DecisionNodeModel] = []
        self.merge_nodes: list[MergeNodeModel] = []
        self.fork_nodes: list[ForkNodeModel] = []
        self.join_nodes: list[JoinNodeModel] = []

    def add_activity(self, activity: "ActivityModel") -> None:
        """Add an activity to the diagram.

        Args:
            activity: The activity to add
        """
        self.activities.append(activity)

    def add_transition(self, transition: "TransitionModel") -> None:
        """Add a transition to the diagram.

        Args:
            transition: The transition to add
        """
        self.transitions.append(transition)

    def add_start_node(self, start_node: "StartNodeModel") -> None:
        """Add a start node to the diagram.

        Args:
            start_node: The start node to add
        """
        self.start_nodes.append(start_node)

    def add_end_node(self, end_node: "EndNodeModel") -> None:
        """Add an end node to the diagram.

        Args:
            end_node: The end node to add
        """
        self.end_nodes.append(end_node)

    def add_decision_node(self, decision_node: "DecisionNodeModel") -> None:
        """Add a decision node to the diagram.

        Args:
            decision_node: The decision node to add
        """
        self.decision_nodes.append(decision_node)

    def add_merge_node(self, merge_node: "MergeNodeModel") -> None:
        """Add a merge node to the diagram.

        Args:
            merge_node: The merge node to add
        """
        self.merge_nodes.append(merge_node)

    def add_fork_node(self, fork_node: "ForkNodeModel") -> None:
        """Add a fork node to the diagram.

        Args:
            fork_node: The fork node to add
        """
        self.fork_nodes.append(fork_node)

    def add_join_node(self, join_node: "JoinNodeModel") -> None:
        """Add a join node to the diagram.

        Args:
            join_node: The join node to add
        """
        self.join_nodes.append(join_node)


class ActivityNodeModel:
    """Base model for an activity node."""

    def __init__(self, id: str, name: str | None = None):
        """Initialize an activity node.

        Args:
            id: The unique identifier for the node
            name: The name of the node
        """
        self.id = id
        self.name = name or id


class ActivityModel(ActivityNodeModel):
    """Model for an activity."""

    def __init__(
        self, id: str, name: str | None = None, description: str | None = None
    ):
        """Initialize an activity.

        Args:
            id: The unique identifier for the activity
            name: The name of the activity
            description: The description of the activity
        """
        super().__init__(id, name)
        self.description = description


class TransitionModel:
    """Model for a transition between activity nodes."""

    def __init__(
        self,
        source_id: str,
        target_id: str,
        guard: str | None = None,
        label: str | None = None,
    ):
        """Initialize a transition.

        Args:
            source_id: The ID of the source node
            target_id: The ID of the target node
            guard: The guard condition for the transition
            label: The label for the transition
        """
        self.source_id = source_id
        self.target_id = target_id
        self.guard = guard
        self.label = label


class StartNodeModel(ActivityNodeModel):
    """Model for a start node."""

    def __init__(self, id: str):
        """Initialize a start node.

        Args:
            id: The unique identifier for the node
        """
        super().__init__(id, "start")


class EndNodeModel(ActivityNodeModel):
    """Model for an end node."""

    def __init__(self, id: str):
        """Initialize an end node.

        Args:
            id: The unique identifier for the node
        """
        super().__init__(id, "end")


class DecisionNodeModel(ActivityNodeModel):
    """Model for a decision node."""

    def __init__(self, id: str, name: str | None = None):
        """Initialize a decision node.

        Args:
            id: The unique identifier for the node
            name: The name of the node
        """
        super().__init__(id, name or "decision")


class MergeNodeModel(ActivityNodeModel):
    """Model for a merge node."""

    def __init__(self, id: str, name: str | None = None):
        """Initialize a merge node.

        Args:
            id: The unique identifier for the node
            name: The name of the node
        """
        super().__init__(id, name or "merge")


class ForkNodeModel(ActivityNodeModel):
    """Model for a fork node."""

    def __init__(self, id: str, name: str | None = None):
        """Initialize a fork node.

        Args:
            id: The unique identifier for the node
            name: The name of the node
        """
        super().__init__(id, name or "fork")


class JoinNodeModel(ActivityNodeModel):
    """Model for a join node."""

    def __init__(self, id: str, name: str | None = None):
        """Initialize a join node.

        Args:
            id: The unique identifier for the node
            name: The name of the node
        """
        super().__init__(id, name or "join")

================
File: uml/diagrams/base.py
================
"""Base classes for UML diagrams.

This module provides base implementations of the core interfaces for UML diagrams.
"""

from abc import ABC, abstractmethod
from pathlib import Path
from typing import Any

from utils.uml.core.exceptions import GeneratorError
from utils.uml.core.filesystem import FileSystem
from utils.uml.core.interfaces import DiagramAnalyzer, DiagramGenerator, DiagramModel


class BaseDiagramModel(DiagramModel, ABC):
    """Base implementation of the DiagramModel interface."""

    def __init__(self, name: str, diagram_type: str):
        """Initialize a base diagram model.

        Args:
            name: The name of the diagram
            diagram_type: The type of the diagram (class, sequence, etc.)
        """
        self._name = name
        self._diagram_type = diagram_type

    @property
    def name(self) -> str:
        """Return the name of the diagram."""
        return self._name

    @property
    def diagram_type(self) -> str:
        """Return the type of the diagram."""
        return self._diagram_type


class BaseDiagramAnalyzer(DiagramAnalyzer, ABC):
    """Base implementation of the DiagramAnalyzer interface."""

    def __init__(self, file_system: FileSystem):
        """Initialize a base diagram analyzer.

        Args:
            file_system: The file system implementation to use
        """
        self.file_system = file_system

    @abstractmethod
    def analyze(self, path: str | Path, **kwargs) -> DiagramModel:
        """Analyze the source code at the given path and return a diagram model."""
        pass


class BaseDiagramGenerator(DiagramGenerator, ABC):
    """Base implementation of the DiagramGenerator interface."""

    def __init__(self, file_system: FileSystem, settings: dict[str, Any] | None = None):
        """Initialize a base diagram generator.

        Args:
            file_system: The file system implementation to use
            settings: Optional settings for the generator
        """
        self.file_system = file_system
        self.settings = settings or {}

    @abstractmethod
    def generate_diagram(
        self,
        model: DiagramModel,
        output_path: str | Path,
        **kwargs,
    ) -> None:
        """Generate a UML diagram from the given model and write it to the output path."""
        pass

    def generate_index(
        self,
        output_dir: str | Path,
        diagrams: list[Path],
        **kwargs,
    ) -> None:
        """Generate an index file for all diagrams in the output directory.

        Args:
            output_dir: The directory containing the diagrams
            diagrams: A list of paths to all diagrams
            **kwargs: Additional generator-specific arguments

        Raises:
            GeneratorError: If the index file cannot be generated
        """
        try:
            output_dir = Path(output_dir) if isinstance(output_dir, str) else output_dir
            index_path = output_dir / "index.rst"

            # Create basic RST index
            lines = [
                "UML Diagrams",
                "===========",
                "",
                ".. toctree::",
                "   :maxdepth: 2",
                "   :caption: Available Diagrams:",
                "",
            ]

            # Add diagram references
            for diagram in sorted(diagrams):
                rel_path = diagram.relative_to(output_dir)
                # Use forward slashes for cross-platform compatibility
                lines.append(f"   {str(rel_path).replace('\\', '/')}")

            lines.append("")  # Add trailing newline

            # Write the index file
            self.file_system.write_file(index_path, "\n".join(lines))

        except Exception as e:
            raise GeneratorError(f"Failed to generate index file: {e}", cause=e)

================
File: uml/diagrams/class_diagram/__init__.py
================
"""Class diagram generation.

This module provides functionality for generating UML class diagrams from Python code.
"""

================
File: uml/diagrams/class_diagram/analyzer.py
================
"""Analyzer for extracting class diagrams from Python code.

This module provides functionality for analyzing Python code and extracting
class diagrams from it.
"""

import ast
import logging
import os
from pathlib import Path
from typing import Any

from utils.uml.core.exceptions import ParserError
from utils.uml.core.filesystem import FileSystem
from utils.uml.diagrams.base import BaseDiagramAnalyzer
from utils.uml.diagrams.class_diagram.models import (
    AttributeModel,
    ClassDiagram,
    ClassModel,
    FileModel,
    FunctionModel,
    ImportModel,
    MethodModel,
    ParameterModel,
    RelationshipModel,
    TypeAnnotation,
    Visibility,
)


class ClassAnalyzer(BaseDiagramAnalyzer):
    """Analyzer for extracting class diagrams from Python code."""

    def __init__(self, file_system: FileSystem):
        """Initialize the class analyzer.

        Args:
            file_system: The file system implementation to use
        """
        super().__init__(file_system)
        self.logger = logging.getLogger(__name__)
        self.processed_files: set[Path] = set()
        self.current_module = ""

    def analyze(
        self,
        path: str | Path,
        module_name: str | None = None,
        exclude_patterns: list[str] | None = None,
        include_private: bool = False,
        **kwargs: Any,
    ) -> ClassDiagram:
        """Analyze the source code at the given path and generate a class diagram.

        Args:
            path: Path to the source code to analyze
            module_name: Optional name of the module being analyzed
            exclude_patterns: Optional list of patterns to exclude
            include_private: Whether to include private members
            **kwargs: Additional analyzer-specific arguments

        Returns:
            A class diagram model

        Raises:
            ParserError: If the analysis fails
        """
        try:
            # Create the diagram
            diagram = ClassDiagram(
                name=module_name
                or (Path(path).name if isinstance(path, str) else path.name),
            )

            # Determine if we're analyzing a directory or a single file
            target_path = Path(path) if isinstance(path, str) else path

            if target_path.is_dir():
                self._analyze_directory(
                    diagram,
                    target_path,
                    exclude_patterns or [],
                    include_private,
                )
            else:
                self._analyze_file(
                    diagram,
                    target_path,
                    include_private=include_private,
                )

            # Process relationships between classes
            self._process_relationships(diagram)

            return diagram
        except Exception as e:
            raise ParserError(f"Failed to analyze code at {path}: {e}", cause=e)

    def _analyze_directory(
        self,
        diagram: ClassDiagram,
        directory: Path,
        exclude_patterns: list[str],
        include_private: bool,
    ) -> None:
        """Analyze all Python files in a directory.

        Args:
            diagram: The class diagram to populate
            directory: The directory to analyze
            exclude_patterns: Patterns to exclude
            include_private: Whether to include private members
        """
        for root, _, files in os.walk(directory):
            # Skip directories matching exclude patterns
            if any(pattern in root for pattern in exclude_patterns):
                continue

            # Process Python files
            for file in files:
                if file.endswith(".py"):
                    file_path = Path(os.path.join(root, file))

                    # Skip files matching exclude patterns
                    if any(pattern in str(file_path) for pattern in exclude_patterns):
                        continue

                    self._analyze_file(
                        diagram,
                        file_path,
                        include_private=include_private,
                    )

    def _analyze_file(
        self,
        diagram: ClassDiagram,
        file_path: Path,
        include_private: bool = False,
    ) -> None:
        """Analyze a single Python file.

        Args:
            diagram: The class diagram to populate
            file_path: The file to analyze
            include_private: Whether to include private members
        """
        # Skip if already processed
        if file_path in self.processed_files:
            return

        self.processed_files.add(file_path)

        try:
            # Read and parse the file
            code = self.file_system.read_file(file_path)
            tree = ast.parse(code)

            # Create file model
            file_model = FileModel(path=file_path)

            # Extract imports, classes, and functions
            visitor = ClassDefinitionVisitor(
                file_path=file_path,
                include_private=include_private,
            )
            visitor.visit(tree)

            # Add imports, classes, and functions to the file model
            file_model.imports = visitor.imports
            file_model.classes = visitor.classes
            file_model.functions = visitor.functions

            # Add the file model to the diagram
            diagram.add_file(file_model)

        except SyntaxError as e:
            self.logger.error(f"Syntax error in {file_path}: {e}")
        except Exception as e:
            self.logger.error(f"Failed to analyze file {file_path}: {e}")

    def _process_relationships(self, diagram: ClassDiagram) -> None:
        """Process relationships between classes.

        Args:
            diagram: The class diagram to process
        """
        # Dictionary to map class names to their full names
        class_dict: dict[str, tuple[str, ClassModel]] = {}

        # Build the class dictionary
        for file in diagram.files:
            for cls in file.classes:
                class_dict[cls.name] = (cls.name, cls)

        # Process inheritance relationships
        for file in diagram.files:
            for cls in file.classes:
                # Add inheritance relationships
                for base in cls.bases:
                    if base in class_dict:
                        base_name, _ = class_dict[base]
                        relationship = RelationshipModel(
                            source=cls.name,
                            target=base_name,
                            type="--|>",  # UML inheritance
                        )
                        diagram.add_relationship(relationship)


class ClassDefinitionVisitor(ast.NodeVisitor):
    """AST visitor that extracts class and function definitions."""

    def __init__(
        self,
        file_path: Path,
        include_private: bool = False,
    ):
        """Initialize the class definition visitor.

        Args:
            file_path: The path to the file being analyzed
            include_private: Whether to include private members
        """
        self.file_path = file_path
        self.include_private = include_private
        self.imports: list[ImportModel] = []
        self.classes: list[ClassModel] = []
        self.functions: list[FunctionModel] = []
        self.module_name = file_path.stem

    def visit_Import(self, node: ast.Import) -> None:
        """Visit an import node.

        Args:
            node: The AST node representing an import
        """
        for name in node.names:
            import_model = ImportModel(
                module=name.name,
                name=name.name.split(".")[-1],
                alias=name.asname,
            )
            self.imports.append(import_model)
        self.generic_visit(node)

    def visit_ImportFrom(self, node: ast.ImportFrom) -> None:
        """Visit an import from node.

        Args:
            node: The AST node representing an import from
        """
        if node.module is None:
            return

        for name in node.names:
            import_model = ImportModel(
                module=node.module,
                name=name.name,
                alias=name.asname,
            )
            self.imports.append(import_model)
        self.generic_visit(node)

    def visit_ClassDef(self, node: ast.ClassDef) -> None:
        """Visit a class definition node.

        Args:
            node: The AST node representing a class definition
        """
        # Skip private classes if not included
        if not self.include_private and node.name.startswith("_"):
            return

        # Create class model
        class_model = ClassModel(
            name=node.name,
            filename=str(self.file_path),
            bases=[
                self._get_base_name(base)
                for base in node.bases
                if isinstance(base, (ast.Name, ast.Attribute))
            ],
            docstring=ast.get_docstring(node),
            decorators=[self._get_decorator_name(d) for d in node.decorator_list],
        )

        # Process class body
        for item in node.body:
            # Process attribute assignments
            if isinstance(item, ast.Assign):
                for target in item.targets:
                    if isinstance(target, ast.Name):
                        # Class attribute
                        attr_name = target.id
                        if self.include_private or not attr_name.startswith("_"):
                            visibility = (
                                Visibility.PRIVATE
                                if attr_name.startswith("__")
                                else Visibility.PROTECTED
                                if attr_name.startswith("_")
                                else Visibility.PUBLIC
                            )

                            # Get default value as string
                            try:
                                default_value = ast.unparse(item.value)
                            except (AttributeError, ValueError):
                                default_value = None

                            attr = AttributeModel(
                                name=attr_name,
                                type_annotation="Any",  # No type info available
                                visibility=visibility,
                                default_value=default_value,
                            )
                            class_model.attributes.append(attr)

            # Process annotated assignments
            elif isinstance(item, ast.AnnAssign) and isinstance(item.target, ast.Name):
                attr_name = item.target.id
                if self.include_private or not attr_name.startswith("_"):
                    visibility = (
                        Visibility.PRIVATE
                        if attr_name.startswith("__")
                        else Visibility.PROTECTED
                        if attr_name.startswith("_")
                        else Visibility.PUBLIC
                    )

                    # Get type annotation
                    type_annotation = self._get_type_annotation(item.annotation)

                    # Get default value if present
                    default_value = None
                    if item.value:
                        try:
                            default_value = ast.unparse(item.value)
                        except (AttributeError, ValueError):
                            pass

                    attr = AttributeModel(
                        name=attr_name,
                        type_annotation=type_annotation,
                        visibility=visibility,
                        default_value=default_value,
                    )
                    class_model.attributes.append(attr)

            # Process methods
            elif isinstance(item, ast.FunctionDef):
                method_name = item.name
                if (
                    self.include_private
                    or not method_name.startswith("_")
                    or method_name == "__init__"
                ):
                    method = self._process_function(item, is_class_method=True)
                    if isinstance(
                        method, MethodModel
                    ):  # Type check to ensure correct type
                        class_model.methods.append(method)

        # Add the class model
        self.classes.append(class_model)
        self.generic_visit(node)

    def visit_FunctionDef(self, node: ast.FunctionDef) -> None:
        """Visit a function definition node.

        Args:
            node: The AST node representing a function definition
        """
        # Skip private functions if not included
        if not self.include_private and node.name.startswith("_"):
            return

        # Only process top-level functions (not inside a class)
        # We can tell by checking the context/parent type
        for ancestor in ast.iter_child_nodes(node):
            if isinstance(ancestor, ast.ClassDef):
                # This is a method inside a class, already handled by visit_ClassDef
                return

        # This is a top-level function
        function = self._process_function(node, is_class_method=False)
        if isinstance(function, FunctionModel):
            self.functions.append(function)

        self.generic_visit(node)

    def _process_function(
        self,
        node: ast.FunctionDef,
        is_class_method: bool = False,
    ) -> MethodModel | FunctionModel:
        """Process a function definition.

        Args:
            node: The AST node representing a function definition
            is_class_method: Whether this is a method in a class

        Returns:
            A method model if is_class_method is True, otherwise a function model
        """
        # Determine visibility
        visibility = (
            Visibility.PRIVATE
            if node.name.startswith("__")
            else Visibility.PROTECTED
            if node.name.startswith("_")
            else Visibility.PUBLIC
        )

        # Process parameters
        parameters: list[ParameterModel] = []
        for i, arg in enumerate(node.args.args):
            # Skip 'self' parameter for class methods
            if is_class_method and i == 0 and arg.arg == "self":
                continue

            # Get type annotation if present
            type_annotation = (
                self._get_type_annotation(arg.annotation) if arg.annotation else "Any"
            )

            # Get default value if present
            default_value = None
            if i >= len(node.args.args) - len(node.args.defaults):
                default_idx = i - (len(node.args.args) - len(node.args.defaults))
                try:
                    default_value = ast.unparse(node.args.defaults[default_idx])
                except (AttributeError, ValueError, IndexError):
                    pass

            param = ParameterModel(
                name=arg.arg,
                type_annotation=type_annotation,
                default_value=default_value,
            )
            parameters.append(param)

        # Get return type annotation
        return_type = (
            self._get_type_annotation(node.returns) if node.returns else "None"
        )

        # Check for staticmethod or classmethod decorators
        is_static = any(
            self._get_decorator_name(d) == "staticmethod" for d in node.decorator_list
        )
        is_classmethod = any(
            self._get_decorator_name(d) == "classmethod" for d in node.decorator_list
        )

        # Create appropriate model
        if is_class_method:
            return MethodModel(
                name=node.name,
                parameters=parameters,
                return_type=return_type,
                visibility=visibility,
                is_static=is_static,
                is_classmethod=is_classmethod,
                docstring=ast.get_docstring(node),
                decorators=[self._get_decorator_name(d) for d in node.decorator_list],
            )
        return FunctionModel(
            name=node.name,
            parameters=parameters,
            return_type=return_type,
            visibility=visibility,
        )

    def _get_base_name(self, node: ast.expr) -> str:
        """Get the name of a base class.

        Args:
            node: The AST node representing a base class

        Returns:
            The name of the base class
        """
        if isinstance(node, ast.Name):
            return node.id
        if isinstance(node, ast.Attribute):
            try:
                return ast.unparse(node)
            except (AttributeError, ValueError):
                return f"{self._get_base_name(node.value)}.{node.attr}"
        return "object"  # Default base class

    def _get_decorator_name(self, node: ast.expr) -> str:
        """Get the name of a decorator.

        Args:
            node: The AST node representing a decorator

        Returns:
            The name of the decorator
        """
        if isinstance(node, ast.Name):
            return node.id
        if isinstance(node, ast.Call) and isinstance(node.func, ast.Name):
            return node.func.id
        if isinstance(node, ast.Attribute):
            try:
                return ast.unparse(node)
            except (AttributeError, ValueError):
                return f"{self._get_base_name(node.value)}.{node.attr}"
        try:
            return ast.unparse(node)
        except (AttributeError, ValueError):
            return "unknown"

    def _get_type_annotation(self, node: ast.expr) -> TypeAnnotation:
        """Get a string representation of a type annotation.

        Args:
            node: The AST node representing a type annotation

        Returns:
            A string representation of the type annotation
        """
        try:
            return ast.unparse(node)
        except (AttributeError, ValueError):
            if isinstance(node, ast.Name):
                return node.id
            if isinstance(node, ast.Subscript):
                if isinstance(node.value, ast.Name):
                    value_name = node.value.id
                    try:
                        slice_name = ast.unparse(node.slice)
                        return f"{value_name}[{slice_name}]"
                    except (AttributeError, ValueError):
                        return f"{value_name}[...]"
                return "..."
            if isinstance(node, ast.Attribute):
                return f"{self._get_base_name(node.value)}.{node.attr}"
            return "Any"  # Default type

================
File: uml/diagrams/class_diagram/generator.py
================
"""Generator for converting class diagrams to PlantUML format.

This module provides functionality for generating PlantUML class diagrams from
class diagram models.
"""

from pathlib import Path
from typing import Any

from utils.uml.core.exceptions import GeneratorError
from utils.uml.core.filesystem import FileSystem
from utils.uml.core.interfaces import DiagramModel
from utils.uml.diagrams.base import BaseDiagramGenerator
from utils.uml.diagrams.class_diagram.models import (
    AttributeModel,
    ClassDiagram,
    ClassModel,
    MethodModel,
    RelationshipModel,
)


class ClassDiagramGenerator(BaseDiagramGenerator):
    """Generates PlantUML class diagrams from class diagram models."""

    def __init__(self, file_system: FileSystem, settings: dict[str, Any] | None = None):
        """Initialize a class diagram generator.

        Args:
            file_system: The file system implementation to use
            settings: Optional settings for the generator
        """
        super().__init__(file_system, settings)
        self.indentation = "  "
        self.current_indent = 0

    def _indent(self) -> str:
        """Get the current indentation string."""
        return self.indentation * self.current_indent

    def _increase_indent(self) -> None:
        """Increase indentation level."""
        self.current_indent += 1

    def _decrease_indent(self) -> None:
        """Decrease indentation level."""
        self.current_indent = max(0, self.current_indent - 1)

    def _format_class(self, class_model: ClassModel, skinny: bool = False) -> list[str]:
        """Format a class model as PlantUML.

        Args:
            class_model: The class model to format
            skinny: Whether to use a skinny class representation

        Returns:
            List of PlantUML lines for the class
        """
        lines = []

        # Class declaration with stereotype if it has decorators
        class_line = "class"
        stereotype = None

        # Check for common decorators and assign stereotypes
        if class_model.decorators:
            for decorator in class_model.decorators:
                if decorator in ("dataclass", "dataclasses.dataclass"):
                    stereotype = "<<dataclass>>"
                elif decorator in ("abc.ABC", "ABC", "ABCMeta"):
                    stereotype = "<<abstract>>"
                elif decorator in ("Enum", "enum.Enum"):
                    stereotype = "<<enumeration>>"
                elif decorator in ("Protocol", "typing.Protocol"):
                    stereotype = "<<protocol>>"

        class_line = f"{class_line} {class_model.name}"
        if stereotype:
            class_line = f"{class_line} {stereotype}"

        lines.append(class_line + " {")
        self._increase_indent()

        # Add attributes
        if class_model.attributes and not skinny:
            for attr in class_model.attributes:
                lines.append(self._format_attribute(attr))

        # Add a separator if we have both attributes and methods
        if class_model.attributes and class_model.methods and not skinny:
            lines.append("--")

        # Add methods
        if class_model.methods and not skinny:
            for method in class_model.methods:
                lines.append(self._format_method(method))

        self._decrease_indent()
        lines.append("}")

        return lines

    def _format_attribute(self, attr: AttributeModel) -> str:
        """Format an attribute as PlantUML.

        Args:
            attr: The attribute to format

        Returns:
            PlantUML formatted attribute
        """
        # Format visibility prefix
        visibility = attr.visibility.value

        # Format default value
        default = f" = {attr.default_value}" if attr.default_value else ""

        # Format type annotation
        type_str = f": {attr.type_annotation}" if attr.type_annotation != "Any" else ""

        return f"{self._indent()}{visibility} {attr.name}{type_str}{default}"

    def _format_method(self, method: MethodModel) -> str:
        """Format a method as PlantUML.

        Args:
            method: The method to format

        Returns:
            PlantUML formatted method
        """
        # Format visibility prefix
        visibility = method.visibility.value

        # Format method modifiers
        modifiers = ""
        if method.is_static:
            modifiers += "{static} "
        elif method.is_classmethod:
            modifiers += "{classmethod} "

        # Format parameters
        params = []
        for param in method.parameters:
            param_str = param.name
            if param.type_annotation and param.type_annotation != "Any":
                param_str += f": {param.type_annotation}"
            if param.default_value:
                param_str += f" = {param.default_value}"
            params.append(param_str)

        param_str = ", ".join(params)
        return_type = (
            f": {method.return_type}"
            if method.return_type and method.return_type != "None"
            else ""
        )

        return f"{self._indent()}{visibility} {modifiers}{method.name}({param_str}){return_type}"

    def _format_relationship(self, rel: RelationshipModel) -> str:
        """Format a relationship as PlantUML.

        Args:
            rel: The relationship to format

        Returns:
            PlantUML formatted relationship
        """
        return f"{rel.source} {rel.type} {rel.target}"

    def generate_plantuml(
        self,
        diagram: ClassDiagram,
        skinny: bool = False,
    ) -> str:
        """Generate PlantUML code from a class diagram model.

        Args:
            diagram: The class diagram model
            skinny: Whether to use skinny class representations

        Returns:
            The generated PlantUML code
        """
        lines = ["@startuml", ""]

        # Add title
        if diagram.name:
            lines.append(f"title {diagram.name}")
            lines.append("")

        # Add global settings from the settings dict, or use defaults
        use_monochrome = self.settings.get("MONOCHROME", True)
        hide_fields = skinny or self.settings.get("HIDE_FIELDS", False)
        hide_methods = skinny or self.settings.get("HIDE_METHODS", False)
        hide_empty_members = self.settings.get("HIDE_EMPTY_MEMBERS", True)

        settings = [
            "skinparam ClassAttributeIconSize 0",
            "skinparam ClassBackgroundColor white",
            "skinparam ClassBorderColor black",
            "hide empty members" if hide_empty_members else "",
            "hide fields" if hide_fields else "",
            "hide methods" if hide_methods else "",
            "skinparam monochrome true" if use_monochrome else "",
        ]

        # Filter out empty settings
        settings = [s for s in settings if s]
        lines.extend(settings)
        lines.append("")

        # Add package organization if available
        # Group classes by their modules/packages
        packages: dict[str, list[ClassModel]] = {}

        for file_model in diagram.files:
            package_name = file_model.path.parent.name
            if package_name not in packages:
                packages[package_name] = []

            packages[package_name].extend(file_model.classes)

        # Output classes by package
        for package_name, classes in packages.items():
            if not classes:
                continue

            if package_name and package_name != ".":
                lines.append(f"package {package_name} {{")
                self._increase_indent()

            # Add classes in this package
            for class_model in classes:
                class_lines = self._format_class(class_model, skinny=skinny)
                lines.extend([f"{self._indent()}{line}" for line in class_lines])
                lines.append("")

            if package_name and package_name != ".":
                self._decrease_indent()
                lines.append("}")
                lines.append("")

        # Add non-packaged classes
        standalone_classes = []
        for file_model in diagram.files:
            if file_model.path.parent.name in packages:
                continue
            standalone_classes.extend(file_model.classes)

        for class_model in standalone_classes:
            class_lines = self._format_class(class_model, skinny=skinny)
            lines.extend(class_lines)
            lines.append("")

        # Add relationships
        lines.append("' Relationships")
        # First, add inheritance relationships
        for rel in diagram.global_relationships:
            if rel.type == "--|>":  # Inheritance relationships first
                lines.append(self._format_relationship(rel))

        # Then add other relationships
        for rel in diagram.global_relationships:
            if rel.type != "--|>":  # Other relationships
                lines.append(self._format_relationship(rel))

        # End the diagram
        lines.append("")
        lines.append("@enduml")

        return "\n".join(lines)

    def generate_diagram(
        self,
        model: DiagramModel,
        output_path: str | Path,
        **kwargs,
    ) -> None:
        """Generate a UML diagram from the given model and write it to the output path.

        Args:
            model: The diagram model to generate a diagram from
            output_path: The path to write the diagram to
            **kwargs: Additional generator-specific arguments:
                - skinny: Whether to use skinny class representations

        Raises:
            GeneratorError: If the diagram cannot be generated
        """
        try:
            # Ensure the model is a ClassDiagram
            if not isinstance(model, ClassDiagram):
                raise GeneratorError(
                    f"Expected ClassDiagram, got {type(model).__name__}",
                )

            # Generate the PlantUML code
            skinny = kwargs.get("skinny", False)
            plantuml_code = self.generate_plantuml(model, skinny=skinny)

            # Ensure output directory exists and write the file
            output_path = (
                Path(output_path) if isinstance(output_path, str) else output_path
            )
            self.file_system.ensure_directory(output_path.parent)
            self.file_system.write_file(output_path, plantuml_code)

        except Exception as e:
            raise GeneratorError(
                f"Failed to generate class diagram: {e}",
                cause=e,
            )

    def generate_index(
        self,
        output_dir: str | Path,
        diagrams: list[Path],
        **kwargs,
    ) -> None:
        """Generate an index file for all diagrams in the output directory.

        Args:
            output_dir: The directory containing the diagrams
            diagrams: A list of paths to all diagrams
            **kwargs: Additional generator-specific arguments

        Raises:
            GeneratorError: If the index file cannot be generated
        """
        # Filter to only include class diagrams
        class_diagrams = [
            d
            for d in diagrams
            if d.name.endswith(".puml") and self._is_class_diagram(d)
        ]

        if not class_diagrams:
            return

        try:
            output_dir = Path(output_dir) if isinstance(output_dir, str) else output_dir
            index_path = output_dir / "class_index.rst"

            # Create basic RST index
            lines = [
                "Class Diagrams",
                "==============",
                "",
                ".. toctree::",
                "   :maxdepth: 1",
                "",
            ]

            # Add diagram references
            for diagram in sorted(class_diagrams):
                rel_path = diagram.relative_to(output_dir)
                # Use forward slashes for cross-platform compatibility
                lines.append(f"   {str(rel_path).replace('\\', '/')}")

            lines.append("")  # Add trailing newline

            # Write the index file
            self.file_system.write_file(index_path, "\n".join(lines))

        except Exception as e:
            raise GeneratorError(
                f"Failed to generate class diagram index: {e}",
                cause=e,
            )

    def _is_class_diagram(self, file_path: Path) -> bool:
        """Check if a file is a class diagram.

        Args:
            file_path: The path to the file to check

        Returns:
            True if the file is a class diagram, False otherwise
        """
        try:
            content = self.file_system.read_file(file_path)
            # Simple heuristic: look for class diagram indicators
            indicators = [
                "class ",
                "interface ",
                "enum ",
                "package ",
                "namespace ",
                "skinparam ClassAttributeIconSize",
            ]
            return any(indicator in content for indicator in indicators)
        except Exception:
            return False

================
File: uml/diagrams/class_diagram/models.py
================
"""Data models for class diagram generation.

This module defines the data models used for representing class diagrams.
"""

from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path

from utils.uml.diagrams.base import BaseDiagramModel

# Type aliases for better readability
ClassName = str
MethodName = str
AttributeName = str
TypeAnnotation = str


class Visibility(str, Enum):
    """Visibility levels for class members."""

    PUBLIC = "+"
    PRIVATE = "-"
    PROTECTED = "#"


@dataclass
class ParameterModel:
    """Function/method parameter representation."""

    name: str
    type_annotation: TypeAnnotation
    default_value: str | None = None


@dataclass
class AttributeModel:
    """Class attribute representation."""

    name: AttributeName
    type_annotation: TypeAnnotation
    visibility: Visibility = Visibility.PUBLIC
    default_value: str | None = None
    docstring: str | None = None
    decorators: list[str] = field(default_factory=list)


@dataclass
class MethodModel:
    """Method representation with signature information.

    Attributes:
        name: Method name
        parameters: List of method parameters
        return_type: Return type annotation
        visibility: Method visibility (+: public, -: private, #: protected)
        is_static: Whether this is a static method
        is_classmethod: Whether this is a class method
        docstring: Method docstring if present
        decorators: List of decorator names
        default_value: Default value if present
    """

    name: MethodName
    parameters: list[ParameterModel]
    return_type: TypeAnnotation
    visibility: Visibility = Visibility.PUBLIC
    is_static: bool = False
    is_classmethod: bool = False
    docstring: str | None = None
    decorators: list[str] = field(default_factory=list)
    default_value: str | None = None

    @property
    def signature(self) -> str:
        """Generate method signature string.

        Returns:
            Formatted method signature
        """
        params = [
            f"{param.name}: {param.type_annotation}"
            + (f" = {param.default_value}" if param.default_value else "")
            for param in self.parameters
        ]
        prefix = ""
        if self.is_static:
            prefix = "@staticmethod "
        elif self.is_classmethod:
            prefix = "@classmethod "
        return f"{prefix}{self.name}({', '.join(params)}) -> {self.return_type}"


@dataclass
class RelationshipModel:
    """Relationship between classes."""

    source: ClassName
    target: ClassName
    type: str  # -->: association, *-->: composition, etc.


@dataclass
class ImportModel:
    """Import statement representation."""

    module: str
    name: str
    alias: str | None = None


@dataclass
class ClassModel:
    """Class representation with methods, attributes and relationships."""

    name: ClassName
    filename: str
    bases: list[ClassName] = field(default_factory=list)
    methods: list[MethodModel] = field(default_factory=list)
    attributes: list[AttributeModel] = field(default_factory=list)
    relationships: list[RelationshipModel] = field(default_factory=list)
    imports: list[ImportModel] = field(default_factory=list)
    docstring: str | None = None
    decorators: list[str] = field(default_factory=list)


@dataclass
class FunctionModel:
    """Standalone function representation."""

    name: str
    parameters: list[ParameterModel]
    return_type: TypeAnnotation
    visibility: Visibility = Visibility.PUBLIC

    @property
    def signature(self) -> str:
        """Generate function signature string.

        Returns:
            Formatted function signature
        """
        params = [
            f"{param.name}: {param.type_annotation}"
            + (f" = {param.default_value}" if param.default_value else "")
            for param in self.parameters
        ]
        return f"{self.name}({', '.join(params)}) -> {self.return_type}"


class ClassDiagram(BaseDiagramModel):
    """Class diagram model containing information about classes and their relationships."""

    def __init__(self, name: str):
        """Initialize a class diagram model.

        Args:
            name: The name of the diagram
        """
        super().__init__(name=name, diagram_type="class")
        self.files: list[FileModel] = []
        self.global_relationships: list[RelationshipModel] = []

    def add_file(self, file_model: "FileModel") -> None:
        """Add a file model to the diagram.

        Args:
            file_model: The file model to add
        """
        self.files.append(file_model)

    def add_relationship(self, relationship: RelationshipModel) -> None:
        """Add a global relationship to the diagram.

        Args:
            relationship: The relationship to add
        """
        self.global_relationships.append(relationship)

    @property
    def all_classes(self) -> list[ClassModel]:
        """Get all classes from all files.

        Returns:
            List of all class models in the diagram
        """
        return [cls for file in self.files for cls in file.classes]

    @property
    def all_functions(self) -> list[FunctionModel]:
        """Get all functions from all files.

        Returns:
            List of all function models in the diagram
        """
        return [func for file in self.files for func in file.functions]


@dataclass
class FileModel:
    """File representation containing classes and functions."""

    path: Path
    classes: list[ClassModel] = field(default_factory=list)
    functions: list[FunctionModel] = field(default_factory=list)
    imports: list[ImportModel] = field(default_factory=list)

    @property
    def filename(self) -> str:
        """Get filename without extension.

        Returns:
            Filename without extension
        """
        return self.path.stem

================
File: uml/diagrams/sequence_diagram/__init__.py
================
"""Sequence diagram generation.

This module provides functionality for generating UML sequence diagrams from Python code.
"""

================
File: uml/diagrams/sequence_diagram/analyzer.py
================
"""Analyzer for extracting sequence diagrams from Python code.

This module provides functionality for analyzing Python code and extracting
sequence diagrams from it.
"""

import ast
import os
from pathlib import Path

from utils.uml.core.exceptions import ParserError
from utils.uml.core.filesystem import FileSystem
from utils.uml.diagrams.base import BaseDiagramAnalyzer
from utils.uml.diagrams.sequence_diagram.models import (
    FunctionCall,
    Message,
    MessageType,
    Participant,
    ParticipantType,
    SequenceDiagram,
)


class ClassInfo:
    """Information about a Python class."""

    def __init__(self, name: str, module: str):
        """Initialize class information.

        Args:
            name: The name of the class
            module: The module containing the class
        """
        self.name = name
        self.module = module
        self.methods: set[str] = set()
        self.base_classes: list[str] = []

    @property
    def full_name(self) -> str:
        """Get the full name with module."""
        return f"{self.module}.{self.name}"


class MethodCallVisitor(ast.NodeVisitor):
    """AST visitor that extracts method calls."""

    def __init__(self, class_name: str, method_name: str, file_path: str):
        """Initialize the method call visitor.

        Args:
            class_name: The name of the class containing the method
            method_name: The name of the method to analyze
            file_path: The path to the file containing the method
        """
        self.class_name = class_name
        self.method_name = method_name
        self.file_path = file_path
        self.calls: list[FunctionCall] = []

    def visit_Call(self, node: ast.Call) -> None:
        """Visit a function call node.

        Args:
            node: The AST node representing a function call
        """
        # Track the line number
        line_number = getattr(node, "lineno", 0)

        # Handle method calls: obj.method()
        if isinstance(node.func, ast.Attribute) and isinstance(
            node.func.value,
            ast.Name,
        ):
            obj_name = node.func.value.id
            method_name = node.func.attr

            # Skip calls to self
            if obj_name == "self":
                # This is a call to another method in the same class
                self.calls.append(
                    FunctionCall(
                        caller_class=self.class_name,
                        caller_method=self.method_name,
                        called_class=self.class_name,
                        called_method=method_name,
                        line_number=line_number,
                        file_path=self.file_path,
                    ),
                )
            else:
                # This is a call to another object's method
                self.calls.append(
                    FunctionCall(
                        caller_class=self.class_name,
                        caller_method=self.method_name,
                        called_class=obj_name,  # This is only the variable name, not necessarily the class
                        called_method=method_name,
                        line_number=line_number,
                        file_path=self.file_path,
                    ),
                )

        # Handle constructor calls: ClassName()
        elif isinstance(node.func, ast.Name):
            func_name = node.func.id

            # Assume it's a constructor call if the name is capitalized
            if func_name[0].isupper():
                self.calls.append(
                    FunctionCall(
                        caller_class=self.class_name,
                        caller_method=self.method_name,
                        called_class=func_name,
                        called_method="__init__",
                        is_constructor=True,
                        line_number=line_number,
                        file_path=self.file_path,
                    ),
                )
            else:
                # This is a normal function call
                self.calls.append(
                    FunctionCall(
                        caller_class=self.class_name,
                        caller_method=self.method_name,
                        called_class=None,  # It's a standalone function
                        called_method=func_name,
                        line_number=line_number,
                        file_path=self.file_path,
                    ),
                )

        # Continue visiting child nodes
        self.generic_visit(node)


class ClassDefVisitor(ast.NodeVisitor):
    """AST visitor that extracts class definitions."""

    def __init__(self, module_name: str, file_path: str):
        """Initialize the class definition visitor.

        Args:
            module_name: The name of the module to analyze
            file_path: The path to the file containing the module
        """
        self.module_name = module_name
        self.file_path = file_path
        self.classes: dict[str, ClassInfo] = {}
        self.method_calls: list[FunctionCall] = []

    def visit_ClassDef(self, node: ast.ClassDef) -> None:
        """Visit a class definition node.

        Args:
            node: The AST node representing a class definition
        """
        class_name = node.name

        # Create class info
        class_info = ClassInfo(class_name, self.module_name)

        # Extract base classes
        for base in node.bases:
            if isinstance(base, ast.Name):
                class_info.base_classes.append(base.id)

        self.classes[class_name] = class_info

        # Visit all methods in the class
        for item in node.body:
            if isinstance(item, ast.FunctionDef):
                method_name = item.name
                class_info.methods.add(method_name)

                # Find method calls inside this method
                visitor = MethodCallVisitor(class_name, method_name, self.file_path)
                visitor.visit(item)
                self.method_calls.extend(visitor.calls)


class SequenceAnalyzer(BaseDiagramAnalyzer):
    """Analyzer for extracting sequence diagrams from Python code."""

    def __init__(self, file_system: FileSystem, root_dir: str | Path = "."):
        """Initialize the sequence analyzer.

        Args:
            file_system: The file system implementation to use
            root_dir: The root directory to analyze
        """
        super().__init__(file_system)
        self.root_dir = Path(root_dir) if isinstance(root_dir, str) else root_dir
        self.classes: dict[str, ClassInfo] = {}
        self.function_calls: list[FunctionCall] = []

    def analyze(
        self,
        path: str | Path,
        entry_class: str | None = None,
        entry_method: str | None = None,
        **kwargs,
    ) -> SequenceDiagram:
        """Analyze the source code at the given path and generate a sequence diagram.

        Args:
            path: Path to the source code to analyze
            entry_class: The name of the entry point class
            entry_method: The name of the entry point method
            **kwargs: Additional analyzer-specific arguments

        Returns:
            A sequence diagram model

        Raises:
            ParserError: If the analysis fails
        """
        try:
            # Analyze the code
            self.analyze_directory(path)

            # Check if entry points are provided
            if not entry_class or not entry_method:
                raise ParserError(
                    "Entry class and method must be provided for sequence diagram generation",
                )

            # Generate the sequence diagram
            return self.generate_sequence_diagram(entry_class, entry_method)
        except Exception as e:
            raise ParserError(f"Failed to analyze code at {path}: {e}", cause=e)

    def analyze_file(self, file_path: str | Path) -> None:
        """Analyze a single Python file.

        Args:
            file_path: Path to the file to analyze

        Raises:
            ParserError: If the file cannot be analyzed
        """
        path = Path(file_path) if isinstance(file_path, str) else file_path

        # Use the file name without extension as module name
        module_name = path.stem

        try:
            # Read and parse the file
            code = self.file_system.read_file(path)
            tree = ast.parse(code)

            # Visit the AST to extract classes and method calls
            visitor = ClassDefVisitor(module_name, str(path))
            visitor.visit(tree)

            # Store the results
            self.classes.update(visitor.classes)
            self.function_calls.extend(visitor.method_calls)

        except SyntaxError as e:
            raise ParserError(f"Syntax error in {file_path}: {e}", cause=e)
        except Exception as e:
            raise ParserError(f"Failed to analyze file {file_path}: {e}", cause=e)

    def analyze_directory(self, dir_path: str | Path | None = None) -> None:
        """Analyze all Python files in a directory.

        Args:
            dir_path: Path to the directory to analyze

        Raises:
            ParserError: If the directory cannot be analyzed
        """
        try:
            if dir_path is None:
                target_dir = self.root_dir
            else:
                target_dir = Path(dir_path) if isinstance(dir_path, str) else dir_path

            # Walk through the directory and analyze Python files
            for root, _, files in os.walk(target_dir):
                for file in files:
                    if file.endswith(".py"):
                        file_path = os.path.join(root, file)
                        self.analyze_file(file_path)
        except Exception as e:
            raise ParserError(f"Failed to analyze directory {dir_path}: {e}", cause=e)

    def generate_sequence_diagram(
        self,
        entry_class: str,
        entry_method: str,
    ) -> SequenceDiagram:
        """Generate a sequence diagram starting from an entry point.

        Args:
            entry_class: The name of the entry point class
            entry_method: The name of the entry point method

        Returns:
            A sequence diagram model
        """
        # Create the diagram
        diagram = SequenceDiagram(title=f"{entry_class}.{entry_method} Sequence")

        # Add the entry point class as a participant
        entry_participant = Participant(name=entry_class, type=ParticipantType.CLASS)
        diagram.add_participant(entry_participant)

        # Process the call graph starting from the entry point
        self._process_call_graph(diagram, entry_class, entry_method)

        return diagram

    def _process_call_graph(
        self,
        diagram: SequenceDiagram,
        caller_class: str,
        caller_method: str,
        level: int = 0,
        processed: set[tuple[str, str]] | None = None,
    ) -> None:
        """Process the call graph recursively.

        Args:
            diagram: The sequence diagram to populate
            caller_class: The name of the caller class
            caller_method: The name of the caller method
            level: The current recursion level
            processed: Set of already processed (class, method) pairs
        """
        if processed is None:
            processed = set()

        # Avoid infinite recursion
        call_key = (caller_class, caller_method)
        if call_key in processed or level > 10:  # Limit recursion depth
            return

        processed.add(call_key)

        # Find all calls made from this method
        calls = [
            call
            for call in self.function_calls
            if call.caller_class == caller_class and call.caller_method == caller_method
        ]

        for call in calls:
            # Skip if called_class is None (function calls)
            if call.called_class is None:
                continue

            # Add the called class as a participant
            called_participant = Participant(
                name=call.called_class,
                type=ParticipantType.CLASS,
            )
            diagram.add_participant(called_participant)

            # Add the message
            message_type = (
                MessageType.CREATE if call.is_constructor else MessageType.SYNCHRONOUS
            )
            is_self = caller_class == call.called_class

            message = Message(
                from_participant=caller_class,
                to_participant=call.called_class,
                text=call.called_method,
                message_type=message_type,
                is_self_message=is_self,
                level=level,
                method_name=call.called_method,
            )
            diagram.add_message(message)

            # Recursively process the called method
            self._process_call_graph(
                diagram,
                call.called_class,
                call.called_method,
                level + 1,
                processed,
            )

            # Add a return message if it's a synchronous call
            if message_type == MessageType.SYNCHRONOUS and not is_self:
                return_message = Message(
                    from_participant=call.called_class,
                    to_participant=caller_class,
                    text="return",
                    message_type=MessageType.REPLY,
                    level=level,
                )
                diagram.add_message(return_message)

================
File: uml/diagrams/sequence_diagram/generator.py
================
"""Generator for converting sequence diagrams to PlantUML format.

This module provides functionality for generating PlantUML sequence diagrams from
sequence diagram models.
"""

from pathlib import Path
from typing import Any

from utils.uml.core.exceptions import GeneratorError
from utils.uml.core.filesystem import FileSystem
from utils.uml.core.interfaces import DiagramModel
from utils.uml.diagrams.base import BaseDiagramGenerator
from utils.uml.diagrams.sequence_diagram.models import (
    ActivationBar,
    Message,
    MessageType,
    Participant,
    SequenceDiagram,
)


class SequenceDiagramGenerator(BaseDiagramGenerator):
    """Generates PlantUML sequence diagrams from sequence models."""

    def __init__(self, file_system: FileSystem, settings: dict[str, Any] | None = None):
        """Initialize a sequence diagram generator.

        Args:
            file_system: The file system implementation to use
            settings: Optional settings for the generator
        """
        super().__init__(file_system, settings)
        self.indentation = "  "
        self.current_indent = 0

    def _indent(self) -> str:
        """Get the current indentation string."""
        return self.indentation * self.current_indent

    def _increase_indent(self) -> None:
        """Increase indentation level."""
        self.current_indent += 1

    def _decrease_indent(self) -> None:
        """Decrease indentation level."""
        self.current_indent = max(0, self.current_indent - 1)

    def _format_participant(self, participant: Participant) -> str:
        """Format a participant as PlantUML.

        Args:
            participant: The participant to format

        Returns:
            The formatted participant string
        """
        participant_type = participant.type.value

        if participant.alias:
            return f'{participant_type} "{participant.name}" as {participant.alias}'

        # Handle special characters in class names by optionally using quotes
        if any(c in participant.name for c in " .-,;:/\\()[]{}<>!@#$%^&*+=|`~"):
            return f'{participant_type} "{participant.name}"'
        return f"{participant_type} {participant.name}"

    def _format_message(self, message: Message) -> str:
        """Format a message as PlantUML.

        Args:
            message: The message to format

        Returns:
            The formatted message string
        """
        arrow = message.message_type.value

        # Format the message text
        if message.method_name:
            text = f"{message.method_name}()"
        else:
            text = message.text

        # Self messages are handled differently
        if message.is_self_message:
            return (
                f"{message.from_participant} {arrow} {message.from_participant}: {text}"
            )
        return f"{message.from_participant} {arrow} {message.to_participant}: {text}"

    def _format_activation(self, activation: ActivationBar) -> str:
        """Format an activation/deactivation as PlantUML.

        Args:
            activation: The activation bar to format

        Returns:
            The formatted activation string
        """
        if activation.is_start:
            return f"activate {activation.participant}"
        return f"deactivate {activation.participant}"

    def generate_plantuml(self, diagram: SequenceDiagram) -> str:
        """Generate PlantUML code from a sequence diagram model.

        Args:
            diagram: The sequence diagram model

        Returns:
            The generated PlantUML code
        """
        lines = ["@startuml", ""]

        # Add title
        if diagram.title:
            lines.append(f"title {diagram.title}")
            lines.append("")

        # Add global settings from the settings dict, or use defaults
        hide_footboxes = self.settings.get("HIDE_FOOTBOXES", True)
        autonumber = self.settings.get("AUTONUMBER", False)

        settings = [
            "skinparam sequenceMessageAlign center",
            "skinparam monochrome true",
            "skinparam lifelinestrategy solid",
        ]

        if hide_footboxes:
            settings.append("hide footbox")

        if autonumber:
            settings.append("autonumber")

        lines.extend(settings)
        lines.append("")

        # Add participants
        for participant in diagram.participants:
            lines.append(self._format_participant(participant))
        lines.append("")

        # Process messages and activations
        active_participants = set()

        for i, message in enumerate(diagram.messages):
            # Handle activations
            if message.message_type in (
                MessageType.SYNCHRONOUS,
                MessageType.ASYNCHRONOUS,
            ):
                # Ensure source is activated if not already
                if (
                    message.from_participant not in active_participants
                    and message.from_participant != message.to_participant
                ):
                    lines.append(f"activate {message.from_participant}")
                    active_participants.add(message.from_participant)

                # Add the message
                lines.append(self._format_message(message))

                # Activate the target
                if (
                    not message.is_self_message
                    and message.to_participant not in active_participants
                ):
                    lines.append(f"activate {message.to_participant}")
                    active_participants.add(message.to_participant)

            elif message.message_type == MessageType.REPLY:
                # Add the message
                lines.append(self._format_message(message))

                # Deactivate the source on return
                if message.from_participant in active_participants:
                    lines.append(f"deactivate {message.from_participant}")
                    active_participants.remove(message.from_participant)

            else:
                # Other message types (CREATE, etc.)
                lines.append(self._format_message(message))

        # End the diagram
        lines.append("")
        lines.append("@enduml")

        return "\n".join(lines)

    def generate_diagram(
        self,
        model: DiagramModel,
        output_path: str | Path,
        **kwargs,
    ) -> None:
        """Generate a UML diagram from the given model and write it to the output path.

        Args:
            model: The diagram model to generate a diagram from
            output_path: The path to write the diagram to
            **kwargs: Additional generator-specific arguments

        Raises:
            GeneratorError: If the diagram cannot be generated
        """
        try:
            # Ensure the model is a SequenceDiagram
            if not isinstance(model, SequenceDiagram):
                raise GeneratorError(
                    f"Expected SequenceDiagram, got {type(model).__name__}",
                )

            # Generate the PlantUML code
            plantuml_code = self.generate_plantuml(model)

            # Ensure output directory exists and write the file
            output_path = (
                Path(output_path) if isinstance(output_path, str) else output_path
            )
            self.file_system.ensure_directory(output_path.parent)
            self.file_system.write_file(output_path, plantuml_code)

        except Exception as e:
            raise GeneratorError(
                f"Failed to generate sequence diagram: {e}",
                cause=e,
            )

    def generate_index(
        self,
        output_dir: str | Path,
        diagrams: list[Path],
        **kwargs,
    ) -> None:
        """Generate an index file for all diagrams in the output directory.

        Args:
            output_dir: The directory containing the diagrams
            diagrams: A list of paths to all diagrams
            **kwargs: Additional generator-specific arguments

        Raises:
            GeneratorError: If the index file cannot be generated
        """
        # Filter to only include sequence diagrams
        sequence_diagrams = [
            d
            for d in diagrams
            if d.name.endswith(".puml") and self._is_sequence_diagram(d)
        ]

        if not sequence_diagrams:
            return

        try:
            output_dir = Path(output_dir) if isinstance(output_dir, str) else output_dir
            index_path = output_dir / "sequence_index.rst"

            # Create basic RST index
            lines = [
                "Sequence Diagrams",
                "================",
                "",
                ".. toctree::",
                "   :maxdepth: 1",
                "",
            ]

            # Add diagram references
            for diagram in sorted(sequence_diagrams):
                rel_path = diagram.relative_to(output_dir)
                # Use forward slashes for cross-platform compatibility
                lines.append(f"   {str(rel_path).replace('\\', '/')}")

            lines.append("")  # Add trailing newline

            # Write the index file
            self.file_system.write_file(index_path, "\n".join(lines))

        except Exception as e:
            raise GeneratorError(
                f"Failed to generate sequence diagram index: {e}",
                cause=e,
            )

    def _is_sequence_diagram(self, file_path: Path) -> bool:
        """Check if a file is a sequence diagram.

        Args:
            file_path: The path to the file to check

        Returns:
            True if the file is a sequence diagram, False otherwise
        """
        try:
            content = self.file_system.read_file(file_path)
            # Simple heuristic: look for sequence diagram indicators
            indicators = [
                "participant",
                "actor",
                "activate",
                "deactivate",
                "skinparam sequenceMessageAlign",
            ]
            return any(indicator in content for indicator in indicators)
        except Exception:
            return False

================
File: uml/diagrams/sequence_diagram/models.py
================
"""Data models for sequence diagram extraction.

This module provides the data models for representing sequence diagrams.
"""

from dataclasses import dataclass, field
from enum import Enum

from utils.uml.diagrams.base import BaseDiagramModel


class ParticipantType(Enum):
    """Types of participants in a sequence diagram."""

    ACTOR = "actor"
    BOUNDARY = "boundary"
    CONTROL = "control"
    ENTITY = "entity"
    DATABASE = "database"
    CLASS = "class"  # Regular Python class


@dataclass
class Participant:
    """Represents a participant in a sequence diagram."""

    name: str
    type: ParticipantType = ParticipantType.CLASS
    module: str | None = None
    alias: str | None = None

    @property
    def full_name(self) -> str:
        """Get the full name with module.

        Returns:
            The full name of the participant, including module if available.
        """
        if self.module:
            return f"{self.module}.{self.name}"
        return self.name


class MessageType(Enum):
    """Types of messages in a sequence diagram."""

    SYNCHRONOUS = "->"
    ASYNCHRONOUS = "->>"
    REPLY = "-->"
    CREATE = "-->>"
    SELF = "->"


@dataclass
class Message:
    """Represents a message between participants."""

    from_participant: str
    to_participant: str
    text: str
    message_type: MessageType = MessageType.SYNCHRONOUS
    is_self_message: bool = False
    level: int = 0  # Call stack level
    method_name: str | None = None
    arguments: list[str] = field(default_factory=list)

    @property
    def formatted_text(self) -> str:
        """Format the text with arguments if needed.

        Returns:
            Formatted text for the message, including method name and arguments if available.
        """
        if self.method_name:
            args_str = ", ".join(self.arguments)
            return f"{self.method_name}({args_str})"
        return self.text


@dataclass
class ActivationBar:
    """Represents activation of a participant."""

    participant: str
    is_start: bool = True  # True for activation start, False for deactivation


class SequenceDiagram(BaseDiagramModel):
    """Represents a sequence diagram."""

    def __init__(self, title: str):
        """Initialize a sequence diagram.

        Args:
            title: The title of the diagram
        """
        super().__init__(name=title, diagram_type="sequence")
        self.title = title
        self.participants: list[Participant] = []
        self.messages: list[Message] = []
        self.activations: list[ActivationBar] = []

    def add_participant(self, participant: Participant) -> None:
        """Add a participant if it doesn't already exist.

        Args:
            participant: The participant to add
        """
        if not any(p.name == participant.name for p in self.participants):
            self.participants.append(participant)

    def add_message(self, message: Message) -> None:
        """Add a message to the diagram.

        Args:
            message: The message to add
        """
        self.messages.append(message)

        # Add activation/deactivation if it's a method call
        if message.message_type in (MessageType.SYNCHRONOUS, MessageType.ASYNCHRONOUS):
            # Start activation on the target
            self.activations.append(
                ActivationBar(
                    participant=message.to_participant,
                    is_start=True,
                ),
            )
        elif message.message_type == MessageType.REPLY:
            # End activation on the source
            self.activations.append(
                ActivationBar(
                    participant=message.from_participant,
                    is_start=False,
                ),
            )


@dataclass
class FunctionCall:
    """Represents a function call extracted from code."""

    caller_class: str | None
    caller_method: str | None
    called_class: str | None
    called_method: str
    arguments: list[str] = field(default_factory=list)
    is_constructor: bool = False
    line_number: int = 0
    file_path: str | None = None

================
File: uml/diagrams/state_diagram/__init__.py
================
"""State diagram generation.

This module will provide functionality for generating UML state diagrams (planned).
"""

================
File: uml/diagrams/state_diagram/analyzer.py
================
"""Analyzer for extracting state diagrams from Python code.

This module provides functionality for analyzing Python code and extracting
state diagrams from it.
"""

import logging
from pathlib import Path
from typing import Any

from utils.uml.core.exceptions import ParserError
from utils.uml.core.filesystem import FileSystem
from utils.uml.diagrams.base import BaseDiagramAnalyzer
from utils.uml.diagrams.state_diagram.models import (
    CompositeStateModel,
    EndStateModel,
    StartStateModel,
    StateDiagram,
    StateModel,
    TransitionModel,
)


class StateAnalyzer(BaseDiagramAnalyzer):
    """Analyzer for extracting state diagrams from Python code."""

    def __init__(self, file_system: FileSystem):
        """Initialize the state analyzer.

        Args:
            file_system: The file system implementation to use
        """
        super().__init__(file_system)
        self.logger = logging.getLogger(__name__)

    def analyze(
        self,
        path: str | Path,
        **kwargs: Any,
    ) -> StateDiagram:
        """Analyze the source code at the given path and generate a state diagram.

        This is a placeholder implementation that will be expanded in the future.
        Currently, it creates a simple example diagram.

        Args:
            path: Path to the source code to analyze
            **kwargs: Additional analyzer-specific arguments

        Returns:
            A state diagram model

        Raises:
            ParserError: If the analysis fails
        """
        try:
            # Create a placeholder diagram
            diagram_name = kwargs.get("name", "State Diagram")
            if isinstance(path, Path):
                if path.is_file():
                    diagram_name = f"State Diagram - {path.stem}"
                else:
                    diagram_name = f"State Diagram - {path.name}"

            diagram = StateDiagram(diagram_name)

            # This is a placeholder implementation
            # In a real implementation, we would analyze the code and extract states

            # Add a simple example diagram
            self._create_example_diagram(diagram)

            return diagram
        except Exception as e:
            raise ParserError(f"Failed to analyze code at {path}: {e}", cause=e)

    def _create_example_diagram(self, diagram: StateDiagram) -> None:
        """Create a simple example diagram.

        Args:
            diagram: The diagram to populate
        """
        # Add start state
        start = StartStateModel("start")
        diagram.add_start_state(start)

        # Add states
        idle = StateModel("idle", "Idle")
        idle.add_entry_action("initialize()")
        idle.add_exit_action("cleanup()")

        processing = StateModel("processing", "Processing")
        processing.add_entry_action("startProcess()")
        processing.add_internal_action("updateProgress()")
        processing.add_exit_action("endProcess()")

        waiting = StateModel("waiting", "Waiting for Input")
        waiting.add_entry_action("displayPrompt()")

        error = StateModel("error", "Error")
        error.add_entry_action("logError()")
        error.add_internal_action("displayError()")

        # Add composite state
        composite = CompositeStateModel("composite", "Composite State")
        substate1 = StateModel("substate1", "Substate 1")
        substate2 = StateModel("substate2", "Substate 2")
        composite.add_substate(substate1)
        composite.add_substate(substate2)
        composite.add_internal_transition(
            TransitionModel("substate1", "substate2", "next", None, "transition()"),
        )

        # Add states to diagram
        diagram.add_state(idle)
        diagram.add_state(processing)
        diagram.add_state(waiting)
        diagram.add_state(error)
        diagram.add_composite_state(composite)

        # Add end state
        end = EndStateModel("end")
        diagram.add_end_state(end)

        # Add transitions
        diagram.add_transition(TransitionModel("start", "idle"))
        diagram.add_transition(
            TransitionModel("idle", "processing", "start", None, "beginProcessing()"),
        )
        diagram.add_transition(
            TransitionModel(
                "processing", "waiting", "needInput", None, "pauseProcessing()"
            ),
        )
        diagram.add_transition(
            TransitionModel(
                "waiting", "processing", "inputReceived", None, "resumeProcessing()"
            ),
        )
        diagram.add_transition(
            TransitionModel(
                "processing", "idle", "complete", None, "finishProcessing()"
            ),
        )
        diagram.add_transition(
            TransitionModel("processing", "error", "error", None, "handleError()"),
        )
        diagram.add_transition(
            TransitionModel("error", "idle", "reset", None, "resetSystem()"),
        )
        diagram.add_transition(
            TransitionModel("idle", "composite", "enterComposite"),
        )
        diagram.add_transition(
            TransitionModel("composite", "idle", "exitComposite"),
        )
        diagram.add_transition(
            TransitionModel("idle", "end", "shutdown"),
        )

================
File: uml/diagrams/state_diagram/generator.py
================
"""Generator for converting state diagrams to PlantUML format.

This module provides functionality for generating PlantUML state diagrams from
state diagram models.
"""

from pathlib import Path
from typing import Any

from utils.uml.core.exceptions import GeneratorError
from utils.uml.core.filesystem import FileSystem
from utils.uml.core.interfaces import DiagramModel
from utils.uml.diagrams.base import BaseDiagramGenerator
from utils.uml.diagrams.state_diagram.models import (
    StateDiagram,
)


class StateDiagramGenerator(BaseDiagramGenerator):
    """Generates PlantUML state diagrams from state diagram models."""

    def __init__(self, file_system: FileSystem, settings: dict[str, Any] | None = None):
        """Initialize a state diagram generator.

        Args:
            file_system: The file system implementation to use
            settings: Optional settings for the generator
        """
        super().__init__(file_system, settings)

    def generate_diagram(
        self,
        model: DiagramModel,
        output_path: str | Path,
        **kwargs,
    ) -> None:
        """Generate a UML diagram from the given model and write it to the output path.

        Args:
            model: The diagram model to generate a diagram from
            output_path: The path to write the diagram to
            **kwargs: Additional generator-specific arguments

        Raises:
            GeneratorError: If the diagram cannot be generated
        """
        try:
            # Ensure the model is a StateDiagram
            if not isinstance(model, StateDiagram):
                raise GeneratorError(
                    f"Expected StateDiagram, got {type(model).__name__}",
                )

            # Generate the PlantUML code
            plantuml_code = self.generate_plantuml(model, **kwargs)

            # Ensure output directory exists and write the file
            output_path = (
                Path(output_path) if isinstance(output_path, str) else output_path
            )
            self.file_system.ensure_directory(output_path.parent)
            self.file_system.write_file(output_path, plantuml_code)

        except Exception as e:
            raise GeneratorError(
                f"Failed to generate state diagram: {e}",
                cause=e,
            )

    def generate_plantuml(
        self,
        diagram: StateDiagram,
        **kwargs,
    ) -> str:
        """Generate PlantUML code from a state diagram model.

        Args:
            diagram: The state diagram model
            **kwargs: Additional generator-specific arguments

        Returns:
            The generated PlantUML code
        """
        lines = ["@startuml", ""]

        # Add title
        if diagram.name:
            lines.append(f"title {diagram.name}")
            lines.append("")

        # Add global settings
        use_monochrome = self.settings.get("MONOCHROME", True)
        settings = [
            "skinparam StateBackgroundColor white",
            "skinparam StateBorderColor black",
            "skinparam ArrowColor black",
            "skinparam monochrome true" if use_monochrome else "",
        ]

        # Filter out empty settings
        settings = [s for s in settings if s]
        lines.extend(settings)
        lines.append("")

        # Add start states
        for start_state in diagram.start_states:
            lines.append(f"[*] --> {start_state.id}")

        # Add states
        for state in diagram.states:
            # State with actions
            if state.entry_actions or state.exit_actions or state.internal_actions:
                lines.append(f"state {state.name} {{")

                # Entry actions
                for action in state.entry_actions:
                    lines.append(f"  entry / {action}")

                # Exit actions
                for action in state.exit_actions:
                    lines.append(f"  exit / {action}")

                # Internal actions
                for action in state.internal_actions:
                    lines.append(f"  {action}")

                lines.append("}")
            else:
                # Simple state
                lines.append(f"state {state.name}")

        # Add composite states
        for composite in diagram.composite_states:
            lines.append(f"state {composite.name} {{")

            # Add substates
            for substate in composite.substates:
                lines.append(f"  state {substate.name}")

            # Add internal transitions
            for transition in composite.internal_transitions:
                source = transition.source_id
                target = transition.target_id
                event = f" : {transition.event}" if transition.event else ""
                guard = f" [{transition.guard}]" if transition.guard else ""
                action = f" / {transition.action}" if transition.action else ""

                lines.append(f"  {source} --> {target}{event}{guard}{action}")

            lines.append("}")

        # Add end states
        for end_state in diagram.end_states:
            lines.append(f"{end_state.id} --> [*]")

        # Add transitions
        lines.append("")
        lines.append("' Transitions")

        # Process transitions
        for transition in diagram.transitions:
            source = transition.source_id
            target = transition.target_id
            event = f" : {transition.event}" if transition.event else ""
            guard = f" [{transition.guard}]" if transition.guard else ""
            action = f" / {transition.action}" if transition.action else ""

            # Skip transitions from start states and to end states (already handled)
            if source in [s.id for s in diagram.start_states] or target in [
                e.id for e in diagram.end_states
            ]:
                continue

            lines.append(f"{source} --> {target}{event}{guard}{action}")

        # End the diagram
        lines.append("")
        lines.append("@enduml")

        return "\n".join(lines)

    def generate_index(
        self,
        output_dir: str | Path,
        diagrams: list[Path],
        **kwargs,
    ) -> None:
        """Generate an index file for all diagrams in the output directory.

        Args:
            output_dir: The directory containing the diagrams
            diagrams: A list of paths to all diagrams
            **kwargs: Additional generator-specific arguments

        Raises:
            GeneratorError: If the index file cannot be generated
        """
        # Filter to only include state diagrams
        state_diagrams = [
            d
            for d in diagrams
            if d.name.endswith(".puml") and self._is_state_diagram(d)
        ]

        if not state_diagrams:
            return

        try:
            output_dir = Path(output_dir) if isinstance(output_dir, str) else output_dir
            index_path = output_dir / "state_index.rst"

            # Create basic RST index
            lines = [
                "State Diagrams",
                "==============",
                "",
                ".. toctree::",
                "   :maxdepth: 1",
                "",
            ]

            # Add diagram references
            for diagram in sorted(state_diagrams):
                rel_path = diagram.relative_to(output_dir)
                # Use forward slashes for cross-platform compatibility
                lines.append(f"   {str(rel_path).replace('\\', '/')}")

            lines.append("")  # Add trailing newline

            # Write the index file
            self.file_system.write_file(index_path, "\n".join(lines))

        except Exception as e:
            raise GeneratorError(
                f"Failed to generate state diagram index: {e}",
                cause=e,
            )

    def _is_state_diagram(self, file_path: Path) -> bool:
        """Check if a file is a state diagram.

        Args:
            file_path: The path to the file to check

        Returns:
            True if the file is a state diagram, False otherwise
        """
        try:
            content = self.file_system.read_file(file_path)
            # Simple heuristic: look for state diagram indicators
            indicators = [
                "state ",
                "[*] -->",
                "--> [*]",
                "skinparam StateBackgroundColor",
            ]
            return any(indicator in content for indicator in indicators)
        except Exception:
            return False

================
File: uml/diagrams/state_diagram/models.py
================
"""Models for state diagrams.

This module provides models for representing state diagrams.
"""

from utils.uml.diagrams.base import BaseDiagramModel


class StateDiagram(BaseDiagramModel):
    """Model for a state diagram."""

    def __init__(self, name: str):
        """Initialize a state diagram.

        Args:
            name: The name of the diagram
        """
        super().__init__(name, "state")
        self.states: list[StateModel] = []
        self.transitions: list[TransitionModel] = []
        self.start_states: list[StartStateModel] = []
        self.end_states: list[EndStateModel] = []
        self.composite_states: list[CompositeStateModel] = []

    def add_state(self, state: "StateModel") -> None:
        """Add a state to the diagram.

        Args:
            state: The state to add
        """
        self.states.append(state)

    def add_transition(self, transition: "TransitionModel") -> None:
        """Add a transition to the diagram.

        Args:
            transition: The transition to add
        """
        self.transitions.append(transition)

    def add_start_state(self, start_state: "StartStateModel") -> None:
        """Add a start state to the diagram.

        Args:
            start_state: The start state to add
        """
        self.start_states.append(start_state)

    def add_end_state(self, end_state: "EndStateModel") -> None:
        """Add an end state to the diagram.

        Args:
            end_state: The end state to add
        """
        self.end_states.append(end_state)

    def add_composite_state(self, composite_state: "CompositeStateModel") -> None:
        """Add a composite state to the diagram.

        Args:
            composite_state: The composite state to add
        """
        self.composite_states.append(composite_state)


class StateModel:
    """Model for a state."""

    def __init__(
        self, id: str, name: str | None = None, description: str | None = None
    ):
        """Initialize a state.

        Args:
            id: The unique identifier for the state
            name: The name of the state
            description: The description of the state
        """
        self.id = id
        self.name = name or id
        self.description = description
        self.entry_actions: list[str] = []
        self.exit_actions: list[str] = []
        self.internal_actions: list[str] = []

    def add_entry_action(self, action: str) -> None:
        """Add an entry action to the state.

        Args:
            action: The entry action to add
        """
        self.entry_actions.append(action)

    def add_exit_action(self, action: str) -> None:
        """Add an exit action to the state.

        Args:
            action: The exit action to add
        """
        self.exit_actions.append(action)

    def add_internal_action(self, action: str) -> None:
        """Add an internal action to the state.

        Args:
            action: The internal action to add
        """
        self.internal_actions.append(action)


class TransitionModel:
    """Model for a transition between states."""

    def __init__(
        self,
        source_id: str,
        target_id: str,
        event: str | None = None,
        guard: str | None = None,
        action: str | None = None,
    ):
        """Initialize a transition.

        Args:
            source_id: The ID of the source state
            target_id: The ID of the target state
            event: The event that triggers the transition
            guard: The guard condition for the transition
            action: The action performed during the transition
        """
        self.source_id = source_id
        self.target_id = target_id
        self.event = event
        self.guard = guard
        self.action = action


class StartStateModel:
    """Model for a start state."""

    def __init__(self, id: str):
        """Initialize a start state.

        Args:
            id: The unique identifier for the state
        """
        self.id = id


class EndStateModel:
    """Model for an end state."""

    def __init__(self, id: str):
        """Initialize an end state.

        Args:
            id: The unique identifier for the state
        """
        self.id = id


class CompositeStateModel(StateModel):
    """Model for a composite state."""

    def __init__(
        self,
        id: str,
        name: str | None = None,
        description: str | None = None,
    ):
        """Initialize a composite state.

        Args:
            id: The unique identifier for the state
            name: The name of the state
            description: The description of the state
        """
        super().__init__(id, name, description)
        self.substates: list[StateModel] = []
        self.internal_transitions: list[TransitionModel] = []
        self.internal_start_states: list[StartStateModel] = []
        self.internal_end_states: list[EndStateModel] = []

    def add_substate(self, state: StateModel) -> None:
        """Add a substate to the composite state.

        Args:
            state: The substate to add
        """
        self.substates.append(state)

    def add_internal_transition(self, transition: TransitionModel) -> None:
        """Add an internal transition to the composite state.

        Args:
            transition: The internal transition to add
        """
        self.internal_transitions.append(transition)

    def add_internal_start_state(self, start_state: StartStateModel) -> None:
        """Add an internal start state to the composite state.

        Args:
            start_state: The internal start state to add
        """
        self.internal_start_states.append(start_state)

    def add_internal_end_state(self, end_state: EndStateModel) -> None:
        """Add an internal end state to the composite state.

        Args:
            end_state: The internal end state to add
        """
        self.internal_end_states.append(end_state)

================
File: uml/factories.py
================
"""Factory classes for UML diagram generation.

This module provides factory classes for creating diagram analyzers and generators.
"""

import logging
from collections.abc import Callable
from typing import Any

from utils.uml.core.exceptions import DiagramTypeError
from utils.uml.core.filesystem import FileSystem
from utils.uml.core.interfaces import DiagramAnalyzer, DiagramFactory, DiagramGenerator
from utils.uml.diagrams.activity_diagram.analyzer import ActivityAnalyzer
from utils.uml.diagrams.activity_diagram.generator import ActivityDiagramGenerator
from utils.uml.diagrams.class_diagram.analyzer import ClassAnalyzer
from utils.uml.diagrams.class_diagram.generator import ClassDiagramGenerator
from utils.uml.diagrams.sequence_diagram.analyzer import SequenceAnalyzer
from utils.uml.diagrams.sequence_diagram.generator import SequenceDiagramGenerator
from utils.uml.diagrams.state_diagram.analyzer import StateAnalyzer
from utils.uml.diagrams.state_diagram.generator import StateDiagramGenerator


class DefaultDiagramFactory(DiagramFactory):
    """Default implementation of DiagramFactory."""

    def __init__(self, file_system: FileSystem, settings: dict[str, Any] | None = None):
        """Initialize factory with file system and settings.

        Args:
            file_system: The file system implementation to use
            settings: Optional settings for the factory
        """
        self.file_system = file_system
        self.settings = settings or {}
        self.logger = logging.getLogger(__name__)

        # Cache for created instances
        self._analyzers: dict[str, DiagramAnalyzer] = {}
        self._generators: dict[str, DiagramGenerator] = {}

        # Define creator functions
        self._analyzer_creators: dict[str, Callable[..., DiagramAnalyzer]] = {}
        self._generator_creators: dict[str, Callable[..., DiagramGenerator]] = {}

        # Register built-in diagram types
        self._register_built_in_types()

    def _register_built_in_types(self) -> None:
        """Register built-in diagram types."""
        # Register sequence diagram
        self._analyzer_creators["sequence"] = lambda **kwargs: SequenceAnalyzer(
            self.file_system,
            kwargs.get("root_dir", "."),
        )
        self._generator_creators["sequence"] = (
            lambda **kwargs: SequenceDiagramGenerator(
                self.file_system,
                {**self.settings.get("sequence_generator", {}), **kwargs},
            )
        )

        # Register class diagram
        self._analyzer_creators["class"] = lambda **kwargs: ClassAnalyzer(
            self.file_system
        )
        self._generator_creators["class"] = lambda **kwargs: ClassDiagramGenerator(
            self.file_system,
            {**self.settings.get("class_generator", {}), **kwargs},
        )

        # Register activity diagram
        self._analyzer_creators["activity"] = lambda **kwargs: ActivityAnalyzer(
            self.file_system
        )
        self._generator_creators["activity"] = (
            lambda **kwargs: ActivityDiagramGenerator(
                self.file_system,
                {**self.settings.get("activity_generator", {}), **kwargs},
            )
        )

        # Register state diagram
        self._analyzer_creators["state"] = lambda **kwargs: StateAnalyzer(
            self.file_system
        )
        self._generator_creators["state"] = lambda **kwargs: StateDiagramGenerator(
            self.file_system,
            {**self.settings.get("state_generator", {}), **kwargs},
        )

    def create_analyzer(self, diagram_type: str, **kwargs) -> DiagramAnalyzer:
        """Create an analyzer for the given diagram type.

        Args:
            diagram_type: The type of diagram to create an analyzer for
            **kwargs: Additional analyzer-specific arguments

        Returns:
            A diagram analyzer for the given diagram type

        Raises:
            DiagramTypeError: If the diagram type is not supported
        """
        # Return cached analyzer if available
        if diagram_type in self._analyzers:
            return self._analyzers[diagram_type]

        # Create analyzer if type is supported
        if diagram_type in self._analyzer_creators:
            analyzer = self._analyzer_creators[diagram_type](**kwargs)
            self._analyzers[diagram_type] = analyzer
            return analyzer

        # Diagram type not supported
        self.logger.error(f"No analyzer available for diagram type: {diagram_type}")
        raise DiagramTypeError(f"Unsupported diagram type: {diagram_type}")

    def create_generator(self, diagram_type: str, **kwargs) -> DiagramGenerator:
        """Create a generator for the given diagram type.

        Args:
            diagram_type: The type of diagram to create a generator for
            **kwargs: Additional generator-specific arguments

        Returns:
            A diagram generator for the given diagram type

        Raises:
            DiagramTypeError: If the diagram type is not supported
        """
        # Return cached generator if available
        if diagram_type in self._generators:
            return self._generators[diagram_type]

        # Create generator if type is supported
        if diagram_type in self._generator_creators:
            generator = self._generator_creators[diagram_type](**kwargs)
            self._generators[diagram_type] = generator
            return generator

        # Diagram type not supported
        self.logger.error(f"No generator available for diagram type: {diagram_type}")
        raise DiagramTypeError(f"Unsupported diagram type: {diagram_type}")

    def register_analyzer(
        self,
        diagram_type: str,
        creator_func: Callable[..., DiagramAnalyzer],
    ) -> None:
        """Register a new analyzer creator function for a diagram type.

        Args:
            diagram_type: The diagram type to register the analyzer for
            creator_func: A function that creates an analyzer instance
        """
        # Clear cache for this type to force recreation on next use
        if diagram_type in self._analyzers:
            del self._analyzers[diagram_type]

        # Register the creator function
        self._analyzer_creators[diagram_type] = creator_func

    def register_generator(
        self,
        diagram_type: str,
        creator_func: Callable[..., DiagramGenerator],
    ) -> None:
        """Register a new generator creator function for a diagram type.

        Args:
            diagram_type: The diagram type to register the generator for
            creator_func: A function that creates a generator instance
        """
        # Clear cache for this type to force recreation on next use
        if diagram_type in self._generators:
            del self._generators[diagram_type]

        # Register the creator function
        self._generator_creators[diagram_type] = creator_func

================
File: uml/pyproject.toml
================
[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[project]
name = "utils-uml"
version = "0.1.0"
description = "UML diagram generation tools"
requires-python = ">=3.10,<4.0"
dependencies = [
    # Add any specific dependencies needed for UML generation
]

[project.scripts]
uml-run = "utils.uml.run:main"
uml-extract-class = "utils.uml.cli.extract_class:main"
uml-extract-sequence = "utils.uml.cli.extract_sequence:main"
uml-extract-activity = "utils.uml.cli.extract_activity:main"
uml-extract-state = "utils.uml.cli.extract_state:main"

[tool.hatch.build.targets.wheel]
packages = ["utils"]

================
File: uml/README.md
================
# UML Diagram Generation Package

This package provides tools for generating UML diagrams from Python code. It supports class, sequence, activity, and state diagrams.

## Installation

The package is designed to be installed as a Python package. To install it in development mode:

```bash
# From the project root directory
pip install -e utils/uml
```

This will install the package in "editable" mode, allowing you to make changes to the code without reinstalling.

## Usage

### Command Line Interface

The package provides several command-line scripts for generating UML diagrams:

```bash
# Generate all diagram types
python -m utils.uml.run --source path/to/source --output path/to/output

# Generate class diagrams
python -m utils.uml.cli.extract_class --source path/to/source

# Generate sequence diagrams
python -m utils.uml.cli.extract_sequence --source path/to/source

# Generate activity diagrams
python -m utils.uml.cli.extract_activity --source path/to/source

# Generate state diagrams
python -m utils.uml.cli.extract_state --source path/to/source

# Run the UML generator on the backend/app directory
python -m utils.uml.cli.run_uml_generator

# Extract sequence diagrams from key entry points in the application
python -m utils.uml.cli.extract_app_sequences
```

### Programmatic Usage

You can also use the package programmatically:

```python
from utils.uml import DefaultFileSystem, UmlService, DefaultDiagramFactory

# Create service
file_system = DefaultFileSystem()
factory = DefaultDiagramFactory(file_system)
service = UmlService(factory)

# Generate a diagram
service.generate_diagram(
    "class",                  # Diagram type: "class", "sequence", "activity", "state"
    "path/to/source",         # Source file or directory
    "path/to/output.puml",    # Output file
    recursive=True,           # Recursively analyze directories
    include_private=False,    # Include private members in diagrams
)
```

## Architecture

The package follows a modular architecture:

- **Core**: Core interfaces and implementations
  - `filesystem.py`: File system abstraction
  - `service.py`: Main service for generating diagrams
  - `interfaces.py`: Interfaces for analyzers and generators
  - `exceptions.py`: Custom exceptions

- **Diagrams**: Diagram-specific implementations
  - `class_diagram/`: Class diagram analyzer and generator
  - `sequence_diagram/`: Sequence diagram analyzer and generator
  - `activity_diagram/`: Activity diagram analyzer and generator
  - `state_diagram/`: State diagram analyzer and generator

- **CLI**: Command-line interfaces
  - `extract_class.py`: Extract class diagrams
  - `extract_sequence.py`: Extract sequence diagrams
  - `extract_activity.py`: Extract activity diagrams
  - `extract_state.py`: Extract state diagrams
  - `extract_app_sequences.py`: Extract sequence diagrams from key entry points
  - `run_uml_generator.py`: Run the UML generator on the backend/app directory

- **Utils**: Utility functions
  - `paths.py`: Path utilities

- **Factories**: Factory classes for creating analyzers and generators
  - `factories.py`: Default factory implementation

## Development

### Adding a New Diagram Type

To add a new diagram type:

1. Create a new directory under `diagrams/` for the new diagram type
2. Implement an analyzer and generator for the new diagram type
3. Register the new diagram type in `factories.py`
4. Add a new CLI script for the new diagram type

### Testing

To test the package:

```bash
# Run tests
pytest utils/uml/tests

================
File: uml/REVIEW.md
================
## Table of Contents

1. **Overall Architecture & Observations**  
   1.1. Purpose & Structure  
   1.2. Main Components  
   1.3. Diagram Types  
2. **Strengths of the Current Codebase**  
3. **Areas for Improvement**  
   3.1. Project Structure & Imports  
   3.2. Redundancies & Repeated Patterns  
   3.3. Error Handling & Logging  
   3.4. CLI Organization & Usage  
   3.5. Code Style & Pythonic Conventions  
   3.6. Type Annotations & `kwargs` Usage  
   3.7. Testing & Validation  
4. **Detailed Recommendations**  
   4.1. Streamlining Diagram Generation  
   4.2. Improving CLI UX  
   4.3. Revisiting AST Parsing & Analyzers  
   4.4. Index Generation  
   4.5. Setup & Scripts  
5. **Summary of Action Items**  

---


## 1. Overall Architecture & Observations

### 1.1 Purpose & Structure

Your repository is focused on **analyzing Python source code** (and occasionally YAML) to produce **PlantUML** diagrams of various types: **class**, **sequence**, **activity**, and **state**. The code is spread across:

- A set of **CLI tools** (in `cli/`) for generating each diagram type (`extract_*.py` scripts), plus an all-in-one CLI called `uml_cli.py`.
- A **core UML library** (in `core/`, `diagrams/`, and `factories.py`) that handles analysis, modeling, and rendering of diagrams.
- Various **utility** modules (`utils/…`).
- Several **scripts** for installing, archiving old code, or setting up virtual environments.

### 1.2 Main Components

1. **`core/`**  
   - Defines foundational interfaces (`DiagramModel`, `DiagramAnalyzer`, `DiagramGenerator`) and a `UmlService` that orchestrates them.
   - `filesystem.py` for reading and writing files, plus some exceptions in `exceptions.py`.

2. **`diagrams/`** (each subfolder for a different UML type)  
   - **Analyzer** (e.g. `class_diagram/analyzer.py`, `sequence_diagram/analyzer.py`) that uses Python’s `ast` or other logic to parse code into a `DiagramModel`.
   - **Generator** (e.g. `class_diagram/generator.py`) that outputs **PlantUML** text from that model.
   - **models.py** that define data structures for each diagram type.

3. **`factories.py`**  
   - A default `DiagramFactory` that chooses which `Analyzer` / `Generator` to instantiate based on diagram type.

4. **`cli/`**  
   - Each script (`extract_class.py`, `extract_sequence.py`, etc.) calls into the `UmlService` and sets up arguments. There’s also a unified CLI (`uml_cli.py`) that can handle all diagram types in one command.

5. **`scripts/`**  
   - Housekeeping scripts (`cleanup_old_code.py`, `install_dev.py`, `setup_venv.py`) that manage environment setup, archiving, etc.

### 1.3 Diagram Types

- **Class Diagrams**: Use `ast` to parse classes/functions, building relationships, attributes, etc.
- **Sequence Diagrams**: Analyze function calls, method calls, or top-level flow in Python code to generate message sequences.
- **Activity & State Diagrams**: Currently placeholders (with some partial examples), but not as deeply integrated as class/sequence.

---

## 2. Strengths of the Current Codebase

1. **Clear Package Separation**  
   Each diagram type (class, sequence, activity, state) is kept in a dedicated subfolder. The code is relatively consistent in structure across them.

2. **Modular & Extensible**  
   - The `DiagramAnalyzer` / `DiagramGenerator` interfaces, combined with `DiagramFactory`, create a plug-in style system. Adding a new diagram type only requires hooking up a new analyzer + generator.

3. **Reasonable Use of Docstrings**  
   Nearly every function and class has a docstring describing its purpose, which is great for maintainability.

4. **CLI Tools**  
   Multiple scripts let users generate each diagram type individually or all in one shot. The approach is flexible for different user needs.

5. **Index Generation**  
   There’s thoughtful logic for generating `.rst` indexes automatically, so you can embed the UML diagrams easily in Sphinx or other docs.

---

## 3. Areas for Improvement

### 3.1 Project Structure & Imports

- **Inconsistent Path Injection**:  
  Many CLI scripts do `sys.path.insert(0, str(Path(__file__).parent.parent.parent.parent))`. This can cause confusion or import errors in different environments. Consider installing your code as a normal Python package (editable install) so that you don’t need to manipulate `sys.path`.
- **`utils/uml/...` vs. `utils.uml...`**:  
  Some references in the code use paths like `from utils.uml.core...`, but physically the code is in `core/`, `diagrams/`, etc. This suggests you might want to unify where your `__init__.py` and `setup.py` (or `pyproject.toml`) place the real “package boundary.”  

### 3.2 Redundancies & Repeated Patterns

- **Four Diagram Types, Very Similar Flows**  
  Each analyzer and generator duplicates patterns: “parse code → build internal model → output `.puml`.” Large chunks of repeated boilerplate could be consolidated if you want a single harness that enumerates `diagram_type` and calls the correct path. This DRY approach might reduce the ongoing maintenance cost.
- **CLI duplication**:  
  `extract_activity.py`, `extract_class.py`, etc. each parse arguments in a nearly identical fashion. This is partially solved by `uml_cli.py`, but the older scripts remain mostly duplicated.

### 3.3 Error Handling & Logging

- **Partial `try/except` in many places**  
  Some scripts do `except Exception as e:` with big tracebacks, while others handle errors more gracefully or not at all. The code generally logs well, but you could unify your approach to logging + error-handling for a cleaner user experience.

### 3.4 CLI Organization & Usage

- You have both **one-file** extraction scripts (like `extract_class.py`) **and** a big unified CLI (`uml_cli.py`). Maintaining both might be overkill. If your final approach is to keep them, that’s fine—but your docs or help text should clarify that “uml_cli.py is the recommended entry point.”

### 3.5 Code Style & Pythonic Conventions

- **`ast.unparse()`** (in the class diagram analyzers) is only available in Python 3.9+. That might be fine if you’re pinned to 3.9 or above. Just be sure that your readme or docs mention that requirement.
- **`camelCase` vs. `snake_case`**:  
  Mostly everything is `snake_case`, but check small spots for consistency (like local variables or function calls).
- **Docstrings**:  
  Generally good, though some docstrings reference older variable names or skip describing `kwargs` usage.

### 3.6 Type Annotations & `kwargs` Usage

- The code uses typed `@dataclass` objects well, but many function signatures rely on `**kwargs` without specifying the exact shape. That can be flexible, but can also make it unclear which arguments are truly accepted.  
- Adding explicit type hints (e.g., `def analyze(self, path: Path, recursive: bool = True, ...) -> ClassDiagram`) can help catch mistakes or missing arguments.

### 3.7 Testing & Validation

- I see no explicit test suite in the repository. This code touches on AST parsing, file I/O, and external dependencies (PlantUML, etc.). Automated tests would drastically help you confirm each diagram type works as intended—especially if you refactor.

---

## 4. Detailed Recommendations

### 4.1 Streamlining Diagram Generation

- **Unify the “Extract & Generate” Flow**  
  Right now, each `extract_*.py` script does basically the same pattern:
  1. Parse CLI arguments.
  2. Create `DefaultFileSystem`, `DefaultDiagramFactory`, `UmlService`.
  3. Call `service.generate_diagram(...)`.

  If you trust the `uml_cli.py`, you can let that be the single official path. Then the older scripts could be optional or removed. This will reduce duplication.

- **Consolidate or Remove Old Scripts**  
  If you want to keep single-command scripts around, consider at least factoring out the argument parser logic so they all share the same parser. That means you update argument logic once.

### 4.2 Improving CLI UX

- **Consistent Command Names**  
  The commands are generally descriptive but somewhat verbose. For example:  
  ```shell
  python -m cli.extract_activity -s myapp --recursive
  ```
  vs
  ```shell
  python -m cli.uml_cli activity -s myapp --recursive
  ```
  Possibly unify them so that it’s always `uml_cli activity --source ...`.

- **Better Help/Docs**  
  For end users, a single `python -m cli.uml_cli --help` might be enough. If you keep the separate scripts, place a note at the top: “This script is basically a wrapper. The recommended usage is `uml_cli activity`.”

### 4.3 Revisiting AST Parsing & Analyzers

- **Class/Sequence Analyzer Overlaps**  
  The Class analyzer does `ast.parse` to find classes, attributes, etc. The Sequence analyzer also does `ast.parse` in a separate pass. Potentially you could unify the scanning, store the AST or partial results, then feed it into multiple diagram types. This is more advanced, so not strictly necessary, but it could yield performance improvements or less repeated logic.

- **Deep or Cross-Module Analysis**  
  Right now, it’s mostly per-file or simple `os.walk()`. If you plan to do large-scale cross-module analysis, consider caching or more robust “symbol table” logic. That might be future scope though.

### 4.4 Index Generation

- Each generator has an `generate_index()` method, but they’re nearly identical with only minor differences.  
- Consider **one** “base index generator” that can handle a “type label” (like “Class Diagrams” vs “Sequence Diagrams”). Then each child class can pass the type-specific checks or indicators. This might reduce the repeated `skinparam`, `'class '` vs `'participant'` detection logic, etc.

### 4.5 Setup & Scripts

- **`scripts/cleanup_old_code.py`**  
  - As it stands, it’s interactive and does exactly what you say. That’s cool, but for large teams, you might want a more automated approach (like a `--force` or `--dry-run` mode).  
- **`scripts/install_dev.py` & `scripts/setup_venv.py`**  
  - There’s overlap between these scripts. One uses `uv` (the “micro Venom” manager?), while the other uses pure python venv. If your team is comfortable with `uv`, no problem; otherwise consider standardizing on `python -m venv`.

---

## 5. Summary of Action Items

1. **Decide on a Single CLI**  
   - Possibly keep `uml_cli.py` and remove the older single-purpose scripts (or demote them to legacy).

2. **Refactor Repeated Patterns**  
   - Merge repeated code in each “diagram type” or each “CLI script.”  
   - Possibly unify `generate_index()` methods, or store them in `BaseDiagramGenerator`.

3. **Stabilize Imports**  
   - Consider turning this into a normal Python package with a root `setup.py` or `pyproject.toml`.  
   - Then you can remove `sys.path.insert()` calls.

4. **Clarify `kwargs`**  
   - If you rely on `**kwargs`, add docstrings or typed arguments for clarity.  
   - Where possible, replace with explicit function parameters.

5. **Add Automated Tests**  
   - A dedicated `tests/` folder with sample Python code to feed each analyzer would help ensure your diagram generation remains correct.

6. **Check Python Versions**  
   - If you support <3.9, you’ll need alternatives for `ast.unparse()`.  
   - Otherwise, specify “Python 3.9+ required” in your README or docs.

7. **Cleanup**  
   - The architecture is quite good overall but can be made more maintainable with some DRY principles and standard Python packaging.

---

### Final Thoughts

Your UML generator is already pretty thorough, handling a variety of diagram types. The biggest improvements would come from **removing duplication** across the diagram-type workflows, **consolidating CLIs**, and **tightening up** the packaging/installation story (so that everything imports consistently without manually updating `sys.path`).

Otherwise, the code is in a strong place, with a flexible foundation to expand upon—especially if you plan to flesh out the activity and state diagram logic further in the future.

---

I hope this helps you see where the code is shining and where you can simplify or consolidate further. If you have any specific follow-up questions—like about merging the analyzers, testing strategies, or advanced AST usage—just let me know. Good luck and happy coding!

================
File: uml/run.py
================
#!/usr/bin/env python
"""Main entry point for UML diagram generation.

This module provides the main entry point for generating UML diagrams using the
unified architecture.
"""

import argparse
import logging
import os
import sys
from pathlib import Path
from typing import Any

from utils.uml.core.exceptions import DiagramTypeError
from utils.uml.core.filesystem import DefaultFileSystem
from utils.uml.core.service import UmlService
from utils.uml.factories import DefaultDiagramFactory
from utils.uml.utils.paths import get_output_base_dir

# Configure logging
logging.basicConfig(level=logging.INFO, format="%(levelname)s: %(message)s")
logger = logging.getLogger(__name__)

# Constants
OUTPUT_BASE_DIR = get_output_base_dir()


def parse_arguments() -> argparse.Namespace:
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(
        description="Generate UML diagrams from source code.",
    )

    parser.add_argument(
        "--type",
        "-t",
        choices=["class", "sequence", "activity", "state", "all"],
        default="all",
        help="Type of diagram to generate (default: all)",
    )

    parser.add_argument(
        "--source",
        "-s",
        required=True,
        help="Source directory or file to analyze",
    )

    parser.add_argument(
        "--output",
        "-o",
        default=str(OUTPUT_BASE_DIR),
        help=f"Output directory for diagrams (default: {OUTPUT_BASE_DIR})",
    )

    parser.add_argument(
        "--recursive",
        "-r",
        action="store_true",
        help="Recursively analyze directories",
    )

    parser.add_argument(
        "--exclude",
        "-e",
        action="append",
        default=[],
        help="Patterns to exclude (can be specified multiple times)",
    )

    parser.add_argument(
        "--include-private",
        "-p",
        action="store_true",
        help="Include private members in diagrams",
    )

    parser.add_argument(
        "--verbose",
        "-v",
        action="store_true",
        help="Enable verbose logging",
    )

    return parser.parse_args()


def create_service(settings: dict[str, Any] | None = None) -> UmlService:
    """Create and return a UML service with the given settings."""
    file_system = DefaultFileSystem()
    factory = DefaultDiagramFactory(file_system, settings)
    return UmlService(factory, settings)


def get_source_paths(
    source_path: str,
    recursive: bool = False,
    exclude_patterns: list[str] | None = None,
) -> list[Path]:
    """Get source paths to analyze.

    Args:
        source_path: The source path to analyze
        recursive: Whether to recursively analyze directories
        exclude_patterns: Patterns to exclude

    Returns:
        A list of paths to analyze
    """
    exclude_patterns = exclude_patterns or []
    source_path_obj = Path(source_path)
    paths = []

    # Helper function to check if a path should be excluded
    def should_exclude(path: Path) -> bool:
        return any(pat in str(path) for pat in exclude_patterns)

    # Case 1: Single file
    if source_path_obj.is_file():
        paths.append(source_path_obj)
        return paths

    # Case 2: Directory with recursive search
    if source_path_obj.is_dir() and recursive:
        for root, dirs, files in os.walk(source_path_obj):
            # Filter directories in-place to skip excluded ones
            dirs[:] = [d for d in dirs if not should_exclude(Path(root) / d)]

            # Add Python files that aren't excluded
            for file in files:
                if file.endswith(".py"):
                    file_path = Path(os.path.join(root, file))
                    if not should_exclude(file_path):
                        paths.append(file_path)
        return paths

    # Case 3: Directory without recursion (top-level only)
    if source_path_obj.is_dir():
        for file in source_path_obj.glob("*.py"):
            if not should_exclude(file):
                paths.append(file)

    return paths


def generate_specific_diagram(
    service: UmlService,
    diagram_type: str,
    source_paths: list[Path],
    output_dir: Path,
) -> list[Path] | None:
    """Generate a specific type of diagram.

    Args:
        service: The UML service to use
        diagram_type: The type of diagram to generate
        source_paths: The source paths to analyze
        output_dir: The output directory

    Returns:
        A list of generated diagram paths, or None if an error occurred
    """
    try:
        type_output_dir = output_dir / diagram_type
        type_output_dir.mkdir(parents=True, exist_ok=True)

        # Convert Path objects to strings to match the expected type
        source_paths_str: list[str | Path] = [str(p) for p in source_paths]
        diagrams = service.generate_diagrams(
            diagram_type,
            source_paths_str,
            type_output_dir,
        )

        if diagrams:
            logger.info(
                f"Generated {len(diagrams)} {diagram_type} diagrams in {type_output_dir}",
            )
        return diagrams
    except DiagramTypeError as e:
        logger.error(f"Error generating {diagram_type} diagrams: {e}")
        return None


def main() -> int:
    """Run the UML generator."""
    try:
        args = parse_arguments()

        # Configure logging
        if args.verbose:
            logging.getLogger().setLevel(logging.DEBUG)

        # Create output directory
        output_dir = Path(args.output)
        output_dir.mkdir(parents=True, exist_ok=True)

        # Create service
        settings = {
            "include_private": args.include_private,
            "recursive": args.recursive,
            "exclude_patterns": args.exclude,
        }
        service = create_service(settings)

        # Get source paths
        source_paths = get_source_paths(
            args.source,
            args.recursive,
            args.exclude,
        )

        if not source_paths:
            logger.error(f"No source files found at {args.source}")
            return 1

        # Generate diagrams
        if args.type == "all":
            # Generate all diagram types
            # Convert Path objects to strings to match the expected type
            source_paths_str: list[str | Path] = [str(p) for p in source_paths]
            source_paths_dict = {
                "class": source_paths_str,
                "sequence": source_paths_str,
                "activity": source_paths_str,
                "state": source_paths_str,
            }
            results = service.generate_all_diagrams(source_paths_dict, output_dir)

            # Log results
            for diagram_type, diagrams in results.items():
                if diagrams:
                    logger.info(
                        f"Generated {len(diagrams)} {diagram_type} diagrams in {output_dir / diagram_type}",
                    )
        else:
            # Generate a specific diagram type
            diagrams = generate_specific_diagram(
                service, args.type, source_paths, output_dir
            )
            if diagrams is None:
                return 1

        logger.info(f"UML diagrams generated successfully in {output_dir}")
        return 0
    except Exception as e:
        logger.error(f"Error generating diagrams: {e}")
        if args.verbose:
            import traceback

            traceback.print_exc()
        return 1


if __name__ == "__main__":
    sys.exit(main())

================
File: uml/scripts/cleanup_old_code.py
================
#!/usr/bin/env python
"""
Script to clean up old UML generator code by moving it to the z_archive directory.

This script:
1. Creates a backup of the old code in the z_archive directory
2. Removes the old directories after backup
3. Updates any references to the old code in documentation
"""

import os
import shutil
from datetime import datetime
from pathlib import Path

# Get the project root directory
PROJECT_ROOT = Path(__file__).parent.parent
UTILS_DIR = PROJECT_ROOT / "utils"
ARCHIVE_DIR = PROJECT_ROOT / "z_archive"

# Directories to archive
OLD_DIRS = [
    UTILS_DIR / "uml_generator",
    UTILS_DIR / "sequence_extractor",
]

# Create timestamp for archive folder
TIMESTAMP = datetime.now().strftime("%Y%m%d_%H%M%S")
ARCHIVE_UML_DIR = ARCHIVE_DIR / f"uml_old_{TIMESTAMP}"


def create_archive_directory():
    """Create the archive directory if it doesn't exist."""
    print(f"Creating archive directory: {ARCHIVE_UML_DIR}")
    os.makedirs(ARCHIVE_UML_DIR, exist_ok=True)


def backup_old_code():
    """Backup old code to the archive directory."""
    for old_dir in OLD_DIRS:
        if old_dir.exists():
            # Get the directory name
            dir_name = old_dir.name

            # Create the destination directory
            dest_dir = ARCHIVE_UML_DIR / dir_name

            print(f"Backing up {old_dir} to {dest_dir}")

            # Copy the directory to the archive
            shutil.copytree(old_dir, dest_dir)

            print(f"Backup of {dir_name} completed")
        else:
            print(f"Directory {old_dir} does not exist, skipping")


def remove_old_directories():
    """Remove old directories after backup."""
    for old_dir in OLD_DIRS:
        if old_dir.exists():
            print(f"Removing directory: {old_dir}")

            # Ask for confirmation before removing
            confirm = input(f"Are you sure you want to remove {old_dir}? (y/n): ")
            if confirm.lower() == "y":
                shutil.rmtree(old_dir)
                print(f"Removed {old_dir}")
            else:
                print(f"Skipping removal of {old_dir}")
        else:
            print(f"Directory {old_dir} does not exist, skipping")


def main():
    """Run the cleanup process."""
    print("Starting cleanup of old UML generator code")

    # Create archive directory
    create_archive_directory()

    # Backup old code
    backup_old_code()

    # Ask if user wants to remove old directories
    remove = input("Do you want to remove the old directories? (y/n): ")
    if remove.lower() == "y":
        remove_old_directories()
    else:
        print("Skipping removal of old directories")

    print("\nCleanup completed!")
    print(f"Old code has been backed up to: {ARCHIVE_UML_DIR}")
    print("\nNext steps:")
    print("1. Update any documentation or scripts that reference the old code")
    print("2. Enhance the activity and state diagram implementations")
    print("3. Create comprehensive test cases")
    print("4. Update documentation to reflect the new architecture")


if __name__ == "__main__":
    main()

================
File: uml/scripts/install_dev.py
================
#!/usr/bin/env python
"""
Script to set up the utils virtual environment and install the utils package in development mode.
"""

import subprocess
import sys
from pathlib import Path


def main():
    """Set up the utils virtual environment and install the utils package in development mode."""
    # Get the utils directory
    utils_dir = Path(__file__).parent.absolute()
    venv_dir = utils_dir / ".venv"

    # Print information
    print(f"Setting up utils virtual environment in {venv_dir}...")

    # Check if uv is installed
    try:
        subprocess.run(
            ["uv", "--version"],
            check=True,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
        )
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("uv not found. Please install uv first:")
        print("  pip install uv")
        return 1

    # Create virtual environment if it doesn't exist
    if not venv_dir.exists():
        print("Creating virtual environment...")
        try:
            subprocess.run(
                ["uv", "venv", str(venv_dir)],
                check=True,
            )
            print(f"Virtual environment created at {venv_dir}")
        except subprocess.CalledProcessError as e:
            print(f"Error creating virtual environment: {e}")
            return 1

    # Determine the activate script path based on the platform
    if sys.platform == "win32":
        activate_script = venv_dir / "Scripts" / "activate.bat"
        activate_cmd = f"call {activate_script}"
    else:
        activate_script = venv_dir / "bin" / "activate"
        activate_cmd = f"source {activate_script}"

    # Install the package in development mode
    print("Installing utils package in development mode...")
    try:
        # On Windows, we need to use a batch file to activate the venv and run the command
        if sys.platform == "win32":
            temp_bat = utils_dir / "temp_install.bat"
            with open(temp_bat, "w") as f:
                f.write("@echo off\n")
                f.write(f"call {activate_script}\n")
                f.write(f"uv pip install -e {utils_dir}\n")

            subprocess.run([str(temp_bat)], check=True, shell=True)
            temp_bat.unlink()  # Remove the temporary batch file
        else:
            # On Unix-like systems, we can use a single shell command
            subprocess.run(
                f"{activate_cmd} && uv pip install -e {utils_dir}",
                check=True,
                shell=True,
            )

        print("Installation successful!")
    except subprocess.CalledProcessError as e:
        print(f"Error installing package: {e}")
        return 1

    # Install additional dependencies
    print("Installing additional dependencies...")
    try:
        if sys.platform == "win32":
            temp_bat = utils_dir / "temp_deps.bat"
            with open(temp_bat, "w") as f:
                f.write("@echo off\n")
                f.write(f"call {activate_script}\n")
                f.write("uv pip install pyyaml\n")

            subprocess.run([str(temp_bat)], check=True, shell=True)
            temp_bat.unlink()  # Remove the temporary batch file
        else:
            subprocess.run(
                f"{activate_cmd} && uv pip install pyyaml",
                check=True,
                shell=True,
            )

        print("Dependencies installed successfully!")
    except subprocess.CalledProcessError as e:
        print(f"Error installing dependencies: {e}")
        return 1

    # Print activation instructions
    print("\nTo activate the virtual environment:")
    if sys.platform == "win32":
        print(f"  {activate_cmd}")
    else:
        print(f"  {activate_cmd}")

    print(
        "\nAfter activating the virtual environment, you can run the UML generator scripts:"
    )
    print("  python utils/run_uml_generator.py")
    print("  python utils/extract_class.py --source backend/app")
    print("  python utils/extract_sequence.py --source backend/app")
    print("  python utils/extract_activity.py --source backend/app")
    print("  python utils/extract_state.py --source backend/app")
    print("  python utils/uml/run.py --type all --source backend/app")

    return 0


if __name__ == "__main__":
    sys.exit(main())

================
File: uml/scripts/setup_venv.py
================
#!/usr/bin/env python
"""
Setup script for creating a virtual environment for utils that installs in the backend.

This script:
1. Creates a virtual environment for utils
2. Installs UV package manager
3. Installs the backend as an editable package
4. Installs any utils-specific dependencies

Usage:
    python utils/setup_venv.py [--clean]

Options:
    --clean    Remove existing virtual environment before creating a new one
"""

import logging
import os
import shutil
import subprocess
import sys
from pathlib import Path

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(message)s",  # Simple format for user-friendly output
    handlers=[logging.StreamHandler()],
)
logger = logging.getLogger(__name__)

# Get the absolute paths
CURRENT_DIR = Path(__file__).parent.absolute()
PROJECT_ROOT = CURRENT_DIR.parent
BACKEND_DIR = PROJECT_ROOT / "backend"
VENV_DIR = CURRENT_DIR / ".venv"


def run_command(cmd, cwd=None):
    """Run a command and log its output."""
    logger.info(f"Running: {' '.join(cmd)}")
    result = subprocess.run(
        cmd,
        cwd=cwd,
        capture_output=True,
        text=True,
        check=False,
    )

    if result.stdout:
        logger.info(result.stdout)

    if result.stderr:
        logger.error(result.stderr)

    if result.returncode != 0:
        logger.error(f"Command failed with exit code {result.returncode}")
        sys.exit(result.returncode)

    return result


def main():
    """Set up the virtual environment."""
    # Check if --clean flag is provided
    clean = "--clean" in sys.argv

    # Remove existing virtual environment if --clean flag is provided
    if clean and VENV_DIR.exists():
        logger.info(f"Removing existing virtual environment at {VENV_DIR}")
        shutil.rmtree(VENV_DIR)

    # Create virtual environment if it doesn't exist
    if not VENV_DIR.exists():
        logger.info(f"Creating virtual environment in {VENV_DIR}")
        run_command([sys.executable, "-m", "venv", str(VENV_DIR)])
    else:
        logger.info(f"Virtual environment already exists at {VENV_DIR}")

    # Determine the Python executable in the virtual environment
    if os.name == "nt":  # Windows
        python_exe = VENV_DIR / "Scripts" / "python.exe"
        uv_path = VENV_DIR / "Scripts" / "uv.exe"
    else:  # Unix/Linux/Mac
        python_exe = VENV_DIR / "bin" / "python"
        uv_path = VENV_DIR / "bin" / "uv"

    # Install UV package manager if not already installed
    if not uv_path.exists():
        logger.info("Installing UV package manager")
        run_command(
            [
                str(python_exe),
                "-m",
                "pip",
                "install",
                "uv",
            ],
        )

    # Install the backend as an editable package using UV
    logger.info(f"Installing backend as editable package from {BACKEND_DIR}")
    run_command(
        [
            str(uv_path),
            "pip",
            "install",
            "--python",
            str(python_exe),
            "-e",
            str(BACKEND_DIR),
        ],
    )

    # Install utils-specific dependencies if any
    utils_pyproject = CURRENT_DIR / "pyproject.toml"
    if utils_pyproject.exists():
        logger.info("Installing utils dependencies")
        run_command(
            [
                str(uv_path),
                "pip",
                "install",
                "--python",
                str(python_exe),
                "-e",
                str(CURRENT_DIR),
            ],
        )

    logger.info("\nSetup complete!")
    logger.info("\nTo activate the virtual environment:")
    if os.name == "nt":  # Windows
        logger.info(f"    Windows CMD: {VENV_DIR}\\Scripts\\activate")
        logger.info(f"    Windows Git Bash: source {VENV_DIR}/Scripts/activate")
    else:  # Unix/Linux/Mac
        logger.info(f"    source {VENV_DIR}/bin/activate")

    logger.info("\nTo run utils scripts with the virtual environment:")
    logger.info(f"    {python_exe} -m utils.extract_sequence --help")


if __name__ == "__main__":
    main()

================
File: uml/utils/__init__.py
================
"""Utility functions for UML diagram generation.

This module provides utility functions used across the UML generation package.
"""

================
File: uml/utils/paths.py
================
"""
Path utilities for the UML generator.

This module provides utility functions for working with paths in the UML generator.
"""

import os
from pathlib import Path


def get_project_root() -> Path:
    """Get the project root directory.

    This function uses a more reliable approach to find the project root
    by looking for specific markers like docs/source/_generated_uml.

    Returns:
        Path to the project root directory
    """
    # Start with the current file's directory
    current_dir = Path(__file__).parent.absolute()

    # Look for the project root by checking for the docs/source/_generated_uml directory
    # Start from the current directory and go up to 5 levels
    for _ in range(5):
        # Check if this could be the project root
        if (current_dir / "docs" / "source" / "_generated_uml").exists():
            return current_dir

        # Move up one directory
        parent = current_dir.parent
        if parent == current_dir:  # We've reached the filesystem root
            break
        current_dir = parent

    # If we couldn't find the project root, use the current working directory
    # This is a fallback and might not be correct in all cases
    return Path(os.getcwd())


def get_output_base_dir() -> Path:
    """Get the base output directory for UML diagrams.

    Returns:
        Path to the base output directory
    """
    return get_project_root() / "docs" / "source" / "_generated_uml"


def get_output_dir(diagram_type: str | None = None) -> Path:
    """Get the output directory for a specific diagram type.

    Args:
        diagram_type: Type of diagram (class, sequence, activity, state)

    Returns:
        Path to the output directory
    """
    base_dir = get_output_base_dir()

    if diagram_type:
        return base_dir / diagram_type

    return base_dir



================================================================
End of Codebase
================================================================
